// Autogenerated using stratification.
requires "x86-configuration.k"

module ADDPS-XMM-XMM
  imports X86-CONFIGURATION

  rule <k>
    execinstr (addps R1:Xmm, R2:Xmm,  .Typedoperands) => .
  ...</k>
    <regstate>
RSMap:Map => updateMap(RSMap,
convToRegKeys(R2) |-> (concatenateMInt(extractMInt(getParentValue(R2, RSMap), 0, 128), concatenateMInt(concatenateMInt(Float2MInt( ( MInt2Float(extractMInt(getParentValue(R1, RSMap), 128, 160), 24, 8)  +Float  MInt2Float(extractMInt(getParentValue(R2, RSMap), 128, 160), 24, 8) ) , 32), Float2MInt( ( MInt2Float(extractMInt(getParentValue(R1, RSMap), 160, 192), 24, 8)  +Float  MInt2Float(extractMInt(getParentValue(R2, RSMap), 160, 192), 24, 8) ) , 32)), concatenateMInt(Float2MInt( ( MInt2Float(extractMInt(getParentValue(R1, RSMap), 192, 224), 24, 8)  +Float  MInt2Float(extractMInt(getParentValue(R2, RSMap), 192, 224), 24, 8) ) , 32), Float2MInt( ( MInt2Float(extractMInt(getParentValue(R1, RSMap), 224, 256), 24, 8)  +Float  MInt2Float(extractMInt(getParentValue(R2, RSMap), 224, 256), 24, 8) ) , 32)))) )


)

    </regstate>
endmodule

module ADDPS-XMM-XMM-SEMANTICS
  imports ADDPS-XMM-XMM
endmodule
/*
TargetInstr:
addps %xmm2, %xmm1
RWSet:
maybe read:{ %xmm1 %xmm2 }
must read:{ %xmm1 %xmm2 }
maybe write:{ %xmm1 }
must write:{ %xmm1 }
maybe undef:{ }
must undef:{ }
required flags:{ sse }

Circuit:
circuit:vaddps %xmm2, %xmm1, %xmm2                    #  1     0    4      OPC=vaddps_xmm_xmm_xmm
circuit:callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7  #  2     0x4  5      OPC=callq_label
circuit:callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1  #  3     0x9  5      OPC=callq_label
BVF:
WARNING: No live out values provided, assuming { }
WARNING: No def in values provided; assuming { %mxcsr::rc[0] }
Target

addps %xmm2, %xmm1

  maybe read:      { %xmm1 %xmm2 }
  must read:       { %xmm1 %xmm2 }
  maybe write:     { %xmm1 }
  must write:      { %xmm1 }
  maybe undef:     { }
  must undef:      { }
  required flags:  { sse }

-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm10

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm10: %ymm10_vaddps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm10: 0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: %ymm0_vmovups_xmm_xmm[127:0]
%xmm1: %ymm1_vmovups_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovups %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm11: %ymm11_vaddps_xmm_xmm_xmm

State for specgen instruction: vmovups %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vaddps %ymm10, %ymm11, %ymm3

Final state:
%ymm3: add_single((0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0])[255:224]) ∘ (add_single((0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0])[223:192]) ∘ (add_single((0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0])[191:160]) ∘ (add_single((0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0])[159:128]) ∘ (add_single((0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0])[127:96]) ∘ (add_single((0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0])[95:64]) ∘ (add_single((0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0])[63:32]) ∘ add_single((0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vaddps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (add_single(%ymm2_vaddps_xmm_xmm_xmm[127:96], %ymm3_vaddps_xmm_xmm_xmm[127:96]) ∘ (add_single(%ymm2_vaddps_xmm_xmm_xmm[95:64], %ymm3_vaddps_xmm_xmm_xmm[95:64]) ∘ (add_single(%ymm2_vaddps_xmm_xmm_xmm[63:32], %ymm3_vaddps_xmm_xmm_xmm[63:32]) ∘ add_single(%ymm2_vaddps_xmm_xmm_xmm[31:0], %ymm3_vaddps_xmm_xmm_xmm[31:0]))))

=====================================
=====================================
Computing circuit for vaddps %xmm2, %xmm1, %xmm2

.target:
vmovdqu %xmm3, %xmm10
vmovups %xmm2, %xmm11
vaddps %ymm10, %ymm11, %ymm3
vmovdqa %xmm3, %xmm1
retq 

Initial state:
%ymm2: %ymm2_addps_xmm_xmm

State for specgen instruction: vaddps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (add_single(%ymm2_vaddps_xmm_xmm_xmm[127:96], %ymm3_vaddps_xmm_xmm_xmm[127:96]) ∘ (add_single(%ymm2_vaddps_xmm_xmm_xmm[95:64], %ymm3_vaddps_xmm_xmm_xmm[95:64]) ∘ (add_single(%ymm2_vaddps_xmm_xmm_xmm[63:32], %ymm3_vaddps_xmm_xmm_xmm[63:32]) ∘ add_single(%ymm2_vaddps_xmm_xmm_xmm[31:0], %ymm3_vaddps_xmm_xmm_xmm[31:0]))))

Final state
%ymm2: 0x0₁₂₈ ∘ (add_single(%ymm1_addps_xmm_xmm[127:96], %ymm2_addps_xmm_xmm[127:96]) ∘ (add_single(%ymm1_addps_xmm_xmm[95:64], %ymm2_addps_xmm_xmm[95:64]) ∘ (add_single(%ymm1_addps_xmm_xmm[63:32], %ymm2_addps_xmm_xmm[63:32]) ∘ add_single(%ymm1_addps_xmm_xmm[31:0], %ymm2_addps_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_addps_xmm_xmm
%rdx/%rdx: %rdx_addps_xmm_xmm

%xmm0: %ymm0_addps_xmm_xmm[127:0]
%xmm1: %ymm1_addps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1

Final state:
%rax/%rax: %rax_addps_xmm_xmm
%rdx/%rdx: %rdx_addps_xmm_xmm

%xmm0: %ymm0_addps_xmm_xmm[127:0]
%xmm1: (%ymm1_addps_xmm_xmm[255:128] ∘ ((%ymm7_addps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (0x0₁₂₈ ∘ (add_single(%ymm1_addps_xmm_xmm[127:96], %ymm2_addps_xmm_xmm[127:96]) ∘ (add_single(%ymm1_addps_xmm_xmm[95:64], %ymm2_addps_xmm_xmm[95:64]) ∘ (add_single(%ymm1_addps_xmm_xmm[63:32], %ymm2_addps_xmm_xmm[63:32]) ∘ add_single(%ymm1_addps_xmm_xmm[31:0], %ymm2_addps_xmm_xmm[31:0])))))[127:0][127:96]))[127:0][31:0] ∘ (%ymm6_addps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (0x0₁₂₈ ∘ (add_single(%ymm1_addps_xmm_xmm[127:96], %ymm2_addps_xmm_xmm[127:96]) ∘ (add_single(%ymm1_addps_xmm_xmm[95:64], %ymm2_addps_xmm_xmm[95:64]) ∘ (add_single(%ymm1_addps_xmm_xmm[63:32], %ymm2_addps_xmm_xmm[63:32]) ∘ add_single(%ymm1_addps_xmm_xmm[31:0], %ymm2_addps_xmm_xmm[31:0])))))[127:0][95:64]))[127:0][31:0] ∘ (%ymm5_addps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (0x0₁₂₈ ∘ (add_single(%ymm1_addps_xmm_xmm[127:96], %ymm2_addps_xmm_xmm[127:96]) ∘ (add_single(%ymm1_addps_xmm_xmm[95:64], %ymm2_addps_xmm_xmm[95:64]) ∘ (add_single(%ymm1_addps_xmm_xmm[63:32], %ymm2_addps_xmm_xmm[63:32]) ∘ add_single(%ymm1_addps_xmm_xmm[31:0], %ymm2_addps_xmm_xmm[31:0])))))[127:0][63:32]))[127:0][31:0] ∘ (%ymm4_addps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (0x0₁₂₈ ∘ (add_single(%ymm1_addps_xmm_xmm[127:96], %ymm2_addps_xmm_xmm[127:96]) ∘ (add_single(%ymm1_addps_xmm_xmm[95:64], %ymm2_addps_xmm_xmm[95:64]) ∘ (add_single(%ymm1_addps_xmm_xmm[63:32], %ymm2_addps_xmm_xmm[63:32]) ∘ add_single(%ymm1_addps_xmm_xmm[31:0], %ymm2_addps_xmm_xmm[31:0])))))[127:0][31:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for addps %xmm2, %xmm1

.target:
vaddps %xmm2, %xmm1, %xmm2
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1
retq 

Initial state:
%xmm1: %ymm1[127:0]

State for specgen instruction: addps %xmm2, %xmm1:
%xmm1: (%ymm1_addps_xmm_xmm[255:128] ∘ ((%ymm7_addps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (0x0₁₂₈ ∘ (add_single(%ymm1_addps_xmm_xmm[127:96], %ymm2_addps_xmm_xmm[127:96]) ∘ (add_single(%ymm1_addps_xmm_xmm[95:64], %ymm2_addps_xmm_xmm[95:64]) ∘ (add_single(%ymm1_addps_xmm_xmm[63:32], %ymm2_addps_xmm_xmm[63:32]) ∘ add_single(%ymm1_addps_xmm_xmm[31:0], %ymm2_addps_xmm_xmm[31:0])))))[127:0][127:96]))[127:0][31:0] ∘ (%ymm6_addps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (0x0₁₂₈ ∘ (add_single(%ymm1_addps_xmm_xmm[127:96], %ymm2_addps_xmm_xmm[127:96]) ∘ (add_single(%ymm1_addps_xmm_xmm[95:64], %ymm2_addps_xmm_xmm[95:64]) ∘ (add_single(%ymm1_addps_xmm_xmm[63:32], %ymm2_addps_xmm_xmm[63:32]) ∘ add_single(%ymm1_addps_xmm_xmm[31:0], %ymm2_addps_xmm_xmm[31:0])))))[127:0][95:64]))[127:0][31:0] ∘ (%ymm5_addps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (0x0₁₂₈ ∘ (add_single(%ymm1_addps_xmm_xmm[127:96], %ymm2_addps_xmm_xmm[127:96]) ∘ (add_single(%ymm1_addps_xmm_xmm[95:64], %ymm2_addps_xmm_xmm[95:64]) ∘ (add_single(%ymm1_addps_xmm_xmm[63:32], %ymm2_addps_xmm_xmm[63:32]) ∘ add_single(%ymm1_addps_xmm_xmm[31:0], %ymm2_addps_xmm_xmm[31:0])))))[127:0][63:32]))[127:0][31:0] ∘ (%ymm4_addps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (0x0₁₂₈ ∘ (add_single(%ymm1_addps_xmm_xmm[127:96], %ymm2_addps_xmm_xmm[127:96]) ∘ (add_single(%ymm1_addps_xmm_xmm[95:64], %ymm2_addps_xmm_xmm[95:64]) ∘ (add_single(%ymm1_addps_xmm_xmm[63:32], %ymm2_addps_xmm_xmm[63:32]) ∘ add_single(%ymm1_addps_xmm_xmm[31:0], %ymm2_addps_xmm_xmm[31:0])))))[127:0][31:0]))[127:0][31:0]))[127:0]

Final state
%xmm1: (%ymm1[255:128] ∘ (add_single(%ymm1[127:96], %ymm2[127:96]) ∘ add_single(%ymm1[95:64], %ymm2[95:64]) ∘ add_single(%ymm1[63:32], %ymm2[63:32]) ∘ add_single(%ymm1[31:0], %ymm2[31:0])))[127:0]

=====================================
Circuits:

%ymm1  : %ymm1[255:128] ∘ (add_single(%ymm1[127:96], %ymm2[127:96]) ∘ add_single(%ymm1[95:64], %ymm2[95:64]) ∘ add_single(%ymm1[63:32], %ymm2[63:32]) ∘ add_single(%ymm1[31:0], %ymm2[31:0]))

sigfpe  : sigfpe
sigbus  : sigbus
sigsegv : sigsegv

*/