// Autogenerated using stratification.
requires "x86-configuration.k"

module VFMADDSUB132PS-XMM-XMM-XMM
  imports X86-CONFIGURATION

  rule <k>
    execinstr (vfmaddsub132ps R1:Xmm, R2:Xmm, R3:Xmm,  .Typedoperands) => .
  ...</k>
    <regstate>
RSMap:Map => updateMap(RSMap,
convToRegKeys(R3) |-> (concatenateMInt(mi(128, 0), concatenateMInt(orMInt(orMInt(xorMInt(orMInt(xorMInt(concatenateMInt(Float2MInt( ( MInt2Float(extractMInt(getParentValue(R2, RSMap), 128, 160), 24, 8)  +Float  ( 0e+00f  -Float  negateFloat(0e+00f) )  ) , 32), Float2MInt( (  ( 0e+00f  -Float  negateFloat(0e+00f) )  -Float  MInt2Float(extractMInt(getParentValue(R2, RSMap), 160, 192), 24, 8) ) , 32)), mi(64, 0)), mi(64, 0)), xorMInt(concatenateMInt(Float2MInt( ( MInt2Float(extractMInt(getParentValue(R2, RSMap), 128, 160), 24, 8)  +Float  ( 0e+00f  -Float  negateFloat(0e+00f) )  ) , 32), Float2MInt( (  ( 0e+00f  -Float  negateFloat(0e+00f) )  -Float  MInt2Float(extractMInt(getParentValue(R2, RSMap), 160, 192), 24, 8) ) , 32)), mi(64, 0))), concatenateMInt(Float2MInt( (  (  ( MInt2Float(extractMInt(getParentValue(R2, RSMap), 128, 160), 24, 8)  +Float  ( 0e+00f  -Float  negateFloat(0e+00f) )  )  -Float  negateFloat( ( MInt2Float(xorMInt(orMInt(xorMInt(Float2MInt( ( MInt2Float(extractMInt(getParentValue(R2, RSMap), 128, 160), 24, 8)  +Float  ( 0e+00f  -Float  negateFloat(0e+00f) )  ) , 32), mi(32, 0)), mi(32, 0)), xorMInt(Float2MInt( ( MInt2Float(extractMInt(getParentValue(R2, RSMap), 128, 160), 24, 8)  +Float  ( 0e+00f  -Float  negateFloat(0e+00f) )  ) , 32), mi(32, 0))), 24, 8)  *Float  ( MInt2Float(extractMInt(getParentValue(R2, RSMap), 128, 160), 24, 8)  +Float  ( 0e+00f  -Float  negateFloat(0e+00f) )  )  ) ) )  -Float  ( MInt2Float(extractMInt(getParentValue(R3, RSMap), 128, 160), 24, 8)  *Float  MInt2Float(extractMInt(getParentValue(R1, RSMap), 128, 160), 24, 8) )  ) , 32), Float2MInt( (  (  (  ( 0e+00f  -Float  negateFloat(0e+00f) )  -Float  MInt2Float(extractMInt(getParentValue(R2, RSMap), 160, 192), 24, 8) )  -Float  negateFloat( ( MInt2Float(xorMInt(orMInt(xorMInt(Float2MInt( (  ( 0e+00f  -Float  negateFloat(0e+00f) )  -Float  MInt2Float(extractMInt(getParentValue(R2, RSMap), 160, 192), 24, 8) ) , 32), mi(32, 0)), mi(32, 0)), xorMInt(Float2MInt( (  ( 0e+00f  -Float  negateFloat(0e+00f) )  -Float  MInt2Float(extractMInt(getParentValue(R2, RSMap), 160, 192), 24, 8) ) , 32), mi(32, 0))), 24, 8)  *Float  (  ( 0e+00f  -Float  negateFloat(0e+00f) )  -Float  MInt2Float(extractMInt(getParentValue(R2, RSMap), 160, 192), 24, 8) )  ) ) )  -Float  ( MInt2Float(extractMInt(getParentValue(R3, RSMap), 160, 192), 24, 8)  *Float  MInt2Float(extractMInt(getParentValue(R1, RSMap), 160, 192), 24, 8) )  ) , 32))), mi(64, 0)), orMInt(orMInt(xorMInt(orMInt(xorMInt(concatenateMInt(Float2MInt( ( MInt2Float(extractMInt(getParentValue(R2, RSMap), 192, 224), 24, 8)  +Float  ( 0e+00f  -Float  negateFloat(0e+00f) )  ) , 32), Float2MInt( (  ( 0e+00f  -Float  negateFloat(0e+00f) )  -Float  MInt2Float(extractMInt(getParentValue(R2, RSMap), 224, 256), 24, 8) ) , 32)), mi(64, 0)), mi(64, 0)), xorMInt(concatenateMInt(Float2MInt( ( MInt2Float(extractMInt(getParentValue(R2, RSMap), 192, 224), 24, 8)  +Float  ( 0e+00f  -Float  negateFloat(0e+00f) )  ) , 32), Float2MInt( (  ( 0e+00f  -Float  negateFloat(0e+00f) )  -Float  MInt2Float(extractMInt(getParentValue(R2, RSMap), 224, 256), 24, 8) ) , 32)), mi(64, 0))), concatenateMInt(Float2MInt( (  (  ( MInt2Float(extractMInt(getParentValue(R2, RSMap), 192, 224), 24, 8)  +Float  ( 0e+00f  -Float  negateFloat(0e+00f) )  )  -Float  negateFloat( ( MInt2Float(xorMInt(orMInt(xorMInt(Float2MInt( ( MInt2Float(extractMInt(getParentValue(R2, RSMap), 192, 224), 24, 8)  +Float  ( 0e+00f  -Float  negateFloat(0e+00f) )  ) , 32), mi(32, 0)), mi(32, 0)), xorMInt(Float2MInt( ( MInt2Float(extractMInt(getParentValue(R2, RSMap), 192, 224), 24, 8)  +Float  ( 0e+00f  -Float  negateFloat(0e+00f) )  ) , 32), mi(32, 0))), 24, 8)  *Float  ( MInt2Float(extractMInt(getParentValue(R2, RSMap), 192, 224), 24, 8)  +Float  ( 0e+00f  -Float  negateFloat(0e+00f) )  )  ) ) )  -Float  ( MInt2Float(extractMInt(getParentValue(R3, RSMap), 192, 224), 24, 8)  *Float  MInt2Float(extractMInt(getParentValue(R1, RSMap), 192, 224), 24, 8) )  ) , 32), Float2MInt( (  (  (  ( 0e+00f  -Float  negateFloat(0e+00f) )  -Float  MInt2Float(extractMInt(getParentValue(R2, RSMap), 224, 256), 24, 8) )  -Float  negateFloat( ( MInt2Float(xorMInt(orMInt(xorMInt(Float2MInt( (  ( 0e+00f  -Float  negateFloat(0e+00f) )  -Float  MInt2Float(extractMInt(getParentValue(R2, RSMap), 224, 256), 24, 8) ) , 32), mi(32, 0)), mi(32, 0)), xorMInt(Float2MInt( (  ( 0e+00f  -Float  negateFloat(0e+00f) )  -Float  MInt2Float(extractMInt(getParentValue(R2, RSMap), 224, 256), 24, 8) ) , 32), mi(32, 0))), 24, 8)  *Float  (  ( 0e+00f  -Float  negateFloat(0e+00f) )  -Float  MInt2Float(extractMInt(getParentValue(R2, RSMap), 224, 256), 24, 8) )  ) ) )  -Float  ( MInt2Float(extractMInt(getParentValue(R3, RSMap), 224, 256), 24, 8)  *Float  MInt2Float(extractMInt(getParentValue(R1, RSMap), 224, 256), 24, 8) )  ) , 32))), mi(64, 0)))) )


)

    </regstate>
endmodule

module VFMADDSUB132PS-XMM-XMM-XMM-SEMANTICS
  imports VFMADDSUB132PS-XMM-XMM-XMM
endmodule
/*
TargetInstr:
vfmaddsub132ps %xmm3, %xmm2, %xmm1
RWSet:
maybe read:{ %xmm1 %xmm2 %xmm3 }
must read:{ %xmm1 %xmm2 %xmm3 }
maybe write:{ %ymm1 }
must write:{ %ymm1 }
maybe undef:{ }
must undef:{ }
required flags:{ fma }

Circuit:
circuit:vpandn %xmm1, %xmm1, %xmm10          #  1     0     4      OPC=vpandn_xmm_xmm_xmm
circuit:vfnmsub231ps %ymm10, %ymm10, %ymm10  #  2     0x4   5      OPC=vfnmsub231ps_ymm_ymm_ymm
circuit:movdqa %xmm2, %xmm7                  #  3     0x9   4      OPC=movdqa_xmm_xmm
circuit:vaddsubps %xmm7, %xmm10, %xmm2       #  4     0xd   4      OPC=vaddsubps_xmm_xmm_xmm
circuit:vfmadd132ps %xmm3, %xmm2, %xmm1      #  5     0x11  5      OPC=vfmadd132ps_xmm_xmm_xmm
BVF:
WARNING: No live out values provided, assuming { }
WARNING: No def in values provided; assuming { %mxcsr::rc[0] }
Target

vfmaddsub132ps %xmm3, %xmm2, %xmm1

  maybe read:      { %xmm1 %xmm2 %xmm3 }
  must read:       { %xmm1 %xmm2 %xmm3 }
  maybe write:     { %ymm1 }
  must write:      { %ymm1 }
  maybe undef:     { }
  must undef:      { }
  required flags:  { fma }

-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm3, %xmm3, %xmm1

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vpandn_xmm_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vpandn_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm14

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm14: %ymm14_vpandn_xmm_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm14: (%ymm14_vpandn_xmm_xmm_xmm[255:128] ∘ %ymm2_vpandn_xmm_xmm_xmm[127:0])[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm2, %xmm3, %xmm10

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm10: %ymm10_vandnps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ ((%ymm2_vandnps_xmm_xmm_xmm[127:64] | %ymm3_vandnps_xmm_xmm_xmm[127:64]) ∘ (%ymm2_vandnps_xmm_xmm_xmm[63:0] | %ymm3_vandnps_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpxor_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpxor_xmm_xmm_xmm

%xmm0: %ymm0_vpxor_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpxor_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpxor_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r8_r9

Final state:
%rax/%rax: %rax_vpxor_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpxor_xmm_xmm_xmm

%xmm0: %ymm0_vpxor_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r8, %r12

Final state:
%r12/%r12: %ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0]

%cf: false
%pf: !((%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r9, %r13

Final state:
%r13/%r13: %ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64]

%cf: false
%pf: !((%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vpxor_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpxor_xmm_xmm_xmm

%xmm0: %ymm0_vpxor_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[255:128] ∘ ((%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[63:0] ∘ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpxor %xmm10, %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vmovdqa %xmm3, %xmm1
callq .move_128_064_xmm1_r8_r9
xorq %r8, %r12
xorq %r9, %r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vandnps_xmm_xmm_xmm

State for specgen instruction: vpxor %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[255:128] ∘ ((%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[63:0] ∘ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm2_vandnps_xmm_xmm_xmm[127:64] ⊕ (%ymm2_vandnps_xmm_xmm_xmm[127:64] | %ymm3_vandnps_xmm_xmm_xmm[127:64])) ∘ (%ymm2_vandnps_xmm_xmm_xmm[63:0] ⊕ (%ymm2_vandnps_xmm_xmm_xmm[63:0] | %ymm3_vandnps_xmm_xmm_xmm[63:0])))

=====================================
=====================================
Computing circuit for vandnps %xmm1, %xmm14, %xmm1

.target:
vorpd %xmm2, %xmm3, %xmm10
vpxor %xmm10, %xmm2, %xmm1
retq 

Initial state:
%ymm1: 0x0₁₂₈ ∘ %ymm3_vpandn_xmm_xmm_xmm[127:0]

State for specgen instruction: vandnps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm2_vandnps_xmm_xmm_xmm[127:64] ⊕ (%ymm2_vandnps_xmm_xmm_xmm[127:64] | %ymm3_vandnps_xmm_xmm_xmm[127:64])) ∘ (%ymm2_vandnps_xmm_xmm_xmm[63:0] ⊕ (%ymm2_vandnps_xmm_xmm_xmm[63:0] | %ymm3_vandnps_xmm_xmm_xmm[63:0])))

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm2_vpandn_xmm_xmm_xmm[127:64] ⊕ (%ymm2_vpandn_xmm_xmm_xmm[127:64] | %ymm3_vpandn_xmm_xmm_xmm[127:64])) ∘ (%ymm2_vpandn_xmm_xmm_xmm[63:0] ⊕ (%ymm2_vpandn_xmm_xmm_xmm[63:0] | %ymm3_vpandn_xmm_xmm_xmm[63:0])))

=====================================
=====================================
Computing circuit for vpandn %xmm1, %xmm1, %xmm10

.target:
vmaxss %xmm3, %xmm3, %xmm1
movdqu %xmm2, %xmm14
vandnps %xmm1, %xmm14, %xmm1
retq 

Initial state:
%ymm10: %ymm10_vfmaddsub132ps_xmm_xmm_xmm

State for specgen instruction: vpandn %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm2_vpandn_xmm_xmm_xmm[127:64] ⊕ (%ymm2_vpandn_xmm_xmm_xmm[127:64] | %ymm3_vpandn_xmm_xmm_xmm[127:64])) ∘ (%ymm2_vpandn_xmm_xmm_xmm[63:0] ⊕ (%ymm2_vpandn_xmm_xmm_xmm[63:0] | %ymm3_vpandn_xmm_xmm_xmm[63:0])))

Final state
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ 0x0₆₄)

=====================================
-------------------------------------
Getting base circuit for vfnmsub132ps %ymm3, %ymm1, %ymm2

Final state:
%ymm2: vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[255:224], %ymm1_vfnmsub231ps_ymm_ymm_ymm[255:224], %ymm3_vfnmsub231ps_ymm_ymm_ymm[255:224]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[223:192], %ymm1_vfnmsub231ps_ymm_ymm_ymm[223:192], %ymm3_vfnmsub231ps_ymm_ymm_ymm[223:192]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[191:160], %ymm1_vfnmsub231ps_ymm_ymm_ymm[191:160], %ymm3_vfnmsub231ps_ymm_ymm_ymm[191:160]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[159:128], %ymm1_vfnmsub231ps_ymm_ymm_ymm[159:128], %ymm3_vfnmsub231ps_ymm_ymm_ymm[159:128]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[127:96], %ymm1_vfnmsub231ps_ymm_ymm_ymm[127:96], %ymm3_vfnmsub231ps_ymm_ymm_ymm[127:96]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[95:64], %ymm1_vfnmsub231ps_ymm_ymm_ymm[95:64], %ymm3_vfnmsub231ps_ymm_ymm_ymm[95:64]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[63:32], %ymm1_vfnmsub231ps_ymm_ymm_ymm[63:32], %ymm3_vfnmsub231ps_ymm_ymm_ymm[63:32]) ∘ vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[31:0], %ymm1_vfnmsub231ps_ymm_ymm_ymm[31:0], %ymm3_vfnmsub231ps_ymm_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vfnmsub231ps_ymm_ymm_ymm
%rdx/%rdx: %rdx_vfnmsub231ps_ymm_ymm_ymm

%xmm0: %ymm0_vfnmsub231ps_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vfnmsub231ps_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vfnmsub231ps_ymm_ymm_ymm
%rdx/%rdx: %rdx_vfnmsub231ps_ymm_ymm_ymm

%xmm0: %ymm0_vfnmsub231ps_ymm_ymm_ymm[127:0]
%xmm1: ((%ymm13_vfnmsub231ps_ymm_ymm_ymm[255:128] ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[255:224], %ymm1_vfnmsub231ps_ymm_ymm_ymm[255:224], %ymm3_vfnmsub231ps_ymm_ymm_ymm[255:224]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[223:192], %ymm1_vfnmsub231ps_ymm_ymm_ymm[223:192], %ymm3_vfnmsub231ps_ymm_ymm_ymm[223:192]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[191:160], %ymm1_vfnmsub231ps_ymm_ymm_ymm[191:160], %ymm3_vfnmsub231ps_ymm_ymm_ymm[191:160]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[159:128], %ymm1_vfnmsub231ps_ymm_ymm_ymm[159:128], %ymm3_vfnmsub231ps_ymm_ymm_ymm[159:128]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[127:96], %ymm1_vfnmsub231ps_ymm_ymm_ymm[127:96], %ymm3_vfnmsub231ps_ymm_ymm_ymm[127:96]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[95:64], %ymm1_vfnmsub231ps_ymm_ymm_ymm[95:64], %ymm3_vfnmsub231ps_ymm_ymm_ymm[95:64]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[63:32], %ymm1_vfnmsub231ps_ymm_ymm_ymm[63:32], %ymm3_vfnmsub231ps_ymm_ymm_ymm[63:32]) ∘ vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[31:0], %ymm1_vfnmsub231ps_ymm_ymm_ymm[31:0], %ymm3_vfnmsub231ps_ymm_ymm_ymm[31:0]))))))))[255:128])[127:0][127:0] ∘ (%ymm12_vfnmsub231ps_ymm_ymm_ymm[255:128] ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[255:224], %ymm1_vfnmsub231ps_ymm_ymm_ymm[255:224], %ymm3_vfnmsub231ps_ymm_ymm_ymm[255:224]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[223:192], %ymm1_vfnmsub231ps_ymm_ymm_ymm[223:192], %ymm3_vfnmsub231ps_ymm_ymm_ymm[223:192]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[191:160], %ymm1_vfnmsub231ps_ymm_ymm_ymm[191:160], %ymm3_vfnmsub231ps_ymm_ymm_ymm[191:160]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[159:128], %ymm1_vfnmsub231ps_ymm_ymm_ymm[159:128], %ymm3_vfnmsub231ps_ymm_ymm_ymm[159:128]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[127:96], %ymm1_vfnmsub231ps_ymm_ymm_ymm[127:96], %ymm3_vfnmsub231ps_ymm_ymm_ymm[127:96]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[95:64], %ymm1_vfnmsub231ps_ymm_ymm_ymm[95:64], %ymm3_vfnmsub231ps_ymm_ymm_ymm[95:64]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[63:32], %ymm1_vfnmsub231ps_ymm_ymm_ymm[63:32], %ymm3_vfnmsub231ps_ymm_ymm_ymm[63:32]) ∘ vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[31:0], %ymm1_vfnmsub231ps_ymm_ymm_ymm[31:0], %ymm3_vfnmsub231ps_ymm_ymm_ymm[31:0]))))))))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vfnmsub231ps %ymm10, %ymm10, %ymm10

.target:
vfnmsub132ps %ymm3, %ymm1, %ymm2
callq .move_256_128_ymm2_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ 0x0₆₄)

State for specgen instruction: vfnmsub231ps %ymm3, %ymm2, %ymm1:
%ymm1: (%ymm13_vfnmsub231ps_ymm_ymm_ymm[255:128] ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[255:224], %ymm1_vfnmsub231ps_ymm_ymm_ymm[255:224], %ymm3_vfnmsub231ps_ymm_ymm_ymm[255:224]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[223:192], %ymm1_vfnmsub231ps_ymm_ymm_ymm[223:192], %ymm3_vfnmsub231ps_ymm_ymm_ymm[223:192]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[191:160], %ymm1_vfnmsub231ps_ymm_ymm_ymm[191:160], %ymm3_vfnmsub231ps_ymm_ymm_ymm[191:160]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[159:128], %ymm1_vfnmsub231ps_ymm_ymm_ymm[159:128], %ymm3_vfnmsub231ps_ymm_ymm_ymm[159:128]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[127:96], %ymm1_vfnmsub231ps_ymm_ymm_ymm[127:96], %ymm3_vfnmsub231ps_ymm_ymm_ymm[127:96]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[95:64], %ymm1_vfnmsub231ps_ymm_ymm_ymm[95:64], %ymm3_vfnmsub231ps_ymm_ymm_ymm[95:64]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[63:32], %ymm1_vfnmsub231ps_ymm_ymm_ymm[63:32], %ymm3_vfnmsub231ps_ymm_ymm_ymm[63:32]) ∘ vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[31:0], %ymm1_vfnmsub231ps_ymm_ymm_ymm[31:0], %ymm3_vfnmsub231ps_ymm_ymm_ymm[31:0]))))))))[255:128])[127:0][127:0] ∘ (%ymm12_vfnmsub231ps_ymm_ymm_ymm[255:128] ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[255:224], %ymm1_vfnmsub231ps_ymm_ymm_ymm[255:224], %ymm3_vfnmsub231ps_ymm_ymm_ymm[255:224]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[223:192], %ymm1_vfnmsub231ps_ymm_ymm_ymm[223:192], %ymm3_vfnmsub231ps_ymm_ymm_ymm[223:192]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[191:160], %ymm1_vfnmsub231ps_ymm_ymm_ymm[191:160], %ymm3_vfnmsub231ps_ymm_ymm_ymm[191:160]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[159:128], %ymm1_vfnmsub231ps_ymm_ymm_ymm[159:128], %ymm3_vfnmsub231ps_ymm_ymm_ymm[159:128]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[127:96], %ymm1_vfnmsub231ps_ymm_ymm_ymm[127:96], %ymm3_vfnmsub231ps_ymm_ymm_ymm[127:96]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[95:64], %ymm1_vfnmsub231ps_ymm_ymm_ymm[95:64], %ymm3_vfnmsub231ps_ymm_ymm_ymm[95:64]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[63:32], %ymm1_vfnmsub231ps_ymm_ymm_ymm[63:32], %ymm3_vfnmsub231ps_ymm_ymm_ymm[63:32]) ∘ vfnmsub132_single(%ymm2_vfnmsub231ps_ymm_ymm_ymm[31:0], %ymm1_vfnmsub231ps_ymm_ymm_ymm[31:0], %ymm3_vfnmsub231ps_ymm_ymm_ymm[31:0]))))))))[127:0])[127:0][127:0]

Final state
%ymm10: vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ (vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ (vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂))) ∘ (vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ (vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ (vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm2, %xmm7

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm7: %ymm7_vfmaddsub132ps_xmm_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm7: (%ymm7_vfmaddsub132ps_xmm_xmm_xmm[255:128] ∘ %ymm2_vfmaddsub132ps_xmm_xmm_xmm[127:0])[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm10

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm10: %ymm10_vaddps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm10: 0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: %ymm0_vmovups_xmm_xmm[127:0]
%xmm1: %ymm1_vmovups_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovups %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm11: %ymm11_vaddps_xmm_xmm_xmm

State for specgen instruction: vmovups %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vaddps %ymm10, %ymm11, %ymm3

Final state:
%ymm3: add_single((0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0])[255:224]) ∘ (add_single((0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0])[223:192]) ∘ (add_single((0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0])[191:160]) ∘ (add_single((0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0])[159:128]) ∘ (add_single((0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0])[127:96]) ∘ (add_single((0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0])[95:64]) ∘ (add_single((0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0])[63:32]) ∘ add_single((0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vaddps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (add_single(%ymm2_vaddps_xmm_xmm_xmm[127:96], %ymm3_vaddps_xmm_xmm_xmm[127:96]) ∘ (add_single(%ymm2_vaddps_xmm_xmm_xmm[95:64], %ymm3_vaddps_xmm_xmm_xmm[95:64]) ∘ (add_single(%ymm2_vaddps_xmm_xmm_xmm[63:32], %ymm3_vaddps_xmm_xmm_xmm[63:32]) ∘ add_single(%ymm2_vaddps_xmm_xmm_xmm[31:0], %ymm3_vaddps_xmm_xmm_xmm[31:0]))))

=====================================
=====================================
Computing circuit for vaddps %xmm2, %xmm1, %xmm3

.target:
vmovdqu %xmm3, %xmm10
vmovups %xmm2, %xmm11
vaddps %ymm10, %ymm11, %ymm3
vmovdqa %xmm3, %xmm1
retq 

Initial state:
%ymm3: %ymm3_addsubps_xmm_xmm

State for specgen instruction: vaddps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (add_single(%ymm2_vaddps_xmm_xmm_xmm[127:96], %ymm3_vaddps_xmm_xmm_xmm[127:96]) ∘ (add_single(%ymm2_vaddps_xmm_xmm_xmm[95:64], %ymm3_vaddps_xmm_xmm_xmm[95:64]) ∘ (add_single(%ymm2_vaddps_xmm_xmm_xmm[63:32], %ymm3_vaddps_xmm_xmm_xmm[63:32]) ∘ add_single(%ymm2_vaddps_xmm_xmm_xmm[31:0], %ymm3_vaddps_xmm_xmm_xmm[31:0]))))

Final state
%ymm3: 0x0₁₂₈ ∘ (add_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ (add_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]) ∘ (add_single(%ymm1_addsubps_xmm_xmm[63:32], %ymm2_addsubps_xmm_xmm[63:32]) ∘ add_single(%ymm1_addsubps_xmm_xmm[31:0], %ymm2_addsubps_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm3_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_addsubps_xmm_xmm
%rdx/%rdx: %rdx_addsubps_xmm_xmm

%xmm0: %ymm0_addsubps_xmm_xmm[127:0]
%xmm1: %ymm1_addsubps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm14

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm14: %ymm14_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm14: 0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminps %ymm1, %ymm14, %ymm1

Final state:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vminps %xmm2, %xmm2, %xmm5

.target:
vmovdqa %xmm3, %xmm1
vmovdqu %xmm2, %xmm14
vminps %ymm1, %ymm14, %ymm1
retq 

Initial state:
%ymm5: %ymm5_vsubps_xmm_xmm_xmm

State for specgen instruction: vminps %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm5: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_subps_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm14

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm14: %ymm14_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm14: 0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminps %ymm1, %ymm14, %ymm1

Final state:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vminps %xmm1, %xmm1, %xmm4

.target:
vmovdqa %xmm3, %xmm1
vmovdqu %xmm2, %xmm14
vminps %ymm1, %ymm14, %ymm1
retq 

Initial state:
%ymm4: %ymm4_subps_xmm_xmm

State for specgen instruction: vminps %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm4: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for vsubps %ymm10, %ymm4, %ymm2

Final state:
%ymm2: sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[255:224], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[255:224]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[223:192], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[223:192]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[191:160], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[191:160]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[159:128], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[159:128]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[127:96], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[127:96]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[95:64], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[95:64]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[63:32], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[63:32]) ∘ sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[31:0], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_subps_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_subps_xmm_xmm[255:128] ∘ (sub_single(%ymm1_subps_xmm_xmm[127:96], %ymm2_subps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_subps_xmm_xmm[95:64], %ymm2_subps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_subps_xmm_xmm[63:32], %ymm2_subps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_subps_xmm_xmm[31:0], %ymm2_subps_xmm_xmm[31:0])))))[127:0]

=====================================
=====================================
Computing circuit for subps %xmm3, %xmm5

.target:
vmovaps %xmm2, %xmm10
vminps %xmm1, %xmm1, %xmm4
vsubps %ymm10, %ymm4, %ymm2
movdqu %xmm2, %xmm1
retq 

Initial state:
%xmm5: (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0]))))[127:0]

State for specgen instruction: subps %xmm2, %xmm1:
%xmm1: (%ymm1_subps_xmm_xmm[255:128] ∘ (sub_single(%ymm1_subps_xmm_xmm[127:96], %ymm2_subps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_subps_xmm_xmm[95:64], %ymm2_subps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_subps_xmm_xmm[63:32], %ymm2_subps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_subps_xmm_xmm[31:0], %ymm2_subps_xmm_xmm[31:0])))))[127:0]

Final state
%xmm5: ((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0]))))[255:128] ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0])))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm5, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vsubps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0]))))

=====================================
=====================================
Computing circuit for vsubps %xmm2, %xmm1, %xmm4

.target:
vminps %xmm2, %xmm2, %xmm5
subps %xmm3, %xmm5
vmovdqu %xmm5, %xmm1
retq 

Initial state:
%ymm4: %ymm4_addsubps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (0x0₁₂₈ ∘ (add_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ (add_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]) ∘ (add_single(%ymm1_addsubps_xmm_xmm[63:32], %ymm2_addsubps_xmm_xmm[63:32]) ∘ add_single(%ymm1_addsubps_xmm_xmm[31:0], %ymm2_addsubps_xmm_xmm[31:0])))))[127:0][31:0])

State for specgen instruction: vsubps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0]))))

Final state
%ymm4: 0x0₁₂₈ ∘ (sub_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_addsubps_xmm_xmm[63:32], %ymm2_addsubps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_addsubps_xmm_xmm[31:0], %ymm2_addsubps_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_256_128_ymm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vunpckhpd_ymm_ymm_ymm

%xmm0: %ymm0_vunpckhpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vunpckhpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vunpckhpd_ymm_ymm_ymm

%xmm0: %ymm0_vunpckhpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vunpckhpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm8

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm8: (%ymm8_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:0])[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm8: ((%ymm8_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:0])[255:128] ∘ (%ymm3_vunpckhpd_ymm_ymm_ymm[127:64] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm11, %xmm9

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm9: (%ymm9_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:128])[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm9: ((%ymm9_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:128])[255:128] ∘ (%ymm3_vunpckhpd_ymm_ymm_ymm[255:192] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:192]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vunpckhpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vunpckhpd_ymm_ymm_ymm

%xmm0: %ymm0_vunpckhpd_ymm_ymm_ymm[127:0]
%xmm1: (((%ymm9_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:128])[255:128] ∘ (%ymm3_vunpckhpd_ymm_ymm_ymm[255:192] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:192]))[127:0][127:0] ∘ ((%ymm8_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:0])[255:128] ∘ (%ymm3_vunpckhpd_ymm_ymm_ymm[127:64] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:64]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhpd %ymm4, %ymm4, %ymm6

.target:
callq .move_256_128_ymm2_xmm8_xmm9
callq .move_256_128_ymm3_xmm10_xmm11
unpckhpd %xmm3, %xmm8
unpckhpd %xmm11, %xmm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_addsubps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (0x0₁₂₈ ∘ (add_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ (add_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]) ∘ (add_single(%ymm1_addsubps_xmm_xmm[63:32], %ymm2_addsubps_xmm_xmm[63:32]) ∘ add_single(%ymm1_addsubps_xmm_xmm[31:0], %ymm2_addsubps_xmm_xmm[31:0])))))[127:0][95:64])

State for specgen instruction: vunpckhpd %ymm3, %ymm2, %ymm1:
%ymm1: ((%ymm9_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:128])[255:128] ∘ (%ymm3_vunpckhpd_ymm_ymm_ymm[255:192] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:192]))[127:0][127:0] ∘ ((%ymm8_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:0])[255:128] ∘ (%ymm3_vunpckhpd_ymm_ymm_ymm[127:64] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:64]))[127:0][127:0]

Final state
%ymm6: 0x0₆₄ ∘ 0x0₆₄ ∘ (sub_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm3_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_addsubps_xmm_xmm
%rdx/%rdx: %rdx_addsubps_xmm_xmm

%xmm0: %ymm0_addsubps_xmm_xmm[127:0]
%xmm1: %ymm1_addsubps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm10, %xmm7

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm7: %ymm7_addsubps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (0x0₁₂₈ ∘ (add_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ (add_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]) ∘ (add_single(%ymm1_addsubps_xmm_xmm[63:32], %ymm2_addsubps_xmm_xmm[63:32]) ∘ add_single(%ymm1_addsubps_xmm_xmm[31:0], %ymm2_addsubps_xmm_xmm[31:0])))))[127:0][127:96])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm7: 0x0₁₂₈ ∘ (0x0₉₆ ∘ add_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1

Final state:
%rax/%rax: %rax_addsubps_xmm_xmm
%rdx/%rdx: %rdx_addsubps_xmm_xmm

%xmm0: %ymm0_addsubps_xmm_xmm[127:0]
%xmm1: (%ymm1_addsubps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₉₆ ∘ add_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96])))[127:0][31:0] ∘ (0x0₆₄ ∘ 0x0₆₄ ∘ (sub_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]))))[127:0][31:0] ∘ (%ymm5_addsubps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (0x0₁₂₈ ∘ (add_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ (add_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]) ∘ (add_single(%ymm1_addsubps_xmm_xmm[63:32], %ymm2_addsubps_xmm_xmm[63:32]) ∘ add_single(%ymm1_addsubps_xmm_xmm[31:0], %ymm2_addsubps_xmm_xmm[31:0])))))[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (sub_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_addsubps_xmm_xmm[63:32], %ymm2_addsubps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_addsubps_xmm_xmm[31:0], %ymm2_addsubps_xmm_xmm[31:0])))))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for addsubps %xmm3, %xmm2

.target:
vaddps %xmm2, %xmm1, %xmm3
callq .move_128_032_xmm3_xmm4_xmm5_xmm6_xmm7
vsubps %xmm2, %xmm1, %xmm4
vunpckhpd %ymm4, %ymm4, %ymm6
callq .move_128_032_xmm3_xmm8_xmm9_xmm10_xmm11
vmovss %xmm11, %xmm10, %xmm7
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1
retq 

Initial state:
%xmm2: %ymm2_vaddsubps_xmm_xmm_xmm[127:0]

State for specgen instruction: addsubps %xmm2, %xmm1:
%xmm1: (%ymm1_addsubps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₉₆ ∘ add_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96])))[127:0][31:0] ∘ (0x0₆₄ ∘ 0x0₆₄ ∘ (sub_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]))))[127:0][31:0] ∘ (%ymm5_addsubps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (0x0₁₂₈ ∘ (add_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ (add_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]) ∘ (add_single(%ymm1_addsubps_xmm_xmm[63:32], %ymm2_addsubps_xmm_xmm[63:32]) ∘ add_single(%ymm1_addsubps_xmm_xmm[31:0], %ymm2_addsubps_xmm_xmm[31:0])))))[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (sub_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_addsubps_xmm_xmm[63:32], %ymm2_addsubps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_addsubps_xmm_xmm[31:0], %ymm2_addsubps_xmm_xmm[31:0])))))[127:0][31:0]))[127:0]

Final state
%xmm2: (%ymm2_vaddsubps_xmm_xmm_xmm[255:128] ∘ (add_single(%ymm2_vaddsubps_xmm_xmm_xmm[127:96], %ymm3_vaddsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vaddsubps_xmm_xmm_xmm[95:64], %ymm3_vaddsubps_xmm_xmm_xmm[95:64]) ∘ add_single(%ymm2_vaddsubps_xmm_xmm_xmm[63:32], %ymm3_vaddsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vaddsubps_xmm_xmm_xmm[31:0], %ymm3_vaddsubps_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vaddsubps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vaddsubps_xmm_xmm_xmm

%xmm0: %ymm0_vaddsubps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vaddsubps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vaddsubps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vaddsubps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vaddsubps_xmm_xmm_xmm[255:128] ∘ (add_single(%ymm2_vaddsubps_xmm_xmm_xmm[127:96], %ymm3_vaddsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vaddsubps_xmm_xmm_xmm[95:64], %ymm3_vaddsubps_xmm_xmm_xmm[95:64]) ∘ add_single(%ymm2_vaddsubps_xmm_xmm_xmm[63:32], %ymm3_vaddsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vaddsubps_xmm_xmm_xmm[31:0], %ymm3_vaddsubps_xmm_xmm_xmm[31:0])))[127:0][127:64][63:0] ∘ (%ymm2_vaddsubps_xmm_xmm_xmm[255:128] ∘ (add_single(%ymm2_vaddsubps_xmm_xmm_xmm[127:96], %ymm3_vaddsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vaddsubps_xmm_xmm_xmm[95:64], %ymm3_vaddsubps_xmm_xmm_xmm[95:64]) ∘ add_single(%ymm2_vaddsubps_xmm_xmm_xmm[63:32], %ymm3_vaddsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vaddsubps_xmm_xmm_xmm[31:0], %ymm3_vaddsubps_xmm_xmm_xmm[31:0])))[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vaddsubps %xmm7, %xmm10, %xmm2

.target:
addsubps %xmm3, %xmm2
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm2: %ymm2_vfmaddsub132ps_xmm_xmm_xmm

State for specgen instruction: vaddsubps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vaddsubps_xmm_xmm_xmm[255:128] ∘ (add_single(%ymm2_vaddsubps_xmm_xmm_xmm[127:96], %ymm3_vaddsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vaddsubps_xmm_xmm_xmm[95:64], %ymm3_vaddsubps_xmm_xmm_xmm[95:64]) ∘ add_single(%ymm2_vaddsubps_xmm_xmm_xmm[63:32], %ymm3_vaddsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vaddsubps_xmm_xmm_xmm[31:0], %ymm3_vaddsubps_xmm_xmm_xmm[31:0])))[127:0][127:64][63:0] ∘ (%ymm2_vaddsubps_xmm_xmm_xmm[255:128] ∘ (add_single(%ymm2_vaddsubps_xmm_xmm_xmm[127:96], %ymm3_vaddsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vaddsubps_xmm_xmm_xmm[95:64], %ymm3_vaddsubps_xmm_xmm_xmm[95:64]) ∘ add_single(%ymm2_vaddsubps_xmm_xmm_xmm[63:32], %ymm3_vaddsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vaddsubps_xmm_xmm_xmm[31:0], %ymm3_vaddsubps_xmm_xmm_xmm[31:0])))[127:0][63:0][63:0])

Final state
%ymm2: 0x0₁₂₈ ∘ (add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[127:96]) ∘ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[95:64]) ∘ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[63:32]) ∘ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm2, %xmm1, %xmm6

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm6: %ymm6_xorps_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm6: 0x0₁₂₈ ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_xorps_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_xorps_xmm_xmm[255:128] ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for xorps %xmm2, %xmm1

.target:
vxorps %xmm2, %xmm1, %xmm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm1: %ymm1_pxor_xmm_xmm[127:0]

State for specgen instruction: xorps %xmm2, %xmm1:
%xmm1: (%ymm1_xorps_xmm_xmm[255:128] ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0])))[127:0]

Final state
%xmm1: (%ymm1_pxor_xmm_xmm[255:128] ∘ ((%ymm1_pxor_xmm_xmm[127:64] ⊕ %ymm2_pxor_xmm_xmm[127:64]) ∘ (%ymm1_pxor_xmm_xmm[63:0] ⊕ %ymm2_pxor_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for pxor %xmm9, %xmm9

.target:
xorps %xmm2, %xmm1
retq 

Initial state:
%xmm9: %ymm9_vfmadd213ps_xmm_xmm_xmm[127:0]

State for specgen instruction: pxor %xmm2, %xmm1:
%xmm1: (%ymm1_pxor_xmm_xmm[255:128] ∘ ((%ymm1_pxor_xmm_xmm[127:64] ⊕ %ymm2_pxor_xmm_xmm[127:64]) ∘ (%ymm1_pxor_xmm_xmm[63:0] ⊕ %ymm2_pxor_xmm_xmm[63:0])))[127:0]

Final state
%xmm9: (%ymm9_vfmadd213ps_xmm_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ 0x0₆₄))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vandps_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vandps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpxor_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpxor_xmm_xmm_xmm

%xmm0: %ymm0_vpxor_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpxor_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpxor_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r8_r9

Final state:
%rax/%rax: %rax_vpxor_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpxor_xmm_xmm_xmm

%xmm0: %ymm0_vpxor_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r8, %r12

Final state:
%r12/%r12: %ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0]

%cf: false
%pf: !((%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r9, %r13

Final state:
%r13/%r13: %ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64]

%cf: false
%pf: !((%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vpxor_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpxor_xmm_xmm_xmm

%xmm0: %ymm0_vpxor_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[255:128] ∘ ((%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[63:0] ∘ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpxor %xmm1, %xmm2, %xmm0

.target:
callq .move_128_064_xmm2_r12_r13
vmovdqa %xmm3, %xmm1
callq .move_128_064_xmm1_r8_r9
xorq %r8, %r12
xorq %r9, %r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm0: %ymm0_pand_xmm_xmm

State for specgen instruction: vpxor %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[255:128] ∘ ((%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[63:0] ∘ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[63:0])

Final state
%ymm0: 0x0₁₂₈ ∘ ((%ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64]) ∘ (%ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm2, %xmm2

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm2: %ymm2_por_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm2: 0x0₁₂₈ ∘ %ymm2_por_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm1, %xmm2, %xmm3

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm3: %ymm3_por_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_por_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_por_xmm_xmm[255:128] ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for por %xmm1, %xmm2

.target:
vmovapd %xmm2, %xmm2
vorpd %xmm1, %xmm2, %xmm3
movdqa %xmm3, %xmm1
retq 

Initial state:
%xmm2: %ymm2_pandn_xmm_xmm[127:0]

State for specgen instruction: por %xmm2, %xmm1:
%xmm1: (%ymm1_por_xmm_xmm[255:128] ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_pandn_xmm_xmm[255:128] ∘ ((%ymm2_pandn_xmm_xmm[127:64] | %ymm1_pandn_xmm_xmm[127:64]) ∘ (%ymm2_pandn_xmm_xmm[63:0] | %ymm1_pandn_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm2, %xmm1, %xmm6

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm6: %ymm6_xorps_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm6: 0x0₁₂₈ ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_xorps_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_xorps_xmm_xmm[255:128] ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for xorps %xmm2, %xmm1

.target:
vxorps %xmm2, %xmm1, %xmm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm1: %ymm1_pxor_xmm_xmm[127:0]

State for specgen instruction: xorps %xmm2, %xmm1:
%xmm1: (%ymm1_xorps_xmm_xmm[255:128] ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0])))[127:0]

Final state
%xmm1: (%ymm1_pxor_xmm_xmm[255:128] ∘ ((%ymm1_pxor_xmm_xmm[127:64] ⊕ %ymm2_pxor_xmm_xmm[127:64]) ∘ (%ymm1_pxor_xmm_xmm[63:0] ⊕ %ymm2_pxor_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for pxor %xmm2, %xmm1

.target:
xorps %xmm2, %xmm1
retq 

Initial state:
%xmm1: %ymm1_pandn_xmm_xmm[127:0]

State for specgen instruction: pxor %xmm2, %xmm1:
%xmm1: (%ymm1_pxor_xmm_xmm[255:128] ∘ ((%ymm1_pxor_xmm_xmm[127:64] ⊕ %ymm2_pxor_xmm_xmm[127:64]) ∘ (%ymm1_pxor_xmm_xmm[63:0] ⊕ %ymm2_pxor_xmm_xmm[63:0])))[127:0]

Final state
%xmm1: (%ymm1_pandn_xmm_xmm[255:128] ∘ ((%ymm1_pandn_xmm_xmm[127:64] ⊕ (%ymm2_pandn_xmm_xmm[127:64] | %ymm1_pandn_xmm_xmm[127:64])) ∘ (%ymm1_pandn_xmm_xmm[63:0] ⊕ (%ymm2_pandn_xmm_xmm[63:0] | %ymm1_pandn_xmm_xmm[63:0]))))[127:0]

=====================================
=====================================
Computing circuit for pandn %xmm2, %xmm0

.target:
por %xmm1, %xmm2
pxor %xmm2, %xmm1
retq 

Initial state:
%xmm0: (0x0₁₂₈ ∘ ((%ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64]) ∘ (%ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0])))[127:0]

State for specgen instruction: pandn %xmm2, %xmm1:
%xmm1: (%ymm1_pandn_xmm_xmm[255:128] ∘ ((%ymm1_pandn_xmm_xmm[127:64] ⊕ (%ymm2_pandn_xmm_xmm[127:64] | %ymm1_pandn_xmm_xmm[127:64])) ∘ (%ymm1_pandn_xmm_xmm[63:0] ⊕ (%ymm2_pandn_xmm_xmm[63:0] | %ymm1_pandn_xmm_xmm[63:0]))))[127:0]

Final state
%xmm0: ((0x0₁₂₈ ∘ ((%ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64]) ∘ (%ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0])))[255:128] ∘ ((%ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64] ⊕ (%ymm2_pand_xmm_xmm[127:64] | %ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64])) ∘ (%ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0] ⊕ (%ymm2_pand_xmm_xmm[63:0] | %ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm0, %xmm2

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm2: %ymm2_pand_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm2: 0x0₁₂₈ ∘ ((%ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64] ⊕ (%ymm2_pand_xmm_xmm[127:64] | %ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64])) ∘ (%ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0] ⊕ (%ymm2_pand_xmm_xmm[63:0] | %ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_pand_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_pand_xmm_xmm[255:128] ∘ ((%ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64] ⊕ (%ymm2_pand_xmm_xmm[127:64] | %ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64])) ∘ (%ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0] ⊕ (%ymm2_pand_xmm_xmm[63:0] | %ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0]))))[127:0]

=====================================
=====================================
Computing circuit for pand %xmm1, %xmm2

.target:
vpxor %xmm1, %xmm2, %xmm0
pandn %xmm2, %xmm0
vmovapd %xmm0, %xmm2
movdqa %xmm2, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vandps_xmm_xmm_xmm[127:0]

State for specgen instruction: pand %xmm2, %xmm1:
%xmm1: (%ymm1_pand_xmm_xmm[255:128] ∘ ((%ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64] ⊕ (%ymm2_pand_xmm_xmm[127:64] | %ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64])) ∘ (%ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0] ⊕ (%ymm2_pand_xmm_xmm[63:0] | %ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0]))))[127:0]

Final state
%xmm2: (%ymm2_vandps_xmm_xmm_xmm[255:128] ∘ ((%ymm3_vandps_xmm_xmm_xmm[127:64] ⊕ %ymm2_vandps_xmm_xmm_xmm[127:64] ⊕ (%ymm3_vandps_xmm_xmm_xmm[127:64] | %ymm3_vandps_xmm_xmm_xmm[127:64] ⊕ %ymm2_vandps_xmm_xmm_xmm[127:64])) ∘ (%ymm3_vandps_xmm_xmm_xmm[63:0] ⊕ %ymm2_vandps_xmm_xmm_xmm[63:0] ⊕ (%ymm3_vandps_xmm_xmm_xmm[63:0] | %ymm3_vandps_xmm_xmm_xmm[63:0] ⊕ %ymm2_vandps_xmm_xmm_xmm[63:0]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: %ymm0_vmovups_xmm_xmm[127:0]
%xmm1: %ymm1_vmovups_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovups %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: 0x0₁₂₈ ∘ %ymm3_vandps_xmm_xmm_xmm[127:0]

State for specgen instruction: vmovups %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vandps_xmm_xmm_xmm[127:64] ⊕ %ymm2_vandps_xmm_xmm_xmm[127:64] ⊕ (%ymm3_vandps_xmm_xmm_xmm[127:64] | %ymm3_vandps_xmm_xmm_xmm[127:64] ⊕ %ymm2_vandps_xmm_xmm_xmm[127:64])) ∘ (%ymm3_vandps_xmm_xmm_xmm[63:0] ⊕ %ymm2_vandps_xmm_xmm_xmm[63:0] ⊕ (%ymm3_vandps_xmm_xmm_xmm[63:0] | %ymm3_vandps_xmm_xmm_xmm[63:0] ⊕ %ymm2_vandps_xmm_xmm_xmm[63:0])))

=====================================
=====================================
Computing circuit for vandps %xmm9, %xmm3, %xmm10

.target:
vmovupd %xmm3, %xmm1
pand %xmm1, %xmm2
vmovups %xmm2, %xmm1
retq 

Initial state:
%ymm10: %ymm10_vfmadd213ps_xmm_xmm_xmm

State for specgen instruction: vandps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vandps_xmm_xmm_xmm[127:64] ⊕ %ymm2_vandps_xmm_xmm_xmm[127:64] ⊕ (%ymm3_vandps_xmm_xmm_xmm[127:64] | %ymm3_vandps_xmm_xmm_xmm[127:64] ⊕ %ymm2_vandps_xmm_xmm_xmm[127:64])) ∘ (%ymm3_vandps_xmm_xmm_xmm[63:0] ⊕ %ymm2_vandps_xmm_xmm_xmm[63:0] ⊕ (%ymm3_vandps_xmm_xmm_xmm[63:0] | %ymm3_vandps_xmm_xmm_xmm[63:0] ⊕ %ymm2_vandps_xmm_xmm_xmm[63:0])))

Final state
%ymm10: 0x0₁₂₈ ∘ ((0x0₆₄ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[127:64] ⊕ (0x0₆₄ | 0x0₆₄ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[127:64])) ∘ (0x0₆₄ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[63:0] ⊕ (0x0₆₄ | 0x0₆₄ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm13

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm13: %ymm13_vfnmsub231ps_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm13: 0x0₁₂₈ ∘ %ymm1_vfnmsub231ps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm6

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm6: %ymm6_vfnmsub231ps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm6: 0x0₁₂₈ ∘ %ymm2_vfnmsub231ps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vfnmsub231ps_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vfnmsub231ps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vfnmsub132ps %ymm1, %ymm13, %ymm6

Final state:
%ymm6: vfnmsub132_single((0x0₁₂₈ ∘ %ymm2_vfnmsub231ps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm1_vfnmsub231ps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vfnmsub231ps_xmm_xmm_xmm[127:0])[255:224]) ∘ (vfnmsub132_single((0x0₁₂₈ ∘ %ymm2_vfnmsub231ps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm1_vfnmsub231ps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vfnmsub231ps_xmm_xmm_xmm[127:0])[223:192]) ∘ (vfnmsub132_single((0x0₁₂₈ ∘ %ymm2_vfnmsub231ps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm1_vfnmsub231ps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vfnmsub231ps_xmm_xmm_xmm[127:0])[191:160]) ∘ (vfnmsub132_single((0x0₁₂₈ ∘ %ymm2_vfnmsub231ps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm1_vfnmsub231ps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vfnmsub231ps_xmm_xmm_xmm[127:0])[159:128]) ∘ (vfnmsub132_single((0x0₁₂₈ ∘ %ymm2_vfnmsub231ps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm1_vfnmsub231ps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vfnmsub231ps_xmm_xmm_xmm[127:0])[127:96]) ∘ (vfnmsub132_single((0x0₁₂₈ ∘ %ymm2_vfnmsub231ps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm1_vfnmsub231ps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vfnmsub231ps_xmm_xmm_xmm[127:0])[95:64]) ∘ (vfnmsub132_single((0x0₁₂₈ ∘ %ymm2_vfnmsub231ps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm1_vfnmsub231ps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vfnmsub231ps_xmm_xmm_xmm[127:0])[63:32]) ∘ vfnmsub132_single((0x0₁₂₈ ∘ %ymm2_vfnmsub231ps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm1_vfnmsub231ps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vfnmsub231ps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: 0x0₁₂₈ ∘ %ymm3_vfnmsub231ps_xmm_xmm_xmm[127:0]

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_xmm_xmm_xmm[127:96], %ymm1_vfnmsub231ps_xmm_xmm_xmm[127:96], %ymm3_vfnmsub231ps_xmm_xmm_xmm[127:96]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_xmm_xmm_xmm[95:64], %ymm1_vfnmsub231ps_xmm_xmm_xmm[95:64], %ymm3_vfnmsub231ps_xmm_xmm_xmm[95:64]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_xmm_xmm_xmm[63:32], %ymm1_vfnmsub231ps_xmm_xmm_xmm[63:32], %ymm3_vfnmsub231ps_xmm_xmm_xmm[63:32]) ∘ vfnmsub132_single(%ymm2_vfnmsub231ps_xmm_xmm_xmm[31:0], %ymm1_vfnmsub231ps_xmm_xmm_xmm[31:0], %ymm3_vfnmsub231ps_xmm_xmm_xmm[31:0]))))

=====================================
=====================================
Computing circuit for vfnmsub231ps %xmm3, %xmm10, %xmm3

.target:
vmovupd %xmm1, %xmm13
vmovdqu %xmm2, %xmm6
vmovapd %xmm3, %xmm1
vfnmsub132ps %ymm1, %ymm13, %ymm6
vmovapd %xmm6, %xmm1
retq 

Initial state:
%ymm3: %ymm3_vfmadd213ps_xmm_xmm_xmm

State for specgen instruction: vfnmsub231ps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_xmm_xmm_xmm[127:96], %ymm1_vfnmsub231ps_xmm_xmm_xmm[127:96], %ymm3_vfnmsub231ps_xmm_xmm_xmm[127:96]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_xmm_xmm_xmm[95:64], %ymm1_vfnmsub231ps_xmm_xmm_xmm[95:64], %ymm3_vfnmsub231ps_xmm_xmm_xmm[95:64]) ∘ (vfnmsub132_single(%ymm2_vfnmsub231ps_xmm_xmm_xmm[63:32], %ymm1_vfnmsub231ps_xmm_xmm_xmm[63:32], %ymm3_vfnmsub231ps_xmm_xmm_xmm[63:32]) ∘ vfnmsub132_single(%ymm2_vfnmsub231ps_xmm_xmm_xmm[31:0], %ymm1_vfnmsub231ps_xmm_xmm_xmm[31:0], %ymm3_vfnmsub231ps_xmm_xmm_xmm[31:0]))))

Final state
%ymm3: 0x0₁₂₈ ∘ (vfnmsub132_single(0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[127:96] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[127:96]), %ymm3_vfmadd213ps_xmm_xmm_xmm[127:96], %ymm3_vfmadd213ps_xmm_xmm_xmm[127:96]) ∘ (vfnmsub132_single(0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[95:64] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[95:64]), %ymm3_vfmadd213ps_xmm_xmm_xmm[95:64], %ymm3_vfmadd213ps_xmm_xmm_xmm[95:64]) ∘ (vfnmsub132_single(0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[63:32] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[63:32]), %ymm3_vfmadd213ps_xmm_xmm_xmm[63:32], %ymm3_vfmadd213ps_xmm_xmm_xmm[63:32]) ∘ vfnmsub132_single(0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[31:0] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[31:0]), %ymm3_vfmadd213ps_xmm_xmm_xmm[31:0], %ymm3_vfmadd213ps_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vfmsub132ps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm1_vfmsub132ps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm3, %xmm0

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm0: %ymm0_vfmsub132ps_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm0: 0x0₁₂₈ ∘ %ymm3_vfmsub132ps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm4

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm4: %ymm4_vfmsub132ps_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm4: 0x0₁₂₈ ∘ %ymm2_vfmsub132ps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vfmsub132ps %ymm0, %ymm4, %ymm1

Final state:
%ymm1: vfmsub132_single((0x0₁₂₈ ∘ %ymm1_vfmsub132ps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm2_vfmsub132ps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vfmsub132ps_xmm_xmm_xmm[127:0])[255:224]) ∘ (vfmsub132_single((0x0₁₂₈ ∘ %ymm1_vfmsub132ps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm2_vfmsub132ps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vfmsub132ps_xmm_xmm_xmm[127:0])[223:192]) ∘ (vfmsub132_single((0x0₁₂₈ ∘ %ymm1_vfmsub132ps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm2_vfmsub132ps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vfmsub132ps_xmm_xmm_xmm[127:0])[191:160]) ∘ (vfmsub132_single((0x0₁₂₈ ∘ %ymm1_vfmsub132ps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm2_vfmsub132ps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vfmsub132ps_xmm_xmm_xmm[127:0])[159:128]) ∘ (vfmsub132_single((0x0₁₂₈ ∘ %ymm1_vfmsub132ps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm2_vfmsub132ps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vfmsub132ps_xmm_xmm_xmm[127:0])[127:96]) ∘ (vfmsub132_single((0x0₁₂₈ ∘ %ymm1_vfmsub132ps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm2_vfmsub132ps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vfmsub132ps_xmm_xmm_xmm[127:0])[95:64]) ∘ (vfmsub132_single((0x0₁₂₈ ∘ %ymm1_vfmsub132ps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm2_vfmsub132ps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vfmsub132ps_xmm_xmm_xmm[127:0])[63:32]) ∘ vfmsub132_single((0x0₁₂₈ ∘ %ymm1_vfmsub132ps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm2_vfmsub132ps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vfmsub132ps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vfmsub132ps %xmm1, %xmm3, %xmm2

.target:
vmovdqa %xmm1, %xmm1
vmovupd %xmm3, %xmm0
vmovupd %xmm2, %xmm4
vfmsub132ps %ymm0, %ymm4, %ymm1
retq 

Initial state:
%ymm2: %ymm2_vfmadd213ps_xmm_xmm_xmm

State for specgen instruction: vfmsub132ps %xmm3, %xmm2, %xmm1:
%ymm1: vfmsub132_single((0x0₁₂₈ ∘ %ymm1_vfmsub132ps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm2_vfmsub132ps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vfmsub132ps_xmm_xmm_xmm[127:0])[255:224]) ∘ (vfmsub132_single((0x0₁₂₈ ∘ %ymm1_vfmsub132ps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm2_vfmsub132ps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vfmsub132ps_xmm_xmm_xmm[127:0])[223:192]) ∘ (vfmsub132_single((0x0₁₂₈ ∘ %ymm1_vfmsub132ps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm2_vfmsub132ps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vfmsub132ps_xmm_xmm_xmm[127:0])[191:160]) ∘ (vfmsub132_single((0x0₁₂₈ ∘ %ymm1_vfmsub132ps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm2_vfmsub132ps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vfmsub132ps_xmm_xmm_xmm[127:0])[159:128]) ∘ (vfmsub132_single((0x0₁₂₈ ∘ %ymm1_vfmsub132ps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm2_vfmsub132ps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vfmsub132ps_xmm_xmm_xmm[127:0])[127:96]) ∘ (vfmsub132_single((0x0₁₂₈ ∘ %ymm1_vfmsub132ps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm2_vfmsub132ps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vfmsub132ps_xmm_xmm_xmm[127:0])[95:64]) ∘ (vfmsub132_single((0x0₁₂₈ ∘ %ymm1_vfmsub132ps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm2_vfmsub132ps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vfmsub132ps_xmm_xmm_xmm[127:0])[63:32]) ∘ vfmsub132_single((0x0₁₂₈ ∘ %ymm1_vfmsub132ps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm2_vfmsub132ps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vfmsub132ps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm2: vfmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ (vfmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ (vfmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ (vfmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ (vfmsub132_single(%ymm2_vfmadd213ps_xmm_xmm_xmm[127:96], vfnmsub132_single(0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[127:96] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[127:96]), %ymm3_vfmadd213ps_xmm_xmm_xmm[127:96], %ymm3_vfmadd213ps_xmm_xmm_xmm[127:96]), %ymm1_vfmadd213ps_xmm_xmm_xmm[127:96]) ∘ (vfmsub132_single(%ymm2_vfmadd213ps_xmm_xmm_xmm[95:64], vfnmsub132_single(0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[95:64] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[95:64]), %ymm3_vfmadd213ps_xmm_xmm_xmm[95:64], %ymm3_vfmadd213ps_xmm_xmm_xmm[95:64]), %ymm1_vfmadd213ps_xmm_xmm_xmm[95:64]) ∘ (vfmsub132_single(%ymm2_vfmadd213ps_xmm_xmm_xmm[63:32], vfnmsub132_single(0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[63:32] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[63:32]), %ymm3_vfmadd213ps_xmm_xmm_xmm[63:32], %ymm3_vfmadd213ps_xmm_xmm_xmm[63:32]), %ymm1_vfmadd213ps_xmm_xmm_xmm[63:32]) ∘ vfmsub132_single(%ymm2_vfmadd213ps_xmm_xmm_xmm[31:0], vfnmsub132_single(0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[31:0] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[31:0]), %ymm3_vfmadd213ps_xmm_xmm_xmm[31:0], %ymm3_vfmadd213ps_xmm_xmm_xmm[31:0]), %ymm1_vfmadd213ps_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm8_xmm9

Final state:
%rax/%rax: %rax_vorpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vorpd_ymm_ymm_ymm

%xmm0: %ymm0_vorpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vorpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm2, %xmm2

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm2: %ymm2_por_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm2: 0x0₁₂₈ ∘ %ymm2_por_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm1, %xmm2, %xmm3

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm3: %ymm3_por_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_por_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_por_xmm_xmm[255:128] ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for por %xmm2, %xmm8

.target:
vmovapd %xmm2, %xmm2
vorpd %xmm1, %xmm2, %xmm3
movdqa %xmm3, %xmm1
retq 

Initial state:
%xmm8: (%ymm8_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[127:0])[127:0]

State for specgen instruction: por %xmm2, %xmm1:
%xmm1: (%ymm1_por_xmm_xmm[255:128] ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0])))[127:0]

Final state
%xmm8: ((%ymm8_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[127:0])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[127:64] | %ymm2_vorpd_ymm_ymm_ymm[127:64]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[63:0] | %ymm2_vorpd_ymm_ymm_ymm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_256_128_ymm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vorpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vorpd_ymm_ymm_ymm

%xmm0: %ymm0_vorpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vorpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm1, %xmm2, %xmm3

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm3: %ymm3_orps_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ ((%ymm1_orps_xmm_xmm[127:64] | %ymm2_orps_xmm_xmm[127:64]) ∘ (%ymm1_orps_xmm_xmm[63:0] | %ymm2_orps_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm10_xmm11

Final state:
%rax/%rax: %rax_orps_xmm_xmm
%rdx/%rdx: %rdx_orps_xmm_xmm

%xmm0: %ymm0_orps_xmm_xmm[127:0]
%xmm1: %ymm1_orps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_orps_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_orps_xmm_xmm[255:128] ∘ ((%ymm1_orps_xmm_xmm[127:64] | %ymm2_orps_xmm_xmm[127:64]) ∘ (%ymm1_orps_xmm_xmm[63:0] | %ymm2_orps_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for orps %xmm2, %xmm1

.target:
vorpd %xmm1, %xmm2, %xmm3
callq .move_256_128_ymm3_xmm10_xmm11
movdqa %xmm10, %xmm1
retq 

Initial state:
%xmm1: %ymm1_orpd_xmm_xmm[127:0]

State for specgen instruction: orps %xmm2, %xmm1:
%xmm1: (%ymm1_orps_xmm_xmm[255:128] ∘ ((%ymm1_orps_xmm_xmm[127:64] | %ymm2_orps_xmm_xmm[127:64]) ∘ (%ymm1_orps_xmm_xmm[63:0] | %ymm2_orps_xmm_xmm[63:0])))[127:0]

Final state
%xmm1: (%ymm1_orpd_xmm_xmm[255:128] ∘ ((%ymm1_orpd_xmm_xmm[127:64] | %ymm2_orpd_xmm_xmm[127:64]) ∘ (%ymm1_orpd_xmm_xmm[63:0] | %ymm2_orpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for orpd %xmm11, %xmm9

.target:
orps %xmm2, %xmm1
retq 

Initial state:
%xmm9: (%ymm9_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[255:128])[127:0]

State for specgen instruction: orpd %xmm2, %xmm1:
%xmm1: (%ymm1_orpd_xmm_xmm[255:128] ∘ ((%ymm1_orpd_xmm_xmm[127:64] | %ymm2_orpd_xmm_xmm[127:64]) ∘ (%ymm1_orpd_xmm_xmm[63:0] | %ymm2_orpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm9: ((%ymm9_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[255:128])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[255:192] | %ymm2_vorpd_ymm_ymm_ymm[255:192]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[191:128] | %ymm2_vorpd_ymm_ymm_ymm[191:128])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vorpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vorpd_ymm_ymm_ymm

%xmm0: %ymm0_vorpd_ymm_ymm_ymm[127:0]
%xmm1: (((%ymm9_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[255:128])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[255:192] | %ymm2_vorpd_ymm_ymm_ymm[255:192]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[191:128] | %ymm2_vorpd_ymm_ymm_ymm[191:128])))[127:0][127:0] ∘ ((%ymm8_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[127:0])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[127:64] | %ymm2_vorpd_ymm_ymm_ymm[127:64]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[63:0] | %ymm2_vorpd_ymm_ymm_ymm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %ymm2, %ymm10, %ymm1

.target:
callq .move_256_128_ymm3_xmm8_xmm9
por %xmm2, %xmm8
callq .move_256_128_ymm2_xmm10_xmm11
orpd %xmm11, %xmm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm1: %ymm1_vfmadd213ps_xmm_xmm_xmm

State for specgen instruction: vorpd %ymm3, %ymm2, %ymm1:
%ymm1: ((%ymm9_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[255:128])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[255:192] | %ymm2_vorpd_ymm_ymm_ymm[255:192]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[191:128] | %ymm2_vorpd_ymm_ymm_ymm[191:128])))[127:0][127:0] ∘ ((%ymm8_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[127:0])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[127:64] | %ymm2_vorpd_ymm_ymm_ymm[127:64]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[63:0] | %ymm2_vorpd_ymm_ymm_ymm[63:0])))[127:0][127:0]

Final state
%ymm1: (vfmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ vfmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) | 0x0₆₄) ∘ (vfmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ vfmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) | 0x0₆₄) ∘ ((vfmsub132_single(%ymm2_vfmadd213ps_xmm_xmm_xmm[127:96], vfnmsub132_single(0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[127:96] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[127:96]), %ymm3_vfmadd213ps_xmm_xmm_xmm[127:96], %ymm3_vfmadd213ps_xmm_xmm_xmm[127:96]), %ymm1_vfmadd213ps_xmm_xmm_xmm[127:96]) ∘ vfmsub132_single(%ymm2_vfmadd213ps_xmm_xmm_xmm[95:64], vfnmsub132_single(0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[95:64] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[95:64]), %ymm3_vfmadd213ps_xmm_xmm_xmm[95:64], %ymm3_vfmadd213ps_xmm_xmm_xmm[95:64]), %ymm1_vfmadd213ps_xmm_xmm_xmm[95:64]) | 0x0₆₄ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[127:64] ⊕ (0x0₆₄ | 0x0₆₄ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[127:64])) ∘ (vfmsub132_single(%ymm2_vfmadd213ps_xmm_xmm_xmm[63:32], vfnmsub132_single(0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[63:32] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[63:32]), %ymm3_vfmadd213ps_xmm_xmm_xmm[63:32], %ymm3_vfmadd213ps_xmm_xmm_xmm[63:32]), %ymm1_vfmadd213ps_xmm_xmm_xmm[63:32]) ∘ vfmsub132_single(%ymm2_vfmadd213ps_xmm_xmm_xmm[31:0], vfnmsub132_single(0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[31:0] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[31:0]), %ymm3_vfmadd213ps_xmm_xmm_xmm[31:0], %ymm3_vfmadd213ps_xmm_xmm_xmm[31:0]), %ymm1_vfmadd213ps_xmm_xmm_xmm[31:0]) | 0x0₆₄ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[63:0] ⊕ (0x0₆₄ | 0x0₆₄ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[63:0])))

=====================================
=====================================
Computing circuit for vfmadd213ps %xmm2, %xmm1, %xmm3

.target:
pxor %xmm9, %xmm9
vandps %xmm9, %xmm3, %xmm10
vfnmsub231ps %xmm3, %xmm10, %xmm3
vfmsub132ps %xmm1, %xmm3, %xmm2
vorpd %ymm2, %ymm10, %ymm1
retq 

Initial state:
%ymm3: %ymm3_vfmadd132ps_xmm_xmm_xmm

State for specgen instruction: vfmadd213ps %xmm3, %xmm2, %xmm1:
%ymm1: (vfmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ vfmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) | 0x0₆₄) ∘ (vfmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ vfmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) | 0x0₆₄) ∘ ((vfmsub132_single(%ymm2_vfmadd213ps_xmm_xmm_xmm[127:96], vfnmsub132_single(0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[127:96] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[127:96]), %ymm3_vfmadd213ps_xmm_xmm_xmm[127:96], %ymm3_vfmadd213ps_xmm_xmm_xmm[127:96]), %ymm1_vfmadd213ps_xmm_xmm_xmm[127:96]) ∘ vfmsub132_single(%ymm2_vfmadd213ps_xmm_xmm_xmm[95:64], vfnmsub132_single(0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[95:64] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[95:64]), %ymm3_vfmadd213ps_xmm_xmm_xmm[95:64], %ymm3_vfmadd213ps_xmm_xmm_xmm[95:64]), %ymm1_vfmadd213ps_xmm_xmm_xmm[95:64]) | 0x0₆₄ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[127:64] ⊕ (0x0₆₄ | 0x0₆₄ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[127:64])) ∘ (vfmsub132_single(%ymm2_vfmadd213ps_xmm_xmm_xmm[63:32], vfnmsub132_single(0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[63:32] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[63:32]), %ymm3_vfmadd213ps_xmm_xmm_xmm[63:32], %ymm3_vfmadd213ps_xmm_xmm_xmm[63:32]), %ymm1_vfmadd213ps_xmm_xmm_xmm[63:32]) ∘ vfmsub132_single(%ymm2_vfmadd213ps_xmm_xmm_xmm[31:0], vfnmsub132_single(0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[31:0] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[31:0]), %ymm3_vfmadd213ps_xmm_xmm_xmm[31:0], %ymm3_vfmadd213ps_xmm_xmm_xmm[31:0]), %ymm1_vfmadd213ps_xmm_xmm_xmm[31:0]) | 0x0₆₄ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[63:0] ⊕ (0x0₆₄ | 0x0₆₄ ⊕ %ymm3_vfmadd213ps_xmm_xmm_xmm[63:0])))

Final state
%ymm3: (vfmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ vfmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) | 0x0₆₄) ∘ (vfmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ vfmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) | 0x0₆₄) ∘ ((vfmsub132_single(%ymm1_vfmadd132ps_xmm_xmm_xmm[127:96], vfnmsub132_single(0x0₃₂ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[127:96] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[127:96]), %ymm2_vfmadd132ps_xmm_xmm_xmm[127:96], %ymm2_vfmadd132ps_xmm_xmm_xmm[127:96]), %ymm3_vfmadd132ps_xmm_xmm_xmm[127:96]) ∘ vfmsub132_single(%ymm1_vfmadd132ps_xmm_xmm_xmm[95:64], vfnmsub132_single(0x0₃₂ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[95:64] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[95:64]), %ymm2_vfmadd132ps_xmm_xmm_xmm[95:64], %ymm2_vfmadd132ps_xmm_xmm_xmm[95:64]), %ymm3_vfmadd132ps_xmm_xmm_xmm[95:64]) | 0x0₆₄ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[127:64] ⊕ (0x0₆₄ | 0x0₆₄ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[127:64])) ∘ (vfmsub132_single(%ymm1_vfmadd132ps_xmm_xmm_xmm[63:32], vfnmsub132_single(0x0₃₂ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[63:32] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[63:32]), %ymm2_vfmadd132ps_xmm_xmm_xmm[63:32], %ymm2_vfmadd132ps_xmm_xmm_xmm[63:32]), %ymm3_vfmadd132ps_xmm_xmm_xmm[63:32]) ∘ vfmsub132_single(%ymm1_vfmadd132ps_xmm_xmm_xmm[31:0], vfnmsub132_single(0x0₃₂ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[31:0] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[31:0]), %ymm2_vfmadd132ps_xmm_xmm_xmm[31:0], %ymm2_vfmadd132ps_xmm_xmm_xmm[31:0]), %ymm3_vfmadd132ps_xmm_xmm_xmm[31:0]) | 0x0₆₄ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[63:0] ⊕ (0x0₆₄ | 0x0₆₄ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vfmadd132ps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vfmadd132ps_xmm_xmm_xmm

%xmm0: %ymm0_vfmadd132ps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vfmadd132ps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vfmadd132ps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vfmadd132ps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm14, %xmm2, %xmm1

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm1: 0x0₂₅₆

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm1: 0x0₁₂₈ ∘ ((0x0₆₄ | (vfmsub132_single(%ymm1_vfmadd132ps_xmm_xmm_xmm[127:96], vfnmsub132_single(0x0₃₂ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[127:96] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[127:96]), %ymm2_vfmadd132ps_xmm_xmm_xmm[127:96], %ymm2_vfmadd132ps_xmm_xmm_xmm[127:96]), %ymm3_vfmadd132ps_xmm_xmm_xmm[127:96]) ∘ vfmsub132_single(%ymm1_vfmadd132ps_xmm_xmm_xmm[95:64], vfnmsub132_single(0x0₃₂ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[95:64] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[95:64]), %ymm2_vfmadd132ps_xmm_xmm_xmm[95:64], %ymm2_vfmadd132ps_xmm_xmm_xmm[95:64]), %ymm3_vfmadd132ps_xmm_xmm_xmm[95:64]) | 0x0₆₄ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[127:64] ⊕ (0x0₆₄ | 0x0₆₄ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[127:64]))) ∘ (0x0₆₄ | (vfmsub132_single(%ymm1_vfmadd132ps_xmm_xmm_xmm[63:32], vfnmsub132_single(0x0₃₂ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[63:32] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[63:32]), %ymm2_vfmadd132ps_xmm_xmm_xmm[63:32], %ymm2_vfmadd132ps_xmm_xmm_xmm[63:32]), %ymm3_vfmadd132ps_xmm_xmm_xmm[63:32]) ∘ vfmsub132_single(%ymm1_vfmadd132ps_xmm_xmm_xmm[31:0], vfnmsub132_single(0x0₃₂ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[31:0] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[31:0]), %ymm2_vfmadd132ps_xmm_xmm_xmm[31:0], %ymm2_vfmadd132ps_xmm_xmm_xmm[31:0]), %ymm3_vfmadd132ps_xmm_xmm_xmm[31:0]) | 0x0₆₄ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[63:0] ⊕ (0x0₆₄ | 0x0₆₄ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[63:0]))))

=====================================
=====================================
Computing circuit for vfmadd132ps %xmm3, %xmm2, %xmm1

.target:
vfmadd213ps %xmm2, %xmm1, %xmm3
callq .move_128_064_xmm3_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm2
vorps %xmm14, %xmm2, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vfmaddsub132ps_xmm_xmm_xmm

State for specgen instruction: vfmadd132ps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((0x0₆₄ | (vfmsub132_single(%ymm1_vfmadd132ps_xmm_xmm_xmm[127:96], vfnmsub132_single(0x0₃₂ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[127:96] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[127:96]), %ymm2_vfmadd132ps_xmm_xmm_xmm[127:96], %ymm2_vfmadd132ps_xmm_xmm_xmm[127:96]), %ymm3_vfmadd132ps_xmm_xmm_xmm[127:96]) ∘ vfmsub132_single(%ymm1_vfmadd132ps_xmm_xmm_xmm[95:64], vfnmsub132_single(0x0₃₂ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[95:64] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[95:64]), %ymm2_vfmadd132ps_xmm_xmm_xmm[95:64], %ymm2_vfmadd132ps_xmm_xmm_xmm[95:64]), %ymm3_vfmadd132ps_xmm_xmm_xmm[95:64]) | 0x0₆₄ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[127:64] ⊕ (0x0₆₄ | 0x0₆₄ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[127:64]))) ∘ (0x0₆₄ | (vfmsub132_single(%ymm1_vfmadd132ps_xmm_xmm_xmm[63:32], vfnmsub132_single(0x0₃₂ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[63:32] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[63:32]), %ymm2_vfmadd132ps_xmm_xmm_xmm[63:32], %ymm2_vfmadd132ps_xmm_xmm_xmm[63:32]), %ymm3_vfmadd132ps_xmm_xmm_xmm[63:32]) ∘ vfmsub132_single(%ymm1_vfmadd132ps_xmm_xmm_xmm[31:0], vfnmsub132_single(0x0₃₂ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[31:0] ⊕ (0x0₃₂ | 0x0₃₂ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[31:0]), %ymm2_vfmadd132ps_xmm_xmm_xmm[31:0], %ymm2_vfmadd132ps_xmm_xmm_xmm[31:0]), %ymm3_vfmadd132ps_xmm_xmm_xmm[31:0]) | 0x0₆₄ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[63:0] ⊕ (0x0₆₄ | 0x0₆₄ ⊕ %ymm2_vfmadd132ps_xmm_xmm_xmm[63:0]))))

Final state
%ymm1: 0x0₁₂₈ ∘ ((0x0₆₄ | (vfmsub132_single(%ymm1_vfmaddsub132ps_xmm_xmm_xmm[127:96], vfnmsub132_single(0x0₃₂ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[127:96]) ⊕ (0x0₃₂ | 0x0₃₂ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[127:96])), add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[127:96]), add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[127:96])), %ymm3_vfmaddsub132ps_xmm_xmm_xmm[127:96]) ∘ vfmsub132_single(%ymm1_vfmaddsub132ps_xmm_xmm_xmm[95:64], vfnmsub132_single(0x0₃₂ ⊕ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[95:64]) ⊕ (0x0₃₂ | 0x0₃₂ ⊕ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[95:64])), sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[95:64]), sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[95:64])), %ymm3_vfmaddsub132ps_xmm_xmm_xmm[95:64]) | 0x0₆₄ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[127:96]) ∘ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[95:64]) ⊕ (0x0₆₄ | 0x0₆₄ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[127:96]) ∘ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[95:64])))) ∘ (0x0₆₄ | (vfmsub132_single(%ymm1_vfmaddsub132ps_xmm_xmm_xmm[63:32], vfnmsub132_single(0x0₃₂ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[63:32]) ⊕ (0x0₃₂ | 0x0₃₂ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[63:32])), add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[63:32]), add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[63:32])), %ymm3_vfmaddsub132ps_xmm_xmm_xmm[63:32]) ∘ vfmsub132_single(%ymm1_vfmaddsub132ps_xmm_xmm_xmm[31:0], vfnmsub132_single(0x0₃₂ ⊕ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[31:0]) ⊕ (0x0₃₂ | 0x0₃₂ ⊕ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[31:0])), sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[31:0]), sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[31:0])), %ymm3_vfmaddsub132ps_xmm_xmm_xmm[31:0]) | 0x0₆₄ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[63:32]) ∘ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[31:0]) ⊕ (0x0₆₄ | 0x0₆₄ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[63:32]) ∘ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[31:0])))))

=====================================
=====================================
Computing circuit for vfmaddsub132ps %xmm3, %xmm2, %xmm1

.target:
vpandn %xmm1, %xmm1, %xmm10
vfnmsub231ps %ymm10, %ymm10, %ymm10
movdqa %xmm2, %xmm7
vaddsubps %xmm7, %xmm10, %xmm2
vfmadd132ps %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm1: %ymm1

State for specgen instruction: vfmaddsub132ps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((0x0₆₄ | (vfmsub132_single(%ymm1_vfmaddsub132ps_xmm_xmm_xmm[127:96], vfnmsub132_single(0x0₃₂ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[127:96]) ⊕ (0x0₃₂ | 0x0₃₂ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[127:96])), add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[127:96]), add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[127:96])), %ymm3_vfmaddsub132ps_xmm_xmm_xmm[127:96]) ∘ vfmsub132_single(%ymm1_vfmaddsub132ps_xmm_xmm_xmm[95:64], vfnmsub132_single(0x0₃₂ ⊕ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[95:64]) ⊕ (0x0₃₂ | 0x0₃₂ ⊕ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[95:64])), sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[95:64]), sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[95:64])), %ymm3_vfmaddsub132ps_xmm_xmm_xmm[95:64]) | 0x0₆₄ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[127:96]) ∘ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[95:64]) ⊕ (0x0₆₄ | 0x0₆₄ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[127:96]) ∘ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[95:64])))) ∘ (0x0₆₄ | (vfmsub132_single(%ymm1_vfmaddsub132ps_xmm_xmm_xmm[63:32], vfnmsub132_single(0x0₃₂ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[63:32]) ⊕ (0x0₃₂ | 0x0₃₂ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[63:32])), add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[63:32]), add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[63:32])), %ymm3_vfmaddsub132ps_xmm_xmm_xmm[63:32]) ∘ vfmsub132_single(%ymm1_vfmaddsub132ps_xmm_xmm_xmm[31:0], vfnmsub132_single(0x0₃₂ ⊕ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[31:0]) ⊕ (0x0₃₂ | 0x0₃₂ ⊕ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[31:0])), sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[31:0]), sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[31:0])), %ymm3_vfmaddsub132ps_xmm_xmm_xmm[31:0]) | 0x0₆₄ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[63:32]) ∘ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[31:0]) ⊕ (0x0₆₄ | 0x0₆₄ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[63:32]) ∘ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2_vfmaddsub132ps_xmm_xmm_xmm[31:0])))))

Final state
%ymm1: 0x0₁₂₈ ∘ ((0x0₆₄ | (vfmsub132_single(%ymm1[127:96], vfnmsub132_single(0x0₃₂ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[127:96]) ⊕ (0x0₃₂ | 0x0₃₂ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[127:96])), add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[127:96]), add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[127:96])), %ymm3[127:96]) ∘ vfmsub132_single(%ymm1[95:64], vfnmsub132_single(0x0₃₂ ⊕ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[95:64]) ⊕ (0x0₃₂ | 0x0₃₂ ⊕ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[95:64])), sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[95:64]), sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[95:64])), %ymm3[95:64]) | 0x0₆₄ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[127:96]) ∘ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[95:64]) ⊕ (0x0₆₄ | 0x0₆₄ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[127:96]) ∘ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[95:64])))) ∘ (0x0₆₄ | (vfmsub132_single(%ymm1[63:32], vfnmsub132_single(0x0₃₂ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[63:32]) ⊕ (0x0₃₂ | 0x0₃₂ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[63:32])), add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[63:32]), add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[63:32])), %ymm3[63:32]) ∘ vfmsub132_single(%ymm1[31:0], vfnmsub132_single(0x0₃₂ ⊕ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[31:0]) ⊕ (0x0₃₂ | 0x0₃₂ ⊕ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[31:0])), sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[31:0]), sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[31:0])), %ymm3[31:0]) | 0x0₆₄ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[63:32]) ∘ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[31:0]) ⊕ (0x0₆₄ | 0x0₆₄ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[63:32]) ∘ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[31:0])))))

=====================================
Circuits:

%ymm1  : 0x0₁₂₈ ∘ ((0x0₆₄ | (vfmsub132_single(%ymm1[127:96], vfnmsub132_single(0x0₃₂ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[127:96]) ⊕ (0x0₃₂ | 0x0₃₂ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[127:96])), add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[127:96]), add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[127:96])), %ymm3[127:96]) ∘ vfmsub132_single(%ymm1[95:64], vfnmsub132_single(0x0₃₂ ⊕ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[95:64]) ⊕ (0x0₃₂ | 0x0₃₂ ⊕ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[95:64])), sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[95:64]), sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[95:64])), %ymm3[95:64]) | 0x0₆₄ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[127:96]) ∘ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[95:64]) ⊕ (0x0₆₄ | 0x0₆₄ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[127:96]) ∘ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[95:64])))) ∘ (0x0₆₄ | (vfmsub132_single(%ymm1[63:32], vfnmsub132_single(0x0₃₂ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[63:32]) ⊕ (0x0₃₂ | 0x0₃₂ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[63:32])), add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[63:32]), add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[63:32])), %ymm3[63:32]) ∘ vfmsub132_single(%ymm1[31:0], vfnmsub132_single(0x0₃₂ ⊕ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[31:0]) ⊕ (0x0₃₂ | 0x0₃₂ ⊕ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[31:0])), sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[31:0]), sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[31:0])), %ymm3[31:0]) | 0x0₆₄ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[63:32]) ∘ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[31:0]) ⊕ (0x0₆₄ | 0x0₆₄ ⊕ add_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[63:32]) ∘ sub_single(vfnmsub132_single(0x0₃₂, 0x0₃₂, 0x0₃₂), %ymm2[31:0])))))

sigfpe  : sigfpe
sigbus  : sigbus
sigsegv : sigsegv

*/