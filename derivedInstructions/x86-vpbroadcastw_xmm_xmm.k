// Autogenerated using stratification.
requires "x86-configuration.k"

module VPBROADCASTW-XMM-XMM
  imports X86-CONFIGURATION

  rule <k>
    execinstr (vpbroadcastw R1:Xmm, R2:Xmm,  .Typedoperands) => .
  ...</k>
    <regstate>
RSMap:Map => updateMap(RSMap,
convToRegKeys(R2) |-> (concatenateMInt(mi(128, 0), concatenateMInt(concatenateMInt(concatenateMInt(extractMInt(getParentValue(R1, RSMap), 240, 256), extractMInt(getParentValue(R1, RSMap), 240, 256)), concatenateMInt(extractMInt(getParentValue(R1, RSMap), 240, 256), extractMInt(getParentValue(R1, RSMap), 240, 256))), concatenateMInt(concatenateMInt(extractMInt(getParentValue(R1, RSMap), 240, 256), extractMInt(getParentValue(R1, RSMap), 240, 256)), concatenateMInt(extractMInt(getParentValue(R1, RSMap), 240, 256), extractMInt(getParentValue(R1, RSMap), 240, 256))))) )


)

    </regstate>
endmodule

module VPBROADCASTW-XMM-XMM-SEMANTICS
  imports VPBROADCASTW-XMM-XMM
endmodule
/*
TargetInstr:
vpbroadcastw %xmm2, %xmm1
RWSet:
maybe read:{ %xmm2 }
must read:{ %xmm2 }
maybe write:{ %ymm1 }
must write:{ %ymm1 }
maybe undef:{ }
must undef:{ }
required flags:{ avx2 }

Circuit:
circuit:callq .move_128_032_xmm2_r10d_r11d_r12d_r13d  #  1     0     5      OPC=callq_label
circuit:callq .move_016_032_r10w_r11w_ebx             #  2     0x5   5      OPC=callq_label
circuit:callq .move_016_008_bx_r8b_r9b                #  3     0xa   5      OPC=callq_label
circuit:callq .move_r9b_to_byte_3_of_rbx              #  4     0xf   5      OPC=callq_label
circuit:vmovd %ebx, %xmm1                             #  5     0x14  4      OPC=vmovd_xmm_r32
circuit:callq .move_r9b_to_byte_19_of_ymm1            #  6     0x18  5      OPC=callq_label
circuit:callq .move_r8b_to_byte_2_of_ymm1             #  7     0x1d  5      OPC=callq_label
circuit:vbroadcastss %xmm1, %xmm1                     #  8     0x22  5      OPC=vbroadcastss_xmm_xmm
BVF:
WARNING: No live out values provided, assuming { }
WARNING: No def in values provided; assuming { %mxcsr::rc[0] }
Target

vpbroadcastw %xmm2, %xmm1

  maybe read:      { %xmm2 }
  must read:       { %xmm2 }
  maybe write:     { %ymm1 }
  must write:      { %ymm1 }
  maybe undef:     { }
  must undef:      { }
  required flags:  { avx2 }

-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vpbroadcastw_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_xmm_xmm

%xmm0: %ymm0_vpbroadcastw_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastw_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r10w_r11w_ebx

Final state:
%rax/%rax: %rax_vpbroadcastw_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_xmm_xmm

%xmm0: %ymm0_vpbroadcastw_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastw_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r8b_r9b

Final state:
%rax/%rax: %rax_vpbroadcastw_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_xmm_xmm

%xmm0: %ymm0_vpbroadcastw_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastw_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r9b_to_byte_3_of_rbx

Final state:
%rax/%rax: %rax_vpbroadcastw_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_xmm_xmm

%xmm0: %ymm0_vpbroadcastw_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastw_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r8b_r9b

Final state:
%rax/%rax: %rax_vmovd_xmm_r32
%rdx/%rdx: %rdx_vmovd_xmm_r32

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r8b_to_byte_0_of_ymm1

Final state:
%rax/%rax: %rax_vmovd_xmm_r32
%rdx/%rdx: %rdx_vmovd_xmm_r32

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r9b_to_byte_1_of_ymm1

Final state:
%rax/%rax: %rax_vmovd_xmm_r32
%rdx/%rdx: %rdx_vmovd_xmm_r32

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq $0x0, %rbx

Final state:
%rbx/%rbx: 0x0₆₄

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: %cf_movzbq_r64_r8

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for movsbq %cl, %rdi

Final state:
%rdi/%rdi: sign-extend-64(%rcx_movzbq_r64_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for adcb %dil, %bl

Final state:
%rbx/%bl: 0x0₆₄[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0][3:0] + 0x0₁ ∘ 0x0₆₄[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:7] = 0x1₁
%of: (sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0][7:7] = 0x1₁ ↔ 0x0₆₄[7:0][7:7] = 0x1₁) ∧ !(sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for movzbq %bl, %r8

.target:
movq $0x0, %rbx
clc 
movsbq %cl, %rdi
adcb %dil, %bl
retq 

Initial state:
%r8/%r8: %r8_xchgb_r8_r8

State for specgen instruction: movzbq %cl, %rbx:
%rbx/%rbx: 0x0₆₄[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0]

Register        -> %rbx
  translates to => %r8
Value is               -> 0x0₆₄[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0]
  after renaming it is => 0x0₅₆ ∘ %rbx_xchgb_r8_r8[7:0]

Final state
%r8/%r8: 0x0₅₆ ∘ %rbx_xchgb_r8_r8[7:0]

=====================================
-------------------------------------
Getting base circuit for movq $0x5, %rbx

Final state:
%rbx/%rbx: 0x5₆₄

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r12d_r13d

Final state:
%rax/%rax: %rax_movzbw_r16_r8
%rdx/%rdx: %rdx_movzbw_r16_r8

%xmm0: %ymm0_movzbw_r16_r8[127:0]
%xmm1: %ymm1_movzbw_r16_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movsbq %cl, %r12

Final state:
%r12/%r12: sign-extend-64(%rcx_movzbw_r16_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r12b_r13b_bx

Final state:
%rax/%rax: %rax_movzbw_r16_r8
%rdx/%rdx: %rdx_movzbw_r16_r8

%xmm0: %ymm0_movzbw_r16_r8[127:0]
%xmm1: %ymm1_movzbw_r16_r8[127:0]

-------------------------------------
=====================================
Computing circuit for movzbw %cl, %cx

.target:
movq $0x5, %rbx
callq .move_064_032_rbx_r12d_r13d
movsbq %cl, %r12
callq .move_008_016_r12b_r13b_bx
retq 

Initial state:
%rcx/%cx: %rcx_xchgb_r8_r8

State for specgen instruction: movzbw %cl, %bx:
%rbx/%bx: 0x5₆₄[63:16] ∘ ((0x0₃₂ ∘ 0x5₆₄[63:32])[7:0][7:0] ∘ sign-extend-64(%rcx_movzbw_r16_r8[7:0])[7:0][7:0])

Register        -> %bx
  translates to => %cx
Value is               -> (0x5₆₄[63:16] ∘ ((0x0₃₂ ∘ 0x5₆₄[63:32])[7:0][7:0] ∘ sign-extend-64(%rcx_movzbw_r16_r8[7:0])[7:0][7:0]))[15:0]
  after renaming it is => 0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]

Final state
%rcx/%cx: %rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0])

=====================================
-------------------------------------
Getting base circuit for movq $0x40, %rbx

Final state:
%rbx/%rbx: 0x40₆₄

-------------------------------------
-------------------------------------
Getting base circuit for movb %ah, %bl

Final state:
%rbx/%bl: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

-------------------------------------
=====================================
Computing circuit for movzbl %bh, %edx

.target:
movq $0x40, %rbx
movb %ah, %bl
retq 

Initial state:
%rdx/%rdx: %rdx_movb_rh_rh

State for specgen instruction: movzbl %ah, %ebx:
%rbx/%rbx: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

Register        -> %rbx
  translates to => %rdx
Value is               -> 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]
  after renaming it is => 0x0₅₆ ∘ %rbx_movb_rh_rh[15:8]

Final state
%rdx/%rdx: 0x0₅₆ ∘ %rbx_movb_rh_rh[15:8]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_032_rdx_r8d_r9d

Final state:
%rax/%rax: %rax_movb_rh_rh
%rdx/%rdx: 0x0₅₆ ∘ %rbx_movb_rh_rh[15:8]

%xmm0: %ymm0_movb_rh_rh[127:0]
%xmm1: %ymm1_movb_rh_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r8d_r9d_rcx

Final state:
%rax/%rax: %rax_movb_rh_rh
%rdx/%rdx: 0x0₅₆ ∘ %rbx_movb_rh_rh[15:8]

%xmm0: %ymm0_movb_rh_rh[127:0]
%xmm1: %ymm1_movb_rh_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movb %cl, %ah

Final state:
%rax/%ah: %rax_movb_rh_rh[63:16] ∘ ((0x0₃₂ ∘ (0x0₅₆ ∘ %rbx_movb_rh_rh[15:8])[63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ (0x0₅₆ ∘ %rbx_movb_rh_rh[15:8])[31:0])[31:0][31:0])[7:0] ∘ %rax_movb_rh_rh[7:0]

-------------------------------------
=====================================
Computing circuit for movb %ch, %bh

.target:
movzbl %bh, %edx
callq .move_064_032_rdx_r8d_r9d
callq .move_032_064_r8d_r9d_rcx
movb %cl, %ah
retq 

Initial state:
%rbx/%bh: %rbx_xchgb_r8_r8

State for specgen instruction: movb %bh, %ah:
%rax/%ah: %rax_movb_rh_rh[63:16] ∘ ((0x0₃₂ ∘ (0x0₅₆ ∘ %rbx_movb_rh_rh[15:8])[63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ (0x0₅₆ ∘ %rbx_movb_rh_rh[15:8])[31:0])[31:0][31:0])[7:0] ∘ %rax_movb_rh_rh[7:0]

Register        -> %ah
  translates to => %bh
Value is               -> (%rax_movb_rh_rh[63:16] ∘ ((0x0₃₂ ∘ (0x0₅₆ ∘ %rbx_movb_rh_rh[15:8])[63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ (0x0₅₆ ∘ %rbx_movb_rh_rh[15:8])[31:0])[31:0][31:0])[7:0] ∘ %rax_movb_rh_rh[7:0])[15:8]
  after renaming it is => 0x0₈

Final state
%rbx/%bh: %rbx_xchgb_r8_r8[63:16] ∘ 0x0₈ ∘ %rbx_xchgb_r8_r8[7:0]

=====================================
-------------------------------------
Getting base circuit for movq $0x40, %rbx

Final state:
%rbx/%rbx: 0x40₆₄

-------------------------------------
-------------------------------------
Getting base circuit for movb %ah, %bl

Final state:
%rbx/%bl: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

-------------------------------------
=====================================
Computing circuit for movzbl %ah, %edx

.target:
movq $0x40, %rbx
movb %ah, %bl
retq 

Initial state:
%rdx/%rdx: %rdx_xaddb_rh_r8

State for specgen instruction: movzbl %ah, %ebx:
%rbx/%rbx: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

Register        -> %rbx
  translates to => %rdx
Value is               -> 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]
  after renaming it is => 0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8]

Final state
%rdx/%rdx: 0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8]

=====================================
-------------------------------------
Getting base circuit for callq .clear_cf

Final state:
%rax/%rax: %rax_xaddb_r8_r8
%rdx/%rdx: %rdx_xaddb_r8_r8

%xmm0: %ymm0_xaddb_r8_r8[127:0]
%xmm1: %ymm1_xaddb_r8_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_of

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_of_into_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movsbq %cl, %r10

Final state:
%r10/%r10: sign-extend-64(%rcx_movsbl_r32_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
=====================================
Computing circuit for movsbl %cl, %r13d

.target:
callq .set_of
callq .read_of_into_rbx
callq .move_064_032_rbx_r10d_r11d
movsbq %cl, %r10
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r13/%r13: %r13_xaddb_r8_r8

State for specgen instruction: movsbl %cl, %ebx:
%rbx/%rbx: (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r13
Value is               -> (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0]

Final state
%r13/%r13: 0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0]

=====================================
-------------------------------------
Getting base circuit for callq .set_of

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_of_into_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movsbq %cl, %r10

Final state:
%r10/%r10: sign-extend-64(%rcx_movsbl_r32_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
=====================================
Computing circuit for movsbl %bl, %r15d

.target:
callq .set_of
callq .read_of_into_rbx
callq .move_064_032_rbx_r10d_r11d
movsbq %cl, %r10
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r15/%r15: %r15_xaddb_r8_r8

State for specgen instruction: movsbl %cl, %ebx:
%rbx/%rbx: (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r15
Value is               -> (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0]

Final state
%r15/%r15: 0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0]

=====================================
-------------------------------------
Getting base circuit for movsbq %r15b, %rcx

Final state:
%rcx/%rcx: sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for adcb %cl, %r13b

Final state:
%r13/%r13b: (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][3:0] + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁
%of: (sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][7:7] = 0x1₁) ∧ !(sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:7] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r13d, %rbx

Final state:
%rbx/%rbx: sign-extend-64(((0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0])[31:0])

-------------------------------------
=====================================
Computing circuit for xaddb %bl, %dl

.target:
callq .clear_cf
movsbl %cl, %r13d
movsbl %bl, %r15d
movsbq %r15b, %rcx
adcb %cl, %r13b
movslq %r13d, %rbx
retq 

Initial state:
%rdx/%dl: 0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8]
%rbx/%bl: %rbx_xaddb_rh_r8

%cf: %cf_xaddb_rh_r8
%pf: %pf_xaddb_rh_r8
%af: %af_xaddb_rh_r8
%zf: %zf_xaddb_rh_r8
%sf: %sf_xaddb_rh_r8
%of: %of_xaddb_rh_r8

State for specgen instruction: xaddb %cl, %bl:
%rcx/%cl: sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])
%rbx/%bl: sign-extend-64(((0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0])[31:0])

%cf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][3:0] + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁
%of: (sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][7:7] = 0x1₁) ∧ !(sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:7] = 0x1₁)

Final state
%rdx/%dl: (0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8])[63:8] ∘ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0]
%rbx/%bl: %rbx_xaddb_rh_r8[63:8] ∘ %rax_xaddb_rh_r8[15:8]

%cf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[8:8] = 0x1₁
%pf: !((0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rax_xaddb_rh_r8[11:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0] = 0x0₈
%sf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁
%of: (%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ %rbx_xaddb_rh_r8[7:7] = 0x1₁) ∧ !(%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for movb %dl, %ah

Final state:
%rax/%ah: %rax_xaddb_rh_r8[63:16] ∘ ((0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8])[63:8] ∘ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0])[7:0] ∘ %rax_xaddb_rh_r8[7:0]

-------------------------------------
=====================================
Computing circuit for xaddb %bl, %ch

.target:
movzbl %ah, %edx
xaddb %bl, %dl
movb %dl, %ah
retq 

Initial state:
%rcx/%ch: %rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0])
%rbx/%bl: %rbx_xchgb_r8_r8[63:16] ∘ 0x0₈ ∘ %rbx_xchgb_r8_r8[7:0]

%cf: %cf_xchgb_r8_r8
%pf: %pf_xchgb_r8_r8
%af: %af_xchgb_r8_r8
%zf: %zf_xchgb_r8_r8
%sf: %sf_xchgb_r8_r8
%of: %of_xchgb_r8_r8

State for specgen instruction: xaddb %bl, %ah:
%rax/%ah: %rax_xaddb_rh_r8[63:16] ∘ ((0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8])[63:8] ∘ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0])[7:0] ∘ %rax_xaddb_rh_r8[7:0]
%rbx/%bl: %rbx_xaddb_rh_r8[63:8] ∘ %rax_xaddb_rh_r8[15:8]

%cf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[8:8] = 0x1₁
%pf: !((0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rax_xaddb_rh_r8[11:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0] = 0x0₈
%sf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁
%of: (%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ %rbx_xaddb_rh_r8[7:7] = 0x1₁) ∧ !(%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)

Final state
%rcx/%ch: (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ %rbx_xchgb_r8_r8[7:0] ∘ (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[7:0]
%rbx/%bl: (%rbx_xchgb_r8_r8[63:16] ∘ 0x0₈ ∘ %rbx_xchgb_r8_r8[7:0])[63:8] ∘ 0x0₈

%cf: false
%pf: !(%rbx_xchgb_r8_r8[0:0] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[1:1] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[2:2] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[3:3] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[4:4] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[5:5] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[6:6] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[7:7] = 0x1₁)
%af: false
%zf: %rbx_xchgb_r8_r8[7:0] = 0x0₈
%sf: %rbx_xchgb_r8_r8[7:7] = 0x1₁
%of: (false ↔ %rbx_xchgb_r8_r8[7:7] = 0x1₁) ∧ !(false ↔ %rbx_xchgb_r8_r8[7:7] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r10b_r11b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_cx_r8b_r9b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r10b_r11b_cx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r8b_r9b_bx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for xchgw %cx, %bx

.target:
callq .move_016_008_bx_r10b_r11b
callq .move_016_008_cx_r8b_r9b
callq .move_008_016_r10b_r11b_cx
callq .move_008_016_r8b_r9b_bx
retq 

Initial state:
%rcx/%cx: %rcx_xaddw_r16_r16
%rbx/%bx: %rbx_xaddw_r16_r16

State for specgen instruction: xchgw %cx, %bx:
%rcx/%cx: %rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])
%rbx/%bx: %rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])

Register        -> %cx
  translates to => %cx
Value is               -> (%rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => %rbx_xaddw_r16_r16[15:0]

Register        -> %bx
  translates to => %bx
Value is               -> (%rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => %rcx_xaddw_r16_r16[15:0]

Final state
%rcx/%cx: %rcx_xaddw_r16_r16[63:16] ∘ %rbx_xaddw_r16_r16[15:0]
%rbx/%bx: %rbx_xaddw_r16_r16[63:16] ∘ %rcx_xaddw_r16_r16[15:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: %cf_addw_r16_r16

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for adcw %cx, %bx

Final state:
%rbx/%bx: %rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[16:16] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addw_r16_r16[15:0][3:0] + 0x0₁ ∘ %rbx_addw_r16_r16[15:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0] = 0x0₁₆
%sf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][15:15] = 0x1₁
%of: (%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ %rbx_addw_r16_r16[15:0][15:15] = 0x1₁) ∧ !(%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:15] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_bx

Final state:
%rax/%rax: %rax_addw_r16_r16
%rdx/%rdx: %rdx_addw_r16_r16

%xmm0: %ymm0_addw_r16_r16[127:0]
%xmm1: %ymm1_addw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for addw %cx, %bx

.target:
clc 
adcw %cx, %bx
callq .set_szp_for_bx
retq 

Initial state:
%rbx/%bx: %rbx_xaddw_r16_r16[63:16] ∘ %rcx_xaddw_r16_r16[15:0]

%cf: %cf_xaddw_r16_r16
%pf: %pf_xaddw_r16_r16
%af: %af_xaddw_r16_r16
%zf: %zf_xaddw_r16_r16
%sf: %sf_xaddw_r16_r16
%of: %of_xaddw_r16_r16

State for specgen instruction: addw %cx, %bx:
%rbx/%bx: %rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[16:16] = 0x1₁
%pf: !((%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addw_r16_r16[15:0][3:0] + 0x0₁ ∘ %rbx_addw_r16_r16[15:0][3:0])[4:4] = 0x1₁
%zf: (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0] = 0x0₁₆
%sf: (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][15:15] = 0x1₁
%of: (%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ %rbx_addw_r16_r16[15:0][15:15] = 0x1₁) ∧ !(%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:15] = 0x1₁)

Register        -> %bx
  translates to => %bx
Value is               -> (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0]
  after renaming it is => (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:0]

Final state
%rbx/%bx: (%rbx_xaddw_r16_r16[63:16] ∘ %rcx_xaddw_r16_r16[15:0])[63:16] ∘ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:0]

%cf: (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[16:16] = 0x1₁
%pf: !((0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rbx_xaddw_r16_r16[3:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:0] = 0x0₁₆
%sf: (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:15] = 0x1₁
%of: (%rbx_xaddw_r16_r16[15:15] = 0x1₁ ↔ %rcx_xaddw_r16_r16[15:15] = 0x1₁) ∧ !(%rbx_xaddw_r16_r16[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:15] = 0x1₁)

=====================================
=====================================
Computing circuit for xaddw %bx, %cx

.target:
xchgw %cx, %bx
addw %cx, %bx
retq 

Initial state:
%rcx/%cx: (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ %rbx_xchgb_r8_r8[7:0] ∘ (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[7:0]
%rbx/%bx: (%rbx_xchgb_r8_r8[63:16] ∘ 0x0₈ ∘ %rbx_xchgb_r8_r8[7:0])[63:8] ∘ 0x0₈

%cf: false
%pf: !(%rbx_xchgb_r8_r8[0:0] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[1:1] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[2:2] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[3:3] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[4:4] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[5:5] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[6:6] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[7:7] = 0x1₁)
%af: false
%zf: %rbx_xchgb_r8_r8[7:0] = 0x0₈
%sf: %rbx_xchgb_r8_r8[7:7] = 0x1₁
%of: (false ↔ %rbx_xchgb_r8_r8[7:7] = 0x1₁) ∧ !(false ↔ %rbx_xchgb_r8_r8[7:7] = 0x1₁)

State for specgen instruction: xaddw %cx, %bx:
%rcx/%cx: %rcx_xaddw_r16_r16[63:16] ∘ %rbx_xaddw_r16_r16[15:0]
%rbx/%bx: (%rbx_xaddw_r16_r16[63:16] ∘ %rcx_xaddw_r16_r16[15:0])[63:16] ∘ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:0]

%cf: (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[16:16] = 0x1₁
%pf: !((0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rbx_xaddw_r16_r16[3:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:0] = 0x0₁₆
%sf: (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:15] = 0x1₁
%of: (%rbx_xaddw_r16_r16[15:15] = 0x1₁ ↔ %rcx_xaddw_r16_r16[15:15] = 0x1₁) ∧ !(%rbx_xaddw_r16_r16[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:15] = 0x1₁)

Final state
%rcx/%cx: ((%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ %rbx_xchgb_r8_r8[7:0] ∘ (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[7:0])[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0])
%rbx/%bx: ((%rbx_xchgb_r8_r8[63:16] ∘ 0x0₈ ∘ %rbx_xchgb_r8_r8[7:0])[63:8] ∘ 0x0₈)[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0])

%cf: false
%pf: !(%rcx_xchgb_r8_r8[0:0] = 0x1₁ ⊕ %rcx_xchgb_r8_r8[1:1] = 0x1₁ ⊕ %rcx_xchgb_r8_r8[2:2] = 0x1₁ ⊕ %rcx_xchgb_r8_r8[3:3] = 0x1₁ ⊕ %rcx_xchgb_r8_r8[4:4] = 0x1₁ ⊕ %rcx_xchgb_r8_r8[5:5] = 0x1₁ ⊕ %rcx_xchgb_r8_r8[6:6] = 0x1₁ ⊕ %rcx_xchgb_r8_r8[7:7] = 0x1₁)
%af: false
%zf: %rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0] = 0x0₁₆
%sf: %rbx_xchgb_r8_r8[7:7] = 0x1₁
%of: (%rbx_xchgb_r8_r8[7:7] = 0x1₁ ↔ false) ∧ !(%rbx_xchgb_r8_r8[7:7] = 0x1₁ ↔ %rbx_xchgb_r8_r8[7:7] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r10b_r11b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_cx_r8b_r9b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r10b_r11b_cx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r8b_r9b_bx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for xchgw %cx, %r8w

.target:
callq .move_016_008_bx_r10b_r11b
callq .move_016_008_cx_r8b_r9b
callq .move_008_016_r10b_r11b_cx
callq .move_008_016_r8b_r9b_bx
retq 

Initial state:
%rcx/%cx: ((%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ %rbx_xchgb_r8_r8[7:0] ∘ (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[7:0])[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0])
%r8/%r8w: 0x0₅₆ ∘ %rbx_xchgb_r8_r8[7:0]

State for specgen instruction: xchgw %cx, %bx:
%rcx/%cx: %rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])
%rbx/%bx: %rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])

Register        -> %cx
  translates to => %cx
Value is               -> (%rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => 0x0₈ ∘ %rbx_xchgb_r8_r8[7:0]

Register        -> %bx
  translates to => %r8w
Value is               -> (%rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => %rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0]

Final state
%rcx/%cx: (((%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ %rbx_xchgb_r8_r8[7:0] ∘ (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[7:0])[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ (0x0₈ ∘ %rbx_xchgb_r8_r8[7:0])
%r8/%r8w: (0x0₅₆ ∘ %rbx_xchgb_r8_r8[7:0])[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0])

=====================================
=====================================
Computing circuit for xchgb %r8b, %bl

.target:
movzbq %bl, %r8
movzbw %cl, %cx
movb %ch, %bh
xaddb %bl, %ch
xaddw %bx, %cx
xchgw %cx, %r8w
retq 

Initial state:
%rbx/%bl: %rbx_vmovd_xmm_r32
%r8/%r8b: %r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0]

State for specgen instruction: xchgb %cl, %bl:
%rcx/%cl: (((%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ %rbx_xchgb_r8_r8[7:0] ∘ (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[7:0])[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ (0x0₈ ∘ %rbx_xchgb_r8_r8[7:0])
%rbx/%bl: ((%rbx_xchgb_r8_r8[63:16] ∘ 0x0₈ ∘ %rbx_xchgb_r8_r8[7:0])[63:8] ∘ 0x0₈)[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0])

Register        -> %cl
  translates to => %r8b
Value is               -> ((((%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ %rbx_xchgb_r8_r8[7:0] ∘ (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[7:0])[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ (0x0₈ ∘ %rbx_xchgb_r8_r8[7:0]))[7:0]
  after renaming it is => %rbx_vmovd_xmm_r32[7:0]

Register        -> %bl
  translates to => %bl
Value is               -> (((%rbx_xchgb_r8_r8[63:16] ∘ 0x0₈ ∘ %rbx_xchgb_r8_r8[7:0])[63:8] ∘ 0x0₈)[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0]))[7:0]
  after renaming it is => %rbx_vmovd_xmm_r32[7:0]

Final state
%rbx/%bl: %rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0]
%r8/%r8b: (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[63:8] ∘ %rbx_vmovd_xmm_r32[7:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_r9b_to_byte_3_of_ymm1

Final state:
%rax/%rax: %rax_vmovd_xmm_r32
%rdx/%rdx: %rdx_vmovd_xmm_r32

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ebx_r8w_r9w

Final state:
%rax/%rax: %rax_vmovd_xmm_r32
%rdx/%rdx: %rdx_vmovd_xmm_r32

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_3_of_rbx_to_r8b

Final state:
%rax/%rax: %rax_vmovd_xmm_r32
%rdx/%rdx: %rdx_vmovd_xmm_r32

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r9b_to_byte_2_of_ymm1

Final state:
%rax/%rax: %rax_vmovd_xmm_r32
%rdx/%rdx: %rdx_vmovd_xmm_r32

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[255:24] ∘ ((%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[63:16] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:0][31:16])[7:0] ∘ (((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[15:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r8b_to_byte_3_of_ymm1

Final state:
%rax/%rax: %rax_vmovd_xmm_r32
%rdx/%rdx: %rdx_vmovd_xmm_r32

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (((((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[255:24] ∘ ((%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[63:16] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:0][31:16])[7:0] ∘ (((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[15:0])[255:32] ∘ ((((%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[63:16] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:0][15:0])[63:8] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:24])[7:0] ∘ ((((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[255:24] ∘ ((%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[63:16] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:0][31:16])[7:0] ∘ (((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[15:0])[23:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovd %ebx, %xmm1

.target:
vzeroall 
callq .move_016_008_bx_r8b_r9b
callq .move_r8b_to_byte_0_of_ymm1
callq .move_r9b_to_byte_1_of_ymm1
xchgb %r8b, %bl
callq .move_r9b_to_byte_3_of_ymm1
callq .move_032_016_ebx_r8w_r9w
callq .move_byte_3_of_rbx_to_r8b
callq .move_r9b_to_byte_2_of_ymm1
callq .move_r8b_to_byte_3_of_ymm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastw_xmm_xmm

State for specgen instruction: vmovd %ebx, %xmm1:
%ymm1: ((((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[255:24] ∘ ((%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[63:16] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:0][31:16])[7:0] ∘ (((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[15:0])[255:32] ∘ ((((%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[63:16] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:0][15:0])[63:8] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:24])[7:0] ∘ ((((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[255:24] ∘ ((%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[63:16] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:0][31:16])[7:0] ∘ (((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[15:0])[23:0]

Final state
%ymm1: 0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_r9b_to_byte_19_of_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastw_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_xmm_xmm

%xmm0: %ymm0_vpbroadcastw_xmm_xmm[127:0]
%xmm1: ((0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[255:160] ∘ (%r9_vpbroadcastw_xmm_xmm[63:8] ∘ (0x0₃₂ ∘ ((0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][63:32])[15:0][15:0] ∘ (0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][31:0])[15:0][15:0]))[15:0][15:8])[7:0] ∘ (0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[151:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r8b_to_byte_2_of_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastw_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_xmm_xmm

%xmm0: %ymm0_vpbroadcastw_xmm_xmm[127:0]
%xmm1: (((0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[255:160] ∘ (%r9_vpbroadcastw_xmm_xmm[63:8] ∘ (0x0₃₂ ∘ ((0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][63:32])[15:0][15:0] ∘ (0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][31:0])[15:0][15:0]))[15:0][15:8])[7:0] ∘ (0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[151:0])[255:24] ∘ (%r8_vpbroadcastw_xmm_xmm[63:8] ∘ (0x0₃₂ ∘ ((0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][63:32])[15:0][15:0] ∘ (0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][31:0])[15:0][15:0]))[15:0][7:0])[7:0] ∘ ((0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[255:160] ∘ (%r9_vpbroadcastw_xmm_xmm[63:8] ∘ (0x0₃₂ ∘ ((0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][63:32])[15:0][15:0] ∘ (0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][31:0])[15:0][15:0]))[15:0][15:8])[7:0] ∘ (0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[151:0])[15:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm1, %xmm1

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm1: ((0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[255:160] ∘ (%r9_vpbroadcastw_xmm_xmm[63:8] ∘ (0x0₃₂ ∘ ((0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][63:32])[15:0][15:0] ∘ (0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][31:0])[15:0][15:0]))[15:0][15:8])[7:0] ∘ (0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[151:0])[255:24] ∘ (%r8_vpbroadcastw_xmm_xmm[63:8] ∘ (0x0₃₂ ∘ ((0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][63:32])[15:0][15:0] ∘ (0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][31:0])[15:0][15:0]))[15:0][7:0])[7:0] ∘ ((0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[255:160] ∘ (%r9_vpbroadcastw_xmm_xmm[63:8] ∘ (0x0₃₂ ∘ ((0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][63:32])[15:0][15:0] ∘ (0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][31:0])[15:0][15:0]))[15:0][15:8])[7:0] ∘ (0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[151:0])[15:0]

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ (%ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]) ∘ (%ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]) ∘ (%ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))

=====================================
=====================================
Computing circuit for vpbroadcastw %xmm2, %xmm1

.target:
callq .move_128_032_xmm2_r10d_r11d_r12d_r13d
callq .move_016_032_r10w_r11w_ebx
callq .move_016_008_bx_r8b_r9b
callq .move_r9b_to_byte_3_of_rbx
vmovd %ebx, %xmm1
callq .move_r9b_to_byte_19_of_ymm1
callq .move_r8b_to_byte_2_of_ymm1
vbroadcastss %xmm1, %xmm1
retq 

Initial state:
%ymm1: %ymm1

State for specgen instruction: vpbroadcastw %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ (%ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]) ∘ (%ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]) ∘ (%ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2[15:0] ∘ %ymm2[15:0] ∘ (%ymm2[15:0] ∘ %ymm2[15:0]) ∘ (%ymm2[15:0] ∘ %ymm2[15:0]) ∘ (%ymm2[15:0] ∘ %ymm2[15:0]))

=====================================
Circuits:

%ymm1  : 0x0₁₂₈ ∘ (%ymm2[15:0] ∘ %ymm2[15:0] ∘ (%ymm2[15:0] ∘ %ymm2[15:0]) ∘ (%ymm2[15:0] ∘ %ymm2[15:0]) ∘ (%ymm2[15:0] ∘ %ymm2[15:0]))

sigfpe  : sigfpe
sigbus  : sigbus
sigsegv : sigsegv

*/