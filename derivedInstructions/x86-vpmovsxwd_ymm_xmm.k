// Autogenerated using stratification.
requires "x86-configuration.k"

module VPMOVSXWD-YMM-XMM
  imports X86-CONFIGURATION

  rule <k>
    execinstr (vpmovsxwd R1:Xmm, R2:Ymm,  .Typedoperands) => .
  ...</k>
    <regstate>
RSMap:Map => updateMap(RSMap,
convToRegKeys(R2) |-> (concatenateMInt(concatenateMInt(addMInt(addMInt(xorMInt(mi(64, 18446744073709551615), concatenateMInt(concatenateMInt(mi(16, 0), extractMInt(getParentValue(R1, RSMap), 128, 144)), concatenateMInt(mi(16, 0), extractMInt(getParentValue(R1, RSMap), 144, 160)))), concatenateMInt(concatenateMInt(mi(16, 0), extractMInt(addMInt(concatenateMInt(extractMInt(getParentValue(R1, RSMap), 128, 160), extractMInt(getParentValue(R1, RSMap), 128, 160)), concatenateMInt(extractMInt(getParentValue(R1, RSMap), 128, 160), extractMInt(getParentValue(R1, RSMap), 128, 160))), 32, 48)), concatenateMInt(mi(16, 0), extractMInt(addMInt(concatenateMInt(extractMInt(getParentValue(R1, RSMap), 128, 160), extractMInt(getParentValue(R1, RSMap), 128, 160)), concatenateMInt(extractMInt(getParentValue(R1, RSMap), 128, 160), extractMInt(getParentValue(R1, RSMap), 128, 160))), 48, 64)))), mi(64, 1)), addMInt(addMInt(xorMInt(mi(64, 18446744073709551615), concatenateMInt(concatenateMInt(mi(16, 0), extractMInt(getParentValue(R1, RSMap), 160, 176)), concatenateMInt(mi(16, 0), extractMInt(getParentValue(R1, RSMap), 176, 192)))), concatenateMInt(concatenateMInt(mi(16, 0), extractMInt(addMInt(concatenateMInt(extractMInt(getParentValue(R1, RSMap), 160, 192), extractMInt(getParentValue(R1, RSMap), 160, 192)), concatenateMInt(extractMInt(getParentValue(R1, RSMap), 160, 192), extractMInt(getParentValue(R1, RSMap), 160, 192))), 32, 48)), concatenateMInt(mi(16, 0), extractMInt(addMInt(concatenateMInt(extractMInt(getParentValue(R1, RSMap), 160, 192), extractMInt(getParentValue(R1, RSMap), 160, 192)), concatenateMInt(extractMInt(getParentValue(R1, RSMap), 160, 192), extractMInt(getParentValue(R1, RSMap), 160, 192))), 48, 64)))), mi(64, 1))), concatenateMInt(addMInt(addMInt(xorMInt(mi(64, 18446744073709551615), concatenateMInt(concatenateMInt(mi(16, 0), extractMInt(getParentValue(R1, RSMap), 192, 208)), concatenateMInt(mi(16, 0), extractMInt(getParentValue(R1, RSMap), 208, 224)))), concatenateMInt(concatenateMInt(mi(16, 0), extractMInt(addMInt(concatenateMInt(extractMInt(getParentValue(R1, RSMap), 192, 224), extractMInt(getParentValue(R1, RSMap), 192, 224)), concatenateMInt(extractMInt(getParentValue(R1, RSMap), 192, 224), extractMInt(getParentValue(R1, RSMap), 192, 224))), 32, 48)), concatenateMInt(mi(16, 0), extractMInt(addMInt(concatenateMInt(extractMInt(getParentValue(R1, RSMap), 192, 224), extractMInt(getParentValue(R1, RSMap), 192, 224)), concatenateMInt(extractMInt(getParentValue(R1, RSMap), 192, 224), extractMInt(getParentValue(R1, RSMap), 192, 224))), 48, 64)))), mi(64, 1)), addMInt(addMInt(xorMInt(mi(64, 18446744073709551615), concatenateMInt(concatenateMInt(mi(16, 0), extractMInt(getParentValue(R1, RSMap), 224, 240)), concatenateMInt(mi(16, 0), extractMInt(getParentValue(R1, RSMap), 240, 256)))), concatenateMInt(concatenateMInt(mi(16, 0), extractMInt(addMInt(concatenateMInt(extractMInt(getParentValue(R1, RSMap), 224, 256), extractMInt(getParentValue(R1, RSMap), 224, 256)), concatenateMInt(extractMInt(getParentValue(R1, RSMap), 224, 256), extractMInt(getParentValue(R1, RSMap), 224, 256))), 32, 48)), concatenateMInt(mi(16, 0), extractMInt(addMInt(concatenateMInt(extractMInt(getParentValue(R1, RSMap), 224, 256), extractMInt(getParentValue(R1, RSMap), 224, 256)), concatenateMInt(extractMInt(getParentValue(R1, RSMap), 224, 256), extractMInt(getParentValue(R1, RSMap), 224, 256))), 48, 64)))), mi(64, 1)))) )


)

    </regstate>
endmodule

module VPMOVSXWD-YMM-XMM-SEMANTICS
  imports VPMOVSXWD-YMM-XMM
endmodule
/*
TargetInstr:
vpmovsxwd %xmm2, %ymm1
RWSet:
maybe read:{ %xmm2 }
must read:{ %xmm2 }
maybe write:{ %ymm1 }
must write:{ %ymm1 }
maybe undef:{ }
must undef:{ }
required flags:{ avx2 }

Circuit:
circuit:callq .move_128_64_xmm2_xmm12_xmm13   #  1     0     5      OPC=callq_label
circuit:vmovq %xmm12, %xmm11                  #  2     0x5   5      OPC=vmovq_xmm_xmm
circuit:pmovsxwd %xmm13, %xmm13               #  3     0xa   6      OPC=pmovsxwd_xmm_xmm
circuit:pmovsxwd %xmm11, %xmm12               #  4     0x10  6      OPC=pmovsxwd_xmm_xmm
circuit:callq .move_128_256_xmm12_xmm13_ymm3  #  5     0x16  5      OPC=callq_label
circuit:vmovaps %ymm3, %ymm1                  #  6     0x1b  4      OPC=vmovaps_ymm_ymm
BVF:
WARNING: No live out values provided, assuming { }
WARNING: No def in values provided; assuming { %mxcsr::rc[0] }
Target

vpmovsxwd %xmm2, %ymm1

  maybe read:      { %xmm2 }
  must read:       { %xmm2 }
  maybe write:     { %ymm1 }
  must write:      { %ymm1 }
  maybe undef:     { }
  must undef:      { }
  required flags:  { avx2 }

-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vpmovsxwd_ymm_xmm
%rdx/%rdx: %rdx_vpmovsxwd_ymm_xmm

%xmm0: %ymm0_vpmovsxwd_ymm_xmm[127:0]
%xmm1: %ymm1_vpmovsxwd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: %ymm0_vmovq_xmm_xmm[127:0]
%xmm1: %ymm1_vmovq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movswq %bx, %r10

Final state:
%r10/%r10: sign-extend-64(%rbx_xchgl_r32_r32[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_xchgl_r32_r32[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ecx_r8w_r9w

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %rcx

Final state:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r8w_r9w_ebx

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xchgl %ebx, %ecx

.target:
movswq %bx, %r10
movslq %ebx, %rbx
callq .move_032_016_ecx_r8w_r9w
callq .move_064_032_rbx_r10d_r11d
movq %r10, %rcx
callq .move_016_032_r8w_r9w_ebx
retq 

Initial state:
%rcx/%rcx: %rcx_xorl_r32_r32
%rbx/%rbx: %rbx_xorl_r32_r32

State for specgen instruction: xchgl %ecx, %ebx:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
%rbx/%rbx: 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])

Register        -> %rcx
  translates to => %rbx
Value is               -> 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
  after renaming it is => 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

Register        -> %rbx
  translates to => %rcx
Value is               -> 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])
  after renaming it is => 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

Final state
%rcx/%rcx: 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]) = 0x0₆₄
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_ebx

Final state:
%rax/%rax: %rax_xorl_r32_r32
%rdx/%rdx: %rdx_xorl_r32_r32

%xmm0: %ymm0_xorl_r32_r32[127:0]
%xmm1: %ymm1_xorl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xorl %r13d, %r13d

.target:
xchgl %ebx, %ecx
xorq %rcx, %rbx
callq .set_szp_for_ebx
retq 

Initial state:
%r13/%r13: %ymm2_vmovq_xmm_xmm[127:0][127:64]

%cf: %cf_vmovq_xmm_xmm
%pf: %pf_vmovq_xmm_xmm
%zf: %zf_vmovq_xmm_xmm
%sf: %sf_vmovq_xmm_xmm
%of: %of_vmovq_xmm_xmm

State for specgen instruction: xorl %ecx, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0] = 0x0₃₂
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][31:31] = 0x1₁
%of: false

Register        -> %rbx
  translates to => %r13
Value is               -> 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
  after renaming it is => 0x0₆₄

Final state
%r13/%r13: 0x0₆₄

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm12, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
xorl %r13d, %r13d
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vpmovsxwd_ymm_xmm

State for specgen instruction: vmovq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_vpmovsxwd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vmovsd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovsd_xmm_xmm_xmm

%xmm0: %ymm0_vmovsd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm3, %xmm13

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm13: %ymm13_vmovsd_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm13: 0x0₁₂₈ ∘ %ymm3_vmovsd_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm9, %xmm13, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsd_xmm_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsd_xmm_xmm_xmm[127:64] ∘ %ymm3_vmovsd_xmm_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovsd %xmm2, %xmm2, %xmm0

.target:
callq .move_128_64_xmm2_xmm8_xmm9
vmovapd %xmm3, %xmm13
vpunpcklqdq %xmm9, %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_pmovsxwd_xmm_xmm

State for specgen instruction: vmovsd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsd_xmm_xmm_xmm[127:64] ∘ %ymm3_vmovsd_xmm_xmm_xmm[63:0])

Final state
%ymm0: 0x0₁₂₈ ∘ %ymm2_pmovsxwd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm3, %xmm3, %xmm13

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm13: %ymm13_vmaxsd_xmm_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm13: 0x0₁₂₈ ∘ (%ymm3_vmaxsd_xmm_xmm_xmm[63:0] ∘ %ymm3_vmaxsd_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm6

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm6: %ymm6_vmaxsd_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm6: 0x0₁₂₈ ∘ %ymm2_vmaxsd_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxpd %ymm13, %ymm6, %ymm3

Final state:
%ymm3: (maxcmp_double((0x0₁₂₈ ∘ %ymm2_vmaxsd_xmm_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ (%ymm3_vmaxsd_xmm_xmm_xmm[63:0] ∘ %ymm3_vmaxsd_xmm_xmm_xmm[63:0]))[255:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxsd_xmm_xmm_xmm[127:0])[255:192] : (0x0₁₂₈ ∘ (%ymm3_vmaxsd_xmm_xmm_xmm[63:0] ∘ %ymm3_vmaxsd_xmm_xmm_xmm[63:0]))[255:192]) ∘ ((maxcmp_double((0x0₁₂₈ ∘ %ymm2_vmaxsd_xmm_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ (%ymm3_vmaxsd_xmm_xmm_xmm[63:0] ∘ %ymm3_vmaxsd_xmm_xmm_xmm[63:0]))[191:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxsd_xmm_xmm_xmm[127:0])[191:128] : (0x0₁₂₈ ∘ (%ymm3_vmaxsd_xmm_xmm_xmm[63:0] ∘ %ymm3_vmaxsd_xmm_xmm_xmm[63:0]))[191:128]) ∘ ((maxcmp_double((0x0₁₂₈ ∘ %ymm2_vmaxsd_xmm_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ (%ymm3_vmaxsd_xmm_xmm_xmm[63:0] ∘ %ymm3_vmaxsd_xmm_xmm_xmm[63:0]))[127:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxsd_xmm_xmm_xmm[127:0])[127:64] : (0x0₁₂₈ ∘ (%ymm3_vmaxsd_xmm_xmm_xmm[63:0] ∘ %ymm3_vmaxsd_xmm_xmm_xmm[63:0]))[127:64]) ∘ (maxcmp_double((0x0₁₂₈ ∘ %ymm2_vmaxsd_xmm_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ (%ymm3_vmaxsd_xmm_xmm_xmm[63:0] ∘ %ymm3_vmaxsd_xmm_xmm_xmm[63:0]))[63:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxsd_xmm_xmm_xmm[127:0])[63:0] : (0x0₁₂₈ ∘ (%ymm3_vmaxsd_xmm_xmm_xmm[63:0] ∘ %ymm3_vmaxsd_xmm_xmm_xmm[63:0]))[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vmovsd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovsd_xmm_xmm_xmm

%xmm0: %ymm0_vmovsd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm3, %xmm13

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm13: %ymm13_vmovsd_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm13: 0x0₁₂₈ ∘ %ymm3_vmovsd_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm9, %xmm13, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsd_xmm_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsd_xmm_xmm_xmm[127:64] ∘ %ymm3_vmovsd_xmm_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovsd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm8_xmm9
vmovapd %xmm3, %xmm13
vpunpcklqdq %xmm9, %xmm13, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxsd_xmm_xmm_xmm

State for specgen instruction: vmovsd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsd_xmm_xmm_xmm[127:64] ∘ %ymm3_vmovsd_xmm_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmaxsd_xmm_xmm_xmm[127:64] ∘ (maxcmp_double(%ymm2_vmaxsd_xmm_xmm_xmm[63:0], %ymm3_vmaxsd_xmm_xmm_xmm[63:0]) = 0x1₁ ? %ymm2_vmaxsd_xmm_xmm_xmm[63:0] : %ymm3_vmaxsd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmaxsd %xmm0, %xmm0, %xmm15

.target:
vpunpcklqdq %xmm3, %xmm3, %xmm13
vmovdqa %xmm2, %xmm6
vmaxpd %ymm13, %ymm6, %ymm3
vmovsd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm15: %ymm15_pmovsxwd_xmm_xmm

State for specgen instruction: vmaxsd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmaxsd_xmm_xmm_xmm[127:64] ∘ (maxcmp_double(%ymm2_vmaxsd_xmm_xmm_xmm[63:0], %ymm3_vmaxsd_xmm_xmm_xmm[63:0]) = 0x1₁ ? %ymm2_vmaxsd_xmm_xmm_xmm[63:0] : %ymm3_vmaxsd_xmm_xmm_xmm[63:0]))

Final state
%ymm15: 0x0₁₂₈ ∘ %ymm2_pmovsxwd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %ymm10

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm10: %ymm10_pmovzxwd_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm10: %ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0] ∘ (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm3, %xmm8

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm8: %ymm8_vminpd_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm8: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: %ymm0_vmovups_xmm_xmm[127:0]
%xmm1: %ymm1_vmovups_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovups %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminpd_xmm_xmm_xmm

State for specgen instruction: vmovups %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm8, %ymm1, %ymm1

Final state:
%ymm1: (mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[255:192], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[255:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[255:192] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[255:192]) ∘ ((mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[191:128], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[191:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[191:128] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[191:128]) ∘ ((mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[127:64], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[127:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[127:64] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[127:64]) ∘ (mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[63:0], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[63:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[63:0] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vminpd %xmm2, %xmm1, %xmm3

.target:
vmaxps %xmm3, %xmm3, %xmm8
vmovups %xmm2, %xmm1
vminpd %ymm8, %ymm1, %ymm1
retq 

Initial state:
%ymm3: %ymm3_minpd_xmm_xmm

State for specgen instruction: vminpd %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[255:192], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[255:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[255:192] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[255:192]) ∘ ((mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[191:128], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[191:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[191:128] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[191:128]) ∘ ((mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[127:64], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[127:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[127:64] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[127:64]) ∘ (mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[63:0], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[63:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[63:0] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[63:0])))

Final state
%ymm3: 0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm3_xmm8_xmm9

Final state:
%rax/%rax: %rax_minpd_xmm_xmm
%rdx/%rdx: %rdx_minpd_xmm_xmm

%xmm0: %ymm0_minpd_xmm_xmm[127:0]
%xmm1: %ymm1_minpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_minpd_xmm_xmm
%rdx/%rdx: %rdx_minpd_xmm_xmm

%xmm0: %ymm0_minpd_xmm_xmm[127:0]
%xmm1: (%ymm1_minpd_xmm_xmm[255:128] ∘ ((%ymm9_minpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0]))))[127:0][127:64]))[127:0][63:0] ∘ (%ymm8_minpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0]))))[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for minpd %xmm10, %xmm10

.target:
vminpd %xmm2, %xmm1, %xmm3
callq .move_128_64_xmm3_xmm8_xmm9
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0] ∘ (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0]))[127:0]

State for specgen instruction: minpd %xmm2, %xmm1:
%xmm1: (%ymm1_minpd_xmm_xmm[255:128] ∘ ((%ymm9_minpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0]))))[127:0][127:64]))[127:0][63:0] ∘ (%ymm8_minpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0]))))[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0] ∘ (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vpmovzxwd_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwd_xmm_xmm

%xmm0: %ymm0_vpmovzxwd_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: %ymm0_vpmovzxwq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r12d_r13d_rdx

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_edx_r10w_r11w

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxwq %xmm5, %xmm13

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_128_064_xmm2_r10_r11
callq .move_032_064_r12d_r13d_rdx
callq .move_032_016_edx_r10w_r11w
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm13: %ymm13_vpmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0])

Final state
%ymm13: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movddup_xmm_xmm
%rdx/%rdx: %rdx_movddup_xmm_xmm

%xmm0: %ymm0_movddup_xmm_xmm[127:0]
%xmm1: %ymm1_movddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r12, %r13

Final state:
%r13/%r13: %ymm2_movddup_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movddup_xmm_xmm
%rdx/%rdx: %rdx_movddup_xmm_xmm

%xmm0: %ymm0_movddup_xmm_xmm[127:0]
%xmm1: (%ymm1_movddup_xmm_xmm[255:128] ∘ (%ymm2_movddup_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_movddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movddup %xmm4, %xmm4

.target:
callq .move_128_064_xmm2_r12_r13
movq %r12, %r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm4: (%ymm4_vpmovzxwd_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[127:0][31:0]))[127:0]

State for specgen instruction: movddup %xmm2, %xmm1:
%xmm1: (%ymm1_movddup_xmm_xmm[255:128] ∘ (%ymm2_movddup_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_movddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm4: ((%ymm4_vpmovzxwd_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[127:0][31:0]))[255:128] ∘ (0x0₃₂ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:0] ∘ (0x0₃₂ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm3

Final state:
%rax/%rax: %rax_vpmovzxwd_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwd_xmm_xmm

%xmm0: %ymm0_vpmovzxwd_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: %ymm0_vpmovzxwq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r12d_r13d_rdx

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_edx_r10w_r11w

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxwq %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_128_064_xmm2_r10_r11
callq .move_032_064_r12d_r13d_rdx
callq .move_032_016_edx_r10w_r11w
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm3, %ymm6

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm6: %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm3, %xmm6, %xmm9

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm3, %xmm2, %xmm14

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm14: %ymm14_vpor_xmm_xmm_xmm

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpor_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vpor %xmm9, %xmm9, %xmm7

.target:
vorps %xmm3, %xmm2, %xmm14
vmovapd %xmm14, %xmm1
retq 

Initial state:
%ymm7: %ymm7_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpor %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

Final state
%ymm7: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm7, %xmm2

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpckldq_xmm_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm2: (%ymm2_vpunpckldq_xmm_xmm_xmm[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm1, %xmm3

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm3: %ymm3_mulpd_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm8: %ymm8_mulpd_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmulpd %ymm8, %ymm3, %ymm6

Final state:
%ymm6: mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[255:192]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[191:128]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[127:64]) ∘ mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_mulpd_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for mulpd %xmm3, %xmm2

.target:
vmovapd %xmm1, %xmm3
vmovaps %xmm2, %xmm8
vmulpd %ymm8, %ymm3, %ymm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vmulpd_xmm_xmm_xmm[127:0]

State for specgen instruction: mulpd %xmm2, %xmm1:
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vmulpd_xmm_xmm_xmm[255:128] ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmulpd_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmulpd %xmm6, %xmm2, %xmm12

.target:
mulpd %xmm3, %xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm12: %ymm12_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vmulpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]) ∘ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm12, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vpunpckldq %xmm2, %xmm1, %xmm8

.target:
vpbroadcastq %xmm3, %ymm6
vunpcklpd %xmm3, %xmm6, %xmm9
vpor %xmm9, %xmm9, %xmm7
unpcklps %xmm7, %xmm2
vmulpd %xmm6, %xmm2, %xmm12
vxorps %xmm12, %xmm2, %xmm1
movdqu %xmm2, %xmm1
retq 

Initial state:
%ymm8: %ymm8_hsubps_xmm_xmm

State for specgen instruction: vpunpckldq %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0]))

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm2

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm2: %ymm2_vunpckhps_xmm_xmm_xmm[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm2: (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpckhps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm9, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vunpckhps_xmm_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: %ymm0_vmovq_xmm_xmm[127:0]
%xmm1: %ymm1_vmovq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movswq %bx, %r10

Final state:
%r10/%r10: sign-extend-64(%rbx_xchgl_r32_r32[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_xchgl_r32_r32[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ecx_r8w_r9w

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %rcx

Final state:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r8w_r9w_ebx

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xchgl %ebx, %ecx

.target:
movswq %bx, %r10
movslq %ebx, %rbx
callq .move_032_016_ecx_r8w_r9w
callq .move_064_032_rbx_r10d_r11d
movq %r10, %rcx
callq .move_016_032_r8w_r9w_ebx
retq 

Initial state:
%rcx/%rcx: %rcx_xorl_r32_r32
%rbx/%rbx: %rbx_xorl_r32_r32

State for specgen instruction: xchgl %ecx, %ebx:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
%rbx/%rbx: 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])

Register        -> %rcx
  translates to => %rbx
Value is               -> 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
  after renaming it is => 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

Register        -> %rbx
  translates to => %rcx
Value is               -> 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])
  after renaming it is => 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

Final state
%rcx/%rcx: 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]) = 0x0₆₄
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_ebx

Final state:
%rax/%rax: %rax_xorl_r32_r32
%rdx/%rdx: %rdx_xorl_r32_r32

%xmm0: %ymm0_xorl_r32_r32[127:0]
%xmm1: %ymm1_xorl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xorl %r13d, %r13d

.target:
xchgl %ebx, %ecx
xorq %rcx, %rbx
callq .set_szp_for_ebx
retq 

Initial state:
%r13/%r13: %ymm2_vmovq_xmm_xmm[127:0][127:64]

%cf: %cf_vmovq_xmm_xmm
%pf: %pf_vmovq_xmm_xmm
%zf: %zf_vmovq_xmm_xmm
%sf: %sf_vmovq_xmm_xmm
%of: %of_vmovq_xmm_xmm

State for specgen instruction: xorl %ecx, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0] = 0x0₃₂
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][31:31] = 0x1₁
%of: false

Register        -> %rbx
  translates to => %r13
Value is               -> 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
  after renaming it is => 0x0₆₄

Final state
%r13/%r13: 0x0₆₄

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
xorl %r13d, %r13d
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][95:64])

State for specgen instruction: vmovq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhps %xmm2, %xmm1, %xmm10

.target:
unpckhpd %xmm3, %xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovddup %xmm9, %xmm1
vmovq %xmm1, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm10: %ymm10_hsubps_xmm_xmm

State for specgen instruction: vunpckhps %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[127:96] ∘ %ymm1_hsubps_xmm_xmm[127:96] ∘ %ymm2_hsubps_xmm_xmm[95:64] ∘ %ymm1_hsubps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm3, %ymm6

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm6: %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm3, %xmm6, %xmm9

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm3, %xmm2, %xmm14

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm14: %ymm14_vpor_xmm_xmm_xmm

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpor_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vpor %xmm9, %xmm9, %xmm7

.target:
vorps %xmm3, %xmm2, %xmm14
vmovapd %xmm14, %xmm1
retq 

Initial state:
%ymm7: %ymm7_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpor %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

Final state
%ymm7: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm7, %xmm2

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpckldq_xmm_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm2: (%ymm2_vpunpckldq_xmm_xmm_xmm[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm1, %xmm3

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm3: %ymm3_mulpd_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm8: %ymm8_mulpd_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmulpd %ymm8, %ymm3, %ymm6

Final state:
%ymm6: mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[255:192]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[191:128]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[127:64]) ∘ mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_mulpd_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for mulpd %xmm3, %xmm2

.target:
vmovapd %xmm1, %xmm3
vmovaps %xmm2, %xmm8
vmulpd %ymm8, %ymm3, %ymm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vmulpd_xmm_xmm_xmm[127:0]

State for specgen instruction: mulpd %xmm2, %xmm1:
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vmulpd_xmm_xmm_xmm[255:128] ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmulpd_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmulpd %xmm6, %xmm2, %xmm12

.target:
mulpd %xmm3, %xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm12: %ymm12_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vmulpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]) ∘ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm12, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vpunpckldq %xmm10, %xmm8, %xmm15

.target:
vpbroadcastq %xmm3, %ymm6
vunpcklpd %xmm3, %xmm6, %xmm9
vpor %xmm9, %xmm9, %xmm7
unpcklps %xmm7, %xmm2
vmulpd %xmm6, %xmm2, %xmm12
vxorps %xmm12, %xmm2, %xmm1
movdqu %xmm2, %xmm1
retq 

Initial state:
%ymm15: %ymm15_hsubps_xmm_xmm

State for specgen instruction: vpunpckldq %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0]))

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[95:64] ∘ %ymm2_hsubps_xmm_xmm[31:0] ∘ (%ymm1_hsubps_xmm_xmm[95:64] ∘ %ymm1_hsubps_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm2

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm2: %ymm2_vunpckhps_xmm_xmm_xmm[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm2: (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpckhps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm9, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vunpckhps_xmm_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: %ymm0_vmovq_xmm_xmm[127:0]
%xmm1: %ymm1_vmovq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movswq %bx, %r10

Final state:
%r10/%r10: sign-extend-64(%rbx_xchgl_r32_r32[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_xchgl_r32_r32[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ecx_r8w_r9w

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %rcx

Final state:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r8w_r9w_ebx

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xchgl %ebx, %ecx

.target:
movswq %bx, %r10
movslq %ebx, %rbx
callq .move_032_016_ecx_r8w_r9w
callq .move_064_032_rbx_r10d_r11d
movq %r10, %rcx
callq .move_016_032_r8w_r9w_ebx
retq 

Initial state:
%rcx/%rcx: %rcx_xorl_r32_r32
%rbx/%rbx: %rbx_xorl_r32_r32

State for specgen instruction: xchgl %ecx, %ebx:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
%rbx/%rbx: 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])

Register        -> %rcx
  translates to => %rbx
Value is               -> 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
  after renaming it is => 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

Register        -> %rbx
  translates to => %rcx
Value is               -> 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])
  after renaming it is => 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

Final state
%rcx/%rcx: 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]) = 0x0₆₄
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_ebx

Final state:
%rax/%rax: %rax_xorl_r32_r32
%rdx/%rdx: %rdx_xorl_r32_r32

%xmm0: %ymm0_xorl_r32_r32[127:0]
%xmm1: %ymm1_xorl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xorl %r13d, %r13d

.target:
xchgl %ebx, %ecx
xorq %rcx, %rbx
callq .set_szp_for_ebx
retq 

Initial state:
%r13/%r13: %ymm2_vmovq_xmm_xmm[127:0][127:64]

%cf: %cf_vmovq_xmm_xmm
%pf: %pf_vmovq_xmm_xmm
%zf: %zf_vmovq_xmm_xmm
%sf: %sf_vmovq_xmm_xmm
%of: %of_vmovq_xmm_xmm

State for specgen instruction: xorl %ecx, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0] = 0x0₃₂
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][31:31] = 0x1₁
%of: false

Register        -> %rbx
  translates to => %r13
Value is               -> 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
  after renaming it is => 0x0₆₄

Final state
%r13/%r13: 0x0₆₄

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
xorl %r13d, %r13d
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][95:64])

State for specgen instruction: vmovq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhps %xmm2, %xmm1, %xmm8

.target:
unpckhpd %xmm3, %xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovddup %xmm9, %xmm1
vmovq %xmm1, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_punpckhdq_xmm_xmm

State for specgen instruction: vunpckhps %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ %ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm8, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_punpckhdq_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_punpckhdq_xmm_xmm[255:128] ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ (%ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])))[127:0]

=====================================
=====================================
Computing circuit for punpckhdq %xmm10, %xmm8

.target:
vunpckhps %xmm2, %xmm1, %xmm8
movdqu %xmm8, %xmm1
retq 

Initial state:
%xmm8: (0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0])))[127:0]

State for specgen instruction: punpckhdq %xmm2, %xmm1:
%xmm1: (%ymm1_punpckhdq_xmm_xmm[255:128] ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ (%ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])))[127:0]

Final state
%xmm8: ((0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0])))[255:128] ∘ (%ymm2_hsubps_xmm_xmm[127:96] ∘ %ymm2_hsubps_xmm_xmm[63:32] ∘ (%ymm1_hsubps_xmm_xmm[127:96] ∘ %ymm1_hsubps_xmm_xmm[63:32])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm14

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm14: %ymm14_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm14: 0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminps %ymm1, %ymm14, %ymm1

Final state:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vminps %xmm2, %xmm2, %xmm5

.target:
vmovdqa %xmm3, %xmm1
vmovdqu %xmm2, %xmm14
vminps %ymm1, %ymm14, %ymm1
retq 

Initial state:
%ymm5: %ymm5_vsubps_xmm_xmm_xmm

State for specgen instruction: vminps %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm5: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_subps_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm14

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm14: %ymm14_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm14: 0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminps %ymm1, %ymm14, %ymm1

Final state:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vminps %xmm1, %xmm1, %xmm4

.target:
vmovdqa %xmm3, %xmm1
vmovdqu %xmm2, %xmm14
vminps %ymm1, %ymm14, %ymm1
retq 

Initial state:
%ymm4: %ymm4_subps_xmm_xmm

State for specgen instruction: vminps %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm4: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for vsubps %ymm10, %ymm4, %ymm2

Final state:
%ymm2: sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[255:224], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[255:224]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[223:192], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[223:192]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[191:160], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[191:160]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[159:128], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[159:128]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[127:96], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[127:96]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[95:64], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[95:64]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[63:32], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[63:32]) ∘ sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[31:0], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_subps_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_subps_xmm_xmm[255:128] ∘ (sub_single(%ymm1_subps_xmm_xmm[127:96], %ymm2_subps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_subps_xmm_xmm[95:64], %ymm2_subps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_subps_xmm_xmm[63:32], %ymm2_subps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_subps_xmm_xmm[31:0], %ymm2_subps_xmm_xmm[31:0])))))[127:0]

=====================================
=====================================
Computing circuit for subps %xmm3, %xmm5

.target:
vmovaps %xmm2, %xmm10
vminps %xmm1, %xmm1, %xmm4
vsubps %ymm10, %ymm4, %ymm2
movdqu %xmm2, %xmm1
retq 

Initial state:
%xmm5: (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0]))))[127:0]

State for specgen instruction: subps %xmm2, %xmm1:
%xmm1: (%ymm1_subps_xmm_xmm[255:128] ∘ (sub_single(%ymm1_subps_xmm_xmm[127:96], %ymm2_subps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_subps_xmm_xmm[95:64], %ymm2_subps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_subps_xmm_xmm[63:32], %ymm2_subps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_subps_xmm_xmm[31:0], %ymm2_subps_xmm_xmm[31:0])))))[127:0]

Final state
%xmm5: ((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0]))))[255:128] ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0])))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm5, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vsubps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0]))))

=====================================
=====================================
Computing circuit for vsubps %xmm8, %xmm15, %xmm4

.target:
vminps %xmm2, %xmm2, %xmm5
subps %xmm3, %xmm5
vmovdqu %xmm5, %xmm1
retq 

Initial state:
%ymm4: %ymm4_hsubps_xmm_xmm

State for specgen instruction: vsubps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0]))))

Final state
%ymm4: 0x0₁₂₈ ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm4, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_hsubps_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_hsubps_xmm_xmm[255:128] ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))[127:0]

=====================================
=====================================
Computing circuit for hsubps %xmm3, %xmm2

.target:
vpunpckldq %xmm2, %xmm1, %xmm8
vunpckhps %xmm2, %xmm1, %xmm10
vpunpckldq %xmm10, %xmm8, %xmm15
punpckhdq %xmm10, %xmm8
vsubps %xmm8, %xmm15, %xmm4
movdqu %xmm4, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vhsubps_xmm_xmm_xmm[127:0]

State for specgen instruction: hsubps %xmm2, %xmm1:
%xmm1: (%ymm1_hsubps_xmm_xmm[255:128] ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))[127:0]

Final state
%xmm2: (%ymm2_vhsubps_xmm_xmm_xmm[255:128] ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vhsubps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vhsubps_xmm_xmm_xmm

%xmm0: %ymm0_vhsubps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vhsubps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vhsubps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vhsubps_xmm_xmm_xmm

%xmm0: %ymm0_vhsubps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vhsubps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vhsubps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32])))

=====================================
=====================================
Computing circuit for vhsubps %xmm13, %xmm1, %xmm1

.target:
hsubps %xmm3, %xmm2
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm1: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0]))

State for specgen instruction: vhsubps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32])))

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0])))

=====================================
=====================================
Computing circuit for vpmovzxwd %xmm10, %xmm14

.target:
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7
vpmovzxwq %xmm5, %xmm13
movddup %xmm4, %xmm4
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm3
vpmovzxwq %xmm3, %xmm1
vhsubps %xmm13, %xmm1, %xmm1
retq 

Initial state:
%ymm14: %ymm14_pmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwd %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0])))

Final state
%ymm14: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[15:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_pmovzxwd_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_pmovzxwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[15:0]))))[127:0]

=====================================
=====================================
Computing circuit for pmovzxwd %xmm15, %xmm3

.target:
vpbroadcastq %xmm2, %ymm10
minpd %xmm10, %xmm10
vpmovzxwd %xmm10, %xmm14
movapd %xmm14, %xmm1
retq 

Initial state:
%xmm3: %ymm3_pmovsxwd_xmm_xmm[127:0]

State for specgen instruction: pmovzxwd %xmm2, %xmm1:
%xmm1: (%ymm1_pmovzxwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[15:0]))))[127:0]

Final state
%xmm3: (%ymm3_pmovsxwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[15:0]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm2

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm2: %ymm2_vunpckhps_xmm_xmm_xmm[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm2: (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpckhps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm9, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vunpckhps_xmm_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: %ymm0_vmovq_xmm_xmm[127:0]
%xmm1: %ymm1_vmovq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movswq %bx, %r10

Final state:
%r10/%r10: sign-extend-64(%rbx_xchgl_r32_r32[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_xchgl_r32_r32[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ecx_r8w_r9w

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %rcx

Final state:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r8w_r9w_ebx

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xchgl %ebx, %ecx

.target:
movswq %bx, %r10
movslq %ebx, %rbx
callq .move_032_016_ecx_r8w_r9w
callq .move_064_032_rbx_r10d_r11d
movq %r10, %rcx
callq .move_016_032_r8w_r9w_ebx
retq 

Initial state:
%rcx/%rcx: %rcx_xorl_r32_r32
%rbx/%rbx: %rbx_xorl_r32_r32

State for specgen instruction: xchgl %ecx, %ebx:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
%rbx/%rbx: 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])

Register        -> %rcx
  translates to => %rbx
Value is               -> 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
  after renaming it is => 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

Register        -> %rbx
  translates to => %rcx
Value is               -> 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])
  after renaming it is => 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

Final state
%rcx/%rcx: 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]) = 0x0₆₄
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_ebx

Final state:
%rax/%rax: %rax_xorl_r32_r32
%rdx/%rdx: %rdx_xorl_r32_r32

%xmm0: %ymm0_xorl_r32_r32[127:0]
%xmm1: %ymm1_xorl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xorl %r13d, %r13d

.target:
xchgl %ebx, %ecx
xorq %rcx, %rbx
callq .set_szp_for_ebx
retq 

Initial state:
%r13/%r13: %ymm2_vmovq_xmm_xmm[127:0][127:64]

%cf: %cf_vmovq_xmm_xmm
%pf: %pf_vmovq_xmm_xmm
%zf: %zf_vmovq_xmm_xmm
%sf: %sf_vmovq_xmm_xmm
%of: %of_vmovq_xmm_xmm

State for specgen instruction: xorl %ecx, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0] = 0x0₃₂
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][31:31] = 0x1₁
%of: false

Register        -> %rbx
  translates to => %r13
Value is               -> 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
  after renaming it is => 0x0₆₄

Final state
%r13/%r13: 0x0₆₄

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
xorl %r13d, %r13d
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][95:64])

State for specgen instruction: vmovq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhps %xmm1, %xmm2, %xmm10

.target:
unpckhpd %xmm3, %xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovddup %xmm9, %xmm1
vmovq %xmm1, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm10: %ymm10_paddd_xmm_xmm

State for specgen instruction: vunpckhps %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_paddd_xmm_xmm[127:96] ∘ %ymm2_paddd_xmm_xmm[127:96] ∘ %ymm1_paddd_xmm_xmm[95:64] ∘ %ymm2_paddd_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm2, %xmm1

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm1: %ymm1_paddd_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm1: (%ymm1_paddd_xmm_xmm[255:128] ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm1_paddd_xmm_xmm[63:32] ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm1_paddd_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_movshdup_xmm_xmm
%rdx/%rdx: %rdx_movshdup_xmm_xmm

%xmm0: %ymm0_movshdup_xmm_xmm[127:0]
%xmm1: %ymm1_movshdup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_movshdup_xmm_xmm
%rdx/%rdx: %rdx_movshdup_xmm_xmm

%xmm0: %ymm0_movshdup_xmm_xmm[127:0]
%xmm1: (%ymm1_movshdup_xmm_xmm[255:128] ∘ (%ymm2_movshdup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movshdup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovshdup_xmm_xmm
%rdx/%rdx: %rdx_vmovshdup_xmm_xmm

%xmm0: %ymm0_vmovshdup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovshdup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm11, %xmm11

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm11: %ymm11_vmovshdup_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovshdup_xmm_xmm[127:0][127:96])

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm11: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (%ymm2_vmovshdup_xmm_xmm[127:96] ∘ %ymm2_vmovshdup_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm11, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmovshdup_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (%ymm2_vmovshdup_xmm_xmm[127:96] ∘ %ymm2_vmovshdup_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm9, %xmm1

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovshdup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (%ymm2_vmovshdup_xmm_xmm[63:32] ∘ %ymm2_vmovshdup_xmm_xmm[63:32]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpcklpd_xmm_xmm
%rdx/%rdx: %rdx_unpcklpd_xmm_xmm

%xmm0: %ymm0_unpcklpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpcklpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm11: %ymm11_unpcklpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm1_unpcklpd_xmm_xmm[127:0][127:64])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_unpcklpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_unpcklpd_xmm_xmm
%rdx/%rdx: %rdx_unpcklpd_xmm_xmm

%xmm0: %ymm0_unpcklpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpcklpd_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ %ymm2_unpcklpd_xmm_xmm[127:0])[127:0][63:0] ∘ (%ymm10_unpcklpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm1_unpcklpd_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpcklpd %xmm3, %xmm1

.target:
callq .move_128_64_xmm1_xmm10_xmm11
vmovdqu %xmm2, %xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ (0x0₆₄ ∘ (%ymm2_vmovshdup_xmm_xmm[63:32] ∘ %ymm2_vmovshdup_xmm_xmm[63:32])))[127:0]

State for specgen instruction: unpcklpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklpd_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ %ymm2_unpcklpd_xmm_xmm[127:0])[127:0][63:0] ∘ (%ymm10_unpcklpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm1_unpcklpd_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ (0x0₆₄ ∘ (%ymm2_vmovshdup_xmm_xmm[63:32] ∘ %ymm2_vmovshdup_xmm_xmm[63:32])))[255:128] ∘ (%ymm2_vmovshdup_xmm_xmm[127:96] ∘ %ymm2_vmovshdup_xmm_xmm[127:96] ∘ (%ymm2_vmovshdup_xmm_xmm[63:32] ∘ %ymm2_vmovshdup_xmm_xmm[63:32])))[127:0]

=====================================
=====================================
Computing circuit for vmovshdup %xmm1, %xmm8

.target:
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovsldup %xmm11, %xmm11
vmovdqa %xmm11, %xmm3
vmovsldup %xmm9, %xmm1
unpcklpd %xmm3, %xmm1
retq 

Initial state:
%ymm8: %ymm8_movshdup_xmm_xmm

State for specgen instruction: vmovshdup %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₆₄ ∘ (%ymm2_vmovshdup_xmm_xmm[63:32] ∘ %ymm2_vmovshdup_xmm_xmm[63:32])))[255:128] ∘ (%ymm2_vmovshdup_xmm_xmm[127:96] ∘ %ymm2_vmovshdup_xmm_xmm[127:96] ∘ (%ymm2_vmovshdup_xmm_xmm[63:32] ∘ %ymm2_vmovshdup_xmm_xmm[63:32]))

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_movshdup_xmm_xmm[127:96] ∘ %ymm2_movshdup_xmm_xmm[127:96] ∘ (%ymm2_movshdup_xmm_xmm[63:32] ∘ %ymm2_movshdup_xmm_xmm[63:32]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_movaps_xmm_xmm
%rdx/%rdx: %rdx_movaps_xmm_xmm

%xmm0: %ymm0_movaps_xmm_xmm[127:0]
%xmm1: %ymm1_movaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1

Final state:
%rax/%rax: %rax_movaps_xmm_xmm
%rdx/%rdx: %rdx_movaps_xmm_xmm

%xmm0: %ymm0_movaps_xmm_xmm[127:0]
%xmm1: (%ymm1_movaps_xmm_xmm[255:128] ∘ ((%ymm7_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm6_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm5_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (%ymm4_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][31:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movaps %xmm8, %xmm1

.target:
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1
retq 

Initial state:
%xmm1: (%ymm1_movshdup_xmm_xmm[255:128] ∘ (%ymm2_movshdup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movshdup_xmm_xmm[127:0][63:0][63:0]))[127:0]

State for specgen instruction: movaps %xmm2, %xmm1:
%xmm1: (%ymm1_movaps_xmm_xmm[255:128] ∘ ((%ymm7_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm6_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm5_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (%ymm4_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][31:0]))[127:0][31:0]))[127:0]

Final state
%xmm1: ((%ymm1_movshdup_xmm_xmm[255:128] ∘ (%ymm2_movshdup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movshdup_xmm_xmm[127:0][63:0][63:0]))[255:128] ∘ (%ymm2_movshdup_xmm_xmm[127:96] ∘ %ymm2_movshdup_xmm_xmm[127:96] ∘ %ymm2_movshdup_xmm_xmm[63:32] ∘ %ymm2_movshdup_xmm_xmm[63:32]))[127:0]

=====================================
=====================================
Computing circuit for movshdup %xmm1, %xmm0

.target:
callq .move_128_064_xmm2_r10_r11
callq .move_064_128_r10_r11_xmm1
vmovshdup %xmm1, %xmm8
movaps %xmm8, %xmm1
retq 

Initial state:
%xmm0: %ymm0_phaddd_xmm_xmm[127:0]

State for specgen instruction: movshdup %xmm2, %xmm1:
%xmm1: ((%ymm1_movshdup_xmm_xmm[255:128] ∘ (%ymm2_movshdup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movshdup_xmm_xmm[127:0][63:0][63:0]))[255:128] ∘ (%ymm2_movshdup_xmm_xmm[127:96] ∘ %ymm2_movshdup_xmm_xmm[127:96] ∘ %ymm2_movshdup_xmm_xmm[63:32] ∘ %ymm2_movshdup_xmm_xmm[63:32]))[127:0]

Final state
%xmm0: (%ymm0_phaddd_xmm_xmm[255:128] ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_phaddd_xmm_xmm
%rdx/%rdx: %rdx_phaddd_xmm_xmm

%xmm0: (%ymm0_phaddd_xmm_xmm[255:128] ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]))[127:0]
%xmm1: %ymm1_phaddd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r8_r9

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r10, %r8

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r8/%r8: %ymm1_paddq_xmm_xmm[127:0][63:0]

%cf: %cf_paddq_xmm_xmm
%pf: %pf_paddq_xmm_xmm
%af: %af_paddq_xmm_xmm
%zf: %zf_paddq_xmm_xmm
%sf: %sf_paddq_xmm_xmm
%of: %of_paddq_xmm_xmm

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r8
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

Final state
%r8/%r8: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r10b_r11b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_cx_r8b_r9b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r10b_r11b_cx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r8b_r9b_bx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for xchgw %r8w, %r8w

.target:
callq .move_016_008_bx_r10b_r11b
callq .move_016_008_cx_r8b_r9b
callq .move_008_016_r10b_r11b_cx
callq .move_008_016_r8b_r9b_bx
retq 

Initial state:
%r8/%r8w: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

State for specgen instruction: xchgw %cx, %bx:
%rcx/%cx: %rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])
%rbx/%bx: %rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])

Register        -> %cx
  translates to => %r8w
Value is               -> (%rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Register        -> %bx
  translates to => %r8w
Value is               -> (%rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Final state
%r8/%r8w: ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

=====================================
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r11, %r9

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r9/%r9: %ymm1_paddq_xmm_xmm[127:0][127:64]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r9
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

Final state
%r9/%r9: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[67:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[67:64])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[127:127] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for paddq %xmm0, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
callq .move_128_064_xmm1_r8_r9
addq %r10, %r8
xchgw %r8w, %r8w
addq %r11, %r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_phaddd_xmm_xmm[127:0]

State for specgen instruction: paddq %xmm2, %xmm1:
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

Final state
%xmm1: (%ymm1_phaddd_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[63:0])[63:0]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r8_r9

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r10, %r8

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r8/%r8: %ymm1_paddq_xmm_xmm[127:0][63:0]

%cf: %cf_paddq_xmm_xmm
%pf: %pf_paddq_xmm_xmm
%af: %af_paddq_xmm_xmm
%zf: %zf_paddq_xmm_xmm
%sf: %sf_paddq_xmm_xmm
%of: %of_paddq_xmm_xmm

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r8
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

Final state
%r8/%r8: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r10b_r11b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_cx_r8b_r9b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r10b_r11b_cx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r8b_r9b_bx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for xchgw %r8w, %r8w

.target:
callq .move_016_008_bx_r10b_r11b
callq .move_016_008_cx_r8b_r9b
callq .move_008_016_r10b_r11b_cx
callq .move_008_016_r8b_r9b_bx
retq 

Initial state:
%r8/%r8w: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

State for specgen instruction: xchgw %cx, %bx:
%rcx/%cx: %rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])
%rbx/%bx: %rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])

Register        -> %cx
  translates to => %r8w
Value is               -> (%rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Register        -> %bx
  translates to => %r8w
Value is               -> (%rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Final state
%r8/%r8w: ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

=====================================
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r11, %r9

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r9/%r9: %ymm1_paddq_xmm_xmm[127:0][127:64]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r9
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

Final state
%r9/%r9: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[67:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[67:64])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[127:127] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for paddq %xmm2, %xmm3

.target:
callq .move_128_064_xmm2_r10_r11
callq .move_128_064_xmm1_r8_r9
addq %r10, %r8
xchgw %r8w, %r8w
addq %r11, %r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm3: %ymm3_vpaddq_xmm_xmm_xmm[127:0]

State for specgen instruction: paddq %xmm2, %xmm1:
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

Final state
%xmm3: (%ymm3_vpaddq_xmm_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: %ymm0_vmovups_xmm_xmm[127:0]
%xmm1: %ymm1_vmovups_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovups %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpaddq_xmm_xmm_xmm

State for specgen instruction: vmovups %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0])

=====================================
=====================================
Computing circuit for vpaddq %xmm9, %xmm2, %xmm6

.target:
paddq %xmm2, %xmm3
vmovups %xmm3, %xmm1
retq 

Initial state:
%ymm6: %ymm6_phaddd_xmm_xmm

State for specgen instruction: vpaddq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0])

Final state
%ymm6: 0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_phaddd_xmm_xmm[127:64] + 0x0₁ ∘ 0x0₆₄)[63:0] ∘ (0x0₁ ∘ %ymm2_phaddd_xmm_xmm[63:0] + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[63:32]))[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm9, %xmm1, %xmm4

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm4: %ymm4_phaddd_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm4: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[63:32] ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[63:0])[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vmovhlps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovhlps_xmm_xmm_xmm

%xmm0: %ymm0_vmovhlps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vmovhlps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovhlps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovhlps_xmm_xmm_xmm

%xmm0: %ymm0_vmovhlps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vmovhlps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r11, %r12

Final state:
%r12/%r12: %ymm3_vmovhlps_xmm_xmm_xmm[127:0][127:64]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovhlps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovhlps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovhlps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmovhlps_xmm_xmm_xmm[127:0][127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovhlps %xmm1, %xmm8, %xmm5

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r12_r13
vzeroall 
movq %r11, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm5: %ymm5_phaddd_xmm_xmm

State for specgen instruction: vmovhlps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovhlps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmovhlps_xmm_xmm_xmm[127:0][127:64][63:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[127:64])[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r8_r9

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r10, %r8

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r8/%r8: %ymm1_paddq_xmm_xmm[127:0][63:0]

%cf: %cf_paddq_xmm_xmm
%pf: %pf_paddq_xmm_xmm
%af: %af_paddq_xmm_xmm
%zf: %zf_paddq_xmm_xmm
%sf: %sf_paddq_xmm_xmm
%of: %of_paddq_xmm_xmm

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r8
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

Final state
%r8/%r8: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r10b_r11b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_cx_r8b_r9b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r10b_r11b_cx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r8b_r9b_bx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for xchgw %r8w, %r8w

.target:
callq .move_016_008_bx_r10b_r11b
callq .move_016_008_cx_r8b_r9b
callq .move_008_016_r10b_r11b_cx
callq .move_008_016_r8b_r9b_bx
retq 

Initial state:
%r8/%r8w: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

State for specgen instruction: xchgw %cx, %bx:
%rcx/%cx: %rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])
%rbx/%bx: %rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])

Register        -> %cx
  translates to => %r8w
Value is               -> (%rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Register        -> %bx
  translates to => %r8w
Value is               -> (%rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Final state
%r8/%r8w: ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

=====================================
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r11, %r9

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r9/%r9: %ymm1_paddq_xmm_xmm[127:0][127:64]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r9
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

Final state
%r9/%r9: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[67:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[67:64])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[127:127] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for paddq %xmm2, %xmm3

.target:
callq .move_128_064_xmm2_r10_r11
callq .move_128_064_xmm1_r8_r9
addq %r10, %r8
xchgw %r8w, %r8w
addq %r11, %r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm3: %ymm3_vpaddq_xmm_xmm_xmm[127:0]

State for specgen instruction: paddq %xmm2, %xmm1:
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

Final state
%xmm3: (%ymm3_vpaddq_xmm_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: %ymm0_vmovups_xmm_xmm[127:0]
%xmm1: %ymm1_vmovups_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovups %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpaddq_xmm_xmm_xmm

State for specgen instruction: vmovups %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0])

=====================================
=====================================
Computing circuit for vpaddq %xmm10, %xmm11, %xmm7

.target:
paddq %xmm2, %xmm3
vmovups %xmm3, %xmm1
retq 

Initial state:
%ymm7: %ymm7_phaddd_xmm_xmm

State for specgen instruction: vpaddq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0])

Final state
%ymm7: 0x0₁₂₈ ∘ ((0x0₁ ∘ 0x0₆₄ + 0x0₁ ∘ 0x0₆₄)[63:0] ∘ (0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[95:64]))[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1

Final state:
%rax/%rax: %rax_phaddd_xmm_xmm
%rdx/%rdx: %rdx_phaddd_xmm_xmm

%xmm0: (%ymm0_phaddd_xmm_xmm[255:128] ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]))[127:0]
%xmm1: ((%ymm1_phaddd_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[63:0])[63:0]))[255:128] ∘ ((0x0₁₂₈ ∘ ((0x0₁ ∘ 0x0₆₄ + 0x0₁ ∘ 0x0₆₄)[63:0] ∘ (0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[95:64]))[63:0]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_phaddd_xmm_xmm[127:64] + 0x0₁ ∘ 0x0₆₄)[63:0] ∘ (0x0₁ ∘ %ymm2_phaddd_xmm_xmm[63:0] + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[63:32]))[63:0]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[127:64])[63:0]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[63:32] ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[63:0])[63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for phaddd %xmm10, %xmm1

.target:
movshdup %xmm1, %xmm0
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
paddq %xmm0, %xmm1
vpaddq %xmm9, %xmm2, %xmm6
vunpcklpd %xmm9, %xmm1, %xmm4
vmovhlps %xmm1, %xmm8, %xmm5
vpaddq %xmm10, %xmm11, %xmm7
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1
retq 

Initial state:
%xmm1: (%ymm1_paddd_xmm_xmm[255:128] ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm1_paddd_xmm_xmm[63:32] ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm1_paddd_xmm_xmm[31:0])))[127:0]

State for specgen instruction: phaddd %xmm2, %xmm1:
%xmm1: ((%ymm1_phaddd_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[63:0])[63:0]))[255:128] ∘ ((0x0₁₂₈ ∘ ((0x0₁ ∘ 0x0₆₄ + 0x0₁ ∘ 0x0₆₄)[63:0] ∘ (0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[95:64]))[63:0]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_phaddd_xmm_xmm[127:64] + 0x0₁ ∘ 0x0₆₄)[63:0] ∘ (0x0₁ ∘ %ymm2_phaddd_xmm_xmm[63:0] + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[63:32]))[63:0]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[127:64])[63:0]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[63:32] ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[63:0])[63:0]))[127:0][31:0]))[127:0]

Final state
%xmm1: ((%ymm1_paddd_xmm_xmm[255:128] ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm1_paddd_xmm_xmm[63:32] ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm1_paddd_xmm_xmm[31:0])))[255:128] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm1_paddd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_paddd_xmm_xmm[127:96]))[31:0] ∘ (0x0₁ ∘ (%ymm1_paddd_xmm_xmm[95:64] ∘ %ymm2_paddd_xmm_xmm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm1_paddd_xmm_xmm[95:64]))[31:0] ∘ (0x0₁ ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm2_paddd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm1_paddd_xmm_xmm[63:32]))[31:0] ∘ (0x0₁ ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm2_paddd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm1_paddd_xmm_xmm[31:0]))[31:0]))[127:0]

=====================================
=====================================
Computing circuit for paddd %xmm3, %xmm2

.target:
vunpckhps %xmm1, %xmm2, %xmm10
unpcklps %xmm2, %xmm1
phaddd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpaddd_xmm_xmm_xmm[127:0]

State for specgen instruction: paddd %xmm2, %xmm1:
%xmm1: ((%ymm1_paddd_xmm_xmm[255:128] ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm1_paddd_xmm_xmm[63:32] ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm1_paddd_xmm_xmm[31:0])))[255:128] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm1_paddd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_paddd_xmm_xmm[127:96]))[31:0] ∘ (0x0₁ ∘ (%ymm1_paddd_xmm_xmm[95:64] ∘ %ymm2_paddd_xmm_xmm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm1_paddd_xmm_xmm[95:64]))[31:0] ∘ (0x0₁ ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm2_paddd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm1_paddd_xmm_xmm[63:32]))[31:0] ∘ (0x0₁ ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm2_paddd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm1_paddd_xmm_xmm[31:0]))[31:0]))[127:0]

Final state
%xmm2: (%ymm2_vpaddd_xmm_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_xmm_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm3_vpaddd_xmm_xmm_xmm[127:96]))[31:0] ∘ (0x0₁ ∘ (%ymm2_vpaddd_xmm_xmm_xmm[95:64] ∘ %ymm3_vpaddd_xmm_xmm_xmm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_xmm_xmm_xmm[95:64]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[63:32] ∘ %ymm3_vpaddd_xmm_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[63:32] ∘ %ymm2_vpaddd_xmm_xmm_xmm[63:32]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[31:0] ∘ %ymm3_vpaddd_xmm_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[31:0] ∘ %ymm2_vpaddd_xmm_xmm_xmm[31:0]))[31:0]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpaddd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpaddd_xmm_xmm_xmm

%xmm0: %ymm0_vpaddd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpaddd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vpaddd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpaddd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vpaddd_xmm_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_xmm_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm3_vpaddd_xmm_xmm_xmm[127:96]))[31:0] ∘ (0x0₁ ∘ (%ymm2_vpaddd_xmm_xmm_xmm[95:64] ∘ %ymm3_vpaddd_xmm_xmm_xmm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_xmm_xmm_xmm[95:64]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[63:32] ∘ %ymm3_vpaddd_xmm_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[63:32] ∘ %ymm2_vpaddd_xmm_xmm_xmm[63:32]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[31:0] ∘ %ymm3_vpaddd_xmm_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[31:0] ∘ %ymm2_vpaddd_xmm_xmm_xmm[31:0]))[31:0]))[127:0][127:64][63:0] ∘ (%ymm2_vpaddd_xmm_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_xmm_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm3_vpaddd_xmm_xmm_xmm[127:96]))[31:0] ∘ (0x0₁ ∘ (%ymm2_vpaddd_xmm_xmm_xmm[95:64] ∘ %ymm3_vpaddd_xmm_xmm_xmm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_xmm_xmm_xmm[95:64]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[63:32] ∘ %ymm3_vpaddd_xmm_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[63:32] ∘ %ymm2_vpaddd_xmm_xmm_xmm[63:32]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[31:0] ∘ %ymm3_vpaddd_xmm_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[31:0] ∘ %ymm2_vpaddd_xmm_xmm_xmm[31:0]))[31:0]))[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpaddd %xmm2, %xmm2, %xmm2

.target:
paddd %xmm3, %xmm2
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm2: %ymm2_pmovsxwd_xmm_xmm

State for specgen instruction: vpaddd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vpaddd_xmm_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_xmm_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm3_vpaddd_xmm_xmm_xmm[127:96]))[31:0] ∘ (0x0₁ ∘ (%ymm2_vpaddd_xmm_xmm_xmm[95:64] ∘ %ymm3_vpaddd_xmm_xmm_xmm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_xmm_xmm_xmm[95:64]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[63:32] ∘ %ymm3_vpaddd_xmm_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[63:32] ∘ %ymm2_vpaddd_xmm_xmm_xmm[63:32]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[31:0] ∘ %ymm3_vpaddd_xmm_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[31:0] ∘ %ymm2_vpaddd_xmm_xmm_xmm[31:0]))[31:0]))[127:0][127:64][63:0] ∘ (%ymm2_vpaddd_xmm_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_xmm_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm3_vpaddd_xmm_xmm_xmm[127:96]))[31:0] ∘ (0x0₁ ∘ (%ymm2_vpaddd_xmm_xmm_xmm[95:64] ∘ %ymm3_vpaddd_xmm_xmm_xmm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_xmm_xmm_xmm[95:64]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[63:32] ∘ %ymm3_vpaddd_xmm_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[63:32] ∘ %ymm2_vpaddd_xmm_xmm_xmm[63:32]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[31:0] ∘ %ymm3_vpaddd_xmm_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[31:0] ∘ %ymm2_vpaddd_xmm_xmm_xmm[31:0]))[31:0]))[127:0][63:0][63:0])

Final state
%ymm2: 0x0₁₂₈ ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm2_pmovsxwd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_pmovsxwd_xmm_xmm[127:96]))[31:0] ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[95:64] ∘ %ymm2_pmovsxwd_xmm_xmm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_pmovsxwd_xmm_xmm[95:64]))[31:0] ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]))[31:0] ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vpmovzxwd_ymm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ %ymm2_vpmovzxwd_ymm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vpmovzxwd_ymm_xmm
%rdx/%rdx: %rdx_vpmovzxwd_ymm_xmm

%xmm0: %ymm0_vpmovzxwd_ymm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vpmovzxwd_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwd_xmm_xmm

%xmm0: %ymm0_vpmovzxwd_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: %ymm0_vpmovzxwq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r12d_r13d_rdx

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_edx_r10w_r11w

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxwq %xmm5, %xmm13

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_128_064_xmm2_r10_r11
callq .move_032_064_r12d_r13d_rdx
callq .move_032_016_edx_r10w_r11w
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm13: %ymm13_vpmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0])

Final state
%ymm13: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movddup_xmm_xmm
%rdx/%rdx: %rdx_movddup_xmm_xmm

%xmm0: %ymm0_movddup_xmm_xmm[127:0]
%xmm1: %ymm1_movddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r12, %r13

Final state:
%r13/%r13: %ymm2_movddup_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movddup_xmm_xmm
%rdx/%rdx: %rdx_movddup_xmm_xmm

%xmm0: %ymm0_movddup_xmm_xmm[127:0]
%xmm1: (%ymm1_movddup_xmm_xmm[255:128] ∘ (%ymm2_movddup_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_movddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movddup %xmm4, %xmm4

.target:
callq .move_128_064_xmm2_r12_r13
movq %r12, %r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm4: (%ymm4_vpmovzxwd_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[127:0][31:0]))[127:0]

State for specgen instruction: movddup %xmm2, %xmm1:
%xmm1: (%ymm1_movddup_xmm_xmm[255:128] ∘ (%ymm2_movddup_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_movddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm4: ((%ymm4_vpmovzxwd_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[127:0][31:0]))[255:128] ∘ (0x0₃₂ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:0] ∘ (0x0₃₂ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm3

Final state:
%rax/%rax: %rax_vpmovzxwd_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwd_xmm_xmm

%xmm0: %ymm0_vpmovzxwd_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: %ymm0_vpmovzxwq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r12d_r13d_rdx

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_edx_r10w_r11w

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxwq %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_128_064_xmm2_r10_r11
callq .move_032_064_r12d_r13d_rdx
callq .move_032_016_edx_r10w_r11w
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm3, %ymm6

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm6: %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm3, %xmm6, %xmm9

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm3, %xmm2, %xmm14

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm14: %ymm14_vpor_xmm_xmm_xmm

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpor_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vpor %xmm9, %xmm9, %xmm7

.target:
vorps %xmm3, %xmm2, %xmm14
vmovapd %xmm14, %xmm1
retq 

Initial state:
%ymm7: %ymm7_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpor %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

Final state
%ymm7: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm7, %xmm2

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpckldq_xmm_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm2: (%ymm2_vpunpckldq_xmm_xmm_xmm[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm1, %xmm3

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm3: %ymm3_mulpd_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm8: %ymm8_mulpd_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmulpd %ymm8, %ymm3, %ymm6

Final state:
%ymm6: mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[255:192]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[191:128]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[127:64]) ∘ mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_mulpd_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for mulpd %xmm3, %xmm2

.target:
vmovapd %xmm1, %xmm3
vmovaps %xmm2, %xmm8
vmulpd %ymm8, %ymm3, %ymm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vmulpd_xmm_xmm_xmm[127:0]

State for specgen instruction: mulpd %xmm2, %xmm1:
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vmulpd_xmm_xmm_xmm[255:128] ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmulpd_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmulpd %xmm6, %xmm2, %xmm12

.target:
mulpd %xmm3, %xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm12: %ymm12_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vmulpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]) ∘ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm12, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vpunpckldq %xmm2, %xmm1, %xmm8

.target:
vpbroadcastq %xmm3, %ymm6
vunpcklpd %xmm3, %xmm6, %xmm9
vpor %xmm9, %xmm9, %xmm7
unpcklps %xmm7, %xmm2
vmulpd %xmm6, %xmm2, %xmm12
vxorps %xmm12, %xmm2, %xmm1
movdqu %xmm2, %xmm1
retq 

Initial state:
%ymm8: %ymm8_hsubps_xmm_xmm

State for specgen instruction: vpunpckldq %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0]))

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm2

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm2: %ymm2_vunpckhps_xmm_xmm_xmm[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm2: (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpckhps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm9, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vunpckhps_xmm_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: %ymm0_vmovq_xmm_xmm[127:0]
%xmm1: %ymm1_vmovq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movswq %bx, %r10

Final state:
%r10/%r10: sign-extend-64(%rbx_xchgl_r32_r32[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_xchgl_r32_r32[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ecx_r8w_r9w

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %rcx

Final state:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r8w_r9w_ebx

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xchgl %ebx, %ecx

.target:
movswq %bx, %r10
movslq %ebx, %rbx
callq .move_032_016_ecx_r8w_r9w
callq .move_064_032_rbx_r10d_r11d
movq %r10, %rcx
callq .move_016_032_r8w_r9w_ebx
retq 

Initial state:
%rcx/%rcx: %rcx_xorl_r32_r32
%rbx/%rbx: %rbx_xorl_r32_r32

State for specgen instruction: xchgl %ecx, %ebx:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
%rbx/%rbx: 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])

Register        -> %rcx
  translates to => %rbx
Value is               -> 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
  after renaming it is => 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

Register        -> %rbx
  translates to => %rcx
Value is               -> 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])
  after renaming it is => 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

Final state
%rcx/%rcx: 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]) = 0x0₆₄
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_ebx

Final state:
%rax/%rax: %rax_xorl_r32_r32
%rdx/%rdx: %rdx_xorl_r32_r32

%xmm0: %ymm0_xorl_r32_r32[127:0]
%xmm1: %ymm1_xorl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xorl %r13d, %r13d

.target:
xchgl %ebx, %ecx
xorq %rcx, %rbx
callq .set_szp_for_ebx
retq 

Initial state:
%r13/%r13: %ymm2_vmovq_xmm_xmm[127:0][127:64]

%cf: %cf_vmovq_xmm_xmm
%pf: %pf_vmovq_xmm_xmm
%zf: %zf_vmovq_xmm_xmm
%sf: %sf_vmovq_xmm_xmm
%of: %of_vmovq_xmm_xmm

State for specgen instruction: xorl %ecx, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0] = 0x0₃₂
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][31:31] = 0x1₁
%of: false

Register        -> %rbx
  translates to => %r13
Value is               -> 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
  after renaming it is => 0x0₆₄

Final state
%r13/%r13: 0x0₆₄

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
xorl %r13d, %r13d
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][95:64])

State for specgen instruction: vmovq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhps %xmm2, %xmm1, %xmm10

.target:
unpckhpd %xmm3, %xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovddup %xmm9, %xmm1
vmovq %xmm1, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm10: %ymm10_hsubps_xmm_xmm

State for specgen instruction: vunpckhps %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[127:96] ∘ %ymm1_hsubps_xmm_xmm[127:96] ∘ %ymm2_hsubps_xmm_xmm[95:64] ∘ %ymm1_hsubps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm3, %ymm6

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm6: %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm3, %xmm6, %xmm9

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm3, %xmm2, %xmm14

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm14: %ymm14_vpor_xmm_xmm_xmm

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpor_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vpor %xmm9, %xmm9, %xmm7

.target:
vorps %xmm3, %xmm2, %xmm14
vmovapd %xmm14, %xmm1
retq 

Initial state:
%ymm7: %ymm7_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpor %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

Final state
%ymm7: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm7, %xmm2

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpckldq_xmm_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm2: (%ymm2_vpunpckldq_xmm_xmm_xmm[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm1, %xmm3

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm3: %ymm3_mulpd_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm8: %ymm8_mulpd_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmulpd %ymm8, %ymm3, %ymm6

Final state:
%ymm6: mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[255:192]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[191:128]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[127:64]) ∘ mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_mulpd_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for mulpd %xmm3, %xmm2

.target:
vmovapd %xmm1, %xmm3
vmovaps %xmm2, %xmm8
vmulpd %ymm8, %ymm3, %ymm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vmulpd_xmm_xmm_xmm[127:0]

State for specgen instruction: mulpd %xmm2, %xmm1:
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vmulpd_xmm_xmm_xmm[255:128] ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmulpd_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmulpd %xmm6, %xmm2, %xmm12

.target:
mulpd %xmm3, %xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm12: %ymm12_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vmulpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]) ∘ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm12, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vpunpckldq %xmm10, %xmm8, %xmm15

.target:
vpbroadcastq %xmm3, %ymm6
vunpcklpd %xmm3, %xmm6, %xmm9
vpor %xmm9, %xmm9, %xmm7
unpcklps %xmm7, %xmm2
vmulpd %xmm6, %xmm2, %xmm12
vxorps %xmm12, %xmm2, %xmm1
movdqu %xmm2, %xmm1
retq 

Initial state:
%ymm15: %ymm15_hsubps_xmm_xmm

State for specgen instruction: vpunpckldq %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0]))

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[95:64] ∘ %ymm2_hsubps_xmm_xmm[31:0] ∘ (%ymm1_hsubps_xmm_xmm[95:64] ∘ %ymm1_hsubps_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm2

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm2: %ymm2_vunpckhps_xmm_xmm_xmm[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm2: (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpckhps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm9, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vunpckhps_xmm_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: %ymm0_vmovq_xmm_xmm[127:0]
%xmm1: %ymm1_vmovq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movswq %bx, %r10

Final state:
%r10/%r10: sign-extend-64(%rbx_xchgl_r32_r32[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_xchgl_r32_r32[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ecx_r8w_r9w

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %rcx

Final state:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r8w_r9w_ebx

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xchgl %ebx, %ecx

.target:
movswq %bx, %r10
movslq %ebx, %rbx
callq .move_032_016_ecx_r8w_r9w
callq .move_064_032_rbx_r10d_r11d
movq %r10, %rcx
callq .move_016_032_r8w_r9w_ebx
retq 

Initial state:
%rcx/%rcx: %rcx_xorl_r32_r32
%rbx/%rbx: %rbx_xorl_r32_r32

State for specgen instruction: xchgl %ecx, %ebx:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
%rbx/%rbx: 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])

Register        -> %rcx
  translates to => %rbx
Value is               -> 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
  after renaming it is => 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

Register        -> %rbx
  translates to => %rcx
Value is               -> 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])
  after renaming it is => 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

Final state
%rcx/%rcx: 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]) = 0x0₆₄
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_ebx

Final state:
%rax/%rax: %rax_xorl_r32_r32
%rdx/%rdx: %rdx_xorl_r32_r32

%xmm0: %ymm0_xorl_r32_r32[127:0]
%xmm1: %ymm1_xorl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xorl %r13d, %r13d

.target:
xchgl %ebx, %ecx
xorq %rcx, %rbx
callq .set_szp_for_ebx
retq 

Initial state:
%r13/%r13: %ymm2_vmovq_xmm_xmm[127:0][127:64]

%cf: %cf_vmovq_xmm_xmm
%pf: %pf_vmovq_xmm_xmm
%zf: %zf_vmovq_xmm_xmm
%sf: %sf_vmovq_xmm_xmm
%of: %of_vmovq_xmm_xmm

State for specgen instruction: xorl %ecx, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0] = 0x0₃₂
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][31:31] = 0x1₁
%of: false

Register        -> %rbx
  translates to => %r13
Value is               -> 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
  after renaming it is => 0x0₆₄

Final state
%r13/%r13: 0x0₆₄

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
xorl %r13d, %r13d
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][95:64])

State for specgen instruction: vmovq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhps %xmm2, %xmm1, %xmm8

.target:
unpckhpd %xmm3, %xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovddup %xmm9, %xmm1
vmovq %xmm1, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_punpckhdq_xmm_xmm

State for specgen instruction: vunpckhps %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ %ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm8, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_punpckhdq_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_punpckhdq_xmm_xmm[255:128] ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ (%ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])))[127:0]

=====================================
=====================================
Computing circuit for punpckhdq %xmm10, %xmm8

.target:
vunpckhps %xmm2, %xmm1, %xmm8
movdqu %xmm8, %xmm1
retq 

Initial state:
%xmm8: (0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0])))[127:0]

State for specgen instruction: punpckhdq %xmm2, %xmm1:
%xmm1: (%ymm1_punpckhdq_xmm_xmm[255:128] ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ (%ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])))[127:0]

Final state
%xmm8: ((0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0])))[255:128] ∘ (%ymm2_hsubps_xmm_xmm[127:96] ∘ %ymm2_hsubps_xmm_xmm[63:32] ∘ (%ymm1_hsubps_xmm_xmm[127:96] ∘ %ymm1_hsubps_xmm_xmm[63:32])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm14

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm14: %ymm14_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm14: 0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminps %ymm1, %ymm14, %ymm1

Final state:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vminps %xmm2, %xmm2, %xmm5

.target:
vmovdqa %xmm3, %xmm1
vmovdqu %xmm2, %xmm14
vminps %ymm1, %ymm14, %ymm1
retq 

Initial state:
%ymm5: %ymm5_vsubps_xmm_xmm_xmm

State for specgen instruction: vminps %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm5: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_subps_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm14

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm14: %ymm14_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm14: 0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminps %ymm1, %ymm14, %ymm1

Final state:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vminps %xmm1, %xmm1, %xmm4

.target:
vmovdqa %xmm3, %xmm1
vmovdqu %xmm2, %xmm14
vminps %ymm1, %ymm14, %ymm1
retq 

Initial state:
%ymm4: %ymm4_subps_xmm_xmm

State for specgen instruction: vminps %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm4: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for vsubps %ymm10, %ymm4, %ymm2

Final state:
%ymm2: sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[255:224], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[255:224]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[223:192], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[223:192]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[191:160], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[191:160]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[159:128], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[159:128]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[127:96], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[127:96]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[95:64], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[95:64]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[63:32], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[63:32]) ∘ sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[31:0], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_subps_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_subps_xmm_xmm[255:128] ∘ (sub_single(%ymm1_subps_xmm_xmm[127:96], %ymm2_subps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_subps_xmm_xmm[95:64], %ymm2_subps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_subps_xmm_xmm[63:32], %ymm2_subps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_subps_xmm_xmm[31:0], %ymm2_subps_xmm_xmm[31:0])))))[127:0]

=====================================
=====================================
Computing circuit for subps %xmm3, %xmm5

.target:
vmovaps %xmm2, %xmm10
vminps %xmm1, %xmm1, %xmm4
vsubps %ymm10, %ymm4, %ymm2
movdqu %xmm2, %xmm1
retq 

Initial state:
%xmm5: (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0]))))[127:0]

State for specgen instruction: subps %xmm2, %xmm1:
%xmm1: (%ymm1_subps_xmm_xmm[255:128] ∘ (sub_single(%ymm1_subps_xmm_xmm[127:96], %ymm2_subps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_subps_xmm_xmm[95:64], %ymm2_subps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_subps_xmm_xmm[63:32], %ymm2_subps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_subps_xmm_xmm[31:0], %ymm2_subps_xmm_xmm[31:0])))))[127:0]

Final state
%xmm5: ((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0]))))[255:128] ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0])))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm5, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vsubps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0]))))

=====================================
=====================================
Computing circuit for vsubps %xmm8, %xmm15, %xmm4

.target:
vminps %xmm2, %xmm2, %xmm5
subps %xmm3, %xmm5
vmovdqu %xmm5, %xmm1
retq 

Initial state:
%ymm4: %ymm4_hsubps_xmm_xmm

State for specgen instruction: vsubps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0]))))

Final state
%ymm4: 0x0₁₂₈ ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm4, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_hsubps_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_hsubps_xmm_xmm[255:128] ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))[127:0]

=====================================
=====================================
Computing circuit for hsubps %xmm3, %xmm2

.target:
vpunpckldq %xmm2, %xmm1, %xmm8
vunpckhps %xmm2, %xmm1, %xmm10
vpunpckldq %xmm10, %xmm8, %xmm15
punpckhdq %xmm10, %xmm8
vsubps %xmm8, %xmm15, %xmm4
movdqu %xmm4, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vhsubps_xmm_xmm_xmm[127:0]

State for specgen instruction: hsubps %xmm2, %xmm1:
%xmm1: (%ymm1_hsubps_xmm_xmm[255:128] ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))[127:0]

Final state
%xmm2: (%ymm2_vhsubps_xmm_xmm_xmm[255:128] ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vhsubps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vhsubps_xmm_xmm_xmm

%xmm0: %ymm0_vhsubps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vhsubps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vhsubps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vhsubps_xmm_xmm_xmm

%xmm0: %ymm0_vhsubps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vhsubps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vhsubps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32])))

=====================================
=====================================
Computing circuit for vhsubps %xmm13, %xmm1, %xmm1

.target:
hsubps %xmm3, %xmm2
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm1: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0]))

State for specgen instruction: vhsubps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32])))

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0])))

=====================================
=====================================
Computing circuit for vpmovzxwd %xmm9, %xmm9

.target:
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7
vpmovzxwq %xmm5, %xmm13
movddup %xmm4, %xmm4
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm3
vpmovzxwq %xmm3, %xmm1
vhsubps %xmm13, %xmm1, %xmm1
retq 

Initial state:
%ymm9: %ymm9_vpmovzxwd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vpmovzxwd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpmovzxwd %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0])))

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[127:112] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[111:96]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[95:80] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[79:64])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vpmovzxwd_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwd_xmm_xmm

%xmm0: %ymm0_vpmovzxwd_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: %ymm0_vpmovzxwq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r12d_r13d_rdx

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_edx_r10w_r11w

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxwq %xmm5, %xmm13

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_128_064_xmm2_r10_r11
callq .move_032_064_r12d_r13d_rdx
callq .move_032_016_edx_r10w_r11w
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm13: %ymm13_vpmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0])

Final state
%ymm13: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movddup_xmm_xmm
%rdx/%rdx: %rdx_movddup_xmm_xmm

%xmm0: %ymm0_movddup_xmm_xmm[127:0]
%xmm1: %ymm1_movddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r12, %r13

Final state:
%r13/%r13: %ymm2_movddup_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movddup_xmm_xmm
%rdx/%rdx: %rdx_movddup_xmm_xmm

%xmm0: %ymm0_movddup_xmm_xmm[127:0]
%xmm1: (%ymm1_movddup_xmm_xmm[255:128] ∘ (%ymm2_movddup_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_movddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movddup %xmm4, %xmm4

.target:
callq .move_128_064_xmm2_r12_r13
movq %r12, %r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm4: (%ymm4_vpmovzxwd_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[127:0][31:0]))[127:0]

State for specgen instruction: movddup %xmm2, %xmm1:
%xmm1: (%ymm1_movddup_xmm_xmm[255:128] ∘ (%ymm2_movddup_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_movddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm4: ((%ymm4_vpmovzxwd_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[127:0][31:0]))[255:128] ∘ (0x0₃₂ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:0] ∘ (0x0₃₂ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm3

Final state:
%rax/%rax: %rax_vpmovzxwd_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwd_xmm_xmm

%xmm0: %ymm0_vpmovzxwd_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: %ymm0_vpmovzxwq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r12d_r13d_rdx

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_edx_r10w_r11w

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxwq %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_128_064_xmm2_r10_r11
callq .move_032_064_r12d_r13d_rdx
callq .move_032_016_edx_r10w_r11w
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm3, %ymm6

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm6: %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm3, %xmm6, %xmm9

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm3, %xmm2, %xmm14

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm14: %ymm14_vpor_xmm_xmm_xmm

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpor_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vpor %xmm9, %xmm9, %xmm7

.target:
vorps %xmm3, %xmm2, %xmm14
vmovapd %xmm14, %xmm1
retq 

Initial state:
%ymm7: %ymm7_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpor %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

Final state
%ymm7: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm7, %xmm2

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpckldq_xmm_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm2: (%ymm2_vpunpckldq_xmm_xmm_xmm[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm1, %xmm3

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm3: %ymm3_mulpd_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm8: %ymm8_mulpd_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmulpd %ymm8, %ymm3, %ymm6

Final state:
%ymm6: mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[255:192]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[191:128]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[127:64]) ∘ mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_mulpd_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for mulpd %xmm3, %xmm2

.target:
vmovapd %xmm1, %xmm3
vmovaps %xmm2, %xmm8
vmulpd %ymm8, %ymm3, %ymm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vmulpd_xmm_xmm_xmm[127:0]

State for specgen instruction: mulpd %xmm2, %xmm1:
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vmulpd_xmm_xmm_xmm[255:128] ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmulpd_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmulpd %xmm6, %xmm2, %xmm12

.target:
mulpd %xmm3, %xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm12: %ymm12_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vmulpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]) ∘ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm12, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vpunpckldq %xmm2, %xmm1, %xmm8

.target:
vpbroadcastq %xmm3, %ymm6
vunpcklpd %xmm3, %xmm6, %xmm9
vpor %xmm9, %xmm9, %xmm7
unpcklps %xmm7, %xmm2
vmulpd %xmm6, %xmm2, %xmm12
vxorps %xmm12, %xmm2, %xmm1
movdqu %xmm2, %xmm1
retq 

Initial state:
%ymm8: %ymm8_hsubps_xmm_xmm

State for specgen instruction: vpunpckldq %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0]))

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm2

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm2: %ymm2_vunpckhps_xmm_xmm_xmm[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm2: (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpckhps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm9, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vunpckhps_xmm_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: %ymm0_vmovq_xmm_xmm[127:0]
%xmm1: %ymm1_vmovq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movswq %bx, %r10

Final state:
%r10/%r10: sign-extend-64(%rbx_xchgl_r32_r32[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_xchgl_r32_r32[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ecx_r8w_r9w

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %rcx

Final state:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r8w_r9w_ebx

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xchgl %ebx, %ecx

.target:
movswq %bx, %r10
movslq %ebx, %rbx
callq .move_032_016_ecx_r8w_r9w
callq .move_064_032_rbx_r10d_r11d
movq %r10, %rcx
callq .move_016_032_r8w_r9w_ebx
retq 

Initial state:
%rcx/%rcx: %rcx_xorl_r32_r32
%rbx/%rbx: %rbx_xorl_r32_r32

State for specgen instruction: xchgl %ecx, %ebx:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
%rbx/%rbx: 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])

Register        -> %rcx
  translates to => %rbx
Value is               -> 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
  after renaming it is => 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

Register        -> %rbx
  translates to => %rcx
Value is               -> 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])
  after renaming it is => 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

Final state
%rcx/%rcx: 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]) = 0x0₆₄
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_ebx

Final state:
%rax/%rax: %rax_xorl_r32_r32
%rdx/%rdx: %rdx_xorl_r32_r32

%xmm0: %ymm0_xorl_r32_r32[127:0]
%xmm1: %ymm1_xorl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xorl %r13d, %r13d

.target:
xchgl %ebx, %ecx
xorq %rcx, %rbx
callq .set_szp_for_ebx
retq 

Initial state:
%r13/%r13: %ymm2_vmovq_xmm_xmm[127:0][127:64]

%cf: %cf_vmovq_xmm_xmm
%pf: %pf_vmovq_xmm_xmm
%zf: %zf_vmovq_xmm_xmm
%sf: %sf_vmovq_xmm_xmm
%of: %of_vmovq_xmm_xmm

State for specgen instruction: xorl %ecx, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0] = 0x0₃₂
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][31:31] = 0x1₁
%of: false

Register        -> %rbx
  translates to => %r13
Value is               -> 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
  after renaming it is => 0x0₆₄

Final state
%r13/%r13: 0x0₆₄

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
xorl %r13d, %r13d
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][95:64])

State for specgen instruction: vmovq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhps %xmm2, %xmm1, %xmm10

.target:
unpckhpd %xmm3, %xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovddup %xmm9, %xmm1
vmovq %xmm1, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm10: %ymm10_hsubps_xmm_xmm

State for specgen instruction: vunpckhps %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[127:96] ∘ %ymm1_hsubps_xmm_xmm[127:96] ∘ %ymm2_hsubps_xmm_xmm[95:64] ∘ %ymm1_hsubps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm3, %ymm6

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm6: %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm3, %xmm6, %xmm9

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm3, %xmm2, %xmm14

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm14: %ymm14_vpor_xmm_xmm_xmm

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpor_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vpor %xmm9, %xmm9, %xmm7

.target:
vorps %xmm3, %xmm2, %xmm14
vmovapd %xmm14, %xmm1
retq 

Initial state:
%ymm7: %ymm7_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpor %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

Final state
%ymm7: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm7, %xmm2

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpckldq_xmm_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm2: (%ymm2_vpunpckldq_xmm_xmm_xmm[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm1, %xmm3

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm3: %ymm3_mulpd_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm8: %ymm8_mulpd_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmulpd %ymm8, %ymm3, %ymm6

Final state:
%ymm6: mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[255:192]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[191:128]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[127:64]) ∘ mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_mulpd_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for mulpd %xmm3, %xmm2

.target:
vmovapd %xmm1, %xmm3
vmovaps %xmm2, %xmm8
vmulpd %ymm8, %ymm3, %ymm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vmulpd_xmm_xmm_xmm[127:0]

State for specgen instruction: mulpd %xmm2, %xmm1:
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vmulpd_xmm_xmm_xmm[255:128] ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmulpd_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmulpd %xmm6, %xmm2, %xmm12

.target:
mulpd %xmm3, %xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm12: %ymm12_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vmulpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]) ∘ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm12, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vpunpckldq %xmm10, %xmm8, %xmm15

.target:
vpbroadcastq %xmm3, %ymm6
vunpcklpd %xmm3, %xmm6, %xmm9
vpor %xmm9, %xmm9, %xmm7
unpcklps %xmm7, %xmm2
vmulpd %xmm6, %xmm2, %xmm12
vxorps %xmm12, %xmm2, %xmm1
movdqu %xmm2, %xmm1
retq 

Initial state:
%ymm15: %ymm15_hsubps_xmm_xmm

State for specgen instruction: vpunpckldq %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0]))

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[95:64] ∘ %ymm2_hsubps_xmm_xmm[31:0] ∘ (%ymm1_hsubps_xmm_xmm[95:64] ∘ %ymm1_hsubps_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm2

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm2: %ymm2_vunpckhps_xmm_xmm_xmm[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm2: (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpckhps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm9, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vunpckhps_xmm_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: %ymm0_vmovq_xmm_xmm[127:0]
%xmm1: %ymm1_vmovq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movswq %bx, %r10

Final state:
%r10/%r10: sign-extend-64(%rbx_xchgl_r32_r32[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_xchgl_r32_r32[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ecx_r8w_r9w

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %rcx

Final state:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r8w_r9w_ebx

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xchgl %ebx, %ecx

.target:
movswq %bx, %r10
movslq %ebx, %rbx
callq .move_032_016_ecx_r8w_r9w
callq .move_064_032_rbx_r10d_r11d
movq %r10, %rcx
callq .move_016_032_r8w_r9w_ebx
retq 

Initial state:
%rcx/%rcx: %rcx_xorl_r32_r32
%rbx/%rbx: %rbx_xorl_r32_r32

State for specgen instruction: xchgl %ecx, %ebx:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
%rbx/%rbx: 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])

Register        -> %rcx
  translates to => %rbx
Value is               -> 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
  after renaming it is => 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

Register        -> %rbx
  translates to => %rcx
Value is               -> 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])
  after renaming it is => 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

Final state
%rcx/%rcx: 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]) = 0x0₆₄
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_ebx

Final state:
%rax/%rax: %rax_xorl_r32_r32
%rdx/%rdx: %rdx_xorl_r32_r32

%xmm0: %ymm0_xorl_r32_r32[127:0]
%xmm1: %ymm1_xorl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xorl %r13d, %r13d

.target:
xchgl %ebx, %ecx
xorq %rcx, %rbx
callq .set_szp_for_ebx
retq 

Initial state:
%r13/%r13: %ymm2_vmovq_xmm_xmm[127:0][127:64]

%cf: %cf_vmovq_xmm_xmm
%pf: %pf_vmovq_xmm_xmm
%zf: %zf_vmovq_xmm_xmm
%sf: %sf_vmovq_xmm_xmm
%of: %of_vmovq_xmm_xmm

State for specgen instruction: xorl %ecx, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0] = 0x0₃₂
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][31:31] = 0x1₁
%of: false

Register        -> %rbx
  translates to => %r13
Value is               -> 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
  after renaming it is => 0x0₆₄

Final state
%r13/%r13: 0x0₆₄

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
xorl %r13d, %r13d
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][95:64])

State for specgen instruction: vmovq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhps %xmm2, %xmm1, %xmm8

.target:
unpckhpd %xmm3, %xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovddup %xmm9, %xmm1
vmovq %xmm1, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_punpckhdq_xmm_xmm

State for specgen instruction: vunpckhps %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ %ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm8, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_punpckhdq_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_punpckhdq_xmm_xmm[255:128] ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ (%ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])))[127:0]

=====================================
=====================================
Computing circuit for punpckhdq %xmm10, %xmm8

.target:
vunpckhps %xmm2, %xmm1, %xmm8
movdqu %xmm8, %xmm1
retq 

Initial state:
%xmm8: (0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0])))[127:0]

State for specgen instruction: punpckhdq %xmm2, %xmm1:
%xmm1: (%ymm1_punpckhdq_xmm_xmm[255:128] ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ (%ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])))[127:0]

Final state
%xmm8: ((0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0])))[255:128] ∘ (%ymm2_hsubps_xmm_xmm[127:96] ∘ %ymm2_hsubps_xmm_xmm[63:32] ∘ (%ymm1_hsubps_xmm_xmm[127:96] ∘ %ymm1_hsubps_xmm_xmm[63:32])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm14

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm14: %ymm14_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm14: 0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminps %ymm1, %ymm14, %ymm1

Final state:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vminps %xmm2, %xmm2, %xmm5

.target:
vmovdqa %xmm3, %xmm1
vmovdqu %xmm2, %xmm14
vminps %ymm1, %ymm14, %ymm1
retq 

Initial state:
%ymm5: %ymm5_vsubps_xmm_xmm_xmm

State for specgen instruction: vminps %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm5: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_subps_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm14

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm14: %ymm14_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm14: 0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminps %ymm1, %ymm14, %ymm1

Final state:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vminps %xmm1, %xmm1, %xmm4

.target:
vmovdqa %xmm3, %xmm1
vmovdqu %xmm2, %xmm14
vminps %ymm1, %ymm14, %ymm1
retq 

Initial state:
%ymm4: %ymm4_subps_xmm_xmm

State for specgen instruction: vminps %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm4: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for vsubps %ymm10, %ymm4, %ymm2

Final state:
%ymm2: sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[255:224], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[255:224]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[223:192], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[223:192]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[191:160], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[191:160]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[159:128], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[159:128]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[127:96], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[127:96]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[95:64], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[95:64]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[63:32], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[63:32]) ∘ sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[31:0], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_subps_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_subps_xmm_xmm[255:128] ∘ (sub_single(%ymm1_subps_xmm_xmm[127:96], %ymm2_subps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_subps_xmm_xmm[95:64], %ymm2_subps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_subps_xmm_xmm[63:32], %ymm2_subps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_subps_xmm_xmm[31:0], %ymm2_subps_xmm_xmm[31:0])))))[127:0]

=====================================
=====================================
Computing circuit for subps %xmm3, %xmm5

.target:
vmovaps %xmm2, %xmm10
vminps %xmm1, %xmm1, %xmm4
vsubps %ymm10, %ymm4, %ymm2
movdqu %xmm2, %xmm1
retq 

Initial state:
%xmm5: (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0]))))[127:0]

State for specgen instruction: subps %xmm2, %xmm1:
%xmm1: (%ymm1_subps_xmm_xmm[255:128] ∘ (sub_single(%ymm1_subps_xmm_xmm[127:96], %ymm2_subps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_subps_xmm_xmm[95:64], %ymm2_subps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_subps_xmm_xmm[63:32], %ymm2_subps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_subps_xmm_xmm[31:0], %ymm2_subps_xmm_xmm[31:0])))))[127:0]

Final state
%xmm5: ((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0]))))[255:128] ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0])))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm5, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vsubps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0]))))

=====================================
=====================================
Computing circuit for vsubps %xmm8, %xmm15, %xmm4

.target:
vminps %xmm2, %xmm2, %xmm5
subps %xmm3, %xmm5
vmovdqu %xmm5, %xmm1
retq 

Initial state:
%ymm4: %ymm4_hsubps_xmm_xmm

State for specgen instruction: vsubps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0]))))

Final state
%ymm4: 0x0₁₂₈ ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm4, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_hsubps_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_hsubps_xmm_xmm[255:128] ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))[127:0]

=====================================
=====================================
Computing circuit for hsubps %xmm3, %xmm2

.target:
vpunpckldq %xmm2, %xmm1, %xmm8
vunpckhps %xmm2, %xmm1, %xmm10
vpunpckldq %xmm10, %xmm8, %xmm15
punpckhdq %xmm10, %xmm8
vsubps %xmm8, %xmm15, %xmm4
movdqu %xmm4, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vhsubps_xmm_xmm_xmm[127:0]

State for specgen instruction: hsubps %xmm2, %xmm1:
%xmm1: (%ymm1_hsubps_xmm_xmm[255:128] ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))[127:0]

Final state
%xmm2: (%ymm2_vhsubps_xmm_xmm_xmm[255:128] ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vhsubps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vhsubps_xmm_xmm_xmm

%xmm0: %ymm0_vhsubps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vhsubps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vhsubps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vhsubps_xmm_xmm_xmm

%xmm0: %ymm0_vhsubps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vhsubps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vhsubps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32])))

=====================================
=====================================
Computing circuit for vhsubps %xmm13, %xmm1, %xmm1

.target:
hsubps %xmm3, %xmm2
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm1: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0]))

State for specgen instruction: vhsubps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32])))

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0])))

=====================================
=====================================
Computing circuit for vpmovzxwd %xmm10, %xmm8

.target:
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7
vpmovzxwq %xmm5, %xmm13
movddup %xmm4, %xmm4
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm3
vpmovzxwq %xmm3, %xmm1
vhsubps %xmm13, %xmm1, %xmm1
retq 

Initial state:
%ymm8: %ymm8_vpmovzxwd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vpmovzxwd_ymm_xmm[127:0][63:0])

State for specgen instruction: vpmovzxwd %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0])))

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[15:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpmovzxwd_ymm_xmm
%rdx/%rdx: %rdx_vpmovzxwd_ymm_xmm

%xmm0: %ymm0_vpmovzxwd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[127:112] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[111:96]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[95:80] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[79:64]))))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[15:0]))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxwd %xmm2, %ymm5

.target:
vmovdqa %xmm2, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
vpmovzxwd %xmm9, %xmm9
vpmovzxwd %xmm10, %xmm8
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm5: %ymm5_pmovsxwd_xmm_xmm

State for specgen instruction: vpmovzxwd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[127:112] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[111:96]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[95:80] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[79:64]))))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[15:0]))))[127:0][127:0]

Final state
%ymm5: 0x0₁₆ ∘ (0x0₁ ∘ (0x0₃₂ ∘ %ymm2_pmovsxwd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_pmovsxwd_xmm_xmm[127:96]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (0x0₃₂ ∘ %ymm2_pmovsxwd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_pmovsxwd_xmm_xmm[127:96]))[15:0]) ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[95:64] ∘ %ymm2_pmovsxwd_xmm_xmm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_pmovsxwd_xmm_xmm[95:64]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[95:64] ∘ %ymm2_pmovsxwd_xmm_xmm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_pmovsxwd_xmm_xmm[95:64]))[15:0])) ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]))[15:0]) ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[15:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpsubq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpsubq_xmm_xmm_xmm

%xmm0: %ymm0_vpsubq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpsubq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpsubq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpsubq_xmm_xmm_xmm

%xmm0: %ymm0_vpsubq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpsubq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_cf

Final state:
%rax/%rax: %rax_stc
%rdx/%rdx: %rdx_stc

%xmm0: %ymm0_stc[127:0]
%xmm1: %ymm1_stc[127:0]

-------------------------------------
=====================================
Computing circuit for stc 

.target:
callq .set_cf
retq 

Initial state:
%cf: %cf_subq_r64_r64

State for specgen instruction: stc :
%cf: true

Final state
%cf: true

=====================================
-------------------------------------
Getting base circuit for movq $0xfffffffffffffffe, %rdx

Final state:
%rdx/%rdx: 0xfffffffffffffffe₆₄

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_incb_r8 ⊕ %rax_incb_r8

%cf: false
%pf: !((%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][0:0] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][1:1] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][2:2] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][3:3] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][4:4] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][5:5] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][6:6] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][7:7] = 0x1₁)
%zf: (%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄
%sf: (%rax_incb_r8 ⊕ %rax_incb_r8)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: false

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for callq .read_zf_into_rcx

Final state:
%rax/%rax: %rax_incb_r8 ⊕ %rax_incb_r8
%rdx/%rdx: %rdx_incb_r8

%xmm0: %ymm0_incb_r8[127:0]
%xmm1: %ymm1_incb_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for adcb %cl, %bl

Final state:
%rbx/%bl: %rbx_incb_r8[63:8] ∘ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0][3:0] + 0x0₁ ∘ %rbx_incb_r8[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:7] = 0x1₁
%of: ((0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0][7:7] = 0x1₁ ↔ %rbx_incb_r8[7:0][7:7] = 0x1₁) ∧ !((0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for incb %dl

.target:
xorq %rax, %rax
clc 
callq .read_zf_into_rcx
adcb %cl, %bl
retq 

Initial state:
%rdx/%dl: 0xfffffffffffffffe₆₄

%pf: %pf_notq_r64
%af: %af_notq_r64
%zf: %zf_notq_r64
%sf: %sf_notq_r64
%of: %of_notq_r64

State for specgen instruction: incb %bl:
%rbx/%bl: %rbx_incb_r8[63:8] ∘ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0]

%pf: !(((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0][3:0] + 0x0₁ ∘ %rbx_incb_r8[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:7] = 0x1₁
%of: ((0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0][7:7] = 0x1₁ ↔ %rbx_incb_r8[7:0][7:7] = 0x1₁) ∧ !((0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:7] = 0x1₁)

Register        -> %bl
  translates to => %dl
Value is               -> (%rbx_incb_r8[63:8] ∘ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0])[7:0]
  after renaming it is => 0xff₈

Final state
%rdx/%dl: 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈

%pf: true
%af: false
%zf: false
%sf: true
%of: false

=====================================
-------------------------------------
Getting base circuit for xorq %rdx, %rbx

Final state:
%rbx/%rbx: %rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈

%cf: false
%pf: !((%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][0:0] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][1:1] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][2:2] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][3:3] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][4:4] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][5:5] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][6:6] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][7:7] = 0x1₁)
%zf: (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈) = 0x0₆₄
%sf: (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[63:63] = 0x1₁
%of: false

-------------------------------------
=====================================
Computing circuit for notq %rcx

.target:
movq $0xfffffffffffffffe, %rdx
incb %dl
xorq %rdx, %rbx
retq 

Initial state:
%rcx/%rcx: %rcx_subq_r64_r64

State for specgen instruction: notq %rbx:
%rbx/%rbx: %rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈

Register        -> %rbx
  translates to => %rcx
Value is               -> %rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈
  after renaming it is => %rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄

Final state
%rcx/%rcx: %rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄

=====================================
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0]

%cf: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[64:64] = 0x1₁
%pf: !(((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][0:0] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][1:1] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][2:2] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][3:3] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][4:4] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][5:5] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][6:6] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)[3:0] + 0x0₁ ∘ %rbx_subq_r64_r64[3:0])[4:4] = 0x1₁
%zf: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0] = 0x0₆₄
%sf: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][63:63] = 0x1₁
%of: ((%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)[63:63] = 0x1₁ ↔ %rbx_subq_r64_r64[63:63] = 0x1₁) ∧ !((%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)[63:63] = 0x1₁ ↔ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:63] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_cf_into_rbx

Final state:
%rax/%rax: %rax_cmc
%rdx/%rdx: %rdx_cmc

%xmm0: %ymm0_cmc[127:0]
%xmm1: %ymm1_cmc[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r8d_r9d

Final state:
%rax/%rax: %rax_cmc
%rdx/%rdx: %rdx_cmc

%xmm0: %ymm0_cmc[127:0]
%xmm1: %ymm1_cmc[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r8b_to_byte_5_of_rbx

Final state:
%rax/%rax: %rax_cmc
%rdx/%rdx: %rdx_cmc

%xmm0: %ymm0_cmc[127:0]
%xmm1: %ymm1_cmc[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_decw_r16 ⊕ %rax_decw_r16

%cf: false
%pf: !((%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][0:0] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][1:1] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][2:2] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][3:3] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][4:4] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][5:5] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][6:6] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][7:7] = 0x1₁)
%zf: (%rax_decw_r16 ⊕ %rax_decw_r16) = 0x0₆₄
%sf: (%rax_decw_r16 ⊕ %rax_decw_r16)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for movq $0xffffffffffffffff, %rsi

Final state:
%rsi/%rsi: 0xffffffffffffffff₆₄

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r10b_r11b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_cx_r8b_r9b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r10b_r11b_cx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r8b_r9b_bx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for xchgw %ax, %bx

.target:
callq .move_016_008_bx_r10b_r11b
callq .move_016_008_cx_r8b_r9b
callq .move_008_016_r10b_r11b_cx
callq .move_008_016_r8b_r9b_bx
retq 

Initial state:
%rax/%ax: %rax_decw_r16 ⊕ %rax_decw_r16
%rbx/%bx: %rbx_decw_r16

State for specgen instruction: xchgw %cx, %bx:
%rcx/%cx: %rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])
%rbx/%bx: %rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])

Register        -> %cx
  translates to => %ax
Value is               -> (%rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => %rbx_decw_r16[15:0]

Register        -> %bx
  translates to => %bx
Value is               -> (%rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => 0x0₁₆

Final state
%rax/%ax: (%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0]
%rbx/%bx: %rbx_decw_r16[63:16] ∘ 0x0₁₆

=====================================
-------------------------------------
Getting base circuit for callq .read_cf_into_rbx

Final state:
%rax/%rax: (%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0]
%rdx/%rdx: %rdx_decw_r16

%xmm0: %ymm0_decw_r16[127:0]
%xmm1: %ymm1_decw_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for adcw %bx, %ax

Final state:
%rax/%ax: ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[63:16] ∘ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0]

%cf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[16:16] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0][3:0] + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0] = 0x0₁₆
%sf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][15:15] = 0x1₁
%of: ((0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0][15:15] = 0x1₁ ↔ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0][15:15] = 0x1₁) ∧ !((0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:15] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: %cf_addw_r16_r16

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for adcw %cx, %bx

Final state:
%rbx/%bx: %rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[16:16] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addw_r16_r16[15:0][3:0] + 0x0₁ ∘ %rbx_addw_r16_r16[15:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0] = 0x0₁₆
%sf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][15:15] = 0x1₁
%of: (%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ %rbx_addw_r16_r16[15:0][15:15] = 0x1₁) ∧ !(%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:15] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_bx

Final state:
%rax/%rax: %rax_addw_r16_r16
%rdx/%rdx: %rdx_addw_r16_r16

%xmm0: %ymm0_addw_r16_r16[127:0]
%xmm1: %ymm1_addw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for addw %ax, %si

.target:
clc 
adcw %cx, %bx
callq .set_szp_for_bx
retq 

Initial state:
%rsi/%si: 0xffffffffffffffff₆₄

%cf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[16:16] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0][3:0] + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0] = 0x0₁₆
%sf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][15:15] = 0x1₁
%of: ((0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0][15:15] = 0x1₁ ↔ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0][15:15] = 0x1₁) ∧ !((0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:15] = 0x1₁)

State for specgen instruction: addw %cx, %bx:
%rbx/%bx: %rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[16:16] = 0x1₁
%pf: !((%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addw_r16_r16[15:0][3:0] + 0x0₁ ∘ %rbx_addw_r16_r16[15:0][3:0])[4:4] = 0x1₁
%zf: (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0] = 0x0₁₆
%sf: (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][15:15] = 0x1₁
%of: (%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ %rbx_addw_r16_r16[15:0][15:15] = 0x1₁) ∧ !(%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:15] = 0x1₁)

Register        -> %bx
  translates to => %si
Value is               -> (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0]
  after renaming it is => (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0]

Final state
%rsi/%si: 0xffffffffffffffff₆₄[63:16] ∘ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0]

%cf: (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[16:16] = 0x1₁
%pf: !((0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rbx_decw_r16[3:0] + 0xf₅)[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0] = 0x0₁₆
%sf: (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:15] = 0x1₁
%of: (%rbx_decw_r16[15:15] = 0x1₁ ↔ true) ∧ !(%rbx_decw_r16[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:15] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for movswq %si, %rbx

Final state:
%rbx/%rbx: sign-extend-64((0xffffffffffffffff₆₄[63:16] ∘ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0])[15:0])

-------------------------------------
=====================================
Computing circuit for decw %bx

.target:
xorq %rax, %rax
movq $0xffffffffffffffff, %rsi
xchgw %ax, %bx
callq .read_cf_into_rbx
adcw %bx, %ax
addw %ax, %si
movswq %si, %rbx
retq 

Initial state:
%rbx/%bx: (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0]

%pf: %pf_cmc
%af: %af_cmc
%zf: %zf_cmc
%sf: %sf_cmc
%of: %of_cmc

State for specgen instruction: decw %bx:
%rbx/%bx: sign-extend-64((0xffffffffffffffff₆₄[63:16] ∘ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0])[15:0])

%pf: !((0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rbx_decw_r16[3:0] + 0xf₅)[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0] = 0x0₁₆
%sf: (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:15] = 0x1₁
%of: (%rbx_decw_r16[15:15] = 0x1₁ ↔ true) ∧ !(%rbx_decw_r16[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:15] = 0x1₁)

Register        -> %bx
  translates to => %bx
Value is               -> sign-extend-64((0xffffffffffffffff₆₄[63:16] ∘ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0])[15:0])[15:0]
  after renaming it is => %cf_cmc ? 0x0₁₆ : 0xffff₁₆

Final state
%rbx/%bx: ((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆)

%pf: !((%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁)
%af: (%cf_cmc ? 0x1₁ : 0x0₁) = 0x1₁
%zf: (%cf_cmc ? 0x0₁₆ : 0xffff₁₆) = 0x0₁₆
%sf: (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁
%of: false ∧ !(false ↔ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for movb %cl, %bh

Final state:
%rbx/%bh: %rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq $0x40, %rbx

Final state:
%rbx/%rbx: 0x40₆₄

-------------------------------------
-------------------------------------
Getting base circuit for movb %ah, %bl

Final state:
%rbx/%bl: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

-------------------------------------
=====================================
Computing circuit for movzbl %ah, %ebp

.target:
movq $0x40, %rbx
movb %ah, %bl
retq 

Initial state:
%rbp/%rbp: %rbp_xorb_r8_rh

State for specgen instruction: movzbl %ah, %ebx:
%rbx/%rbx: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

Register        -> %rbx
  translates to => %rbp
Value is               -> 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]
  after renaming it is => 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

Final state
%rbp/%rbp: 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

=====================================
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh

%cf: false
%pf: !((%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][0:0] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][1:1] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][2:2] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][3:3] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][4:4] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][5:5] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][6:6] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][7:7] = 0x1₁)
%zf: (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh) = 0x0₆₄
%sf: (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_cf_into_rcx

Final state:
%rax/%rax: %rax_setc_rh
%rdx/%rdx: %rdx_setc_rh

%xmm0: %ymm0_setc_rh[127:0]
%xmm1: %ymm1_setc_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movb %cl, %ah

Final state:
%rax/%ah: %rax_setc_rh[63:16] ∘ (0x0₆₃ ∘ (%cf_setc_rh ? 0x1₁ : 0x0₁))[7:0] ∘ %rax_setc_rh[7:0]

-------------------------------------
=====================================
Computing circuit for setc %bh

.target:
callq .read_cf_into_rcx
movb %cl, %ah
retq 

Initial state:
%rbx/%bh: %rbx_xorb_r8_rh

State for specgen instruction: setc %ah:
%rax/%ah: %rax_setc_rh[63:16] ∘ (0x0₆₃ ∘ (%cf_setc_rh ? 0x1₁ : 0x0₁))[7:0] ∘ %rax_setc_rh[7:0]

Register        -> %ah
  translates to => %bh
Value is               -> (%rax_setc_rh[63:16] ∘ (0x0₆₃ ∘ (%cf_setc_rh ? 0x1₁ : 0x0₁))[7:0] ∘ %rax_setc_rh[7:0])[15:8]
  after renaming it is => 0x0₈

Final state
%rbx/%bh: %rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0]

=====================================
-------------------------------------
Getting base circuit for movswq %bx, %rdx

Final state:
%rdx/%rdx: sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rbp, %rdx

Final state:
%rdx/%rdx: sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

%cf: false
%pf: !((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][0:0] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][1:1] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][2:2] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][3:3] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][4:4] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][5:5] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][6:6] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][7:7] = 0x1₁)
%zf: (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]) = 0x0₆₄
%sf: (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for movslq %edx, %rbx

Final state:
%rbx/%rbx: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_bl

Final state:
%rax/%rax: %rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh
%rdx/%rdx: sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

%xmm0: %ymm0_xorb_r8_rh[127:0]
%xmm1: %ymm1_xorb_r8_rh[127:0]

-------------------------------------
=====================================
Computing circuit for xorb %bh, %bl

.target:
movzbl %ah, %ebp
xorq %rax, %rax
setc %bh
movswq %bx, %rdx
xorq %rbp, %rdx
movslq %edx, %rbx
callq .set_szp_for_bl
retq 

Initial state:
%rbx/%bl: %rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0]

%cf: %cf_xorb_r8_r8
%pf: %pf_xorb_r8_r8
%zf: %zf_xorb_r8_r8
%sf: %sf_xorb_r8_r8
%of: %of_xorb_r8_r8

State for specgen instruction: xorb %ah, %bl:
%rbx/%bl: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])

%cf: false
%pf: !(sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][0:0] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][1:1] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][2:2] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][3:3] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][4:4] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][5:5] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][6:6] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][7:7] = 0x1₁)
%zf: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0] = 0x0₈
%sf: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:7] = 0x1₁
%of: false

Register        -> %bl
  translates to => %bl
Value is               -> sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0]
  after renaming it is => %rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]

Final state
%rbx/%bl: (%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0])

%cf: false
%pf: !((%rbx_xorb_r8_r8[0:0] ⊕ %rcx_xorb_r8_r8[0:0]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[1:1] ⊕ %rcx_xorb_r8_r8[1:1]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[2:2] ⊕ %rcx_xorb_r8_r8[2:2]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[3:3] ⊕ %rcx_xorb_r8_r8[3:3]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[4:4] ⊕ %rcx_xorb_r8_r8[4:4]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[5:5] ⊕ %rcx_xorb_r8_r8[5:5]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[6:6] ⊕ %rcx_xorb_r8_r8[6:6]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[7:7] ⊕ %rcx_xorb_r8_r8[7:7]) = 0x1₁)
%zf: (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]) = 0x0₈
%sf: (%rbx_xorb_r8_r8[7:7] ⊕ %rcx_xorb_r8_r8[7:7]) = 0x1₁
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .set_szp_for_bl

Final state:
%rax/%rax: %rax_xorb_r8_r8
%rdx/%rdx: %rdx_xorb_r8_r8

%xmm0: %ymm0_xorb_r8_r8[127:0]
%xmm1: %ymm1_xorb_r8_r8[127:0]

-------------------------------------
=====================================
Computing circuit for xorb %al, %al

.target:
movb %cl, %bh
xorb %bh, %bl
callq .set_szp_for_bl
retq 

Initial state:
%rax/%al: %rax_xorb_rh_rh

%cf: %cf_xorb_rh_rh
%pf: %pf_xorb_rh_rh
%zf: %zf_xorb_rh_rh
%sf: %sf_xorb_rh_rh
%of: %of_xorb_rh_rh

State for specgen instruction: xorb %cl, %bl:
%rbx/%bl: (%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0])

%cf: false
%pf: !(((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][0:0] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][1:1] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][2:2] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][3:3] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][4:4] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][5:5] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][6:6] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][7:7] = 0x1₁)
%zf: ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0] = 0x0₈
%sf: ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:7] = 0x1₁
%of: false

Register        -> %bl
  translates to => %al
Value is               -> ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0]
  after renaming it is => 0x0₈

Final state
%rax/%al: %rax_xorb_rh_rh[63:8] ∘ 0x0₈

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for movq $0x40, %rbx

Final state:
%rbx/%rbx: 0x40₆₄

-------------------------------------
-------------------------------------
Getting base circuit for movb %ah, %bl

Final state:
%rbx/%bl: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

-------------------------------------
=====================================
Computing circuit for movzbl %ah, %edx

.target:
movq $0x40, %rbx
movb %ah, %bl
retq 

Initial state:
%rdx/%rdx: %rdx_xaddb_rh_r8

State for specgen instruction: movzbl %ah, %ebx:
%rbx/%rbx: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

Register        -> %rbx
  translates to => %rdx
Value is               -> 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]
  after renaming it is => 0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8]

Final state
%rdx/%rdx: 0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8]

=====================================
-------------------------------------
Getting base circuit for callq .clear_cf

Final state:
%rax/%rax: %rax_xaddb_r8_r8
%rdx/%rdx: %rdx_xaddb_r8_r8

%xmm0: %ymm0_xaddb_r8_r8[127:0]
%xmm1: %ymm1_xaddb_r8_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_of

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_of_into_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movsbq %cl, %r10

Final state:
%r10/%r10: sign-extend-64(%rcx_movsbl_r32_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
=====================================
Computing circuit for movsbl %cl, %r13d

.target:
callq .set_of
callq .read_of_into_rbx
callq .move_064_032_rbx_r10d_r11d
movsbq %cl, %r10
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r13/%r13: %r13_xaddb_r8_r8

State for specgen instruction: movsbl %cl, %ebx:
%rbx/%rbx: (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r13
Value is               -> (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0]

Final state
%r13/%r13: 0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0]

=====================================
-------------------------------------
Getting base circuit for callq .set_of

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_of_into_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movsbq %cl, %r10

Final state:
%r10/%r10: sign-extend-64(%rcx_movsbl_r32_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
=====================================
Computing circuit for movsbl %bl, %r15d

.target:
callq .set_of
callq .read_of_into_rbx
callq .move_064_032_rbx_r10d_r11d
movsbq %cl, %r10
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r15/%r15: %r15_xaddb_r8_r8

State for specgen instruction: movsbl %cl, %ebx:
%rbx/%rbx: (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r15
Value is               -> (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0]

Final state
%r15/%r15: 0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0]

=====================================
-------------------------------------
Getting base circuit for movsbq %r15b, %rcx

Final state:
%rcx/%rcx: sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for adcb %cl, %r13b

Final state:
%r13/%r13b: (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][3:0] + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁
%of: (sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][7:7] = 0x1₁) ∧ !(sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:7] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r13d, %rbx

Final state:
%rbx/%rbx: sign-extend-64(((0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0])[31:0])

-------------------------------------
=====================================
Computing circuit for xaddb %bl, %dl

.target:
callq .clear_cf
movsbl %cl, %r13d
movsbl %bl, %r15d
movsbq %r15b, %rcx
adcb %cl, %r13b
movslq %r13d, %rbx
retq 

Initial state:
%rdx/%dl: 0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8]
%rbx/%bl: %rbx_xaddb_rh_r8

%cf: %cf_xaddb_rh_r8
%pf: %pf_xaddb_rh_r8
%af: %af_xaddb_rh_r8
%zf: %zf_xaddb_rh_r8
%sf: %sf_xaddb_rh_r8
%of: %of_xaddb_rh_r8

State for specgen instruction: xaddb %cl, %bl:
%rcx/%cl: sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])
%rbx/%bl: sign-extend-64(((0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0])[31:0])

%cf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][3:0] + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁
%of: (sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][7:7] = 0x1₁) ∧ !(sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:7] = 0x1₁)

Final state
%rdx/%dl: (0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8])[63:8] ∘ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0]
%rbx/%bl: %rbx_xaddb_rh_r8[63:8] ∘ %rax_xaddb_rh_r8[15:8]

%cf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[8:8] = 0x1₁
%pf: !((0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rax_xaddb_rh_r8[11:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0] = 0x0₈
%sf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁
%of: (%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ %rbx_xaddb_rh_r8[7:7] = 0x1₁) ∧ !(%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for movb %dl, %ah

Final state:
%rax/%ah: %rax_xaddb_rh_r8[63:16] ∘ ((0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8])[63:8] ∘ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0])[7:0] ∘ %rax_xaddb_rh_r8[7:0]

-------------------------------------
=====================================
Computing circuit for xaddb %al, %bh

.target:
movzbl %ah, %edx
xaddb %bl, %dl
movb %dl, %ah
retq 

Initial state:
%rax/%al: %rax_xorb_rh_rh[63:8] ∘ 0x0₈
%rbx/%bh: %rbx_xorb_rh_rh

%cf: false
%pf: true
%af: %af_xorb_rh_rh
%zf: true
%sf: false
%of: false

State for specgen instruction: xaddb %bl, %ah:
%rax/%ah: %rax_xaddb_rh_r8[63:16] ∘ ((0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8])[63:8] ∘ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0])[7:0] ∘ %rax_xaddb_rh_r8[7:0]
%rbx/%bl: %rbx_xaddb_rh_r8[63:8] ∘ %rax_xaddb_rh_r8[15:8]

%cf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[8:8] = 0x1₁
%pf: !((0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rax_xaddb_rh_r8[11:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0] = 0x0₈
%sf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁
%of: (%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ %rbx_xaddb_rh_r8[7:7] = 0x1₁) ∧ !(%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)

Final state
%rax/%al: (%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8]
%rbx/%bh: %rbx_xorb_rh_rh[63:16] ∘ %rbx_xorb_rh_rh[15:8] ∘ %rbx_xorb_rh_rh[7:0]

%cf: false
%pf: !(%rbx_xorb_rh_rh[8:8] = 0x1₁ ⊕ %rbx_xorb_rh_rh[9:9] = 0x1₁ ⊕ %rbx_xorb_rh_rh[10:10] = 0x1₁ ⊕ %rbx_xorb_rh_rh[11:11] = 0x1₁ ⊕ %rbx_xorb_rh_rh[12:12] = 0x1₁ ⊕ %rbx_xorb_rh_rh[13:13] = 0x1₁ ⊕ %rbx_xorb_rh_rh[14:14] = 0x1₁ ⊕ %rbx_xorb_rh_rh[15:15] = 0x1₁)
%af: false
%zf: %rbx_xorb_rh_rh[15:8] = 0x0₈
%sf: %rbx_xorb_rh_rh[15:15] = 0x1₁
%of: (%rbx_xorb_rh_rh[15:15] = 0x1₁ ↔ false) ∧ !(%rbx_xorb_rh_rh[15:15] = 0x1₁ ↔ %rbx_xorb_rh_rh[15:15] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for movq $0x4, %rdi

Final state:
%rdi/%rdi: 0x4₆₄

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_shlb_r8_one ⊕ %rax_shlb_r8_one

%cf: false
%pf: !((%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][0:0] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][1:1] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][2:2] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][3:3] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][4:4] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][5:5] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][6:6] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][7:7] = 0x1₁)
%zf: (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one) = 0x0₆₄
%sf: (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: false

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][3:0] + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][7:7] = 0x1₁ ↔ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][7:7] = 0x1₁) ∧ !((%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:7] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for adcb %bl, %bl

Final state:
%rbx/%bl: %rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0]

%cf: ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[8:8] = 0x1₁
%pf: !(((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rbx_shlb_r8_one[7:0][3:0] + 0x0₁ ∘ %rbx_shlb_r8_one[7:0][3:0])[4:4] = 0x1₁
%zf: ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0] = 0x0₈
%sf: ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:7] = 0x1₁
%of: (%rbx_shlb_r8_one[7:0][7:7] = 0x1₁ ↔ %rbx_shlb_r8_one[7:0][7:7] = 0x1₁) ∧ !(%rbx_shlb_r8_one[7:0][7:7] = 0x1₁ ↔ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:7] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_bl

Final state:
%rax/%rax: (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0]
%rdx/%rdx: %rdx_shlb_r8_one

%xmm0: %ymm0_shlb_r8_one[127:0]
%xmm1: %ymm1_shlb_r8_one[127:0]

-------------------------------------
=====================================
Computing circuit for shlb $0x1, %dil

.target:
xorq %rax, %rax
clc 
adcb %al, %al
adcb %bl, %bl
callq .set_szp_for_bl
retq 

Initial state:
%rdi/%dil: 0x4₆₄

%cf: %cf_xorb_rh_r8
%pf: %pf_xorb_rh_r8
%zf: %zf_xorb_rh_r8
%sf: %sf_xorb_rh_r8
%of: %of_xorb_rh_r8

State for specgen instruction: shlb $0x1, %bl:
%rbx/%bl: %rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0]

%cf: ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[8:8] = 0x1₁
%pf: !((%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%zf: (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0] = 0x0₈
%sf: (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:7] = 0x1₁
%of: (%rbx_shlb_r8_one[7:0][7:7] = 0x1₁ ↔ %rbx_shlb_r8_one[7:0][7:7] = 0x1₁) ∧ !(%rbx_shlb_r8_one[7:0][7:7] = 0x1₁ ↔ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:7] = 0x1₁)

Register        -> %bl
  translates to => %dil
Value is               -> (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0]
  after renaming it is => 0x8₈

Final state
%rdi/%dil: 0x4₆₄[63:8] ∘ 0x8₈

%cf: false
%pf: false
%zf: false
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for xorq %r8, %r8

Final state:
%r8/%r8: %r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8

%cf: false
%pf: !((%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][0:0] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][1:1] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][2:2] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][3:3] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][4:4] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][5:5] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][6:6] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][7:7] = 0x1₁)
%zf: (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8) = 0x0₆₄
%sf: (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for movq $0x40, %rbx

Final state:
%rbx/%rbx: 0x40₆₄

-------------------------------------
-------------------------------------
Getting base circuit for movb %ah, %bl

Final state:
%rbx/%bl: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

-------------------------------------
=====================================
Computing circuit for movzbl %ah, %ebp

.target:
movq $0x40, %rbx
movb %ah, %bl
retq 

Initial state:
%rbp/%rbp: %rbp_xorb_r8_rh

State for specgen instruction: movzbl %ah, %ebx:
%rbx/%rbx: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

Register        -> %rbx
  translates to => %rbp
Value is               -> 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]
  after renaming it is => 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

Final state
%rbp/%rbp: 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

=====================================
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh

%cf: false
%pf: !((%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][0:0] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][1:1] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][2:2] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][3:3] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][4:4] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][5:5] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][6:6] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][7:7] = 0x1₁)
%zf: (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh) = 0x0₆₄
%sf: (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_cf_into_rcx

Final state:
%rax/%rax: %rax_setc_rh
%rdx/%rdx: %rdx_setc_rh

%xmm0: %ymm0_setc_rh[127:0]
%xmm1: %ymm1_setc_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movb %cl, %ah

Final state:
%rax/%ah: %rax_setc_rh[63:16] ∘ (0x0₆₃ ∘ (%cf_setc_rh ? 0x1₁ : 0x0₁))[7:0] ∘ %rax_setc_rh[7:0]

-------------------------------------
=====================================
Computing circuit for setc %bh

.target:
callq .read_cf_into_rcx
movb %cl, %ah
retq 

Initial state:
%rbx/%bh: %rbx_xorb_r8_rh

State for specgen instruction: setc %ah:
%rax/%ah: %rax_setc_rh[63:16] ∘ (0x0₆₃ ∘ (%cf_setc_rh ? 0x1₁ : 0x0₁))[7:0] ∘ %rax_setc_rh[7:0]

Register        -> %ah
  translates to => %bh
Value is               -> (%rax_setc_rh[63:16] ∘ (0x0₆₃ ∘ (%cf_setc_rh ? 0x1₁ : 0x0₁))[7:0] ∘ %rax_setc_rh[7:0])[15:8]
  after renaming it is => 0x0₈

Final state
%rbx/%bh: %rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0]

=====================================
-------------------------------------
Getting base circuit for movswq %bx, %rdx

Final state:
%rdx/%rdx: sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rbp, %rdx

Final state:
%rdx/%rdx: sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

%cf: false
%pf: !((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][0:0] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][1:1] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][2:2] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][3:3] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][4:4] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][5:5] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][6:6] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][7:7] = 0x1₁)
%zf: (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]) = 0x0₆₄
%sf: (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for movslq %edx, %rbx

Final state:
%rbx/%rbx: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_bl

Final state:
%rax/%rax: %rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh
%rdx/%rdx: sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

%xmm0: %ymm0_xorb_r8_rh[127:0]
%xmm1: %ymm1_xorb_r8_rh[127:0]

-------------------------------------
=====================================
Computing circuit for xorb %ah, %bl

.target:
movzbl %ah, %ebp
xorq %rax, %rax
setc %bh
movswq %bx, %rdx
xorq %rbp, %rdx
movslq %edx, %rbx
callq .set_szp_for_bl
retq 

Initial state:
%rbx/%bl: %rbx_xorb_rh_r8

%cf: false
%pf: !((%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][0:0] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][1:1] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][2:2] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][3:3] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][4:4] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][5:5] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][6:6] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][7:7] = 0x1₁)
%zf: (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8) = 0x0₆₄
%sf: (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[63:63] = 0x1₁
%of: false

State for specgen instruction: xorb %ah, %bl:
%rbx/%bl: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])

%cf: false
%pf: !(sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][0:0] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][1:1] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][2:2] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][3:3] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][4:4] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][5:5] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][6:6] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][7:7] = 0x1₁)
%zf: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0] = 0x0₈
%sf: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:7] = 0x1₁
%of: false

Register        -> %bl
  translates to => %bl
Value is               -> sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0]
  after renaming it is => %rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]

Final state
%rbx/%bl: %rbx_xorb_rh_r8[63:8] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8])

%cf: false
%pf: !((%rbx_xorb_rh_r8[0:0] ⊕ %rax_xorb_rh_r8[8:8]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[1:1] ⊕ %rax_xorb_rh_r8[9:9]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[2:2] ⊕ %rax_xorb_rh_r8[10:10]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[3:3] ⊕ %rax_xorb_rh_r8[11:11]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[4:4] ⊕ %rax_xorb_rh_r8[12:12]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[5:5] ⊕ %rax_xorb_rh_r8[13:13]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[6:6] ⊕ %rax_xorb_rh_r8[14:14]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁)
%zf: (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) = 0x0₈
%sf: (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁
%of: false

=====================================
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16

%cf: false
%pf: !((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][0:0] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][1:1] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][2:2] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][3:3] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][4:4] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][5:5] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][6:6] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][7:7] = 0x1₁)
%zf: (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16) = 0x0₆₄
%sf: (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: false

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for adcw %cx, %ax

Final state:
%rax/%ax: (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0]

%cf: ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[16:16] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_popcntw_r16_r16[15:0][3:0] + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0] = 0x0₁₆
%sf: ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][15:15] = 0x1₁
%of: (%rcx_popcntw_r16_r16[15:0][15:15] = 0x1₁ ↔ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0][15:15] = 0x1₁) ∧ !(%rcx_popcntw_r16_r16[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:15] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for popcntq %rax, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][1:0][0:0]))))) + 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][1:0][0:0])))))

%cf: false
%pf: false
%af: false
%zf: (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0] = 0x0₆₄
%sf: false
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: false

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
=====================================
Computing circuit for popcntw %r8w, %ax

.target:
xorq %rax, %rax
clc 
adcw %cx, %ax
popcntq %rax, %rbx
clc 
retq 

Initial state:
%rax/%ax: %rax_xorb_rh_r8

%cf: false
%pf: !((%rbx_xorb_rh_r8[0:0] ⊕ %rax_xorb_rh_r8[8:8]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[1:1] ⊕ %rax_xorb_rh_r8[9:9]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[2:2] ⊕ %rax_xorb_rh_r8[10:10]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[3:3] ⊕ %rax_xorb_rh_r8[11:11]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[4:4] ⊕ %rax_xorb_rh_r8[12:12]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[5:5] ⊕ %rax_xorb_rh_r8[13:13]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[6:6] ⊕ %rax_xorb_rh_r8[14:14]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁)
%af: TMP_BOOL_47
%zf: (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) = 0x0₈
%sf: (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁
%of: false

State for specgen instruction: popcntw %cx, %bx:
%rbx/%bx: 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][1:0][0:0]))))) + 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][1:0][0:0])))))

%cf: false
%pf: false
%af: false
%zf: (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0] = 0x0₆₄
%sf: false
%of: false

Register        -> %bx
  translates to => %ax
Value is               -> (0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][1:0][0:0]))))) + 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][1:0][0:0]))))))[15:0]
  after renaming it is => 0x0₁₆

Final state
%rax/%ax: %rax_xorb_rh_r8[63:16] ∘ 0x0₁₆

%cf: false
%pf: false
%af: false
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rcx

Final state:
%rcx/%rcx: %rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh

%cf: false
%pf: !((%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][0:0] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][1:1] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][2:2] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][3:3] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][4:4] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][5:5] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][6:6] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][7:7] = 0x1₁)
%zf: (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh) = 0x0₆₄
%sf: (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_sf_into_rbx

Final state:
%rax/%rax: %rax_movzbw_r16_rh
%rdx/%rdx: %rdx_movzbw_r16_rh

%xmm0: %ymm0_movzbw_r16_rh[127:0]
%xmm1: %ymm1_movzbw_r16_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movb %ah, %bl

Final state:
%rbx/%bl: (0x0₆₃ ∘ ((%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[63:63] = 0x1₁ ? 0x1₁ : 0x0₁))[63:8] ∘ %rax_movzbw_r16_rh[15:8]

-------------------------------------
=====================================
Computing circuit for movzbw %ah, %si

.target:
xorq %rcx, %rcx
callq .read_sf_into_rbx
movb %ah, %bl
retq 

Initial state:
%rsi/%si: %rsi_xaddb_r8_rh

State for specgen instruction: movzbw %ah, %bx:
%rbx/%bx: (0x0₆₃ ∘ ((%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[63:63] = 0x1₁ ? 0x1₁ : 0x0₁))[63:8] ∘ %rax_movzbw_r16_rh[15:8]

Register        -> %bx
  translates to => %si
Value is               -> ((0x0₆₃ ∘ ((%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[63:63] = 0x1₁ ? 0x1₁ : 0x0₁))[63:8] ∘ %rax_movzbw_r16_rh[15:8])[15:0]
  after renaming it is => 0x0₈ ∘ %rax_xaddb_r8_rh[15:8]

Final state
%rsi/%si: %rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8])

=====================================
-------------------------------------
Getting base circuit for movq $0x0, %rbx

Final state:
%rbx/%rbx: 0x0₆₄

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: %cf_movzbq_r64_r8

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for movsbq %cl, %rdi

Final state:
%rdi/%rdi: sign-extend-64(%rcx_movzbq_r64_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for adcb %dil, %bl

Final state:
%rbx/%bl: 0x0₆₄[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0][3:0] + 0x0₁ ∘ 0x0₆₄[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:7] = 0x1₁
%of: (sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0][7:7] = 0x1₁ ↔ 0x0₆₄[7:0][7:7] = 0x1₁) ∧ !(sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for movzbq %bl, %r12

.target:
movq $0x0, %rbx
clc 
movsbq %cl, %rdi
adcb %dil, %bl
retq 

Initial state:
%r12/%r12: %r12_xaddb_r8_rh

State for specgen instruction: movzbq %cl, %rbx:
%rbx/%rbx: 0x0₆₄[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0]

Register        -> %rbx
  translates to => %r12
Value is               -> 0x0₆₄[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0]
  after renaming it is => 0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0]

Final state
%r12/%r12: 0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0]

=====================================
-------------------------------------
Getting base circuit for movslq %r12d, %rdx

Final state:
%rdx/%rdx: sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_dx_r8b_r9b

Final state:
%rax/%rax: %rax_xaddb_r8_rh
%rdx/%rdx: sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])

%xmm0: %ymm0_xaddb_r8_rh[127:0]
%xmm1: %ymm1_xaddb_r8_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_of

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_of_into_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movsbq %cl, %r10

Final state:
%r10/%r10: sign-extend-64(%rcx_movsbl_r32_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
=====================================
Computing circuit for movsbl %r12b, %ebx

.target:
callq .set_of
callq .read_of_into_rbx
callq .move_064_032_rbx_r10d_r11d
movsbq %cl, %r10
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%rbx/%rbx: %rbx_xaddb_r8_rh

State for specgen instruction: movsbl %cl, %ebx:
%rbx/%rbx: (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]

Register        -> %rbx
  translates to => %rbx
Value is               -> (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0]

Final state
%rbx/%rbx: 0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0]

=====================================
-------------------------------------
Getting base circuit for movb %dl, %ah

Final state:
%rax/%ah: %rax_xaddb_r8_rh[63:16] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[7:0] ∘ %rax_xaddb_r8_rh[7:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r9b_to_byte_6_of_rbx

Final state:
%rax/%rax: %rax_xaddb_r8_rh[63:16] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[7:0] ∘ %rax_xaddb_r8_rh[7:0]
%rdx/%rdx: sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])

%xmm0: %ymm0_xaddb_r8_rh[127:0]
%xmm1: %ymm1_xaddb_r8_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for popcntq %rdx, %r9

Final state:
%r9/%r9: 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][3:0][1:0][0:0]))))) + 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][3:0][1:0][0:0])))))

%cf: false
%pf: false
%af: false
%zf: sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0]) = 0x0₆₄
%sf: false
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %sil, %bl

Final state:
%rbx/%bl: ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[63:8] ∘ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0][3:0] + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:7] = 0x1₁
%of: ((%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0][7:7] = 0x1₁ ↔ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0][7:7] = 0x1₁) ∧ !((%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for xaddb %ah, %bl

.target:
movzbw %ah, %si
movzbq %bl, %r12
movslq %r12d, %rdx
callq .move_016_008_dx_r8b_r9b
movsbl %r12b, %ebx
movb %dl, %ah
callq .move_r9b_to_byte_6_of_rbx
popcntq %rdx, %r9
adcb %sil, %bl
retq 

Initial state:
%rax/%ah: %rax_xorb_rh_r8[63:16] ∘ 0x0₁₆
%rbx/%bl: %rbx_xorb_rh_r8[63:8] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8])

%cf: false
%pf: false
%af: false
%zf: true
%sf: false
%of: false

State for specgen instruction: xaddb %ah, %bl:
%rax/%ah: %rax_xaddb_r8_rh[63:16] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[7:0] ∘ %rax_xaddb_r8_rh[7:0]
%rbx/%bl: ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[63:8] ∘ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0][3:0] + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:7] = 0x1₁
%of: ((%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0][7:7] = 0x1₁ ↔ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0][7:7] = 0x1₁) ∧ !((%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:7] = 0x1₁)

Final state
%rax/%ah: (%rax_xorb_rh_r8[63:16] ∘ 0x0₁₆)[63:16] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) ∘ (%rax_xorb_rh_r8[63:16] ∘ 0x0₁₆)[7:0]
%rbx/%bl: (%rbx_xorb_rh_r8[63:8] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]))[63:8] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8])

%cf: false
%pf: !((%rbx_xorb_rh_r8[0:0] ⊕ %rax_xorb_rh_r8[8:8]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[1:1] ⊕ %rax_xorb_rh_r8[9:9]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[2:2] ⊕ %rax_xorb_rh_r8[10:10]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[3:3] ⊕ %rax_xorb_rh_r8[11:11]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[4:4] ⊕ %rax_xorb_rh_r8[12:12]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[5:5] ⊕ %rax_xorb_rh_r8[13:13]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[6:6] ⊕ %rax_xorb_rh_r8[14:14]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁)
%af: false
%zf: (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) = 0x0₈
%sf: (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁
%of: (false ↔ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁) ∧ !(false ↔ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_rcll_r32_one[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for adcl %ebx, %ebx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0]

%cf: ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[32:32] = 0x1₁
%pf: !(((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][3:0] + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][3:0])[4:4] = 0x1₁
%zf: ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0] = 0x0₃₂
%sf: ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][31:31] = 0x1₁
%of: (sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][31:31] = 0x1₁ ↔ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][31:31] = 0x1₁) ∧ !(sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][31:31] = 0x1₁ ↔ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:31] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for rcll $0x1, %edi

.target:
movslq %ebx, %rbx
adcl %ebx, %ebx
retq 

Initial state:
%rdi/%rdi: 0x4₆₄[63:8] ∘ 0x8₈

%cf: false
%of: (false ↔ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁) ∧ !(false ↔ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁)

State for specgen instruction: rcll $0x1, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0]

%cf: ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[32:32] = 0x1₁
%of: (sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][31:31] = 0x1₁ ↔ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][31:31] = 0x1₁) ∧ !(sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][31:31] = 0x1₁ ↔ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:31] = 0x1₁)

Register        -> %rbx
  translates to => %rdi
Value is               -> 0x0₃₂ ∘ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0]
  after renaming it is => 0x10₆₄

Final state
%rdi/%rdi: 0x10₆₄

%cf: false
%of: false

=====================================
=====================================
Computing circuit for xorb %al, %ah

.target:
movq $0x4, %rdi
shlb $0x1, %dil
xorq %r8, %r8
xorb %ah, %bl
popcntw %r8w, %ax
xaddb %ah, %bl
rcll $0x1, %edi
retq 

Initial state:
%rax/%ah: (%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8]

%cf: false
%pf: !(%rbx_xorb_rh_rh[8:8] = 0x1₁ ⊕ %rbx_xorb_rh_rh[9:9] = 0x1₁ ⊕ %rbx_xorb_rh_rh[10:10] = 0x1₁ ⊕ %rbx_xorb_rh_rh[11:11] = 0x1₁ ⊕ %rbx_xorb_rh_rh[12:12] = 0x1₁ ⊕ %rbx_xorb_rh_rh[13:13] = 0x1₁ ⊕ %rbx_xorb_rh_rh[14:14] = 0x1₁ ⊕ %rbx_xorb_rh_rh[15:15] = 0x1₁)
%zf: %rbx_xorb_rh_rh[15:8] = 0x0₈
%sf: %rbx_xorb_rh_rh[15:15] = 0x1₁
%of: (%rbx_xorb_rh_rh[15:15] = 0x1₁ ↔ false) ∧ !(%rbx_xorb_rh_rh[15:15] = 0x1₁ ↔ %rbx_xorb_rh_rh[15:15] = 0x1₁)

State for specgen instruction: xorb %bl, %ah:
%rax/%ah: (%rax_xorb_rh_r8[63:16] ∘ 0x0₁₆)[63:16] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) ∘ (%rax_xorb_rh_r8[63:16] ∘ 0x0₁₆)[7:0]

%cf: false
%pf: !((%rbx_xorb_rh_r8[0:0] ⊕ %rax_xorb_rh_r8[8:8]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[1:1] ⊕ %rax_xorb_rh_r8[9:9]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[2:2] ⊕ %rax_xorb_rh_r8[10:10]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[3:3] ⊕ %rax_xorb_rh_r8[11:11]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[4:4] ⊕ %rax_xorb_rh_r8[12:12]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[5:5] ⊕ %rax_xorb_rh_r8[13:13]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[6:6] ⊕ %rax_xorb_rh_r8[14:14]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁)
%zf: (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) = 0x0₈
%sf: (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁
%of: false

Register        -> %ah
  translates to => %ah
Value is               -> ((%rax_xorb_rh_r8[63:16] ∘ 0x0₁₆)[63:16] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) ∘ (%rax_xorb_rh_r8[63:16] ∘ 0x0₁₆)[7:0])[15:8]
  after renaming it is => %rbx_xorb_rh_rh[15:8] ⊕ %rax_xorb_rh_rh[15:8]

Final state
%rax/%ah: ((%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8])[63:16] ∘ (%rbx_xorb_rh_rh[15:8] ⊕ %rax_xorb_rh_rh[15:8]) ∘ ((%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8])[7:0]

%cf: false
%pf: !((%rbx_xorb_rh_rh[8:8] ⊕ %rax_xorb_rh_rh[8:8]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[9:9] ⊕ %rax_xorb_rh_rh[9:9]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[10:10] ⊕ %rax_xorb_rh_rh[10:10]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[11:11] ⊕ %rax_xorb_rh_rh[11:11]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[12:12] ⊕ %rax_xorb_rh_rh[12:12]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[13:13] ⊕ %rax_xorb_rh_rh[13:13]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[14:14] ⊕ %rax_xorb_rh_rh[14:14]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[15:15] ⊕ %rax_xorb_rh_rh[15:15]) = 0x1₁)
%zf: (%rbx_xorb_rh_rh[15:8] ⊕ %rax_xorb_rh_rh[15:8]) = 0x0₈
%sf: (%rbx_xorb_rh_rh[15:15] ⊕ %rax_xorb_rh_rh[15:15]) = 0x1₁
%of: false

=====================================
=====================================
Computing circuit for xorb %bh, %bh

.target:
xorb %al, %al
xaddb %al, %bh
xorb %al, %ah
retq 

Initial state:
%rbx/%bh: ((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆)

%cf: %cf_cmc
%pf: !((%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁)
%zf: (%cf_cmc ? 0x0₁₆ : 0xffff₁₆) = 0x0₁₆
%sf: (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁
%of: false ∧ !(false ↔ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁)

State for specgen instruction: xorb %bh, %ah:
%rax/%ah: ((%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8])[63:16] ∘ (%rbx_xorb_rh_rh[15:8] ⊕ %rax_xorb_rh_rh[15:8]) ∘ ((%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8])[7:0]

%cf: false
%pf: !((%rbx_xorb_rh_rh[8:8] ⊕ %rax_xorb_rh_rh[8:8]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[9:9] ⊕ %rax_xorb_rh_rh[9:9]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[10:10] ⊕ %rax_xorb_rh_rh[10:10]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[11:11] ⊕ %rax_xorb_rh_rh[11:11]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[12:12] ⊕ %rax_xorb_rh_rh[12:12]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[13:13] ⊕ %rax_xorb_rh_rh[13:13]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[14:14] ⊕ %rax_xorb_rh_rh[14:14]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[15:15] ⊕ %rax_xorb_rh_rh[15:15]) = 0x1₁)
%zf: (%rbx_xorb_rh_rh[15:8] ⊕ %rax_xorb_rh_rh[15:8]) = 0x0₈
%sf: (%rbx_xorb_rh_rh[15:15] ⊕ %rax_xorb_rh_rh[15:15]) = 0x1₁
%of: false

Register        -> %ah
  translates to => %bh
Value is               -> (((%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8])[63:16] ∘ (%rbx_xorb_rh_rh[15:8] ⊕ %rax_xorb_rh_rh[15:8]) ∘ ((%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8])[7:0])[15:8]
  after renaming it is => 0x0₈

Final state
%rbx/%bh: (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0]

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for adcb %bl, %bl

Final state:
%rbx/%bl: ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[63:8] ∘ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0][3:0] + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:7] = 0x1₁
%of: (((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0][7:7] = 0x1₁ ↔ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0][7:7] = 0x1₁) ∧ !(((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for cmc 

.target:
callq .read_cf_into_rbx
callq .move_064_032_rbx_r8d_r9d
callq .move_r8b_to_byte_5_of_rbx
decw %bx
xorb %bh, %bh
adcb %bl, %bl
retq 

Initial state:
%cf: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[64:64] = 0x1₁

State for specgen instruction: cmc :
%cf: ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[8:8] = 0x1₁

Final state
%cf: (((0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %rbx_subq_r64_r64)[64:64] = 0x1₁ ? 0x0₉ : 0xff₉) + ((0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %rbx_subq_r64_r64)[64:64] = 0x1₁ ? 0x0₉ : 0xff₉))[8:8] = 0x1₁

=====================================
=====================================
Computing circuit for subq %r9, %r11

.target:
stc 
notq %rcx
adcq %rcx, %rbx
cmc 
retq 

Initial state:
%r11/%r11: %ymm2_vpsubq_xmm_xmm_xmm[127:0][127:64]

%cf: %cf_vpsubq_xmm_xmm_xmm
%pf: %pf_vpsubq_xmm_xmm_xmm
%af: %af_vpsubq_xmm_xmm_xmm
%zf: %zf_vpsubq_xmm_xmm_xmm
%sf: %sf_vpsubq_xmm_xmm_xmm
%of: %of_vpsubq_xmm_xmm_xmm

State for specgen instruction: subq %rcx, %rbx:
%rbx/%rbx: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0]

%cf: (((0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %rbx_subq_r64_r64)[64:64] = 0x1₁ ? 0x0₉ : 0xff₉) + ((0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %rbx_subq_r64_r64)[64:64] = 0x1₁ ? 0x0₉ : 0xff₉))[8:8] = 0x1₁
%pf: !(((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][0:0] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][1:1] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][2:2] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][3:3] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][4:4] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][5:5] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][6:6] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)[3:0] + 0x0₁ ∘ %rbx_subq_r64_r64[3:0])[4:4] = 0x1₁
%zf: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0] = 0x0₆₄
%sf: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][63:63] = 0x1₁
%of: ((%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)[63:63] = 0x1₁ ↔ %rbx_subq_r64_r64[63:63] = 0x1₁) ∧ !((%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)[63:63] = 0x1₁ ↔ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r11
Value is               -> ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0]
  after renaming it is => (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[63:0]

Final state
%r11/%r11: (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[63:0]

%cf: (((0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[64:64] = 0x1₁ ? 0x0₉ : 0xff₉) + ((0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[64:64] = 0x1₁ ? 0x0₉ : 0xff₉))[8:8] = 0x1₁
%pf: !((0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[7:7] = 0x1₁)
%af: (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[67:64] ⊕ 0xf₄) + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[67:64])[4:4] = 0x1₁
%zf: (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[63:63] = 0x1₁
%of: ((%ymm3_vpsubq_xmm_xmm_xmm[127:127] ⊕ 0x1₁) = 0x1₁ ↔ %ymm2_vpsubq_xmm_xmm_xmm[127:127] = 0x1₁) ∧ !((%ymm3_vpsubq_xmm_xmm_xmm[127:127] ⊕ 0x1₁) = 0x1₁ ↔ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .set_cf

Final state:
%rax/%rax: %rax_stc
%rdx/%rdx: %rdx_stc

%xmm0: %ymm0_stc[127:0]
%xmm1: %ymm1_stc[127:0]

-------------------------------------
=====================================
Computing circuit for stc 

.target:
callq .set_cf
retq 

Initial state:
%cf: %cf_subq_r64_r64

State for specgen instruction: stc :
%cf: true

Final state
%cf: true

=====================================
-------------------------------------
Getting base circuit for movq $0xfffffffffffffffe, %rdx

Final state:
%rdx/%rdx: 0xfffffffffffffffe₆₄

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_incb_r8 ⊕ %rax_incb_r8

%cf: false
%pf: !((%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][0:0] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][1:1] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][2:2] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][3:3] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][4:4] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][5:5] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][6:6] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][7:7] = 0x1₁)
%zf: (%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄
%sf: (%rax_incb_r8 ⊕ %rax_incb_r8)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: false

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for callq .read_zf_into_rcx

Final state:
%rax/%rax: %rax_incb_r8 ⊕ %rax_incb_r8
%rdx/%rdx: %rdx_incb_r8

%xmm0: %ymm0_incb_r8[127:0]
%xmm1: %ymm1_incb_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for adcb %cl, %bl

Final state:
%rbx/%bl: %rbx_incb_r8[63:8] ∘ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0][3:0] + 0x0₁ ∘ %rbx_incb_r8[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:7] = 0x1₁
%of: ((0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0][7:7] = 0x1₁ ↔ %rbx_incb_r8[7:0][7:7] = 0x1₁) ∧ !((0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for incb %dl

.target:
xorq %rax, %rax
clc 
callq .read_zf_into_rcx
adcb %cl, %bl
retq 

Initial state:
%rdx/%dl: 0xfffffffffffffffe₆₄

%pf: %pf_notq_r64
%af: %af_notq_r64
%zf: %zf_notq_r64
%sf: %sf_notq_r64
%of: %of_notq_r64

State for specgen instruction: incb %bl:
%rbx/%bl: %rbx_incb_r8[63:8] ∘ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0]

%pf: !(((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0][3:0] + 0x0₁ ∘ %rbx_incb_r8[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:7] = 0x1₁
%of: ((0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0][7:7] = 0x1₁ ↔ %rbx_incb_r8[7:0][7:7] = 0x1₁) ∧ !((0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:7] = 0x1₁)

Register        -> %bl
  translates to => %dl
Value is               -> (%rbx_incb_r8[63:8] ∘ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0])[7:0]
  after renaming it is => 0xff₈

Final state
%rdx/%dl: 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈

%pf: true
%af: false
%zf: false
%sf: true
%of: false

=====================================
-------------------------------------
Getting base circuit for xorq %rdx, %rbx

Final state:
%rbx/%rbx: %rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈

%cf: false
%pf: !((%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][0:0] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][1:1] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][2:2] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][3:3] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][4:4] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][5:5] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][6:6] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][7:7] = 0x1₁)
%zf: (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈) = 0x0₆₄
%sf: (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[63:63] = 0x1₁
%of: false

-------------------------------------
=====================================
Computing circuit for notq %rcx

.target:
movq $0xfffffffffffffffe, %rdx
incb %dl
xorq %rdx, %rbx
retq 

Initial state:
%rcx/%rcx: %rcx_subq_r64_r64

State for specgen instruction: notq %rbx:
%rbx/%rbx: %rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈

Register        -> %rbx
  translates to => %rcx
Value is               -> %rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈
  after renaming it is => %rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄

Final state
%rcx/%rcx: %rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄

=====================================
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0]

%cf: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[64:64] = 0x1₁
%pf: !(((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][0:0] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][1:1] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][2:2] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][3:3] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][4:4] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][5:5] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][6:6] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)[3:0] + 0x0₁ ∘ %rbx_subq_r64_r64[3:0])[4:4] = 0x1₁
%zf: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0] = 0x0₆₄
%sf: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][63:63] = 0x1₁
%of: ((%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)[63:63] = 0x1₁ ↔ %rbx_subq_r64_r64[63:63] = 0x1₁) ∧ !((%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)[63:63] = 0x1₁ ↔ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:63] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_cf_into_rbx

Final state:
%rax/%rax: %rax_cmc
%rdx/%rdx: %rdx_cmc

%xmm0: %ymm0_cmc[127:0]
%xmm1: %ymm1_cmc[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r8d_r9d

Final state:
%rax/%rax: %rax_cmc
%rdx/%rdx: %rdx_cmc

%xmm0: %ymm0_cmc[127:0]
%xmm1: %ymm1_cmc[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r8b_to_byte_5_of_rbx

Final state:
%rax/%rax: %rax_cmc
%rdx/%rdx: %rdx_cmc

%xmm0: %ymm0_cmc[127:0]
%xmm1: %ymm1_cmc[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_decw_r16 ⊕ %rax_decw_r16

%cf: false
%pf: !((%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][0:0] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][1:1] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][2:2] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][3:3] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][4:4] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][5:5] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][6:6] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][7:7] = 0x1₁)
%zf: (%rax_decw_r16 ⊕ %rax_decw_r16) = 0x0₆₄
%sf: (%rax_decw_r16 ⊕ %rax_decw_r16)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for movq $0xffffffffffffffff, %rsi

Final state:
%rsi/%rsi: 0xffffffffffffffff₆₄

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r10b_r11b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_cx_r8b_r9b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r10b_r11b_cx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r8b_r9b_bx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for xchgw %ax, %bx

.target:
callq .move_016_008_bx_r10b_r11b
callq .move_016_008_cx_r8b_r9b
callq .move_008_016_r10b_r11b_cx
callq .move_008_016_r8b_r9b_bx
retq 

Initial state:
%rax/%ax: %rax_decw_r16 ⊕ %rax_decw_r16
%rbx/%bx: %rbx_decw_r16

State for specgen instruction: xchgw %cx, %bx:
%rcx/%cx: %rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])
%rbx/%bx: %rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])

Register        -> %cx
  translates to => %ax
Value is               -> (%rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => %rbx_decw_r16[15:0]

Register        -> %bx
  translates to => %bx
Value is               -> (%rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => 0x0₁₆

Final state
%rax/%ax: (%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0]
%rbx/%bx: %rbx_decw_r16[63:16] ∘ 0x0₁₆

=====================================
-------------------------------------
Getting base circuit for callq .read_cf_into_rbx

Final state:
%rax/%rax: (%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0]
%rdx/%rdx: %rdx_decw_r16

%xmm0: %ymm0_decw_r16[127:0]
%xmm1: %ymm1_decw_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for adcw %bx, %ax

Final state:
%rax/%ax: ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[63:16] ∘ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0]

%cf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[16:16] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0][3:0] + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0] = 0x0₁₆
%sf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][15:15] = 0x1₁
%of: ((0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0][15:15] = 0x1₁ ↔ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0][15:15] = 0x1₁) ∧ !((0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:15] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: %cf_addw_r16_r16

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for adcw %cx, %bx

Final state:
%rbx/%bx: %rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[16:16] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addw_r16_r16[15:0][3:0] + 0x0₁ ∘ %rbx_addw_r16_r16[15:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0] = 0x0₁₆
%sf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][15:15] = 0x1₁
%of: (%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ %rbx_addw_r16_r16[15:0][15:15] = 0x1₁) ∧ !(%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:15] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_bx

Final state:
%rax/%rax: %rax_addw_r16_r16
%rdx/%rdx: %rdx_addw_r16_r16

%xmm0: %ymm0_addw_r16_r16[127:0]
%xmm1: %ymm1_addw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for addw %ax, %si

.target:
clc 
adcw %cx, %bx
callq .set_szp_for_bx
retq 

Initial state:
%rsi/%si: 0xffffffffffffffff₆₄

%cf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[16:16] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0][3:0] + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0] = 0x0₁₆
%sf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][15:15] = 0x1₁
%of: ((0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0][15:15] = 0x1₁ ↔ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0][15:15] = 0x1₁) ∧ !((0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:15] = 0x1₁)

State for specgen instruction: addw %cx, %bx:
%rbx/%bx: %rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[16:16] = 0x1₁
%pf: !((%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addw_r16_r16[15:0][3:0] + 0x0₁ ∘ %rbx_addw_r16_r16[15:0][3:0])[4:4] = 0x1₁
%zf: (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0] = 0x0₁₆
%sf: (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][15:15] = 0x1₁
%of: (%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ %rbx_addw_r16_r16[15:0][15:15] = 0x1₁) ∧ !(%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:15] = 0x1₁)

Register        -> %bx
  translates to => %si
Value is               -> (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0]
  after renaming it is => (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0]

Final state
%rsi/%si: 0xffffffffffffffff₆₄[63:16] ∘ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0]

%cf: (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[16:16] = 0x1₁
%pf: !((0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rbx_decw_r16[3:0] + 0xf₅)[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0] = 0x0₁₆
%sf: (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:15] = 0x1₁
%of: (%rbx_decw_r16[15:15] = 0x1₁ ↔ true) ∧ !(%rbx_decw_r16[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:15] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for movswq %si, %rbx

Final state:
%rbx/%rbx: sign-extend-64((0xffffffffffffffff₆₄[63:16] ∘ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0])[15:0])

-------------------------------------
=====================================
Computing circuit for decw %bx

.target:
xorq %rax, %rax
movq $0xffffffffffffffff, %rsi
xchgw %ax, %bx
callq .read_cf_into_rbx
adcw %bx, %ax
addw %ax, %si
movswq %si, %rbx
retq 

Initial state:
%rbx/%bx: (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0]

%pf: %pf_cmc
%af: %af_cmc
%zf: %zf_cmc
%sf: %sf_cmc
%of: %of_cmc

State for specgen instruction: decw %bx:
%rbx/%bx: sign-extend-64((0xffffffffffffffff₆₄[63:16] ∘ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0])[15:0])

%pf: !((0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rbx_decw_r16[3:0] + 0xf₅)[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0] = 0x0₁₆
%sf: (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:15] = 0x1₁
%of: (%rbx_decw_r16[15:15] = 0x1₁ ↔ true) ∧ !(%rbx_decw_r16[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:15] = 0x1₁)

Register        -> %bx
  translates to => %bx
Value is               -> sign-extend-64((0xffffffffffffffff₆₄[63:16] ∘ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0])[15:0])[15:0]
  after renaming it is => %cf_cmc ? 0x0₁₆ : 0xffff₁₆

Final state
%rbx/%bx: ((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆)

%pf: !((%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁)
%af: (%cf_cmc ? 0x1₁ : 0x0₁) = 0x1₁
%zf: (%cf_cmc ? 0x0₁₆ : 0xffff₁₆) = 0x0₁₆
%sf: (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁
%of: false ∧ !(false ↔ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for movb %cl, %bh

Final state:
%rbx/%bh: %rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq $0x40, %rbx

Final state:
%rbx/%rbx: 0x40₆₄

-------------------------------------
-------------------------------------
Getting base circuit for movb %ah, %bl

Final state:
%rbx/%bl: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

-------------------------------------
=====================================
Computing circuit for movzbl %ah, %ebp

.target:
movq $0x40, %rbx
movb %ah, %bl
retq 

Initial state:
%rbp/%rbp: %rbp_xorb_r8_rh

State for specgen instruction: movzbl %ah, %ebx:
%rbx/%rbx: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

Register        -> %rbx
  translates to => %rbp
Value is               -> 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]
  after renaming it is => 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

Final state
%rbp/%rbp: 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

=====================================
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh

%cf: false
%pf: !((%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][0:0] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][1:1] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][2:2] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][3:3] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][4:4] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][5:5] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][6:6] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][7:7] = 0x1₁)
%zf: (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh) = 0x0₆₄
%sf: (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_cf_into_rcx

Final state:
%rax/%rax: %rax_setc_rh
%rdx/%rdx: %rdx_setc_rh

%xmm0: %ymm0_setc_rh[127:0]
%xmm1: %ymm1_setc_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movb %cl, %ah

Final state:
%rax/%ah: %rax_setc_rh[63:16] ∘ (0x0₆₃ ∘ (%cf_setc_rh ? 0x1₁ : 0x0₁))[7:0] ∘ %rax_setc_rh[7:0]

-------------------------------------
=====================================
Computing circuit for setc %bh

.target:
callq .read_cf_into_rcx
movb %cl, %ah
retq 

Initial state:
%rbx/%bh: %rbx_xorb_r8_rh

State for specgen instruction: setc %ah:
%rax/%ah: %rax_setc_rh[63:16] ∘ (0x0₆₃ ∘ (%cf_setc_rh ? 0x1₁ : 0x0₁))[7:0] ∘ %rax_setc_rh[7:0]

Register        -> %ah
  translates to => %bh
Value is               -> (%rax_setc_rh[63:16] ∘ (0x0₆₃ ∘ (%cf_setc_rh ? 0x1₁ : 0x0₁))[7:0] ∘ %rax_setc_rh[7:0])[15:8]
  after renaming it is => 0x0₈

Final state
%rbx/%bh: %rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0]

=====================================
-------------------------------------
Getting base circuit for movswq %bx, %rdx

Final state:
%rdx/%rdx: sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rbp, %rdx

Final state:
%rdx/%rdx: sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

%cf: false
%pf: !((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][0:0] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][1:1] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][2:2] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][3:3] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][4:4] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][5:5] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][6:6] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][7:7] = 0x1₁)
%zf: (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]) = 0x0₆₄
%sf: (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for movslq %edx, %rbx

Final state:
%rbx/%rbx: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_bl

Final state:
%rax/%rax: %rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh
%rdx/%rdx: sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

%xmm0: %ymm0_xorb_r8_rh[127:0]
%xmm1: %ymm1_xorb_r8_rh[127:0]

-------------------------------------
=====================================
Computing circuit for xorb %bh, %bl

.target:
movzbl %ah, %ebp
xorq %rax, %rax
setc %bh
movswq %bx, %rdx
xorq %rbp, %rdx
movslq %edx, %rbx
callq .set_szp_for_bl
retq 

Initial state:
%rbx/%bl: %rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0]

%cf: %cf_xorb_r8_r8
%pf: %pf_xorb_r8_r8
%zf: %zf_xorb_r8_r8
%sf: %sf_xorb_r8_r8
%of: %of_xorb_r8_r8

State for specgen instruction: xorb %ah, %bl:
%rbx/%bl: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])

%cf: false
%pf: !(sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][0:0] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][1:1] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][2:2] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][3:3] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][4:4] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][5:5] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][6:6] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][7:7] = 0x1₁)
%zf: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0] = 0x0₈
%sf: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:7] = 0x1₁
%of: false

Register        -> %bl
  translates to => %bl
Value is               -> sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0]
  after renaming it is => %rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]

Final state
%rbx/%bl: (%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0])

%cf: false
%pf: !((%rbx_xorb_r8_r8[0:0] ⊕ %rcx_xorb_r8_r8[0:0]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[1:1] ⊕ %rcx_xorb_r8_r8[1:1]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[2:2] ⊕ %rcx_xorb_r8_r8[2:2]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[3:3] ⊕ %rcx_xorb_r8_r8[3:3]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[4:4] ⊕ %rcx_xorb_r8_r8[4:4]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[5:5] ⊕ %rcx_xorb_r8_r8[5:5]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[6:6] ⊕ %rcx_xorb_r8_r8[6:6]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[7:7] ⊕ %rcx_xorb_r8_r8[7:7]) = 0x1₁)
%zf: (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]) = 0x0₈
%sf: (%rbx_xorb_r8_r8[7:7] ⊕ %rcx_xorb_r8_r8[7:7]) = 0x1₁
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .set_szp_for_bl

Final state:
%rax/%rax: %rax_xorb_r8_r8
%rdx/%rdx: %rdx_xorb_r8_r8

%xmm0: %ymm0_xorb_r8_r8[127:0]
%xmm1: %ymm1_xorb_r8_r8[127:0]

-------------------------------------
=====================================
Computing circuit for xorb %al, %al

.target:
movb %cl, %bh
xorb %bh, %bl
callq .set_szp_for_bl
retq 

Initial state:
%rax/%al: %rax_xorb_rh_rh

%cf: %cf_xorb_rh_rh
%pf: %pf_xorb_rh_rh
%zf: %zf_xorb_rh_rh
%sf: %sf_xorb_rh_rh
%of: %of_xorb_rh_rh

State for specgen instruction: xorb %cl, %bl:
%rbx/%bl: (%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0])

%cf: false
%pf: !(((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][0:0] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][1:1] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][2:2] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][3:3] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][4:4] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][5:5] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][6:6] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][7:7] = 0x1₁)
%zf: ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0] = 0x0₈
%sf: ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:7] = 0x1₁
%of: false

Register        -> %bl
  translates to => %al
Value is               -> ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0]
  after renaming it is => 0x0₈

Final state
%rax/%al: %rax_xorb_rh_rh[63:8] ∘ 0x0₈

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for movq $0x40, %rbx

Final state:
%rbx/%rbx: 0x40₆₄

-------------------------------------
-------------------------------------
Getting base circuit for movb %ah, %bl

Final state:
%rbx/%bl: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

-------------------------------------
=====================================
Computing circuit for movzbl %ah, %edx

.target:
movq $0x40, %rbx
movb %ah, %bl
retq 

Initial state:
%rdx/%rdx: %rdx_xaddb_rh_r8

State for specgen instruction: movzbl %ah, %ebx:
%rbx/%rbx: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

Register        -> %rbx
  translates to => %rdx
Value is               -> 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]
  after renaming it is => 0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8]

Final state
%rdx/%rdx: 0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8]

=====================================
-------------------------------------
Getting base circuit for callq .clear_cf

Final state:
%rax/%rax: %rax_xaddb_r8_r8
%rdx/%rdx: %rdx_xaddb_r8_r8

%xmm0: %ymm0_xaddb_r8_r8[127:0]
%xmm1: %ymm1_xaddb_r8_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_of

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_of_into_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movsbq %cl, %r10

Final state:
%r10/%r10: sign-extend-64(%rcx_movsbl_r32_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
=====================================
Computing circuit for movsbl %cl, %r13d

.target:
callq .set_of
callq .read_of_into_rbx
callq .move_064_032_rbx_r10d_r11d
movsbq %cl, %r10
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r13/%r13: %r13_xaddb_r8_r8

State for specgen instruction: movsbl %cl, %ebx:
%rbx/%rbx: (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r13
Value is               -> (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0]

Final state
%r13/%r13: 0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0]

=====================================
-------------------------------------
Getting base circuit for callq .set_of

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_of_into_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movsbq %cl, %r10

Final state:
%r10/%r10: sign-extend-64(%rcx_movsbl_r32_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
=====================================
Computing circuit for movsbl %bl, %r15d

.target:
callq .set_of
callq .read_of_into_rbx
callq .move_064_032_rbx_r10d_r11d
movsbq %cl, %r10
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r15/%r15: %r15_xaddb_r8_r8

State for specgen instruction: movsbl %cl, %ebx:
%rbx/%rbx: (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r15
Value is               -> (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0]

Final state
%r15/%r15: 0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0]

=====================================
-------------------------------------
Getting base circuit for movsbq %r15b, %rcx

Final state:
%rcx/%rcx: sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for adcb %cl, %r13b

Final state:
%r13/%r13b: (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][3:0] + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁
%of: (sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][7:7] = 0x1₁) ∧ !(sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:7] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r13d, %rbx

Final state:
%rbx/%rbx: sign-extend-64(((0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0])[31:0])

-------------------------------------
=====================================
Computing circuit for xaddb %bl, %dl

.target:
callq .clear_cf
movsbl %cl, %r13d
movsbl %bl, %r15d
movsbq %r15b, %rcx
adcb %cl, %r13b
movslq %r13d, %rbx
retq 

Initial state:
%rdx/%dl: 0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8]
%rbx/%bl: %rbx_xaddb_rh_r8

%cf: %cf_xaddb_rh_r8
%pf: %pf_xaddb_rh_r8
%af: %af_xaddb_rh_r8
%zf: %zf_xaddb_rh_r8
%sf: %sf_xaddb_rh_r8
%of: %of_xaddb_rh_r8

State for specgen instruction: xaddb %cl, %bl:
%rcx/%cl: sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])
%rbx/%bl: sign-extend-64(((0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0])[31:0])

%cf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][3:0] + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁
%of: (sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][7:7] = 0x1₁) ∧ !(sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:7] = 0x1₁)

Final state
%rdx/%dl: (0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8])[63:8] ∘ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0]
%rbx/%bl: %rbx_xaddb_rh_r8[63:8] ∘ %rax_xaddb_rh_r8[15:8]

%cf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[8:8] = 0x1₁
%pf: !((0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rax_xaddb_rh_r8[11:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0] = 0x0₈
%sf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁
%of: (%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ %rbx_xaddb_rh_r8[7:7] = 0x1₁) ∧ !(%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for movb %dl, %ah

Final state:
%rax/%ah: %rax_xaddb_rh_r8[63:16] ∘ ((0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8])[63:8] ∘ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0])[7:0] ∘ %rax_xaddb_rh_r8[7:0]

-------------------------------------
=====================================
Computing circuit for xaddb %al, %bh

.target:
movzbl %ah, %edx
xaddb %bl, %dl
movb %dl, %ah
retq 

Initial state:
%rax/%al: %rax_xorb_rh_rh[63:8] ∘ 0x0₈
%rbx/%bh: %rbx_xorb_rh_rh

%cf: false
%pf: true
%af: %af_xorb_rh_rh
%zf: true
%sf: false
%of: false

State for specgen instruction: xaddb %bl, %ah:
%rax/%ah: %rax_xaddb_rh_r8[63:16] ∘ ((0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8])[63:8] ∘ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0])[7:0] ∘ %rax_xaddb_rh_r8[7:0]
%rbx/%bl: %rbx_xaddb_rh_r8[63:8] ∘ %rax_xaddb_rh_r8[15:8]

%cf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[8:8] = 0x1₁
%pf: !((0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rax_xaddb_rh_r8[11:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0] = 0x0₈
%sf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁
%of: (%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ %rbx_xaddb_rh_r8[7:7] = 0x1₁) ∧ !(%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)

Final state
%rax/%al: (%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8]
%rbx/%bh: %rbx_xorb_rh_rh[63:16] ∘ %rbx_xorb_rh_rh[15:8] ∘ %rbx_xorb_rh_rh[7:0]

%cf: false
%pf: !(%rbx_xorb_rh_rh[8:8] = 0x1₁ ⊕ %rbx_xorb_rh_rh[9:9] = 0x1₁ ⊕ %rbx_xorb_rh_rh[10:10] = 0x1₁ ⊕ %rbx_xorb_rh_rh[11:11] = 0x1₁ ⊕ %rbx_xorb_rh_rh[12:12] = 0x1₁ ⊕ %rbx_xorb_rh_rh[13:13] = 0x1₁ ⊕ %rbx_xorb_rh_rh[14:14] = 0x1₁ ⊕ %rbx_xorb_rh_rh[15:15] = 0x1₁)
%af: false
%zf: %rbx_xorb_rh_rh[15:8] = 0x0₈
%sf: %rbx_xorb_rh_rh[15:15] = 0x1₁
%of: (%rbx_xorb_rh_rh[15:15] = 0x1₁ ↔ false) ∧ !(%rbx_xorb_rh_rh[15:15] = 0x1₁ ↔ %rbx_xorb_rh_rh[15:15] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for movq $0x4, %rdi

Final state:
%rdi/%rdi: 0x4₆₄

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_shlb_r8_one ⊕ %rax_shlb_r8_one

%cf: false
%pf: !((%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][0:0] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][1:1] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][2:2] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][3:3] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][4:4] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][5:5] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][6:6] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][7:7] = 0x1₁)
%zf: (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one) = 0x0₆₄
%sf: (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: false

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][3:0] + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][7:7] = 0x1₁ ↔ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][7:7] = 0x1₁) ∧ !((%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:7] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for adcb %bl, %bl

Final state:
%rbx/%bl: %rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0]

%cf: ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[8:8] = 0x1₁
%pf: !(((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rbx_shlb_r8_one[7:0][3:0] + 0x0₁ ∘ %rbx_shlb_r8_one[7:0][3:0])[4:4] = 0x1₁
%zf: ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0] = 0x0₈
%sf: ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:7] = 0x1₁
%of: (%rbx_shlb_r8_one[7:0][7:7] = 0x1₁ ↔ %rbx_shlb_r8_one[7:0][7:7] = 0x1₁) ∧ !(%rbx_shlb_r8_one[7:0][7:7] = 0x1₁ ↔ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:7] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_bl

Final state:
%rax/%rax: (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0]
%rdx/%rdx: %rdx_shlb_r8_one

%xmm0: %ymm0_shlb_r8_one[127:0]
%xmm1: %ymm1_shlb_r8_one[127:0]

-------------------------------------
=====================================
Computing circuit for shlb $0x1, %dil

.target:
xorq %rax, %rax
clc 
adcb %al, %al
adcb %bl, %bl
callq .set_szp_for_bl
retq 

Initial state:
%rdi/%dil: 0x4₆₄

%cf: %cf_xorb_rh_r8
%pf: %pf_xorb_rh_r8
%zf: %zf_xorb_rh_r8
%sf: %sf_xorb_rh_r8
%of: %of_xorb_rh_r8

State for specgen instruction: shlb $0x1, %bl:
%rbx/%bl: %rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0]

%cf: ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[8:8] = 0x1₁
%pf: !((%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%zf: (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0] = 0x0₈
%sf: (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:7] = 0x1₁
%of: (%rbx_shlb_r8_one[7:0][7:7] = 0x1₁ ↔ %rbx_shlb_r8_one[7:0][7:7] = 0x1₁) ∧ !(%rbx_shlb_r8_one[7:0][7:7] = 0x1₁ ↔ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:7] = 0x1₁)

Register        -> %bl
  translates to => %dil
Value is               -> (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0]
  after renaming it is => 0x8₈

Final state
%rdi/%dil: 0x4₆₄[63:8] ∘ 0x8₈

%cf: false
%pf: false
%zf: false
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for xorq %r8, %r8

Final state:
%r8/%r8: %r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8

%cf: false
%pf: !((%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][0:0] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][1:1] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][2:2] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][3:3] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][4:4] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][5:5] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][6:6] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][7:7] = 0x1₁)
%zf: (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8) = 0x0₆₄
%sf: (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for movq $0x40, %rbx

Final state:
%rbx/%rbx: 0x40₆₄

-------------------------------------
-------------------------------------
Getting base circuit for movb %ah, %bl

Final state:
%rbx/%bl: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

-------------------------------------
=====================================
Computing circuit for movzbl %ah, %ebp

.target:
movq $0x40, %rbx
movb %ah, %bl
retq 

Initial state:
%rbp/%rbp: %rbp_xorb_r8_rh

State for specgen instruction: movzbl %ah, %ebx:
%rbx/%rbx: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

Register        -> %rbx
  translates to => %rbp
Value is               -> 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]
  after renaming it is => 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

Final state
%rbp/%rbp: 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

=====================================
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh

%cf: false
%pf: !((%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][0:0] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][1:1] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][2:2] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][3:3] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][4:4] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][5:5] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][6:6] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][7:7] = 0x1₁)
%zf: (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh) = 0x0₆₄
%sf: (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_cf_into_rcx

Final state:
%rax/%rax: %rax_setc_rh
%rdx/%rdx: %rdx_setc_rh

%xmm0: %ymm0_setc_rh[127:0]
%xmm1: %ymm1_setc_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movb %cl, %ah

Final state:
%rax/%ah: %rax_setc_rh[63:16] ∘ (0x0₆₃ ∘ (%cf_setc_rh ? 0x1₁ : 0x0₁))[7:0] ∘ %rax_setc_rh[7:0]

-------------------------------------
=====================================
Computing circuit for setc %bh

.target:
callq .read_cf_into_rcx
movb %cl, %ah
retq 

Initial state:
%rbx/%bh: %rbx_xorb_r8_rh

State for specgen instruction: setc %ah:
%rax/%ah: %rax_setc_rh[63:16] ∘ (0x0₆₃ ∘ (%cf_setc_rh ? 0x1₁ : 0x0₁))[7:0] ∘ %rax_setc_rh[7:0]

Register        -> %ah
  translates to => %bh
Value is               -> (%rax_setc_rh[63:16] ∘ (0x0₆₃ ∘ (%cf_setc_rh ? 0x1₁ : 0x0₁))[7:0] ∘ %rax_setc_rh[7:0])[15:8]
  after renaming it is => 0x0₈

Final state
%rbx/%bh: %rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0]

=====================================
-------------------------------------
Getting base circuit for movswq %bx, %rdx

Final state:
%rdx/%rdx: sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rbp, %rdx

Final state:
%rdx/%rdx: sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

%cf: false
%pf: !((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][0:0] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][1:1] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][2:2] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][3:3] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][4:4] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][5:5] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][6:6] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][7:7] = 0x1₁)
%zf: (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]) = 0x0₆₄
%sf: (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for movslq %edx, %rbx

Final state:
%rbx/%rbx: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_bl

Final state:
%rax/%rax: %rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh
%rdx/%rdx: sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

%xmm0: %ymm0_xorb_r8_rh[127:0]
%xmm1: %ymm1_xorb_r8_rh[127:0]

-------------------------------------
=====================================
Computing circuit for xorb %ah, %bl

.target:
movzbl %ah, %ebp
xorq %rax, %rax
setc %bh
movswq %bx, %rdx
xorq %rbp, %rdx
movslq %edx, %rbx
callq .set_szp_for_bl
retq 

Initial state:
%rbx/%bl: %rbx_xorb_rh_r8

%cf: false
%pf: !((%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][0:0] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][1:1] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][2:2] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][3:3] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][4:4] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][5:5] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][6:6] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][7:7] = 0x1₁)
%zf: (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8) = 0x0₆₄
%sf: (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[63:63] = 0x1₁
%of: false

State for specgen instruction: xorb %ah, %bl:
%rbx/%bl: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])

%cf: false
%pf: !(sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][0:0] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][1:1] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][2:2] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][3:3] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][4:4] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][5:5] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][6:6] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][7:7] = 0x1₁)
%zf: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0] = 0x0₈
%sf: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:7] = 0x1₁
%of: false

Register        -> %bl
  translates to => %bl
Value is               -> sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0]
  after renaming it is => %rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]

Final state
%rbx/%bl: %rbx_xorb_rh_r8[63:8] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8])

%cf: false
%pf: !((%rbx_xorb_rh_r8[0:0] ⊕ %rax_xorb_rh_r8[8:8]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[1:1] ⊕ %rax_xorb_rh_r8[9:9]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[2:2] ⊕ %rax_xorb_rh_r8[10:10]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[3:3] ⊕ %rax_xorb_rh_r8[11:11]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[4:4] ⊕ %rax_xorb_rh_r8[12:12]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[5:5] ⊕ %rax_xorb_rh_r8[13:13]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[6:6] ⊕ %rax_xorb_rh_r8[14:14]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁)
%zf: (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) = 0x0₈
%sf: (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁
%of: false

=====================================
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16

%cf: false
%pf: !((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][0:0] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][1:1] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][2:2] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][3:3] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][4:4] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][5:5] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][6:6] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][7:7] = 0x1₁)
%zf: (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16) = 0x0₆₄
%sf: (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: false

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for adcw %cx, %ax

Final state:
%rax/%ax: (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0]

%cf: ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[16:16] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_popcntw_r16_r16[15:0][3:0] + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0] = 0x0₁₆
%sf: ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][15:15] = 0x1₁
%of: (%rcx_popcntw_r16_r16[15:0][15:15] = 0x1₁ ↔ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0][15:15] = 0x1₁) ∧ !(%rcx_popcntw_r16_r16[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:15] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for popcntq %rax, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][1:0][0:0]))))) + 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][1:0][0:0])))))

%cf: false
%pf: false
%af: false
%zf: (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0] = 0x0₆₄
%sf: false
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: false

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
=====================================
Computing circuit for popcntw %r8w, %ax

.target:
xorq %rax, %rax
clc 
adcw %cx, %ax
popcntq %rax, %rbx
clc 
retq 

Initial state:
%rax/%ax: %rax_xorb_rh_r8

%cf: false
%pf: !((%rbx_xorb_rh_r8[0:0] ⊕ %rax_xorb_rh_r8[8:8]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[1:1] ⊕ %rax_xorb_rh_r8[9:9]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[2:2] ⊕ %rax_xorb_rh_r8[10:10]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[3:3] ⊕ %rax_xorb_rh_r8[11:11]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[4:4] ⊕ %rax_xorb_rh_r8[12:12]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[5:5] ⊕ %rax_xorb_rh_r8[13:13]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[6:6] ⊕ %rax_xorb_rh_r8[14:14]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁)
%af: TMP_BOOL_64
%zf: (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) = 0x0₈
%sf: (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁
%of: false

State for specgen instruction: popcntw %cx, %bx:
%rbx/%bx: 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][1:0][0:0]))))) + 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][1:0][0:0])))))

%cf: false
%pf: false
%af: false
%zf: (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0] = 0x0₆₄
%sf: false
%of: false

Register        -> %bx
  translates to => %ax
Value is               -> (0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][1:0][0:0]))))) + 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][1:0][0:0]))))))[15:0]
  after renaming it is => 0x0₁₆

Final state
%rax/%ax: %rax_xorb_rh_r8[63:16] ∘ 0x0₁₆

%cf: false
%pf: false
%af: false
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rcx

Final state:
%rcx/%rcx: %rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh

%cf: false
%pf: !((%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][0:0] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][1:1] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][2:2] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][3:3] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][4:4] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][5:5] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][6:6] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][7:7] = 0x1₁)
%zf: (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh) = 0x0₆₄
%sf: (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_sf_into_rbx

Final state:
%rax/%rax: %rax_movzbw_r16_rh
%rdx/%rdx: %rdx_movzbw_r16_rh

%xmm0: %ymm0_movzbw_r16_rh[127:0]
%xmm1: %ymm1_movzbw_r16_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movb %ah, %bl

Final state:
%rbx/%bl: (0x0₆₃ ∘ ((%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[63:63] = 0x1₁ ? 0x1₁ : 0x0₁))[63:8] ∘ %rax_movzbw_r16_rh[15:8]

-------------------------------------
=====================================
Computing circuit for movzbw %ah, %si

.target:
xorq %rcx, %rcx
callq .read_sf_into_rbx
movb %ah, %bl
retq 

Initial state:
%rsi/%si: %rsi_xaddb_r8_rh

State for specgen instruction: movzbw %ah, %bx:
%rbx/%bx: (0x0₆₃ ∘ ((%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[63:63] = 0x1₁ ? 0x1₁ : 0x0₁))[63:8] ∘ %rax_movzbw_r16_rh[15:8]

Register        -> %bx
  translates to => %si
Value is               -> ((0x0₆₃ ∘ ((%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[63:63] = 0x1₁ ? 0x1₁ : 0x0₁))[63:8] ∘ %rax_movzbw_r16_rh[15:8])[15:0]
  after renaming it is => 0x0₈ ∘ %rax_xaddb_r8_rh[15:8]

Final state
%rsi/%si: %rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8])

=====================================
-------------------------------------
Getting base circuit for movq $0x0, %rbx

Final state:
%rbx/%rbx: 0x0₆₄

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: %cf_movzbq_r64_r8

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for movsbq %cl, %rdi

Final state:
%rdi/%rdi: sign-extend-64(%rcx_movzbq_r64_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for adcb %dil, %bl

Final state:
%rbx/%bl: 0x0₆₄[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0][3:0] + 0x0₁ ∘ 0x0₆₄[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:7] = 0x1₁
%of: (sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0][7:7] = 0x1₁ ↔ 0x0₆₄[7:0][7:7] = 0x1₁) ∧ !(sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for movzbq %bl, %r12

.target:
movq $0x0, %rbx
clc 
movsbq %cl, %rdi
adcb %dil, %bl
retq 

Initial state:
%r12/%r12: %r12_xaddb_r8_rh

State for specgen instruction: movzbq %cl, %rbx:
%rbx/%rbx: 0x0₆₄[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0]

Register        -> %rbx
  translates to => %r12
Value is               -> 0x0₆₄[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0]
  after renaming it is => 0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0]

Final state
%r12/%r12: 0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0]

=====================================
-------------------------------------
Getting base circuit for movslq %r12d, %rdx

Final state:
%rdx/%rdx: sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_dx_r8b_r9b

Final state:
%rax/%rax: %rax_xaddb_r8_rh
%rdx/%rdx: sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])

%xmm0: %ymm0_xaddb_r8_rh[127:0]
%xmm1: %ymm1_xaddb_r8_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_of

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_of_into_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movsbq %cl, %r10

Final state:
%r10/%r10: sign-extend-64(%rcx_movsbl_r32_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
=====================================
Computing circuit for movsbl %r12b, %ebx

.target:
callq .set_of
callq .read_of_into_rbx
callq .move_064_032_rbx_r10d_r11d
movsbq %cl, %r10
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%rbx/%rbx: %rbx_xaddb_r8_rh

State for specgen instruction: movsbl %cl, %ebx:
%rbx/%rbx: (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]

Register        -> %rbx
  translates to => %rbx
Value is               -> (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0]

Final state
%rbx/%rbx: 0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0]

=====================================
-------------------------------------
Getting base circuit for movb %dl, %ah

Final state:
%rax/%ah: %rax_xaddb_r8_rh[63:16] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[7:0] ∘ %rax_xaddb_r8_rh[7:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r9b_to_byte_6_of_rbx

Final state:
%rax/%rax: %rax_xaddb_r8_rh[63:16] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[7:0] ∘ %rax_xaddb_r8_rh[7:0]
%rdx/%rdx: sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])

%xmm0: %ymm0_xaddb_r8_rh[127:0]
%xmm1: %ymm1_xaddb_r8_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for popcntq %rdx, %r9

Final state:
%r9/%r9: 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][3:0][1:0][0:0]))))) + 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][3:0][1:0][0:0])))))

%cf: false
%pf: false
%af: false
%zf: sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0]) = 0x0₆₄
%sf: false
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %sil, %bl

Final state:
%rbx/%bl: ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[63:8] ∘ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0][3:0] + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:7] = 0x1₁
%of: ((%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0][7:7] = 0x1₁ ↔ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0][7:7] = 0x1₁) ∧ !((%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for xaddb %ah, %bl

.target:
movzbw %ah, %si
movzbq %bl, %r12
movslq %r12d, %rdx
callq .move_016_008_dx_r8b_r9b
movsbl %r12b, %ebx
movb %dl, %ah
callq .move_r9b_to_byte_6_of_rbx
popcntq %rdx, %r9
adcb %sil, %bl
retq 

Initial state:
%rax/%ah: %rax_xorb_rh_r8[63:16] ∘ 0x0₁₆
%rbx/%bl: %rbx_xorb_rh_r8[63:8] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8])

%cf: false
%pf: false
%af: false
%zf: true
%sf: false
%of: false

State for specgen instruction: xaddb %ah, %bl:
%rax/%ah: %rax_xaddb_r8_rh[63:16] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[7:0] ∘ %rax_xaddb_r8_rh[7:0]
%rbx/%bl: ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[63:8] ∘ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0][3:0] + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:7] = 0x1₁
%of: ((%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0][7:7] = 0x1₁ ↔ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0][7:7] = 0x1₁) ∧ !((%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:7] = 0x1₁)

Final state
%rax/%ah: (%rax_xorb_rh_r8[63:16] ∘ 0x0₁₆)[63:16] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) ∘ (%rax_xorb_rh_r8[63:16] ∘ 0x0₁₆)[7:0]
%rbx/%bl: (%rbx_xorb_rh_r8[63:8] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]))[63:8] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8])

%cf: false
%pf: !((%rbx_xorb_rh_r8[0:0] ⊕ %rax_xorb_rh_r8[8:8]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[1:1] ⊕ %rax_xorb_rh_r8[9:9]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[2:2] ⊕ %rax_xorb_rh_r8[10:10]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[3:3] ⊕ %rax_xorb_rh_r8[11:11]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[4:4] ⊕ %rax_xorb_rh_r8[12:12]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[5:5] ⊕ %rax_xorb_rh_r8[13:13]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[6:6] ⊕ %rax_xorb_rh_r8[14:14]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁)
%af: false
%zf: (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) = 0x0₈
%sf: (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁
%of: (false ↔ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁) ∧ !(false ↔ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_rcll_r32_one[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for adcl %ebx, %ebx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0]

%cf: ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[32:32] = 0x1₁
%pf: !(((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][3:0] + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][3:0])[4:4] = 0x1₁
%zf: ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0] = 0x0₃₂
%sf: ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][31:31] = 0x1₁
%of: (sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][31:31] = 0x1₁ ↔ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][31:31] = 0x1₁) ∧ !(sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][31:31] = 0x1₁ ↔ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:31] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for rcll $0x1, %edi

.target:
movslq %ebx, %rbx
adcl %ebx, %ebx
retq 

Initial state:
%rdi/%rdi: 0x4₆₄[63:8] ∘ 0x8₈

%cf: false
%of: (false ↔ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁) ∧ !(false ↔ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁)

State for specgen instruction: rcll $0x1, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0]

%cf: ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[32:32] = 0x1₁
%of: (sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][31:31] = 0x1₁ ↔ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][31:31] = 0x1₁) ∧ !(sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][31:31] = 0x1₁ ↔ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:31] = 0x1₁)

Register        -> %rbx
  translates to => %rdi
Value is               -> 0x0₃₂ ∘ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0]
  after renaming it is => 0x10₆₄

Final state
%rdi/%rdi: 0x10₆₄

%cf: false
%of: false

=====================================
=====================================
Computing circuit for xorb %al, %ah

.target:
movq $0x4, %rdi
shlb $0x1, %dil
xorq %r8, %r8
xorb %ah, %bl
popcntw %r8w, %ax
xaddb %ah, %bl
rcll $0x1, %edi
retq 

Initial state:
%rax/%ah: (%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8]

%cf: false
%pf: !(%rbx_xorb_rh_rh[8:8] = 0x1₁ ⊕ %rbx_xorb_rh_rh[9:9] = 0x1₁ ⊕ %rbx_xorb_rh_rh[10:10] = 0x1₁ ⊕ %rbx_xorb_rh_rh[11:11] = 0x1₁ ⊕ %rbx_xorb_rh_rh[12:12] = 0x1₁ ⊕ %rbx_xorb_rh_rh[13:13] = 0x1₁ ⊕ %rbx_xorb_rh_rh[14:14] = 0x1₁ ⊕ %rbx_xorb_rh_rh[15:15] = 0x1₁)
%zf: %rbx_xorb_rh_rh[15:8] = 0x0₈
%sf: %rbx_xorb_rh_rh[15:15] = 0x1₁
%of: (%rbx_xorb_rh_rh[15:15] = 0x1₁ ↔ false) ∧ !(%rbx_xorb_rh_rh[15:15] = 0x1₁ ↔ %rbx_xorb_rh_rh[15:15] = 0x1₁)

State for specgen instruction: xorb %bl, %ah:
%rax/%ah: (%rax_xorb_rh_r8[63:16] ∘ 0x0₁₆)[63:16] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) ∘ (%rax_xorb_rh_r8[63:16] ∘ 0x0₁₆)[7:0]

%cf: false
%pf: !((%rbx_xorb_rh_r8[0:0] ⊕ %rax_xorb_rh_r8[8:8]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[1:1] ⊕ %rax_xorb_rh_r8[9:9]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[2:2] ⊕ %rax_xorb_rh_r8[10:10]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[3:3] ⊕ %rax_xorb_rh_r8[11:11]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[4:4] ⊕ %rax_xorb_rh_r8[12:12]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[5:5] ⊕ %rax_xorb_rh_r8[13:13]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[6:6] ⊕ %rax_xorb_rh_r8[14:14]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁)
%zf: (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) = 0x0₈
%sf: (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁
%of: false

Register        -> %ah
  translates to => %ah
Value is               -> ((%rax_xorb_rh_r8[63:16] ∘ 0x0₁₆)[63:16] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) ∘ (%rax_xorb_rh_r8[63:16] ∘ 0x0₁₆)[7:0])[15:8]
  after renaming it is => %rbx_xorb_rh_rh[15:8] ⊕ %rax_xorb_rh_rh[15:8]

Final state
%rax/%ah: ((%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8])[63:16] ∘ (%rbx_xorb_rh_rh[15:8] ⊕ %rax_xorb_rh_rh[15:8]) ∘ ((%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8])[7:0]

%cf: false
%pf: !((%rbx_xorb_rh_rh[8:8] ⊕ %rax_xorb_rh_rh[8:8]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[9:9] ⊕ %rax_xorb_rh_rh[9:9]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[10:10] ⊕ %rax_xorb_rh_rh[10:10]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[11:11] ⊕ %rax_xorb_rh_rh[11:11]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[12:12] ⊕ %rax_xorb_rh_rh[12:12]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[13:13] ⊕ %rax_xorb_rh_rh[13:13]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[14:14] ⊕ %rax_xorb_rh_rh[14:14]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[15:15] ⊕ %rax_xorb_rh_rh[15:15]) = 0x1₁)
%zf: (%rbx_xorb_rh_rh[15:8] ⊕ %rax_xorb_rh_rh[15:8]) = 0x0₈
%sf: (%rbx_xorb_rh_rh[15:15] ⊕ %rax_xorb_rh_rh[15:15]) = 0x1₁
%of: false

=====================================
=====================================
Computing circuit for xorb %bh, %bh

.target:
xorb %al, %al
xaddb %al, %bh
xorb %al, %ah
retq 

Initial state:
%rbx/%bh: ((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆)

%cf: %cf_cmc
%pf: !((%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁)
%zf: (%cf_cmc ? 0x0₁₆ : 0xffff₁₆) = 0x0₁₆
%sf: (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁
%of: false ∧ !(false ↔ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁)

State for specgen instruction: xorb %bh, %ah:
%rax/%ah: ((%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8])[63:16] ∘ (%rbx_xorb_rh_rh[15:8] ⊕ %rax_xorb_rh_rh[15:8]) ∘ ((%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8])[7:0]

%cf: false
%pf: !((%rbx_xorb_rh_rh[8:8] ⊕ %rax_xorb_rh_rh[8:8]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[9:9] ⊕ %rax_xorb_rh_rh[9:9]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[10:10] ⊕ %rax_xorb_rh_rh[10:10]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[11:11] ⊕ %rax_xorb_rh_rh[11:11]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[12:12] ⊕ %rax_xorb_rh_rh[12:12]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[13:13] ⊕ %rax_xorb_rh_rh[13:13]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[14:14] ⊕ %rax_xorb_rh_rh[14:14]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[15:15] ⊕ %rax_xorb_rh_rh[15:15]) = 0x1₁)
%zf: (%rbx_xorb_rh_rh[15:8] ⊕ %rax_xorb_rh_rh[15:8]) = 0x0₈
%sf: (%rbx_xorb_rh_rh[15:15] ⊕ %rax_xorb_rh_rh[15:15]) = 0x1₁
%of: false

Register        -> %ah
  translates to => %bh
Value is               -> (((%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8])[63:16] ∘ (%rbx_xorb_rh_rh[15:8] ⊕ %rax_xorb_rh_rh[15:8]) ∘ ((%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8])[7:0])[15:8]
  after renaming it is => 0x0₈

Final state
%rbx/%bh: (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0]

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for adcb %bl, %bl

Final state:
%rbx/%bl: ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[63:8] ∘ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0][3:0] + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:7] = 0x1₁
%of: (((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0][7:7] = 0x1₁ ↔ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0][7:7] = 0x1₁) ∧ !(((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for cmc 

.target:
callq .read_cf_into_rbx
callq .move_064_032_rbx_r8d_r9d
callq .move_r8b_to_byte_5_of_rbx
decw %bx
xorb %bh, %bh
adcb %bl, %bl
retq 

Initial state:
%cf: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[64:64] = 0x1₁

State for specgen instruction: cmc :
%cf: ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[8:8] = 0x1₁

Final state
%cf: (((0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %rbx_subq_r64_r64)[64:64] = 0x1₁ ? 0x0₉ : 0xff₉) + ((0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %rbx_subq_r64_r64)[64:64] = 0x1₁ ? 0x0₉ : 0xff₉))[8:8] = 0x1₁

=====================================
=====================================
Computing circuit for subq %r8, %r10

.target:
stc 
notq %rcx
adcq %rcx, %rbx
cmc 
retq 

Initial state:
%r10/%r10: %ymm2_vpsubq_xmm_xmm_xmm[127:0][63:0]

%cf: (((0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[64:64] = 0x1₁ ? 0x0₉ : 0xff₉) + ((0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[64:64] = 0x1₁ ? 0x0₉ : 0xff₉))[8:8] = 0x1₁
%pf: !((0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[7:7] = 0x1₁)
%af: (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[67:64] ⊕ 0xf₄) + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[67:64])[4:4] = 0x1₁
%zf: (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[63:63] = 0x1₁
%of: ((%ymm3_vpsubq_xmm_xmm_xmm[127:127] ⊕ 0x1₁) = 0x1₁ ↔ %ymm2_vpsubq_xmm_xmm_xmm[127:127] = 0x1₁) ∧ !((%ymm3_vpsubq_xmm_xmm_xmm[127:127] ⊕ 0x1₁) = 0x1₁ ↔ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[63:63] = 0x1₁)

State for specgen instruction: subq %rcx, %rbx:
%rbx/%rbx: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0]

%cf: (((0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %rbx_subq_r64_r64)[64:64] = 0x1₁ ? 0x0₉ : 0xff₉) + ((0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %rbx_subq_r64_r64)[64:64] = 0x1₁ ? 0x0₉ : 0xff₉))[8:8] = 0x1₁
%pf: !(((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][0:0] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][1:1] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][2:2] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][3:3] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][4:4] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][5:5] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][6:6] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)[3:0] + 0x0₁ ∘ %rbx_subq_r64_r64[3:0])[4:4] = 0x1₁
%zf: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0] = 0x0₆₄
%sf: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][63:63] = 0x1₁
%of: ((%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)[63:63] = 0x1₁ ↔ %rbx_subq_r64_r64[63:63] = 0x1₁) ∧ !((%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)[63:63] = 0x1₁ ↔ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r10
Value is               -> ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0]
  after renaming it is => (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[63:0]

Final state
%r10/%r10: (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[63:0]

%cf: (((0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[64:64] = 0x1₁ ? 0x0₉ : 0xff₉) + ((0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[64:64] = 0x1₁ ? 0x0₉ : 0xff₉))[8:8] = 0x1₁
%pf: !((0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[3:0] ⊕ 0xf₄) + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[63:63] = 0x1₁
%of: ((%ymm3_vpsubq_xmm_xmm_xmm[63:63] ⊕ 0x1₁) = 0x1₁ ↔ %ymm2_vpsubq_xmm_xmm_xmm[63:63] = 0x1₁) ∧ !((%ymm3_vpsubq_xmm_xmm_xmm[63:63] ⊕ 0x1₁) = 0x1₁ ↔ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpsubq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpsubq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[63:0][63:0] ∘ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpsubq %xmm3, %xmm5, %xmm9

.target:
callq .move_128_064_xmm2_r10_r11
callq .move_128_064_xmm3_r8_r9
vzeroall 
subq %r9, %r11
subq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_pmovsxwd_xmm_xmm

State for specgen instruction: vpsubq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[63:0][63:0] ∘ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ ((0x0₁ ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[47:32]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]))[15:0])))[63:0] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[15:0]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[15:0])))[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_movaps_xmm_xmm
%rdx/%rdx: %rdx_movaps_xmm_xmm

%xmm0: %ymm0_movaps_xmm_xmm[127:0]
%xmm1: %ymm1_movaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1

Final state:
%rax/%rax: %rax_movaps_xmm_xmm
%rdx/%rdx: %rdx_movaps_xmm_xmm

%xmm0: %ymm0_movaps_xmm_xmm[127:0]
%xmm1: (%ymm1_movaps_xmm_xmm[255:128] ∘ ((%ymm7_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm6_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm5_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (%ymm4_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][31:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movaps %xmm9, %xmm1

.target:
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1
retq 

Initial state:
%xmm1: %ymm1_pmovsxwd_xmm_xmm[127:0]

State for specgen instruction: movaps %xmm2, %xmm1:
%xmm1: (%ymm1_movaps_xmm_xmm[255:128] ∘ ((%ymm7_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm6_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm5_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (%ymm4_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][31:0]))[127:0][31:0]))[127:0]

Final state
%xmm1: (%ymm1_pmovsxwd_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[47:32]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]))[15:0])))[63:0] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[15:0]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[15:0])))[63:32] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[15:0]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[15:0])))[31:0]))[127:0]

=====================================
=====================================
Computing circuit for pmovsxwd %xmm13, %xmm13

.target:
vmovsd %xmm2, %xmm2, %xmm0
vmaxsd %xmm0, %xmm0, %xmm15
pmovzxwd %xmm15, %xmm3
vpaddd %xmm2, %xmm2, %xmm2
vpmovzxwd %xmm2, %ymm5
vpsubq %xmm3, %xmm5, %xmm9
movaps %xmm9, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_vpmovsxwd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vpmovsxwd_ymm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: pmovsxwd %xmm2, %xmm1:
%xmm1: (%ymm1_pmovsxwd_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[47:32]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]))[15:0])))[63:0] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[15:0]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[15:0])))[63:32] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[15:0]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[15:0])))[31:0]))[127:0]

Final state
%xmm13: ((%ymm13_vpmovsxwd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vpmovsxwd_ymm_xmm[127:0][127:64]))[255:128] ∘ ((0x0₁ ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[127:112] ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[111:96]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[127:96] ∘ %ymm2_vpmovsxwd_ymm_xmm[127:96]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[127:96] ∘ %ymm2_vpmovsxwd_ymm_xmm[127:96]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[127:96] ∘ %ymm2_vpmovsxwd_ymm_xmm[127:96]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[127:96] ∘ %ymm2_vpmovsxwd_ymm_xmm[127:96]))[15:0])))[63:0] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[95:80] ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[79:64]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[95:64] ∘ %ymm2_vpmovsxwd_ymm_xmm[95:64]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[95:64] ∘ %ymm2_vpmovsxwd_ymm_xmm[95:64]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[95:64] ∘ %ymm2_vpmovsxwd_ymm_xmm[95:64]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[95:64] ∘ %ymm2_vpmovsxwd_ymm_xmm[95:64]))[15:0])))[63:32] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[95:80] ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[79:64]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[95:64] ∘ %ymm2_vpmovsxwd_ymm_xmm[95:64]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[95:64] ∘ %ymm2_vpmovsxwd_ymm_xmm[95:64]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[95:64] ∘ %ymm2_vpmovsxwd_ymm_xmm[95:64]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[95:64] ∘ %ymm2_vpmovsxwd_ymm_xmm[95:64]))[15:0])))[31:0]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vmovsd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovsd_xmm_xmm_xmm

%xmm0: %ymm0_vmovsd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm3, %xmm13

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm13: %ymm13_vmovsd_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm13: 0x0₁₂₈ ∘ %ymm3_vmovsd_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm9, %xmm13, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsd_xmm_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsd_xmm_xmm_xmm[127:64] ∘ %ymm3_vmovsd_xmm_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovsd %xmm2, %xmm2, %xmm0

.target:
callq .move_128_64_xmm2_xmm8_xmm9
vmovapd %xmm3, %xmm13
vpunpcklqdq %xmm9, %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_pmovsxwd_xmm_xmm

State for specgen instruction: vmovsd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsd_xmm_xmm_xmm[127:64] ∘ %ymm3_vmovsd_xmm_xmm_xmm[63:0])

Final state
%ymm0: 0x0₁₂₈ ∘ %ymm2_pmovsxwd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm3, %xmm3, %xmm13

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm13: %ymm13_vmaxsd_xmm_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm13: 0x0₁₂₈ ∘ (%ymm3_vmaxsd_xmm_xmm_xmm[63:0] ∘ %ymm3_vmaxsd_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm6

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm6: %ymm6_vmaxsd_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm6: 0x0₁₂₈ ∘ %ymm2_vmaxsd_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxpd %ymm13, %ymm6, %ymm3

Final state:
%ymm3: (maxcmp_double((0x0₁₂₈ ∘ %ymm2_vmaxsd_xmm_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ (%ymm3_vmaxsd_xmm_xmm_xmm[63:0] ∘ %ymm3_vmaxsd_xmm_xmm_xmm[63:0]))[255:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxsd_xmm_xmm_xmm[127:0])[255:192] : (0x0₁₂₈ ∘ (%ymm3_vmaxsd_xmm_xmm_xmm[63:0] ∘ %ymm3_vmaxsd_xmm_xmm_xmm[63:0]))[255:192]) ∘ ((maxcmp_double((0x0₁₂₈ ∘ %ymm2_vmaxsd_xmm_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ (%ymm3_vmaxsd_xmm_xmm_xmm[63:0] ∘ %ymm3_vmaxsd_xmm_xmm_xmm[63:0]))[191:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxsd_xmm_xmm_xmm[127:0])[191:128] : (0x0₁₂₈ ∘ (%ymm3_vmaxsd_xmm_xmm_xmm[63:0] ∘ %ymm3_vmaxsd_xmm_xmm_xmm[63:0]))[191:128]) ∘ ((maxcmp_double((0x0₁₂₈ ∘ %ymm2_vmaxsd_xmm_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ (%ymm3_vmaxsd_xmm_xmm_xmm[63:0] ∘ %ymm3_vmaxsd_xmm_xmm_xmm[63:0]))[127:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxsd_xmm_xmm_xmm[127:0])[127:64] : (0x0₁₂₈ ∘ (%ymm3_vmaxsd_xmm_xmm_xmm[63:0] ∘ %ymm3_vmaxsd_xmm_xmm_xmm[63:0]))[127:64]) ∘ (maxcmp_double((0x0₁₂₈ ∘ %ymm2_vmaxsd_xmm_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ (%ymm3_vmaxsd_xmm_xmm_xmm[63:0] ∘ %ymm3_vmaxsd_xmm_xmm_xmm[63:0]))[63:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxsd_xmm_xmm_xmm[127:0])[63:0] : (0x0₁₂₈ ∘ (%ymm3_vmaxsd_xmm_xmm_xmm[63:0] ∘ %ymm3_vmaxsd_xmm_xmm_xmm[63:0]))[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vmovsd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovsd_xmm_xmm_xmm

%xmm0: %ymm0_vmovsd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm3, %xmm13

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm13: %ymm13_vmovsd_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm13: 0x0₁₂₈ ∘ %ymm3_vmovsd_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm9, %xmm13, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsd_xmm_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsd_xmm_xmm_xmm[127:64] ∘ %ymm3_vmovsd_xmm_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovsd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm8_xmm9
vmovapd %xmm3, %xmm13
vpunpcklqdq %xmm9, %xmm13, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxsd_xmm_xmm_xmm

State for specgen instruction: vmovsd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsd_xmm_xmm_xmm[127:64] ∘ %ymm3_vmovsd_xmm_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmaxsd_xmm_xmm_xmm[127:64] ∘ (maxcmp_double(%ymm2_vmaxsd_xmm_xmm_xmm[63:0], %ymm3_vmaxsd_xmm_xmm_xmm[63:0]) = 0x1₁ ? %ymm2_vmaxsd_xmm_xmm_xmm[63:0] : %ymm3_vmaxsd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmaxsd %xmm0, %xmm0, %xmm15

.target:
vpunpcklqdq %xmm3, %xmm3, %xmm13
vmovdqa %xmm2, %xmm6
vmaxpd %ymm13, %ymm6, %ymm3
vmovsd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm15: %ymm15_pmovsxwd_xmm_xmm

State for specgen instruction: vmaxsd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmaxsd_xmm_xmm_xmm[127:64] ∘ (maxcmp_double(%ymm2_vmaxsd_xmm_xmm_xmm[63:0], %ymm3_vmaxsd_xmm_xmm_xmm[63:0]) = 0x1₁ ? %ymm2_vmaxsd_xmm_xmm_xmm[63:0] : %ymm3_vmaxsd_xmm_xmm_xmm[63:0]))

Final state
%ymm15: 0x0₁₂₈ ∘ %ymm2_pmovsxwd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %ymm10

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm10: %ymm10_pmovzxwd_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm10: %ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0] ∘ (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm3, %xmm8

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm8: %ymm8_vminpd_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm8: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: %ymm0_vmovups_xmm_xmm[127:0]
%xmm1: %ymm1_vmovups_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovups %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminpd_xmm_xmm_xmm

State for specgen instruction: vmovups %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm8, %ymm1, %ymm1

Final state:
%ymm1: (mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[255:192], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[255:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[255:192] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[255:192]) ∘ ((mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[191:128], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[191:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[191:128] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[191:128]) ∘ ((mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[127:64], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[127:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[127:64] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[127:64]) ∘ (mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[63:0], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[63:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[63:0] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vminpd %xmm2, %xmm1, %xmm3

.target:
vmaxps %xmm3, %xmm3, %xmm8
vmovups %xmm2, %xmm1
vminpd %ymm8, %ymm1, %ymm1
retq 

Initial state:
%ymm3: %ymm3_minpd_xmm_xmm

State for specgen instruction: vminpd %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[255:192], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[255:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[255:192] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[255:192]) ∘ ((mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[191:128], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[191:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[191:128] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[191:128]) ∘ ((mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[127:64], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[127:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[127:64] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[127:64]) ∘ (mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[63:0], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[63:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[63:0] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[63:0])))

Final state
%ymm3: 0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm3_xmm8_xmm9

Final state:
%rax/%rax: %rax_minpd_xmm_xmm
%rdx/%rdx: %rdx_minpd_xmm_xmm

%xmm0: %ymm0_minpd_xmm_xmm[127:0]
%xmm1: %ymm1_minpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_minpd_xmm_xmm
%rdx/%rdx: %rdx_minpd_xmm_xmm

%xmm0: %ymm0_minpd_xmm_xmm[127:0]
%xmm1: (%ymm1_minpd_xmm_xmm[255:128] ∘ ((%ymm9_minpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0]))))[127:0][127:64]))[127:0][63:0] ∘ (%ymm8_minpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0]))))[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for minpd %xmm10, %xmm10

.target:
vminpd %xmm2, %xmm1, %xmm3
callq .move_128_64_xmm3_xmm8_xmm9
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0] ∘ (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0]))[127:0]

State for specgen instruction: minpd %xmm2, %xmm1:
%xmm1: (%ymm1_minpd_xmm_xmm[255:128] ∘ ((%ymm9_minpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0]))))[127:0][127:64]))[127:0][63:0] ∘ (%ymm8_minpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0]))))[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0] ∘ (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vpmovzxwd_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwd_xmm_xmm

%xmm0: %ymm0_vpmovzxwd_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: %ymm0_vpmovzxwq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r12d_r13d_rdx

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_edx_r10w_r11w

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxwq %xmm5, %xmm13

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_128_064_xmm2_r10_r11
callq .move_032_064_r12d_r13d_rdx
callq .move_032_016_edx_r10w_r11w
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm13: %ymm13_vpmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0])

Final state
%ymm13: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movddup_xmm_xmm
%rdx/%rdx: %rdx_movddup_xmm_xmm

%xmm0: %ymm0_movddup_xmm_xmm[127:0]
%xmm1: %ymm1_movddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r12, %r13

Final state:
%r13/%r13: %ymm2_movddup_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movddup_xmm_xmm
%rdx/%rdx: %rdx_movddup_xmm_xmm

%xmm0: %ymm0_movddup_xmm_xmm[127:0]
%xmm1: (%ymm1_movddup_xmm_xmm[255:128] ∘ (%ymm2_movddup_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_movddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movddup %xmm4, %xmm4

.target:
callq .move_128_064_xmm2_r12_r13
movq %r12, %r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm4: (%ymm4_vpmovzxwd_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[127:0][31:0]))[127:0]

State for specgen instruction: movddup %xmm2, %xmm1:
%xmm1: (%ymm1_movddup_xmm_xmm[255:128] ∘ (%ymm2_movddup_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_movddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm4: ((%ymm4_vpmovzxwd_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[127:0][31:0]))[255:128] ∘ (0x0₃₂ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:0] ∘ (0x0₃₂ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm3

Final state:
%rax/%rax: %rax_vpmovzxwd_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwd_xmm_xmm

%xmm0: %ymm0_vpmovzxwd_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: %ymm0_vpmovzxwq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r12d_r13d_rdx

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_edx_r10w_r11w

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxwq %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_128_064_xmm2_r10_r11
callq .move_032_064_r12d_r13d_rdx
callq .move_032_016_edx_r10w_r11w
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm3, %ymm6

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm6: %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm3, %xmm6, %xmm9

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm3, %xmm2, %xmm14

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm14: %ymm14_vpor_xmm_xmm_xmm

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpor_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vpor %xmm9, %xmm9, %xmm7

.target:
vorps %xmm3, %xmm2, %xmm14
vmovapd %xmm14, %xmm1
retq 

Initial state:
%ymm7: %ymm7_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpor %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

Final state
%ymm7: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm7, %xmm2

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpckldq_xmm_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm2: (%ymm2_vpunpckldq_xmm_xmm_xmm[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm1, %xmm3

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm3: %ymm3_mulpd_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm8: %ymm8_mulpd_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmulpd %ymm8, %ymm3, %ymm6

Final state:
%ymm6: mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[255:192]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[191:128]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[127:64]) ∘ mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_mulpd_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for mulpd %xmm3, %xmm2

.target:
vmovapd %xmm1, %xmm3
vmovaps %xmm2, %xmm8
vmulpd %ymm8, %ymm3, %ymm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vmulpd_xmm_xmm_xmm[127:0]

State for specgen instruction: mulpd %xmm2, %xmm1:
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vmulpd_xmm_xmm_xmm[255:128] ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmulpd_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmulpd %xmm6, %xmm2, %xmm12

.target:
mulpd %xmm3, %xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm12: %ymm12_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vmulpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]) ∘ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm12, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vpunpckldq %xmm2, %xmm1, %xmm8

.target:
vpbroadcastq %xmm3, %ymm6
vunpcklpd %xmm3, %xmm6, %xmm9
vpor %xmm9, %xmm9, %xmm7
unpcklps %xmm7, %xmm2
vmulpd %xmm6, %xmm2, %xmm12
vxorps %xmm12, %xmm2, %xmm1
movdqu %xmm2, %xmm1
retq 

Initial state:
%ymm8: %ymm8_hsubps_xmm_xmm

State for specgen instruction: vpunpckldq %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0]))

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm2

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm2: %ymm2_vunpckhps_xmm_xmm_xmm[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm2: (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpckhps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm9, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vunpckhps_xmm_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: %ymm0_vmovq_xmm_xmm[127:0]
%xmm1: %ymm1_vmovq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movswq %bx, %r10

Final state:
%r10/%r10: sign-extend-64(%rbx_xchgl_r32_r32[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_xchgl_r32_r32[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ecx_r8w_r9w

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %rcx

Final state:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r8w_r9w_ebx

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xchgl %ebx, %ecx

.target:
movswq %bx, %r10
movslq %ebx, %rbx
callq .move_032_016_ecx_r8w_r9w
callq .move_064_032_rbx_r10d_r11d
movq %r10, %rcx
callq .move_016_032_r8w_r9w_ebx
retq 

Initial state:
%rcx/%rcx: %rcx_xorl_r32_r32
%rbx/%rbx: %rbx_xorl_r32_r32

State for specgen instruction: xchgl %ecx, %ebx:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
%rbx/%rbx: 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])

Register        -> %rcx
  translates to => %rbx
Value is               -> 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
  after renaming it is => 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

Register        -> %rbx
  translates to => %rcx
Value is               -> 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])
  after renaming it is => 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

Final state
%rcx/%rcx: 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]) = 0x0₆₄
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_ebx

Final state:
%rax/%rax: %rax_xorl_r32_r32
%rdx/%rdx: %rdx_xorl_r32_r32

%xmm0: %ymm0_xorl_r32_r32[127:0]
%xmm1: %ymm1_xorl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xorl %r13d, %r13d

.target:
xchgl %ebx, %ecx
xorq %rcx, %rbx
callq .set_szp_for_ebx
retq 

Initial state:
%r13/%r13: %ymm2_vmovq_xmm_xmm[127:0][127:64]

%cf: %cf_vmovq_xmm_xmm
%pf: %pf_vmovq_xmm_xmm
%zf: %zf_vmovq_xmm_xmm
%sf: %sf_vmovq_xmm_xmm
%of: %of_vmovq_xmm_xmm

State for specgen instruction: xorl %ecx, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0] = 0x0₃₂
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][31:31] = 0x1₁
%of: false

Register        -> %rbx
  translates to => %r13
Value is               -> 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
  after renaming it is => 0x0₆₄

Final state
%r13/%r13: 0x0₆₄

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
xorl %r13d, %r13d
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][95:64])

State for specgen instruction: vmovq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhps %xmm2, %xmm1, %xmm10

.target:
unpckhpd %xmm3, %xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovddup %xmm9, %xmm1
vmovq %xmm1, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm10: %ymm10_hsubps_xmm_xmm

State for specgen instruction: vunpckhps %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[127:96] ∘ %ymm1_hsubps_xmm_xmm[127:96] ∘ %ymm2_hsubps_xmm_xmm[95:64] ∘ %ymm1_hsubps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm3, %ymm6

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm6: %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm3, %xmm6, %xmm9

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm3, %xmm2, %xmm14

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm14: %ymm14_vpor_xmm_xmm_xmm

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpor_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vpor %xmm9, %xmm9, %xmm7

.target:
vorps %xmm3, %xmm2, %xmm14
vmovapd %xmm14, %xmm1
retq 

Initial state:
%ymm7: %ymm7_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpor %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

Final state
%ymm7: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm7, %xmm2

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpckldq_xmm_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm2: (%ymm2_vpunpckldq_xmm_xmm_xmm[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm1, %xmm3

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm3: %ymm3_mulpd_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm8: %ymm8_mulpd_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmulpd %ymm8, %ymm3, %ymm6

Final state:
%ymm6: mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[255:192]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[191:128]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[127:64]) ∘ mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_mulpd_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for mulpd %xmm3, %xmm2

.target:
vmovapd %xmm1, %xmm3
vmovaps %xmm2, %xmm8
vmulpd %ymm8, %ymm3, %ymm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vmulpd_xmm_xmm_xmm[127:0]

State for specgen instruction: mulpd %xmm2, %xmm1:
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vmulpd_xmm_xmm_xmm[255:128] ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmulpd_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmulpd %xmm6, %xmm2, %xmm12

.target:
mulpd %xmm3, %xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm12: %ymm12_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vmulpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]) ∘ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm12, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vpunpckldq %xmm10, %xmm8, %xmm15

.target:
vpbroadcastq %xmm3, %ymm6
vunpcklpd %xmm3, %xmm6, %xmm9
vpor %xmm9, %xmm9, %xmm7
unpcklps %xmm7, %xmm2
vmulpd %xmm6, %xmm2, %xmm12
vxorps %xmm12, %xmm2, %xmm1
movdqu %xmm2, %xmm1
retq 

Initial state:
%ymm15: %ymm15_hsubps_xmm_xmm

State for specgen instruction: vpunpckldq %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0]))

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[95:64] ∘ %ymm2_hsubps_xmm_xmm[31:0] ∘ (%ymm1_hsubps_xmm_xmm[95:64] ∘ %ymm1_hsubps_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm2

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm2: %ymm2_vunpckhps_xmm_xmm_xmm[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm2: (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpckhps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm9, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vunpckhps_xmm_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: %ymm0_vmovq_xmm_xmm[127:0]
%xmm1: %ymm1_vmovq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movswq %bx, %r10

Final state:
%r10/%r10: sign-extend-64(%rbx_xchgl_r32_r32[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_xchgl_r32_r32[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ecx_r8w_r9w

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %rcx

Final state:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r8w_r9w_ebx

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xchgl %ebx, %ecx

.target:
movswq %bx, %r10
movslq %ebx, %rbx
callq .move_032_016_ecx_r8w_r9w
callq .move_064_032_rbx_r10d_r11d
movq %r10, %rcx
callq .move_016_032_r8w_r9w_ebx
retq 

Initial state:
%rcx/%rcx: %rcx_xorl_r32_r32
%rbx/%rbx: %rbx_xorl_r32_r32

State for specgen instruction: xchgl %ecx, %ebx:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
%rbx/%rbx: 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])

Register        -> %rcx
  translates to => %rbx
Value is               -> 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
  after renaming it is => 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

Register        -> %rbx
  translates to => %rcx
Value is               -> 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])
  after renaming it is => 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

Final state
%rcx/%rcx: 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]) = 0x0₆₄
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_ebx

Final state:
%rax/%rax: %rax_xorl_r32_r32
%rdx/%rdx: %rdx_xorl_r32_r32

%xmm0: %ymm0_xorl_r32_r32[127:0]
%xmm1: %ymm1_xorl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xorl %r13d, %r13d

.target:
xchgl %ebx, %ecx
xorq %rcx, %rbx
callq .set_szp_for_ebx
retq 

Initial state:
%r13/%r13: %ymm2_vmovq_xmm_xmm[127:0][127:64]

%cf: %cf_vmovq_xmm_xmm
%pf: %pf_vmovq_xmm_xmm
%zf: %zf_vmovq_xmm_xmm
%sf: %sf_vmovq_xmm_xmm
%of: %of_vmovq_xmm_xmm

State for specgen instruction: xorl %ecx, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0] = 0x0₃₂
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][31:31] = 0x1₁
%of: false

Register        -> %rbx
  translates to => %r13
Value is               -> 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
  after renaming it is => 0x0₆₄

Final state
%r13/%r13: 0x0₆₄

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
xorl %r13d, %r13d
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][95:64])

State for specgen instruction: vmovq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhps %xmm2, %xmm1, %xmm8

.target:
unpckhpd %xmm3, %xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovddup %xmm9, %xmm1
vmovq %xmm1, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_punpckhdq_xmm_xmm

State for specgen instruction: vunpckhps %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ %ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm8, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_punpckhdq_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_punpckhdq_xmm_xmm[255:128] ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ (%ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])))[127:0]

=====================================
=====================================
Computing circuit for punpckhdq %xmm10, %xmm8

.target:
vunpckhps %xmm2, %xmm1, %xmm8
movdqu %xmm8, %xmm1
retq 

Initial state:
%xmm8: (0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0])))[127:0]

State for specgen instruction: punpckhdq %xmm2, %xmm1:
%xmm1: (%ymm1_punpckhdq_xmm_xmm[255:128] ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ (%ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])))[127:0]

Final state
%xmm8: ((0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0])))[255:128] ∘ (%ymm2_hsubps_xmm_xmm[127:96] ∘ %ymm2_hsubps_xmm_xmm[63:32] ∘ (%ymm1_hsubps_xmm_xmm[127:96] ∘ %ymm1_hsubps_xmm_xmm[63:32])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm14

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm14: %ymm14_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm14: 0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminps %ymm1, %ymm14, %ymm1

Final state:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vminps %xmm2, %xmm2, %xmm5

.target:
vmovdqa %xmm3, %xmm1
vmovdqu %xmm2, %xmm14
vminps %ymm1, %ymm14, %ymm1
retq 

Initial state:
%ymm5: %ymm5_vsubps_xmm_xmm_xmm

State for specgen instruction: vminps %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm5: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_subps_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm14

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm14: %ymm14_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm14: 0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminps %ymm1, %ymm14, %ymm1

Final state:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vminps %xmm1, %xmm1, %xmm4

.target:
vmovdqa %xmm3, %xmm1
vmovdqu %xmm2, %xmm14
vminps %ymm1, %ymm14, %ymm1
retq 

Initial state:
%ymm4: %ymm4_subps_xmm_xmm

State for specgen instruction: vminps %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm4: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for vsubps %ymm10, %ymm4, %ymm2

Final state:
%ymm2: sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[255:224], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[255:224]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[223:192], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[223:192]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[191:160], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[191:160]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[159:128], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[159:128]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[127:96], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[127:96]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[95:64], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[95:64]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[63:32], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[63:32]) ∘ sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[31:0], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_subps_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_subps_xmm_xmm[255:128] ∘ (sub_single(%ymm1_subps_xmm_xmm[127:96], %ymm2_subps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_subps_xmm_xmm[95:64], %ymm2_subps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_subps_xmm_xmm[63:32], %ymm2_subps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_subps_xmm_xmm[31:0], %ymm2_subps_xmm_xmm[31:0])))))[127:0]

=====================================
=====================================
Computing circuit for subps %xmm3, %xmm5

.target:
vmovaps %xmm2, %xmm10
vminps %xmm1, %xmm1, %xmm4
vsubps %ymm10, %ymm4, %ymm2
movdqu %xmm2, %xmm1
retq 

Initial state:
%xmm5: (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0]))))[127:0]

State for specgen instruction: subps %xmm2, %xmm1:
%xmm1: (%ymm1_subps_xmm_xmm[255:128] ∘ (sub_single(%ymm1_subps_xmm_xmm[127:96], %ymm2_subps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_subps_xmm_xmm[95:64], %ymm2_subps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_subps_xmm_xmm[63:32], %ymm2_subps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_subps_xmm_xmm[31:0], %ymm2_subps_xmm_xmm[31:0])))))[127:0]

Final state
%xmm5: ((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0]))))[255:128] ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0])))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm5, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vsubps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0]))))

=====================================
=====================================
Computing circuit for vsubps %xmm8, %xmm15, %xmm4

.target:
vminps %xmm2, %xmm2, %xmm5
subps %xmm3, %xmm5
vmovdqu %xmm5, %xmm1
retq 

Initial state:
%ymm4: %ymm4_hsubps_xmm_xmm

State for specgen instruction: vsubps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0]))))

Final state
%ymm4: 0x0₁₂₈ ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm4, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_hsubps_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_hsubps_xmm_xmm[255:128] ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))[127:0]

=====================================
=====================================
Computing circuit for hsubps %xmm3, %xmm2

.target:
vpunpckldq %xmm2, %xmm1, %xmm8
vunpckhps %xmm2, %xmm1, %xmm10
vpunpckldq %xmm10, %xmm8, %xmm15
punpckhdq %xmm10, %xmm8
vsubps %xmm8, %xmm15, %xmm4
movdqu %xmm4, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vhsubps_xmm_xmm_xmm[127:0]

State for specgen instruction: hsubps %xmm2, %xmm1:
%xmm1: (%ymm1_hsubps_xmm_xmm[255:128] ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))[127:0]

Final state
%xmm2: (%ymm2_vhsubps_xmm_xmm_xmm[255:128] ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vhsubps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vhsubps_xmm_xmm_xmm

%xmm0: %ymm0_vhsubps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vhsubps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vhsubps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vhsubps_xmm_xmm_xmm

%xmm0: %ymm0_vhsubps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vhsubps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vhsubps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32])))

=====================================
=====================================
Computing circuit for vhsubps %xmm13, %xmm1, %xmm1

.target:
hsubps %xmm3, %xmm2
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm1: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0]))

State for specgen instruction: vhsubps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32])))

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0])))

=====================================
=====================================
Computing circuit for vpmovzxwd %xmm10, %xmm14

.target:
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7
vpmovzxwq %xmm5, %xmm13
movddup %xmm4, %xmm4
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm3
vpmovzxwq %xmm3, %xmm1
vhsubps %xmm13, %xmm1, %xmm1
retq 

Initial state:
%ymm14: %ymm14_pmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwd %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0])))

Final state
%ymm14: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[15:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_pmovzxwd_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_pmovzxwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[15:0]))))[127:0]

=====================================
=====================================
Computing circuit for pmovzxwd %xmm15, %xmm3

.target:
vpbroadcastq %xmm2, %ymm10
minpd %xmm10, %xmm10
vpmovzxwd %xmm10, %xmm14
movapd %xmm14, %xmm1
retq 

Initial state:
%xmm3: %ymm3_pmovsxwd_xmm_xmm[127:0]

State for specgen instruction: pmovzxwd %xmm2, %xmm1:
%xmm1: (%ymm1_pmovzxwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[15:0]))))[127:0]

Final state
%xmm3: (%ymm3_pmovsxwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[15:0]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm2

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm2: %ymm2_vunpckhps_xmm_xmm_xmm[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm2: (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpckhps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm9, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vunpckhps_xmm_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: %ymm0_vmovq_xmm_xmm[127:0]
%xmm1: %ymm1_vmovq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movswq %bx, %r10

Final state:
%r10/%r10: sign-extend-64(%rbx_xchgl_r32_r32[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_xchgl_r32_r32[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ecx_r8w_r9w

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %rcx

Final state:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r8w_r9w_ebx

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xchgl %ebx, %ecx

.target:
movswq %bx, %r10
movslq %ebx, %rbx
callq .move_032_016_ecx_r8w_r9w
callq .move_064_032_rbx_r10d_r11d
movq %r10, %rcx
callq .move_016_032_r8w_r9w_ebx
retq 

Initial state:
%rcx/%rcx: %rcx_xorl_r32_r32
%rbx/%rbx: %rbx_xorl_r32_r32

State for specgen instruction: xchgl %ecx, %ebx:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
%rbx/%rbx: 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])

Register        -> %rcx
  translates to => %rbx
Value is               -> 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
  after renaming it is => 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

Register        -> %rbx
  translates to => %rcx
Value is               -> 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])
  after renaming it is => 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

Final state
%rcx/%rcx: 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]) = 0x0₆₄
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_ebx

Final state:
%rax/%rax: %rax_xorl_r32_r32
%rdx/%rdx: %rdx_xorl_r32_r32

%xmm0: %ymm0_xorl_r32_r32[127:0]
%xmm1: %ymm1_xorl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xorl %r13d, %r13d

.target:
xchgl %ebx, %ecx
xorq %rcx, %rbx
callq .set_szp_for_ebx
retq 

Initial state:
%r13/%r13: %ymm2_vmovq_xmm_xmm[127:0][127:64]

%cf: %cf_vmovq_xmm_xmm
%pf: %pf_vmovq_xmm_xmm
%zf: %zf_vmovq_xmm_xmm
%sf: %sf_vmovq_xmm_xmm
%of: %of_vmovq_xmm_xmm

State for specgen instruction: xorl %ecx, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0] = 0x0₃₂
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][31:31] = 0x1₁
%of: false

Register        -> %rbx
  translates to => %r13
Value is               -> 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
  after renaming it is => 0x0₆₄

Final state
%r13/%r13: 0x0₆₄

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
xorl %r13d, %r13d
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][95:64])

State for specgen instruction: vmovq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhps %xmm1, %xmm2, %xmm10

.target:
unpckhpd %xmm3, %xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovddup %xmm9, %xmm1
vmovq %xmm1, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm10: %ymm10_paddd_xmm_xmm

State for specgen instruction: vunpckhps %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_paddd_xmm_xmm[127:96] ∘ %ymm2_paddd_xmm_xmm[127:96] ∘ %ymm1_paddd_xmm_xmm[95:64] ∘ %ymm2_paddd_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm2, %xmm1

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm1: %ymm1_paddd_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm1: (%ymm1_paddd_xmm_xmm[255:128] ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm1_paddd_xmm_xmm[63:32] ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm1_paddd_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_movshdup_xmm_xmm
%rdx/%rdx: %rdx_movshdup_xmm_xmm

%xmm0: %ymm0_movshdup_xmm_xmm[127:0]
%xmm1: %ymm1_movshdup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_movshdup_xmm_xmm
%rdx/%rdx: %rdx_movshdup_xmm_xmm

%xmm0: %ymm0_movshdup_xmm_xmm[127:0]
%xmm1: (%ymm1_movshdup_xmm_xmm[255:128] ∘ (%ymm2_movshdup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movshdup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovshdup_xmm_xmm
%rdx/%rdx: %rdx_vmovshdup_xmm_xmm

%xmm0: %ymm0_vmovshdup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovshdup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm11, %xmm11

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm11: %ymm11_vmovshdup_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovshdup_xmm_xmm[127:0][127:96])

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm11: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (%ymm2_vmovshdup_xmm_xmm[127:96] ∘ %ymm2_vmovshdup_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm11, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmovshdup_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (%ymm2_vmovshdup_xmm_xmm[127:96] ∘ %ymm2_vmovshdup_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm9, %xmm1

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovshdup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (%ymm2_vmovshdup_xmm_xmm[63:32] ∘ %ymm2_vmovshdup_xmm_xmm[63:32]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpcklpd_xmm_xmm
%rdx/%rdx: %rdx_unpcklpd_xmm_xmm

%xmm0: %ymm0_unpcklpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpcklpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm11: %ymm11_unpcklpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm1_unpcklpd_xmm_xmm[127:0][127:64])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_unpcklpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_unpcklpd_xmm_xmm
%rdx/%rdx: %rdx_unpcklpd_xmm_xmm

%xmm0: %ymm0_unpcklpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpcklpd_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ %ymm2_unpcklpd_xmm_xmm[127:0])[127:0][63:0] ∘ (%ymm10_unpcklpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm1_unpcklpd_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpcklpd %xmm3, %xmm1

.target:
callq .move_128_64_xmm1_xmm10_xmm11
vmovdqu %xmm2, %xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ (0x0₆₄ ∘ (%ymm2_vmovshdup_xmm_xmm[63:32] ∘ %ymm2_vmovshdup_xmm_xmm[63:32])))[127:0]

State for specgen instruction: unpcklpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklpd_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ %ymm2_unpcklpd_xmm_xmm[127:0])[127:0][63:0] ∘ (%ymm10_unpcklpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm1_unpcklpd_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ (0x0₆₄ ∘ (%ymm2_vmovshdup_xmm_xmm[63:32] ∘ %ymm2_vmovshdup_xmm_xmm[63:32])))[255:128] ∘ (%ymm2_vmovshdup_xmm_xmm[127:96] ∘ %ymm2_vmovshdup_xmm_xmm[127:96] ∘ (%ymm2_vmovshdup_xmm_xmm[63:32] ∘ %ymm2_vmovshdup_xmm_xmm[63:32])))[127:0]

=====================================
=====================================
Computing circuit for vmovshdup %xmm1, %xmm8

.target:
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovsldup %xmm11, %xmm11
vmovdqa %xmm11, %xmm3
vmovsldup %xmm9, %xmm1
unpcklpd %xmm3, %xmm1
retq 

Initial state:
%ymm8: %ymm8_movshdup_xmm_xmm

State for specgen instruction: vmovshdup %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₆₄ ∘ (%ymm2_vmovshdup_xmm_xmm[63:32] ∘ %ymm2_vmovshdup_xmm_xmm[63:32])))[255:128] ∘ (%ymm2_vmovshdup_xmm_xmm[127:96] ∘ %ymm2_vmovshdup_xmm_xmm[127:96] ∘ (%ymm2_vmovshdup_xmm_xmm[63:32] ∘ %ymm2_vmovshdup_xmm_xmm[63:32]))

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_movshdup_xmm_xmm[127:96] ∘ %ymm2_movshdup_xmm_xmm[127:96] ∘ (%ymm2_movshdup_xmm_xmm[63:32] ∘ %ymm2_movshdup_xmm_xmm[63:32]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_movaps_xmm_xmm
%rdx/%rdx: %rdx_movaps_xmm_xmm

%xmm0: %ymm0_movaps_xmm_xmm[127:0]
%xmm1: %ymm1_movaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1

Final state:
%rax/%rax: %rax_movaps_xmm_xmm
%rdx/%rdx: %rdx_movaps_xmm_xmm

%xmm0: %ymm0_movaps_xmm_xmm[127:0]
%xmm1: (%ymm1_movaps_xmm_xmm[255:128] ∘ ((%ymm7_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm6_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm5_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (%ymm4_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][31:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movaps %xmm8, %xmm1

.target:
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1
retq 

Initial state:
%xmm1: (%ymm1_movshdup_xmm_xmm[255:128] ∘ (%ymm2_movshdup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movshdup_xmm_xmm[127:0][63:0][63:0]))[127:0]

State for specgen instruction: movaps %xmm2, %xmm1:
%xmm1: (%ymm1_movaps_xmm_xmm[255:128] ∘ ((%ymm7_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm6_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm5_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (%ymm4_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][31:0]))[127:0][31:0]))[127:0]

Final state
%xmm1: ((%ymm1_movshdup_xmm_xmm[255:128] ∘ (%ymm2_movshdup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movshdup_xmm_xmm[127:0][63:0][63:0]))[255:128] ∘ (%ymm2_movshdup_xmm_xmm[127:96] ∘ %ymm2_movshdup_xmm_xmm[127:96] ∘ %ymm2_movshdup_xmm_xmm[63:32] ∘ %ymm2_movshdup_xmm_xmm[63:32]))[127:0]

=====================================
=====================================
Computing circuit for movshdup %xmm1, %xmm0

.target:
callq .move_128_064_xmm2_r10_r11
callq .move_064_128_r10_r11_xmm1
vmovshdup %xmm1, %xmm8
movaps %xmm8, %xmm1
retq 

Initial state:
%xmm0: %ymm0_phaddd_xmm_xmm[127:0]

State for specgen instruction: movshdup %xmm2, %xmm1:
%xmm1: ((%ymm1_movshdup_xmm_xmm[255:128] ∘ (%ymm2_movshdup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movshdup_xmm_xmm[127:0][63:0][63:0]))[255:128] ∘ (%ymm2_movshdup_xmm_xmm[127:96] ∘ %ymm2_movshdup_xmm_xmm[127:96] ∘ %ymm2_movshdup_xmm_xmm[63:32] ∘ %ymm2_movshdup_xmm_xmm[63:32]))[127:0]

Final state
%xmm0: (%ymm0_phaddd_xmm_xmm[255:128] ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_phaddd_xmm_xmm
%rdx/%rdx: %rdx_phaddd_xmm_xmm

%xmm0: (%ymm0_phaddd_xmm_xmm[255:128] ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]))[127:0]
%xmm1: %ymm1_phaddd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r8_r9

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r10, %r8

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r8/%r8: %ymm1_paddq_xmm_xmm[127:0][63:0]

%cf: %cf_paddq_xmm_xmm
%pf: %pf_paddq_xmm_xmm
%af: %af_paddq_xmm_xmm
%zf: %zf_paddq_xmm_xmm
%sf: %sf_paddq_xmm_xmm
%of: %of_paddq_xmm_xmm

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r8
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

Final state
%r8/%r8: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r10b_r11b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_cx_r8b_r9b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r10b_r11b_cx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r8b_r9b_bx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for xchgw %r8w, %r8w

.target:
callq .move_016_008_bx_r10b_r11b
callq .move_016_008_cx_r8b_r9b
callq .move_008_016_r10b_r11b_cx
callq .move_008_016_r8b_r9b_bx
retq 

Initial state:
%r8/%r8w: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

State for specgen instruction: xchgw %cx, %bx:
%rcx/%cx: %rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])
%rbx/%bx: %rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])

Register        -> %cx
  translates to => %r8w
Value is               -> (%rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Register        -> %bx
  translates to => %r8w
Value is               -> (%rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Final state
%r8/%r8w: ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

=====================================
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r11, %r9

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r9/%r9: %ymm1_paddq_xmm_xmm[127:0][127:64]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r9
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

Final state
%r9/%r9: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[67:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[67:64])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[127:127] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for paddq %xmm0, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
callq .move_128_064_xmm1_r8_r9
addq %r10, %r8
xchgw %r8w, %r8w
addq %r11, %r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_phaddd_xmm_xmm[127:0]

State for specgen instruction: paddq %xmm2, %xmm1:
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

Final state
%xmm1: (%ymm1_phaddd_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[63:0])[63:0]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r8_r9

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r10, %r8

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r8/%r8: %ymm1_paddq_xmm_xmm[127:0][63:0]

%cf: %cf_paddq_xmm_xmm
%pf: %pf_paddq_xmm_xmm
%af: %af_paddq_xmm_xmm
%zf: %zf_paddq_xmm_xmm
%sf: %sf_paddq_xmm_xmm
%of: %of_paddq_xmm_xmm

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r8
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

Final state
%r8/%r8: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r10b_r11b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_cx_r8b_r9b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r10b_r11b_cx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r8b_r9b_bx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for xchgw %r8w, %r8w

.target:
callq .move_016_008_bx_r10b_r11b
callq .move_016_008_cx_r8b_r9b
callq .move_008_016_r10b_r11b_cx
callq .move_008_016_r8b_r9b_bx
retq 

Initial state:
%r8/%r8w: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

State for specgen instruction: xchgw %cx, %bx:
%rcx/%cx: %rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])
%rbx/%bx: %rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])

Register        -> %cx
  translates to => %r8w
Value is               -> (%rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Register        -> %bx
  translates to => %r8w
Value is               -> (%rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Final state
%r8/%r8w: ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

=====================================
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r11, %r9

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r9/%r9: %ymm1_paddq_xmm_xmm[127:0][127:64]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r9
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

Final state
%r9/%r9: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[67:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[67:64])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[127:127] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for paddq %xmm2, %xmm3

.target:
callq .move_128_064_xmm2_r10_r11
callq .move_128_064_xmm1_r8_r9
addq %r10, %r8
xchgw %r8w, %r8w
addq %r11, %r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm3: %ymm3_vpaddq_xmm_xmm_xmm[127:0]

State for specgen instruction: paddq %xmm2, %xmm1:
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

Final state
%xmm3: (%ymm3_vpaddq_xmm_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: %ymm0_vmovups_xmm_xmm[127:0]
%xmm1: %ymm1_vmovups_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovups %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpaddq_xmm_xmm_xmm

State for specgen instruction: vmovups %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0])

=====================================
=====================================
Computing circuit for vpaddq %xmm9, %xmm2, %xmm6

.target:
paddq %xmm2, %xmm3
vmovups %xmm3, %xmm1
retq 

Initial state:
%ymm6: %ymm6_phaddd_xmm_xmm

State for specgen instruction: vpaddq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0])

Final state
%ymm6: 0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_phaddd_xmm_xmm[127:64] + 0x0₁ ∘ 0x0₆₄)[63:0] ∘ (0x0₁ ∘ %ymm2_phaddd_xmm_xmm[63:0] + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[63:32]))[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm9, %xmm1, %xmm4

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm4: %ymm4_phaddd_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm4: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[63:32] ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[63:0])[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vmovhlps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovhlps_xmm_xmm_xmm

%xmm0: %ymm0_vmovhlps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vmovhlps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovhlps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovhlps_xmm_xmm_xmm

%xmm0: %ymm0_vmovhlps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vmovhlps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r11, %r12

Final state:
%r12/%r12: %ymm3_vmovhlps_xmm_xmm_xmm[127:0][127:64]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovhlps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovhlps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovhlps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmovhlps_xmm_xmm_xmm[127:0][127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovhlps %xmm1, %xmm8, %xmm5

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r12_r13
vzeroall 
movq %r11, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm5: %ymm5_phaddd_xmm_xmm

State for specgen instruction: vmovhlps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovhlps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmovhlps_xmm_xmm_xmm[127:0][127:64][63:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[127:64])[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r8_r9

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r10, %r8

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r8/%r8: %ymm1_paddq_xmm_xmm[127:0][63:0]

%cf: %cf_paddq_xmm_xmm
%pf: %pf_paddq_xmm_xmm
%af: %af_paddq_xmm_xmm
%zf: %zf_paddq_xmm_xmm
%sf: %sf_paddq_xmm_xmm
%of: %of_paddq_xmm_xmm

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r8
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

Final state
%r8/%r8: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r10b_r11b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_cx_r8b_r9b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r10b_r11b_cx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r8b_r9b_bx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for xchgw %r8w, %r8w

.target:
callq .move_016_008_bx_r10b_r11b
callq .move_016_008_cx_r8b_r9b
callq .move_008_016_r10b_r11b_cx
callq .move_008_016_r8b_r9b_bx
retq 

Initial state:
%r8/%r8w: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

State for specgen instruction: xchgw %cx, %bx:
%rcx/%cx: %rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])
%rbx/%bx: %rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])

Register        -> %cx
  translates to => %r8w
Value is               -> (%rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Register        -> %bx
  translates to => %r8w
Value is               -> (%rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Final state
%r8/%r8w: ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

=====================================
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r11, %r9

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r9/%r9: %ymm1_paddq_xmm_xmm[127:0][127:64]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r9
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

Final state
%r9/%r9: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[67:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[67:64])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[127:127] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for paddq %xmm2, %xmm3

.target:
callq .move_128_064_xmm2_r10_r11
callq .move_128_064_xmm1_r8_r9
addq %r10, %r8
xchgw %r8w, %r8w
addq %r11, %r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm3: %ymm3_vpaddq_xmm_xmm_xmm[127:0]

State for specgen instruction: paddq %xmm2, %xmm1:
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

Final state
%xmm3: (%ymm3_vpaddq_xmm_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: %ymm0_vmovups_xmm_xmm[127:0]
%xmm1: %ymm1_vmovups_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovups %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpaddq_xmm_xmm_xmm

State for specgen instruction: vmovups %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0])

=====================================
=====================================
Computing circuit for vpaddq %xmm10, %xmm11, %xmm7

.target:
paddq %xmm2, %xmm3
vmovups %xmm3, %xmm1
retq 

Initial state:
%ymm7: %ymm7_phaddd_xmm_xmm

State for specgen instruction: vpaddq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0])

Final state
%ymm7: 0x0₁₂₈ ∘ ((0x0₁ ∘ 0x0₆₄ + 0x0₁ ∘ 0x0₆₄)[63:0] ∘ (0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[95:64]))[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1

Final state:
%rax/%rax: %rax_phaddd_xmm_xmm
%rdx/%rdx: %rdx_phaddd_xmm_xmm

%xmm0: (%ymm0_phaddd_xmm_xmm[255:128] ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]))[127:0]
%xmm1: ((%ymm1_phaddd_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[63:0])[63:0]))[255:128] ∘ ((0x0₁₂₈ ∘ ((0x0₁ ∘ 0x0₆₄ + 0x0₁ ∘ 0x0₆₄)[63:0] ∘ (0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[95:64]))[63:0]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_phaddd_xmm_xmm[127:64] + 0x0₁ ∘ 0x0₆₄)[63:0] ∘ (0x0₁ ∘ %ymm2_phaddd_xmm_xmm[63:0] + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[63:32]))[63:0]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[127:64])[63:0]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[63:32] ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[63:0])[63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for phaddd %xmm10, %xmm1

.target:
movshdup %xmm1, %xmm0
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
paddq %xmm0, %xmm1
vpaddq %xmm9, %xmm2, %xmm6
vunpcklpd %xmm9, %xmm1, %xmm4
vmovhlps %xmm1, %xmm8, %xmm5
vpaddq %xmm10, %xmm11, %xmm7
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1
retq 

Initial state:
%xmm1: (%ymm1_paddd_xmm_xmm[255:128] ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm1_paddd_xmm_xmm[63:32] ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm1_paddd_xmm_xmm[31:0])))[127:0]

State for specgen instruction: phaddd %xmm2, %xmm1:
%xmm1: ((%ymm1_phaddd_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[63:0])[63:0]))[255:128] ∘ ((0x0₁₂₈ ∘ ((0x0₁ ∘ 0x0₆₄ + 0x0₁ ∘ 0x0₆₄)[63:0] ∘ (0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[95:64]))[63:0]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_phaddd_xmm_xmm[127:64] + 0x0₁ ∘ 0x0₆₄)[63:0] ∘ (0x0₁ ∘ %ymm2_phaddd_xmm_xmm[63:0] + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[63:32]))[63:0]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[127:64])[63:0]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[63:32] ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[63:0])[63:0]))[127:0][31:0]))[127:0]

Final state
%xmm1: ((%ymm1_paddd_xmm_xmm[255:128] ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm1_paddd_xmm_xmm[63:32] ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm1_paddd_xmm_xmm[31:0])))[255:128] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm1_paddd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_paddd_xmm_xmm[127:96]))[31:0] ∘ (0x0₁ ∘ (%ymm1_paddd_xmm_xmm[95:64] ∘ %ymm2_paddd_xmm_xmm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm1_paddd_xmm_xmm[95:64]))[31:0] ∘ (0x0₁ ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm2_paddd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm1_paddd_xmm_xmm[63:32]))[31:0] ∘ (0x0₁ ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm2_paddd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm1_paddd_xmm_xmm[31:0]))[31:0]))[127:0]

=====================================
=====================================
Computing circuit for paddd %xmm3, %xmm2

.target:
vunpckhps %xmm1, %xmm2, %xmm10
unpcklps %xmm2, %xmm1
phaddd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpaddd_xmm_xmm_xmm[127:0]

State for specgen instruction: paddd %xmm2, %xmm1:
%xmm1: ((%ymm1_paddd_xmm_xmm[255:128] ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm1_paddd_xmm_xmm[63:32] ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm1_paddd_xmm_xmm[31:0])))[255:128] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm1_paddd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_paddd_xmm_xmm[127:96]))[31:0] ∘ (0x0₁ ∘ (%ymm1_paddd_xmm_xmm[95:64] ∘ %ymm2_paddd_xmm_xmm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm1_paddd_xmm_xmm[95:64]))[31:0] ∘ (0x0₁ ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm2_paddd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm1_paddd_xmm_xmm[63:32]))[31:0] ∘ (0x0₁ ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm2_paddd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm1_paddd_xmm_xmm[31:0]))[31:0]))[127:0]

Final state
%xmm2: (%ymm2_vpaddd_xmm_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_xmm_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm3_vpaddd_xmm_xmm_xmm[127:96]))[31:0] ∘ (0x0₁ ∘ (%ymm2_vpaddd_xmm_xmm_xmm[95:64] ∘ %ymm3_vpaddd_xmm_xmm_xmm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_xmm_xmm_xmm[95:64]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[63:32] ∘ %ymm3_vpaddd_xmm_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[63:32] ∘ %ymm2_vpaddd_xmm_xmm_xmm[63:32]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[31:0] ∘ %ymm3_vpaddd_xmm_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[31:0] ∘ %ymm2_vpaddd_xmm_xmm_xmm[31:0]))[31:0]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpaddd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpaddd_xmm_xmm_xmm

%xmm0: %ymm0_vpaddd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpaddd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vpaddd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpaddd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vpaddd_xmm_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_xmm_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm3_vpaddd_xmm_xmm_xmm[127:96]))[31:0] ∘ (0x0₁ ∘ (%ymm2_vpaddd_xmm_xmm_xmm[95:64] ∘ %ymm3_vpaddd_xmm_xmm_xmm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_xmm_xmm_xmm[95:64]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[63:32] ∘ %ymm3_vpaddd_xmm_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[63:32] ∘ %ymm2_vpaddd_xmm_xmm_xmm[63:32]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[31:0] ∘ %ymm3_vpaddd_xmm_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[31:0] ∘ %ymm2_vpaddd_xmm_xmm_xmm[31:0]))[31:0]))[127:0][127:64][63:0] ∘ (%ymm2_vpaddd_xmm_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_xmm_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm3_vpaddd_xmm_xmm_xmm[127:96]))[31:0] ∘ (0x0₁ ∘ (%ymm2_vpaddd_xmm_xmm_xmm[95:64] ∘ %ymm3_vpaddd_xmm_xmm_xmm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_xmm_xmm_xmm[95:64]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[63:32] ∘ %ymm3_vpaddd_xmm_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[63:32] ∘ %ymm2_vpaddd_xmm_xmm_xmm[63:32]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[31:0] ∘ %ymm3_vpaddd_xmm_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[31:0] ∘ %ymm2_vpaddd_xmm_xmm_xmm[31:0]))[31:0]))[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpaddd %xmm2, %xmm2, %xmm2

.target:
paddd %xmm3, %xmm2
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm2: %ymm2_pmovsxwd_xmm_xmm

State for specgen instruction: vpaddd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vpaddd_xmm_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_xmm_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm3_vpaddd_xmm_xmm_xmm[127:96]))[31:0] ∘ (0x0₁ ∘ (%ymm2_vpaddd_xmm_xmm_xmm[95:64] ∘ %ymm3_vpaddd_xmm_xmm_xmm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_xmm_xmm_xmm[95:64]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[63:32] ∘ %ymm3_vpaddd_xmm_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[63:32] ∘ %ymm2_vpaddd_xmm_xmm_xmm[63:32]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[31:0] ∘ %ymm3_vpaddd_xmm_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[31:0] ∘ %ymm2_vpaddd_xmm_xmm_xmm[31:0]))[31:0]))[127:0][127:64][63:0] ∘ (%ymm2_vpaddd_xmm_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_xmm_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm3_vpaddd_xmm_xmm_xmm[127:96]))[31:0] ∘ (0x0₁ ∘ (%ymm2_vpaddd_xmm_xmm_xmm[95:64] ∘ %ymm3_vpaddd_xmm_xmm_xmm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_xmm_xmm_xmm[95:64]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[63:32] ∘ %ymm3_vpaddd_xmm_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[63:32] ∘ %ymm2_vpaddd_xmm_xmm_xmm[63:32]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[31:0] ∘ %ymm3_vpaddd_xmm_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm3_vpaddd_xmm_xmm_xmm[31:0] ∘ %ymm2_vpaddd_xmm_xmm_xmm[31:0]))[31:0]))[127:0][63:0][63:0])

Final state
%ymm2: 0x0₁₂₈ ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm2_pmovsxwd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_pmovsxwd_xmm_xmm[127:96]))[31:0] ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[95:64] ∘ %ymm2_pmovsxwd_xmm_xmm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_pmovsxwd_xmm_xmm[95:64]))[31:0] ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]))[31:0] ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vpmovzxwd_ymm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ %ymm2_vpmovzxwd_ymm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vpmovzxwd_ymm_xmm
%rdx/%rdx: %rdx_vpmovzxwd_ymm_xmm

%xmm0: %ymm0_vpmovzxwd_ymm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vpmovzxwd_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwd_xmm_xmm

%xmm0: %ymm0_vpmovzxwd_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: %ymm0_vpmovzxwq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r12d_r13d_rdx

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_edx_r10w_r11w

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxwq %xmm5, %xmm13

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_128_064_xmm2_r10_r11
callq .move_032_064_r12d_r13d_rdx
callq .move_032_016_edx_r10w_r11w
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm13: %ymm13_vpmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0])

Final state
%ymm13: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movddup_xmm_xmm
%rdx/%rdx: %rdx_movddup_xmm_xmm

%xmm0: %ymm0_movddup_xmm_xmm[127:0]
%xmm1: %ymm1_movddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r12, %r13

Final state:
%r13/%r13: %ymm2_movddup_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movddup_xmm_xmm
%rdx/%rdx: %rdx_movddup_xmm_xmm

%xmm0: %ymm0_movddup_xmm_xmm[127:0]
%xmm1: (%ymm1_movddup_xmm_xmm[255:128] ∘ (%ymm2_movddup_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_movddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movddup %xmm4, %xmm4

.target:
callq .move_128_064_xmm2_r12_r13
movq %r12, %r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm4: (%ymm4_vpmovzxwd_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[127:0][31:0]))[127:0]

State for specgen instruction: movddup %xmm2, %xmm1:
%xmm1: (%ymm1_movddup_xmm_xmm[255:128] ∘ (%ymm2_movddup_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_movddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm4: ((%ymm4_vpmovzxwd_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[127:0][31:0]))[255:128] ∘ (0x0₃₂ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:0] ∘ (0x0₃₂ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm3

Final state:
%rax/%rax: %rax_vpmovzxwd_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwd_xmm_xmm

%xmm0: %ymm0_vpmovzxwd_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: %ymm0_vpmovzxwq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r12d_r13d_rdx

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_edx_r10w_r11w

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxwq %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_128_064_xmm2_r10_r11
callq .move_032_064_r12d_r13d_rdx
callq .move_032_016_edx_r10w_r11w
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm3, %ymm6

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm6: %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm3, %xmm6, %xmm9

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm3, %xmm2, %xmm14

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm14: %ymm14_vpor_xmm_xmm_xmm

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpor_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vpor %xmm9, %xmm9, %xmm7

.target:
vorps %xmm3, %xmm2, %xmm14
vmovapd %xmm14, %xmm1
retq 

Initial state:
%ymm7: %ymm7_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpor %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

Final state
%ymm7: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm7, %xmm2

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpckldq_xmm_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm2: (%ymm2_vpunpckldq_xmm_xmm_xmm[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm1, %xmm3

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm3: %ymm3_mulpd_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm8: %ymm8_mulpd_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmulpd %ymm8, %ymm3, %ymm6

Final state:
%ymm6: mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[255:192]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[191:128]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[127:64]) ∘ mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_mulpd_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for mulpd %xmm3, %xmm2

.target:
vmovapd %xmm1, %xmm3
vmovaps %xmm2, %xmm8
vmulpd %ymm8, %ymm3, %ymm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vmulpd_xmm_xmm_xmm[127:0]

State for specgen instruction: mulpd %xmm2, %xmm1:
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vmulpd_xmm_xmm_xmm[255:128] ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmulpd_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmulpd %xmm6, %xmm2, %xmm12

.target:
mulpd %xmm3, %xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm12: %ymm12_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vmulpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]) ∘ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm12, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vpunpckldq %xmm2, %xmm1, %xmm8

.target:
vpbroadcastq %xmm3, %ymm6
vunpcklpd %xmm3, %xmm6, %xmm9
vpor %xmm9, %xmm9, %xmm7
unpcklps %xmm7, %xmm2
vmulpd %xmm6, %xmm2, %xmm12
vxorps %xmm12, %xmm2, %xmm1
movdqu %xmm2, %xmm1
retq 

Initial state:
%ymm8: %ymm8_hsubps_xmm_xmm

State for specgen instruction: vpunpckldq %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0]))

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm2

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm2: %ymm2_vunpckhps_xmm_xmm_xmm[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm2: (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpckhps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm9, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vunpckhps_xmm_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: %ymm0_vmovq_xmm_xmm[127:0]
%xmm1: %ymm1_vmovq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movswq %bx, %r10

Final state:
%r10/%r10: sign-extend-64(%rbx_xchgl_r32_r32[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_xchgl_r32_r32[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ecx_r8w_r9w

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %rcx

Final state:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r8w_r9w_ebx

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xchgl %ebx, %ecx

.target:
movswq %bx, %r10
movslq %ebx, %rbx
callq .move_032_016_ecx_r8w_r9w
callq .move_064_032_rbx_r10d_r11d
movq %r10, %rcx
callq .move_016_032_r8w_r9w_ebx
retq 

Initial state:
%rcx/%rcx: %rcx_xorl_r32_r32
%rbx/%rbx: %rbx_xorl_r32_r32

State for specgen instruction: xchgl %ecx, %ebx:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
%rbx/%rbx: 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])

Register        -> %rcx
  translates to => %rbx
Value is               -> 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
  after renaming it is => 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

Register        -> %rbx
  translates to => %rcx
Value is               -> 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])
  after renaming it is => 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

Final state
%rcx/%rcx: 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]) = 0x0₆₄
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_ebx

Final state:
%rax/%rax: %rax_xorl_r32_r32
%rdx/%rdx: %rdx_xorl_r32_r32

%xmm0: %ymm0_xorl_r32_r32[127:0]
%xmm1: %ymm1_xorl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xorl %r13d, %r13d

.target:
xchgl %ebx, %ecx
xorq %rcx, %rbx
callq .set_szp_for_ebx
retq 

Initial state:
%r13/%r13: %ymm2_vmovq_xmm_xmm[127:0][127:64]

%cf: %cf_vmovq_xmm_xmm
%pf: %pf_vmovq_xmm_xmm
%zf: %zf_vmovq_xmm_xmm
%sf: %sf_vmovq_xmm_xmm
%of: %of_vmovq_xmm_xmm

State for specgen instruction: xorl %ecx, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0] = 0x0₃₂
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][31:31] = 0x1₁
%of: false

Register        -> %rbx
  translates to => %r13
Value is               -> 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
  after renaming it is => 0x0₆₄

Final state
%r13/%r13: 0x0₆₄

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
xorl %r13d, %r13d
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][95:64])

State for specgen instruction: vmovq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhps %xmm2, %xmm1, %xmm10

.target:
unpckhpd %xmm3, %xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovddup %xmm9, %xmm1
vmovq %xmm1, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm10: %ymm10_hsubps_xmm_xmm

State for specgen instruction: vunpckhps %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[127:96] ∘ %ymm1_hsubps_xmm_xmm[127:96] ∘ %ymm2_hsubps_xmm_xmm[95:64] ∘ %ymm1_hsubps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm3, %ymm6

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm6: %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm3, %xmm6, %xmm9

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm3, %xmm2, %xmm14

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm14: %ymm14_vpor_xmm_xmm_xmm

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpor_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vpor %xmm9, %xmm9, %xmm7

.target:
vorps %xmm3, %xmm2, %xmm14
vmovapd %xmm14, %xmm1
retq 

Initial state:
%ymm7: %ymm7_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpor %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

Final state
%ymm7: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm7, %xmm2

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpckldq_xmm_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm2: (%ymm2_vpunpckldq_xmm_xmm_xmm[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm1, %xmm3

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm3: %ymm3_mulpd_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm8: %ymm8_mulpd_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmulpd %ymm8, %ymm3, %ymm6

Final state:
%ymm6: mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[255:192]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[191:128]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[127:64]) ∘ mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_mulpd_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for mulpd %xmm3, %xmm2

.target:
vmovapd %xmm1, %xmm3
vmovaps %xmm2, %xmm8
vmulpd %ymm8, %ymm3, %ymm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vmulpd_xmm_xmm_xmm[127:0]

State for specgen instruction: mulpd %xmm2, %xmm1:
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vmulpd_xmm_xmm_xmm[255:128] ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmulpd_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmulpd %xmm6, %xmm2, %xmm12

.target:
mulpd %xmm3, %xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm12: %ymm12_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vmulpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]) ∘ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm12, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vpunpckldq %xmm10, %xmm8, %xmm15

.target:
vpbroadcastq %xmm3, %ymm6
vunpcklpd %xmm3, %xmm6, %xmm9
vpor %xmm9, %xmm9, %xmm7
unpcklps %xmm7, %xmm2
vmulpd %xmm6, %xmm2, %xmm12
vxorps %xmm12, %xmm2, %xmm1
movdqu %xmm2, %xmm1
retq 

Initial state:
%ymm15: %ymm15_hsubps_xmm_xmm

State for specgen instruction: vpunpckldq %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0]))

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[95:64] ∘ %ymm2_hsubps_xmm_xmm[31:0] ∘ (%ymm1_hsubps_xmm_xmm[95:64] ∘ %ymm1_hsubps_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm2

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm2: %ymm2_vunpckhps_xmm_xmm_xmm[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm2: (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpckhps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm9, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vunpckhps_xmm_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: %ymm0_vmovq_xmm_xmm[127:0]
%xmm1: %ymm1_vmovq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movswq %bx, %r10

Final state:
%r10/%r10: sign-extend-64(%rbx_xchgl_r32_r32[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_xchgl_r32_r32[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ecx_r8w_r9w

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %rcx

Final state:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r8w_r9w_ebx

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xchgl %ebx, %ecx

.target:
movswq %bx, %r10
movslq %ebx, %rbx
callq .move_032_016_ecx_r8w_r9w
callq .move_064_032_rbx_r10d_r11d
movq %r10, %rcx
callq .move_016_032_r8w_r9w_ebx
retq 

Initial state:
%rcx/%rcx: %rcx_xorl_r32_r32
%rbx/%rbx: %rbx_xorl_r32_r32

State for specgen instruction: xchgl %ecx, %ebx:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
%rbx/%rbx: 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])

Register        -> %rcx
  translates to => %rbx
Value is               -> 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
  after renaming it is => 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

Register        -> %rbx
  translates to => %rcx
Value is               -> 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])
  after renaming it is => 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

Final state
%rcx/%rcx: 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]) = 0x0₆₄
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_ebx

Final state:
%rax/%rax: %rax_xorl_r32_r32
%rdx/%rdx: %rdx_xorl_r32_r32

%xmm0: %ymm0_xorl_r32_r32[127:0]
%xmm1: %ymm1_xorl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xorl %r13d, %r13d

.target:
xchgl %ebx, %ecx
xorq %rcx, %rbx
callq .set_szp_for_ebx
retq 

Initial state:
%r13/%r13: %ymm2_vmovq_xmm_xmm[127:0][127:64]

%cf: %cf_vmovq_xmm_xmm
%pf: %pf_vmovq_xmm_xmm
%zf: %zf_vmovq_xmm_xmm
%sf: %sf_vmovq_xmm_xmm
%of: %of_vmovq_xmm_xmm

State for specgen instruction: xorl %ecx, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0] = 0x0₃₂
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][31:31] = 0x1₁
%of: false

Register        -> %rbx
  translates to => %r13
Value is               -> 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
  after renaming it is => 0x0₆₄

Final state
%r13/%r13: 0x0₆₄

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
xorl %r13d, %r13d
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][95:64])

State for specgen instruction: vmovq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhps %xmm2, %xmm1, %xmm8

.target:
unpckhpd %xmm3, %xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovddup %xmm9, %xmm1
vmovq %xmm1, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_punpckhdq_xmm_xmm

State for specgen instruction: vunpckhps %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ %ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm8, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_punpckhdq_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_punpckhdq_xmm_xmm[255:128] ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ (%ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])))[127:0]

=====================================
=====================================
Computing circuit for punpckhdq %xmm10, %xmm8

.target:
vunpckhps %xmm2, %xmm1, %xmm8
movdqu %xmm8, %xmm1
retq 

Initial state:
%xmm8: (0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0])))[127:0]

State for specgen instruction: punpckhdq %xmm2, %xmm1:
%xmm1: (%ymm1_punpckhdq_xmm_xmm[255:128] ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ (%ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])))[127:0]

Final state
%xmm8: ((0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0])))[255:128] ∘ (%ymm2_hsubps_xmm_xmm[127:96] ∘ %ymm2_hsubps_xmm_xmm[63:32] ∘ (%ymm1_hsubps_xmm_xmm[127:96] ∘ %ymm1_hsubps_xmm_xmm[63:32])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm14

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm14: %ymm14_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm14: 0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminps %ymm1, %ymm14, %ymm1

Final state:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vminps %xmm2, %xmm2, %xmm5

.target:
vmovdqa %xmm3, %xmm1
vmovdqu %xmm2, %xmm14
vminps %ymm1, %ymm14, %ymm1
retq 

Initial state:
%ymm5: %ymm5_vsubps_xmm_xmm_xmm

State for specgen instruction: vminps %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm5: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_subps_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm14

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm14: %ymm14_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm14: 0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminps %ymm1, %ymm14, %ymm1

Final state:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vminps %xmm1, %xmm1, %xmm4

.target:
vmovdqa %xmm3, %xmm1
vmovdqu %xmm2, %xmm14
vminps %ymm1, %ymm14, %ymm1
retq 

Initial state:
%ymm4: %ymm4_subps_xmm_xmm

State for specgen instruction: vminps %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm4: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for vsubps %ymm10, %ymm4, %ymm2

Final state:
%ymm2: sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[255:224], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[255:224]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[223:192], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[223:192]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[191:160], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[191:160]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[159:128], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[159:128]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[127:96], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[127:96]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[95:64], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[95:64]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[63:32], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[63:32]) ∘ sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[31:0], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_subps_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_subps_xmm_xmm[255:128] ∘ (sub_single(%ymm1_subps_xmm_xmm[127:96], %ymm2_subps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_subps_xmm_xmm[95:64], %ymm2_subps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_subps_xmm_xmm[63:32], %ymm2_subps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_subps_xmm_xmm[31:0], %ymm2_subps_xmm_xmm[31:0])))))[127:0]

=====================================
=====================================
Computing circuit for subps %xmm3, %xmm5

.target:
vmovaps %xmm2, %xmm10
vminps %xmm1, %xmm1, %xmm4
vsubps %ymm10, %ymm4, %ymm2
movdqu %xmm2, %xmm1
retq 

Initial state:
%xmm5: (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0]))))[127:0]

State for specgen instruction: subps %xmm2, %xmm1:
%xmm1: (%ymm1_subps_xmm_xmm[255:128] ∘ (sub_single(%ymm1_subps_xmm_xmm[127:96], %ymm2_subps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_subps_xmm_xmm[95:64], %ymm2_subps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_subps_xmm_xmm[63:32], %ymm2_subps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_subps_xmm_xmm[31:0], %ymm2_subps_xmm_xmm[31:0])))))[127:0]

Final state
%xmm5: ((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0]))))[255:128] ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0])))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm5, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vsubps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0]))))

=====================================
=====================================
Computing circuit for vsubps %xmm8, %xmm15, %xmm4

.target:
vminps %xmm2, %xmm2, %xmm5
subps %xmm3, %xmm5
vmovdqu %xmm5, %xmm1
retq 

Initial state:
%ymm4: %ymm4_hsubps_xmm_xmm

State for specgen instruction: vsubps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0]))))

Final state
%ymm4: 0x0₁₂₈ ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm4, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_hsubps_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_hsubps_xmm_xmm[255:128] ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))[127:0]

=====================================
=====================================
Computing circuit for hsubps %xmm3, %xmm2

.target:
vpunpckldq %xmm2, %xmm1, %xmm8
vunpckhps %xmm2, %xmm1, %xmm10
vpunpckldq %xmm10, %xmm8, %xmm15
punpckhdq %xmm10, %xmm8
vsubps %xmm8, %xmm15, %xmm4
movdqu %xmm4, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vhsubps_xmm_xmm_xmm[127:0]

State for specgen instruction: hsubps %xmm2, %xmm1:
%xmm1: (%ymm1_hsubps_xmm_xmm[255:128] ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))[127:0]

Final state
%xmm2: (%ymm2_vhsubps_xmm_xmm_xmm[255:128] ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vhsubps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vhsubps_xmm_xmm_xmm

%xmm0: %ymm0_vhsubps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vhsubps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vhsubps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vhsubps_xmm_xmm_xmm

%xmm0: %ymm0_vhsubps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vhsubps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vhsubps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32])))

=====================================
=====================================
Computing circuit for vhsubps %xmm13, %xmm1, %xmm1

.target:
hsubps %xmm3, %xmm2
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm1: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0]))

State for specgen instruction: vhsubps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32])))

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0])))

=====================================
=====================================
Computing circuit for vpmovzxwd %xmm9, %xmm9

.target:
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7
vpmovzxwq %xmm5, %xmm13
movddup %xmm4, %xmm4
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm3
vpmovzxwq %xmm3, %xmm1
vhsubps %xmm13, %xmm1, %xmm1
retq 

Initial state:
%ymm9: %ymm9_vpmovzxwd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vpmovzxwd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpmovzxwd %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0])))

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[127:112] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[111:96]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[95:80] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[79:64])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vpmovzxwd_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwd_xmm_xmm

%xmm0: %ymm0_vpmovzxwd_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: %ymm0_vpmovzxwq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r12d_r13d_rdx

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_edx_r10w_r11w

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxwq %xmm5, %xmm13

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_128_064_xmm2_r10_r11
callq .move_032_064_r12d_r13d_rdx
callq .move_032_016_edx_r10w_r11w
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm13: %ymm13_vpmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0])

Final state
%ymm13: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movddup_xmm_xmm
%rdx/%rdx: %rdx_movddup_xmm_xmm

%xmm0: %ymm0_movddup_xmm_xmm[127:0]
%xmm1: %ymm1_movddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r12, %r13

Final state:
%r13/%r13: %ymm2_movddup_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movddup_xmm_xmm
%rdx/%rdx: %rdx_movddup_xmm_xmm

%xmm0: %ymm0_movddup_xmm_xmm[127:0]
%xmm1: (%ymm1_movddup_xmm_xmm[255:128] ∘ (%ymm2_movddup_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_movddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movddup %xmm4, %xmm4

.target:
callq .move_128_064_xmm2_r12_r13
movq %r12, %r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm4: (%ymm4_vpmovzxwd_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[127:0][31:0]))[127:0]

State for specgen instruction: movddup %xmm2, %xmm1:
%xmm1: (%ymm1_movddup_xmm_xmm[255:128] ∘ (%ymm2_movddup_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_movddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm4: ((%ymm4_vpmovzxwd_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[127:0][31:0]))[255:128] ∘ (0x0₃₂ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:0] ∘ (0x0₃₂ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm3

Final state:
%rax/%rax: %rax_vpmovzxwd_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwd_xmm_xmm

%xmm0: %ymm0_vpmovzxwd_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: %ymm0_vpmovzxwq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r12d_r13d_rdx

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_edx_r10w_r11w

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxwq %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_128_064_xmm2_r10_r11
callq .move_032_064_r12d_r13d_rdx
callq .move_032_016_edx_r10w_r11w
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm3, %ymm6

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm6: %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm3, %xmm6, %xmm9

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm3, %xmm2, %xmm14

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm14: %ymm14_vpor_xmm_xmm_xmm

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpor_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vpor %xmm9, %xmm9, %xmm7

.target:
vorps %xmm3, %xmm2, %xmm14
vmovapd %xmm14, %xmm1
retq 

Initial state:
%ymm7: %ymm7_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpor %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

Final state
%ymm7: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm7, %xmm2

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpckldq_xmm_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm2: (%ymm2_vpunpckldq_xmm_xmm_xmm[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm1, %xmm3

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm3: %ymm3_mulpd_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm8: %ymm8_mulpd_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmulpd %ymm8, %ymm3, %ymm6

Final state:
%ymm6: mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[255:192]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[191:128]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[127:64]) ∘ mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_mulpd_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for mulpd %xmm3, %xmm2

.target:
vmovapd %xmm1, %xmm3
vmovaps %xmm2, %xmm8
vmulpd %ymm8, %ymm3, %ymm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vmulpd_xmm_xmm_xmm[127:0]

State for specgen instruction: mulpd %xmm2, %xmm1:
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vmulpd_xmm_xmm_xmm[255:128] ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmulpd_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmulpd %xmm6, %xmm2, %xmm12

.target:
mulpd %xmm3, %xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm12: %ymm12_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vmulpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]) ∘ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm12, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vpunpckldq %xmm2, %xmm1, %xmm8

.target:
vpbroadcastq %xmm3, %ymm6
vunpcklpd %xmm3, %xmm6, %xmm9
vpor %xmm9, %xmm9, %xmm7
unpcklps %xmm7, %xmm2
vmulpd %xmm6, %xmm2, %xmm12
vxorps %xmm12, %xmm2, %xmm1
movdqu %xmm2, %xmm1
retq 

Initial state:
%ymm8: %ymm8_hsubps_xmm_xmm

State for specgen instruction: vpunpckldq %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0]))

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm2

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm2: %ymm2_vunpckhps_xmm_xmm_xmm[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm2: (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpckhps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm9, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vunpckhps_xmm_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: %ymm0_vmovq_xmm_xmm[127:0]
%xmm1: %ymm1_vmovq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movswq %bx, %r10

Final state:
%r10/%r10: sign-extend-64(%rbx_xchgl_r32_r32[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_xchgl_r32_r32[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ecx_r8w_r9w

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %rcx

Final state:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r8w_r9w_ebx

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xchgl %ebx, %ecx

.target:
movswq %bx, %r10
movslq %ebx, %rbx
callq .move_032_016_ecx_r8w_r9w
callq .move_064_032_rbx_r10d_r11d
movq %r10, %rcx
callq .move_016_032_r8w_r9w_ebx
retq 

Initial state:
%rcx/%rcx: %rcx_xorl_r32_r32
%rbx/%rbx: %rbx_xorl_r32_r32

State for specgen instruction: xchgl %ecx, %ebx:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
%rbx/%rbx: 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])

Register        -> %rcx
  translates to => %rbx
Value is               -> 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
  after renaming it is => 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

Register        -> %rbx
  translates to => %rcx
Value is               -> 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])
  after renaming it is => 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

Final state
%rcx/%rcx: 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]) = 0x0₆₄
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_ebx

Final state:
%rax/%rax: %rax_xorl_r32_r32
%rdx/%rdx: %rdx_xorl_r32_r32

%xmm0: %ymm0_xorl_r32_r32[127:0]
%xmm1: %ymm1_xorl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xorl %r13d, %r13d

.target:
xchgl %ebx, %ecx
xorq %rcx, %rbx
callq .set_szp_for_ebx
retq 

Initial state:
%r13/%r13: %ymm2_vmovq_xmm_xmm[127:0][127:64]

%cf: %cf_vmovq_xmm_xmm
%pf: %pf_vmovq_xmm_xmm
%zf: %zf_vmovq_xmm_xmm
%sf: %sf_vmovq_xmm_xmm
%of: %of_vmovq_xmm_xmm

State for specgen instruction: xorl %ecx, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0] = 0x0₃₂
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][31:31] = 0x1₁
%of: false

Register        -> %rbx
  translates to => %r13
Value is               -> 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
  after renaming it is => 0x0₆₄

Final state
%r13/%r13: 0x0₆₄

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
xorl %r13d, %r13d
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][95:64])

State for specgen instruction: vmovq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhps %xmm2, %xmm1, %xmm10

.target:
unpckhpd %xmm3, %xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovddup %xmm9, %xmm1
vmovq %xmm1, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm10: %ymm10_hsubps_xmm_xmm

State for specgen instruction: vunpckhps %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[127:96] ∘ %ymm1_hsubps_xmm_xmm[127:96] ∘ %ymm2_hsubps_xmm_xmm[95:64] ∘ %ymm1_hsubps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm3, %ymm6

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm6: %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm3, %xmm6, %xmm9

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm3, %xmm2, %xmm14

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm14: %ymm14_vpor_xmm_xmm_xmm

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpor_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vpor %xmm9, %xmm9, %xmm7

.target:
vorps %xmm3, %xmm2, %xmm14
vmovapd %xmm14, %xmm1
retq 

Initial state:
%ymm7: %ymm7_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpor %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

Final state
%ymm7: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm7, %xmm2

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpckldq_xmm_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm2: (%ymm2_vpunpckldq_xmm_xmm_xmm[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm1, %xmm3

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm3: %ymm3_mulpd_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm8: %ymm8_mulpd_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmulpd %ymm8, %ymm3, %ymm6

Final state:
%ymm6: mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[255:192]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[191:128]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[127:64]) ∘ mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_mulpd_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for mulpd %xmm3, %xmm2

.target:
vmovapd %xmm1, %xmm3
vmovaps %xmm2, %xmm8
vmulpd %ymm8, %ymm3, %ymm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vmulpd_xmm_xmm_xmm[127:0]

State for specgen instruction: mulpd %xmm2, %xmm1:
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vmulpd_xmm_xmm_xmm[255:128] ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmulpd_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmulpd %xmm6, %xmm2, %xmm12

.target:
mulpd %xmm3, %xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm12: %ymm12_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vmulpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]) ∘ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm12, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vpunpckldq %xmm10, %xmm8, %xmm15

.target:
vpbroadcastq %xmm3, %ymm6
vunpcklpd %xmm3, %xmm6, %xmm9
vpor %xmm9, %xmm9, %xmm7
unpcklps %xmm7, %xmm2
vmulpd %xmm6, %xmm2, %xmm12
vxorps %xmm12, %xmm2, %xmm1
movdqu %xmm2, %xmm1
retq 

Initial state:
%ymm15: %ymm15_hsubps_xmm_xmm

State for specgen instruction: vpunpckldq %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0]))

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[95:64] ∘ %ymm2_hsubps_xmm_xmm[31:0] ∘ (%ymm1_hsubps_xmm_xmm[95:64] ∘ %ymm1_hsubps_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm2

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm2: %ymm2_vunpckhps_xmm_xmm_xmm[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm2: (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpckhps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm9, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vunpckhps_xmm_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: %ymm0_vmovq_xmm_xmm[127:0]
%xmm1: %ymm1_vmovq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movswq %bx, %r10

Final state:
%r10/%r10: sign-extend-64(%rbx_xchgl_r32_r32[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_xchgl_r32_r32[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ecx_r8w_r9w

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %rcx

Final state:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r8w_r9w_ebx

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xchgl %ebx, %ecx

.target:
movswq %bx, %r10
movslq %ebx, %rbx
callq .move_032_016_ecx_r8w_r9w
callq .move_064_032_rbx_r10d_r11d
movq %r10, %rcx
callq .move_016_032_r8w_r9w_ebx
retq 

Initial state:
%rcx/%rcx: %rcx_xorl_r32_r32
%rbx/%rbx: %rbx_xorl_r32_r32

State for specgen instruction: xchgl %ecx, %ebx:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
%rbx/%rbx: 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])

Register        -> %rcx
  translates to => %rbx
Value is               -> 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
  after renaming it is => 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

Register        -> %rbx
  translates to => %rcx
Value is               -> 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])
  after renaming it is => 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

Final state
%rcx/%rcx: 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]) = 0x0₆₄
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_ebx

Final state:
%rax/%rax: %rax_xorl_r32_r32
%rdx/%rdx: %rdx_xorl_r32_r32

%xmm0: %ymm0_xorl_r32_r32[127:0]
%xmm1: %ymm1_xorl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xorl %r13d, %r13d

.target:
xchgl %ebx, %ecx
xorq %rcx, %rbx
callq .set_szp_for_ebx
retq 

Initial state:
%r13/%r13: %ymm2_vmovq_xmm_xmm[127:0][127:64]

%cf: %cf_vmovq_xmm_xmm
%pf: %pf_vmovq_xmm_xmm
%zf: %zf_vmovq_xmm_xmm
%sf: %sf_vmovq_xmm_xmm
%of: %of_vmovq_xmm_xmm

State for specgen instruction: xorl %ecx, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0] = 0x0₃₂
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][31:31] = 0x1₁
%of: false

Register        -> %rbx
  translates to => %r13
Value is               -> 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
  after renaming it is => 0x0₆₄

Final state
%r13/%r13: 0x0₆₄

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
xorl %r13d, %r13d
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][95:64])

State for specgen instruction: vmovq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhps %xmm2, %xmm1, %xmm8

.target:
unpckhpd %xmm3, %xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovddup %xmm9, %xmm1
vmovq %xmm1, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_punpckhdq_xmm_xmm

State for specgen instruction: vunpckhps %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ %ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm8, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_punpckhdq_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_punpckhdq_xmm_xmm[255:128] ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ (%ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])))[127:0]

=====================================
=====================================
Computing circuit for punpckhdq %xmm10, %xmm8

.target:
vunpckhps %xmm2, %xmm1, %xmm8
movdqu %xmm8, %xmm1
retq 

Initial state:
%xmm8: (0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0])))[127:0]

State for specgen instruction: punpckhdq %xmm2, %xmm1:
%xmm1: (%ymm1_punpckhdq_xmm_xmm[255:128] ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ (%ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])))[127:0]

Final state
%xmm8: ((0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0])))[255:128] ∘ (%ymm2_hsubps_xmm_xmm[127:96] ∘ %ymm2_hsubps_xmm_xmm[63:32] ∘ (%ymm1_hsubps_xmm_xmm[127:96] ∘ %ymm1_hsubps_xmm_xmm[63:32])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm14

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm14: %ymm14_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm14: 0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminps %ymm1, %ymm14, %ymm1

Final state:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vminps %xmm2, %xmm2, %xmm5

.target:
vmovdqa %xmm3, %xmm1
vmovdqu %xmm2, %xmm14
vminps %ymm1, %ymm14, %ymm1
retq 

Initial state:
%ymm5: %ymm5_vsubps_xmm_xmm_xmm

State for specgen instruction: vminps %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm5: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_subps_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm14

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm14: %ymm14_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm14: 0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminps %ymm1, %ymm14, %ymm1

Final state:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vminps %xmm1, %xmm1, %xmm4

.target:
vmovdqa %xmm3, %xmm1
vmovdqu %xmm2, %xmm14
vminps %ymm1, %ymm14, %ymm1
retq 

Initial state:
%ymm4: %ymm4_subps_xmm_xmm

State for specgen instruction: vminps %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm4: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for vsubps %ymm10, %ymm4, %ymm2

Final state:
%ymm2: sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[255:224], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[255:224]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[223:192], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[223:192]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[191:160], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[191:160]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[159:128], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[159:128]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[127:96], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[127:96]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[95:64], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[95:64]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[63:32], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[63:32]) ∘ sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[31:0], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_subps_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_subps_xmm_xmm[255:128] ∘ (sub_single(%ymm1_subps_xmm_xmm[127:96], %ymm2_subps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_subps_xmm_xmm[95:64], %ymm2_subps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_subps_xmm_xmm[63:32], %ymm2_subps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_subps_xmm_xmm[31:0], %ymm2_subps_xmm_xmm[31:0])))))[127:0]

=====================================
=====================================
Computing circuit for subps %xmm3, %xmm5

.target:
vmovaps %xmm2, %xmm10
vminps %xmm1, %xmm1, %xmm4
vsubps %ymm10, %ymm4, %ymm2
movdqu %xmm2, %xmm1
retq 

Initial state:
%xmm5: (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0]))))[127:0]

State for specgen instruction: subps %xmm2, %xmm1:
%xmm1: (%ymm1_subps_xmm_xmm[255:128] ∘ (sub_single(%ymm1_subps_xmm_xmm[127:96], %ymm2_subps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_subps_xmm_xmm[95:64], %ymm2_subps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_subps_xmm_xmm[63:32], %ymm2_subps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_subps_xmm_xmm[31:0], %ymm2_subps_xmm_xmm[31:0])))))[127:0]

Final state
%xmm5: ((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0]))))[255:128] ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0])))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm5, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vsubps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0]))))

=====================================
=====================================
Computing circuit for vsubps %xmm8, %xmm15, %xmm4

.target:
vminps %xmm2, %xmm2, %xmm5
subps %xmm3, %xmm5
vmovdqu %xmm5, %xmm1
retq 

Initial state:
%ymm4: %ymm4_hsubps_xmm_xmm

State for specgen instruction: vsubps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0]))))

Final state
%ymm4: 0x0₁₂₈ ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm4, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_hsubps_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_hsubps_xmm_xmm[255:128] ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))[127:0]

=====================================
=====================================
Computing circuit for hsubps %xmm3, %xmm2

.target:
vpunpckldq %xmm2, %xmm1, %xmm8
vunpckhps %xmm2, %xmm1, %xmm10
vpunpckldq %xmm10, %xmm8, %xmm15
punpckhdq %xmm10, %xmm8
vsubps %xmm8, %xmm15, %xmm4
movdqu %xmm4, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vhsubps_xmm_xmm_xmm[127:0]

State for specgen instruction: hsubps %xmm2, %xmm1:
%xmm1: (%ymm1_hsubps_xmm_xmm[255:128] ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))[127:0]

Final state
%xmm2: (%ymm2_vhsubps_xmm_xmm_xmm[255:128] ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vhsubps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vhsubps_xmm_xmm_xmm

%xmm0: %ymm0_vhsubps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vhsubps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vhsubps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vhsubps_xmm_xmm_xmm

%xmm0: %ymm0_vhsubps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vhsubps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vhsubps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32])))

=====================================
=====================================
Computing circuit for vhsubps %xmm13, %xmm1, %xmm1

.target:
hsubps %xmm3, %xmm2
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm1: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0]))

State for specgen instruction: vhsubps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32])))

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0])))

=====================================
=====================================
Computing circuit for vpmovzxwd %xmm10, %xmm8

.target:
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7
vpmovzxwq %xmm5, %xmm13
movddup %xmm4, %xmm4
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm3
vpmovzxwq %xmm3, %xmm1
vhsubps %xmm13, %xmm1, %xmm1
retq 

Initial state:
%ymm8: %ymm8_vpmovzxwd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vpmovzxwd_ymm_xmm[127:0][63:0])

State for specgen instruction: vpmovzxwd %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0])))

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[15:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpmovzxwd_ymm_xmm
%rdx/%rdx: %rdx_vpmovzxwd_ymm_xmm

%xmm0: %ymm0_vpmovzxwd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[127:112] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[111:96]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[95:80] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[79:64]))))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[15:0]))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxwd %xmm2, %ymm5

.target:
vmovdqa %xmm2, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
vpmovzxwd %xmm9, %xmm9
vpmovzxwd %xmm10, %xmm8
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm5: %ymm5_pmovsxwd_xmm_xmm

State for specgen instruction: vpmovzxwd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[127:112] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[111:96]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[95:80] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[79:64]))))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_ymm_xmm[15:0]))))[127:0][127:0]

Final state
%ymm5: 0x0₁₆ ∘ (0x0₁ ∘ (0x0₃₂ ∘ %ymm2_pmovsxwd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_pmovsxwd_xmm_xmm[127:96]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (0x0₃₂ ∘ %ymm2_pmovsxwd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_pmovsxwd_xmm_xmm[127:96]))[15:0]) ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[95:64] ∘ %ymm2_pmovsxwd_xmm_xmm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_pmovsxwd_xmm_xmm[95:64]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[95:64] ∘ %ymm2_pmovsxwd_xmm_xmm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_pmovsxwd_xmm_xmm[95:64]))[15:0])) ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]))[15:0]) ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[15:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpsubq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpsubq_xmm_xmm_xmm

%xmm0: %ymm0_vpsubq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpsubq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpsubq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpsubq_xmm_xmm_xmm

%xmm0: %ymm0_vpsubq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpsubq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_cf

Final state:
%rax/%rax: %rax_stc
%rdx/%rdx: %rdx_stc

%xmm0: %ymm0_stc[127:0]
%xmm1: %ymm1_stc[127:0]

-------------------------------------
=====================================
Computing circuit for stc 

.target:
callq .set_cf
retq 

Initial state:
%cf: %cf_subq_r64_r64

State for specgen instruction: stc :
%cf: true

Final state
%cf: true

=====================================
-------------------------------------
Getting base circuit for movq $0xfffffffffffffffe, %rdx

Final state:
%rdx/%rdx: 0xfffffffffffffffe₆₄

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_incb_r8 ⊕ %rax_incb_r8

%cf: false
%pf: !((%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][0:0] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][1:1] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][2:2] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][3:3] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][4:4] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][5:5] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][6:6] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][7:7] = 0x1₁)
%zf: (%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄
%sf: (%rax_incb_r8 ⊕ %rax_incb_r8)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: false

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for callq .read_zf_into_rcx

Final state:
%rax/%rax: %rax_incb_r8 ⊕ %rax_incb_r8
%rdx/%rdx: %rdx_incb_r8

%xmm0: %ymm0_incb_r8[127:0]
%xmm1: %ymm1_incb_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for adcb %cl, %bl

Final state:
%rbx/%bl: %rbx_incb_r8[63:8] ∘ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0][3:0] + 0x0₁ ∘ %rbx_incb_r8[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:7] = 0x1₁
%of: ((0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0][7:7] = 0x1₁ ↔ %rbx_incb_r8[7:0][7:7] = 0x1₁) ∧ !((0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for incb %dl

.target:
xorq %rax, %rax
clc 
callq .read_zf_into_rcx
adcb %cl, %bl
retq 

Initial state:
%rdx/%dl: 0xfffffffffffffffe₆₄

%pf: %pf_notq_r64
%af: %af_notq_r64
%zf: %zf_notq_r64
%sf: %sf_notq_r64
%of: %of_notq_r64

State for specgen instruction: incb %bl:
%rbx/%bl: %rbx_incb_r8[63:8] ∘ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0]

%pf: !(((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0][3:0] + 0x0₁ ∘ %rbx_incb_r8[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:7] = 0x1₁
%of: ((0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0][7:7] = 0x1₁ ↔ %rbx_incb_r8[7:0][7:7] = 0x1₁) ∧ !((0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:7] = 0x1₁)

Register        -> %bl
  translates to => %dl
Value is               -> (%rbx_incb_r8[63:8] ∘ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0])[7:0]
  after renaming it is => 0xff₈

Final state
%rdx/%dl: 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈

%pf: true
%af: false
%zf: false
%sf: true
%of: false

=====================================
-------------------------------------
Getting base circuit for xorq %rdx, %rbx

Final state:
%rbx/%rbx: %rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈

%cf: false
%pf: !((%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][0:0] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][1:1] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][2:2] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][3:3] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][4:4] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][5:5] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][6:6] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][7:7] = 0x1₁)
%zf: (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈) = 0x0₆₄
%sf: (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[63:63] = 0x1₁
%of: false

-------------------------------------
=====================================
Computing circuit for notq %rcx

.target:
movq $0xfffffffffffffffe, %rdx
incb %dl
xorq %rdx, %rbx
retq 

Initial state:
%rcx/%rcx: %rcx_subq_r64_r64

State for specgen instruction: notq %rbx:
%rbx/%rbx: %rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈

Register        -> %rbx
  translates to => %rcx
Value is               -> %rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈
  after renaming it is => %rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄

Final state
%rcx/%rcx: %rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄

=====================================
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0]

%cf: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[64:64] = 0x1₁
%pf: !(((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][0:0] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][1:1] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][2:2] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][3:3] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][4:4] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][5:5] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][6:6] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)[3:0] + 0x0₁ ∘ %rbx_subq_r64_r64[3:0])[4:4] = 0x1₁
%zf: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0] = 0x0₆₄
%sf: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][63:63] = 0x1₁
%of: ((%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)[63:63] = 0x1₁ ↔ %rbx_subq_r64_r64[63:63] = 0x1₁) ∧ !((%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)[63:63] = 0x1₁ ↔ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:63] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_cf_into_rbx

Final state:
%rax/%rax: %rax_cmc
%rdx/%rdx: %rdx_cmc

%xmm0: %ymm0_cmc[127:0]
%xmm1: %ymm1_cmc[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r8d_r9d

Final state:
%rax/%rax: %rax_cmc
%rdx/%rdx: %rdx_cmc

%xmm0: %ymm0_cmc[127:0]
%xmm1: %ymm1_cmc[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r8b_to_byte_5_of_rbx

Final state:
%rax/%rax: %rax_cmc
%rdx/%rdx: %rdx_cmc

%xmm0: %ymm0_cmc[127:0]
%xmm1: %ymm1_cmc[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_decw_r16 ⊕ %rax_decw_r16

%cf: false
%pf: !((%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][0:0] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][1:1] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][2:2] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][3:3] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][4:4] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][5:5] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][6:6] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][7:7] = 0x1₁)
%zf: (%rax_decw_r16 ⊕ %rax_decw_r16) = 0x0₆₄
%sf: (%rax_decw_r16 ⊕ %rax_decw_r16)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for movq $0xffffffffffffffff, %rsi

Final state:
%rsi/%rsi: 0xffffffffffffffff₆₄

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r10b_r11b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_cx_r8b_r9b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r10b_r11b_cx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r8b_r9b_bx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for xchgw %ax, %bx

.target:
callq .move_016_008_bx_r10b_r11b
callq .move_016_008_cx_r8b_r9b
callq .move_008_016_r10b_r11b_cx
callq .move_008_016_r8b_r9b_bx
retq 

Initial state:
%rax/%ax: %rax_decw_r16 ⊕ %rax_decw_r16
%rbx/%bx: %rbx_decw_r16

State for specgen instruction: xchgw %cx, %bx:
%rcx/%cx: %rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])
%rbx/%bx: %rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])

Register        -> %cx
  translates to => %ax
Value is               -> (%rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => %rbx_decw_r16[15:0]

Register        -> %bx
  translates to => %bx
Value is               -> (%rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => 0x0₁₆

Final state
%rax/%ax: (%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0]
%rbx/%bx: %rbx_decw_r16[63:16] ∘ 0x0₁₆

=====================================
-------------------------------------
Getting base circuit for callq .read_cf_into_rbx

Final state:
%rax/%rax: (%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0]
%rdx/%rdx: %rdx_decw_r16

%xmm0: %ymm0_decw_r16[127:0]
%xmm1: %ymm1_decw_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for adcw %bx, %ax

Final state:
%rax/%ax: ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[63:16] ∘ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0]

%cf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[16:16] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0][3:0] + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0] = 0x0₁₆
%sf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][15:15] = 0x1₁
%of: ((0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0][15:15] = 0x1₁ ↔ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0][15:15] = 0x1₁) ∧ !((0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:15] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: %cf_addw_r16_r16

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for adcw %cx, %bx

Final state:
%rbx/%bx: %rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[16:16] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addw_r16_r16[15:0][3:0] + 0x0₁ ∘ %rbx_addw_r16_r16[15:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0] = 0x0₁₆
%sf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][15:15] = 0x1₁
%of: (%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ %rbx_addw_r16_r16[15:0][15:15] = 0x1₁) ∧ !(%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:15] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_bx

Final state:
%rax/%rax: %rax_addw_r16_r16
%rdx/%rdx: %rdx_addw_r16_r16

%xmm0: %ymm0_addw_r16_r16[127:0]
%xmm1: %ymm1_addw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for addw %ax, %si

.target:
clc 
adcw %cx, %bx
callq .set_szp_for_bx
retq 

Initial state:
%rsi/%si: 0xffffffffffffffff₆₄

%cf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[16:16] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0][3:0] + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0] = 0x0₁₆
%sf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][15:15] = 0x1₁
%of: ((0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0][15:15] = 0x1₁ ↔ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0][15:15] = 0x1₁) ∧ !((0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:15] = 0x1₁)

State for specgen instruction: addw %cx, %bx:
%rbx/%bx: %rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[16:16] = 0x1₁
%pf: !((%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addw_r16_r16[15:0][3:0] + 0x0₁ ∘ %rbx_addw_r16_r16[15:0][3:0])[4:4] = 0x1₁
%zf: (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0] = 0x0₁₆
%sf: (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][15:15] = 0x1₁
%of: (%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ %rbx_addw_r16_r16[15:0][15:15] = 0x1₁) ∧ !(%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:15] = 0x1₁)

Register        -> %bx
  translates to => %si
Value is               -> (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0]
  after renaming it is => (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0]

Final state
%rsi/%si: 0xffffffffffffffff₆₄[63:16] ∘ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0]

%cf: (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[16:16] = 0x1₁
%pf: !((0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rbx_decw_r16[3:0] + 0xf₅)[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0] = 0x0₁₆
%sf: (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:15] = 0x1₁
%of: (%rbx_decw_r16[15:15] = 0x1₁ ↔ true) ∧ !(%rbx_decw_r16[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:15] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for movswq %si, %rbx

Final state:
%rbx/%rbx: sign-extend-64((0xffffffffffffffff₆₄[63:16] ∘ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0])[15:0])

-------------------------------------
=====================================
Computing circuit for decw %bx

.target:
xorq %rax, %rax
movq $0xffffffffffffffff, %rsi
xchgw %ax, %bx
callq .read_cf_into_rbx
adcw %bx, %ax
addw %ax, %si
movswq %si, %rbx
retq 

Initial state:
%rbx/%bx: (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0]

%pf: %pf_cmc
%af: %af_cmc
%zf: %zf_cmc
%sf: %sf_cmc
%of: %of_cmc

State for specgen instruction: decw %bx:
%rbx/%bx: sign-extend-64((0xffffffffffffffff₆₄[63:16] ∘ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0])[15:0])

%pf: !((0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rbx_decw_r16[3:0] + 0xf₅)[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0] = 0x0₁₆
%sf: (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:15] = 0x1₁
%of: (%rbx_decw_r16[15:15] = 0x1₁ ↔ true) ∧ !(%rbx_decw_r16[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:15] = 0x1₁)

Register        -> %bx
  translates to => %bx
Value is               -> sign-extend-64((0xffffffffffffffff₆₄[63:16] ∘ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0])[15:0])[15:0]
  after renaming it is => %cf_cmc ? 0x0₁₆ : 0xffff₁₆

Final state
%rbx/%bx: ((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆)

%pf: !((%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁)
%af: (%cf_cmc ? 0x1₁ : 0x0₁) = 0x1₁
%zf: (%cf_cmc ? 0x0₁₆ : 0xffff₁₆) = 0x0₁₆
%sf: (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁
%of: false ∧ !(false ↔ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for movb %cl, %bh

Final state:
%rbx/%bh: %rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq $0x40, %rbx

Final state:
%rbx/%rbx: 0x40₆₄

-------------------------------------
-------------------------------------
Getting base circuit for movb %ah, %bl

Final state:
%rbx/%bl: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

-------------------------------------
=====================================
Computing circuit for movzbl %ah, %ebp

.target:
movq $0x40, %rbx
movb %ah, %bl
retq 

Initial state:
%rbp/%rbp: %rbp_xorb_r8_rh

State for specgen instruction: movzbl %ah, %ebx:
%rbx/%rbx: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

Register        -> %rbx
  translates to => %rbp
Value is               -> 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]
  after renaming it is => 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

Final state
%rbp/%rbp: 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

=====================================
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh

%cf: false
%pf: !((%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][0:0] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][1:1] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][2:2] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][3:3] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][4:4] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][5:5] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][6:6] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][7:7] = 0x1₁)
%zf: (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh) = 0x0₆₄
%sf: (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_cf_into_rcx

Final state:
%rax/%rax: %rax_setc_rh
%rdx/%rdx: %rdx_setc_rh

%xmm0: %ymm0_setc_rh[127:0]
%xmm1: %ymm1_setc_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movb %cl, %ah

Final state:
%rax/%ah: %rax_setc_rh[63:16] ∘ (0x0₆₃ ∘ (%cf_setc_rh ? 0x1₁ : 0x0₁))[7:0] ∘ %rax_setc_rh[7:0]

-------------------------------------
=====================================
Computing circuit for setc %bh

.target:
callq .read_cf_into_rcx
movb %cl, %ah
retq 

Initial state:
%rbx/%bh: %rbx_xorb_r8_rh

State for specgen instruction: setc %ah:
%rax/%ah: %rax_setc_rh[63:16] ∘ (0x0₆₃ ∘ (%cf_setc_rh ? 0x1₁ : 0x0₁))[7:0] ∘ %rax_setc_rh[7:0]

Register        -> %ah
  translates to => %bh
Value is               -> (%rax_setc_rh[63:16] ∘ (0x0₆₃ ∘ (%cf_setc_rh ? 0x1₁ : 0x0₁))[7:0] ∘ %rax_setc_rh[7:0])[15:8]
  after renaming it is => 0x0₈

Final state
%rbx/%bh: %rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0]

=====================================
-------------------------------------
Getting base circuit for movswq %bx, %rdx

Final state:
%rdx/%rdx: sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rbp, %rdx

Final state:
%rdx/%rdx: sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

%cf: false
%pf: !((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][0:0] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][1:1] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][2:2] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][3:3] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][4:4] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][5:5] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][6:6] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][7:7] = 0x1₁)
%zf: (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]) = 0x0₆₄
%sf: (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for movslq %edx, %rbx

Final state:
%rbx/%rbx: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_bl

Final state:
%rax/%rax: %rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh
%rdx/%rdx: sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

%xmm0: %ymm0_xorb_r8_rh[127:0]
%xmm1: %ymm1_xorb_r8_rh[127:0]

-------------------------------------
=====================================
Computing circuit for xorb %bh, %bl

.target:
movzbl %ah, %ebp
xorq %rax, %rax
setc %bh
movswq %bx, %rdx
xorq %rbp, %rdx
movslq %edx, %rbx
callq .set_szp_for_bl
retq 

Initial state:
%rbx/%bl: %rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0]

%cf: %cf_xorb_r8_r8
%pf: %pf_xorb_r8_r8
%zf: %zf_xorb_r8_r8
%sf: %sf_xorb_r8_r8
%of: %of_xorb_r8_r8

State for specgen instruction: xorb %ah, %bl:
%rbx/%bl: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])

%cf: false
%pf: !(sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][0:0] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][1:1] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][2:2] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][3:3] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][4:4] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][5:5] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][6:6] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][7:7] = 0x1₁)
%zf: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0] = 0x0₈
%sf: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:7] = 0x1₁
%of: false

Register        -> %bl
  translates to => %bl
Value is               -> sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0]
  after renaming it is => %rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]

Final state
%rbx/%bl: (%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0])

%cf: false
%pf: !((%rbx_xorb_r8_r8[0:0] ⊕ %rcx_xorb_r8_r8[0:0]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[1:1] ⊕ %rcx_xorb_r8_r8[1:1]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[2:2] ⊕ %rcx_xorb_r8_r8[2:2]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[3:3] ⊕ %rcx_xorb_r8_r8[3:3]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[4:4] ⊕ %rcx_xorb_r8_r8[4:4]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[5:5] ⊕ %rcx_xorb_r8_r8[5:5]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[6:6] ⊕ %rcx_xorb_r8_r8[6:6]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[7:7] ⊕ %rcx_xorb_r8_r8[7:7]) = 0x1₁)
%zf: (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]) = 0x0₈
%sf: (%rbx_xorb_r8_r8[7:7] ⊕ %rcx_xorb_r8_r8[7:7]) = 0x1₁
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .set_szp_for_bl

Final state:
%rax/%rax: %rax_xorb_r8_r8
%rdx/%rdx: %rdx_xorb_r8_r8

%xmm0: %ymm0_xorb_r8_r8[127:0]
%xmm1: %ymm1_xorb_r8_r8[127:0]

-------------------------------------
=====================================
Computing circuit for xorb %al, %al

.target:
movb %cl, %bh
xorb %bh, %bl
callq .set_szp_for_bl
retq 

Initial state:
%rax/%al: %rax_xorb_rh_rh

%cf: %cf_xorb_rh_rh
%pf: %pf_xorb_rh_rh
%zf: %zf_xorb_rh_rh
%sf: %sf_xorb_rh_rh
%of: %of_xorb_rh_rh

State for specgen instruction: xorb %cl, %bl:
%rbx/%bl: (%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0])

%cf: false
%pf: !(((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][0:0] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][1:1] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][2:2] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][3:3] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][4:4] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][5:5] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][6:6] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][7:7] = 0x1₁)
%zf: ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0] = 0x0₈
%sf: ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:7] = 0x1₁
%of: false

Register        -> %bl
  translates to => %al
Value is               -> ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0]
  after renaming it is => 0x0₈

Final state
%rax/%al: %rax_xorb_rh_rh[63:8] ∘ 0x0₈

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for movq $0x40, %rbx

Final state:
%rbx/%rbx: 0x40₆₄

-------------------------------------
-------------------------------------
Getting base circuit for movb %ah, %bl

Final state:
%rbx/%bl: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

-------------------------------------
=====================================
Computing circuit for movzbl %ah, %edx

.target:
movq $0x40, %rbx
movb %ah, %bl
retq 

Initial state:
%rdx/%rdx: %rdx_xaddb_rh_r8

State for specgen instruction: movzbl %ah, %ebx:
%rbx/%rbx: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

Register        -> %rbx
  translates to => %rdx
Value is               -> 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]
  after renaming it is => 0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8]

Final state
%rdx/%rdx: 0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8]

=====================================
-------------------------------------
Getting base circuit for callq .clear_cf

Final state:
%rax/%rax: %rax_xaddb_r8_r8
%rdx/%rdx: %rdx_xaddb_r8_r8

%xmm0: %ymm0_xaddb_r8_r8[127:0]
%xmm1: %ymm1_xaddb_r8_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_of

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_of_into_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movsbq %cl, %r10

Final state:
%r10/%r10: sign-extend-64(%rcx_movsbl_r32_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
=====================================
Computing circuit for movsbl %cl, %r13d

.target:
callq .set_of
callq .read_of_into_rbx
callq .move_064_032_rbx_r10d_r11d
movsbq %cl, %r10
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r13/%r13: %r13_xaddb_r8_r8

State for specgen instruction: movsbl %cl, %ebx:
%rbx/%rbx: (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r13
Value is               -> (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0]

Final state
%r13/%r13: 0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0]

=====================================
-------------------------------------
Getting base circuit for callq .set_of

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_of_into_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movsbq %cl, %r10

Final state:
%r10/%r10: sign-extend-64(%rcx_movsbl_r32_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
=====================================
Computing circuit for movsbl %bl, %r15d

.target:
callq .set_of
callq .read_of_into_rbx
callq .move_064_032_rbx_r10d_r11d
movsbq %cl, %r10
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r15/%r15: %r15_xaddb_r8_r8

State for specgen instruction: movsbl %cl, %ebx:
%rbx/%rbx: (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r15
Value is               -> (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0]

Final state
%r15/%r15: 0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0]

=====================================
-------------------------------------
Getting base circuit for movsbq %r15b, %rcx

Final state:
%rcx/%rcx: sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for adcb %cl, %r13b

Final state:
%r13/%r13b: (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][3:0] + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁
%of: (sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][7:7] = 0x1₁) ∧ !(sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:7] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r13d, %rbx

Final state:
%rbx/%rbx: sign-extend-64(((0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0])[31:0])

-------------------------------------
=====================================
Computing circuit for xaddb %bl, %dl

.target:
callq .clear_cf
movsbl %cl, %r13d
movsbl %bl, %r15d
movsbq %r15b, %rcx
adcb %cl, %r13b
movslq %r13d, %rbx
retq 

Initial state:
%rdx/%dl: 0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8]
%rbx/%bl: %rbx_xaddb_rh_r8

%cf: %cf_xaddb_rh_r8
%pf: %pf_xaddb_rh_r8
%af: %af_xaddb_rh_r8
%zf: %zf_xaddb_rh_r8
%sf: %sf_xaddb_rh_r8
%of: %of_xaddb_rh_r8

State for specgen instruction: xaddb %cl, %bl:
%rcx/%cl: sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])
%rbx/%bl: sign-extend-64(((0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0])[31:0])

%cf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][3:0] + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁
%of: (sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][7:7] = 0x1₁) ∧ !(sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:7] = 0x1₁)

Final state
%rdx/%dl: (0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8])[63:8] ∘ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0]
%rbx/%bl: %rbx_xaddb_rh_r8[63:8] ∘ %rax_xaddb_rh_r8[15:8]

%cf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[8:8] = 0x1₁
%pf: !((0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rax_xaddb_rh_r8[11:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0] = 0x0₈
%sf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁
%of: (%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ %rbx_xaddb_rh_r8[7:7] = 0x1₁) ∧ !(%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for movb %dl, %ah

Final state:
%rax/%ah: %rax_xaddb_rh_r8[63:16] ∘ ((0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8])[63:8] ∘ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0])[7:0] ∘ %rax_xaddb_rh_r8[7:0]

-------------------------------------
=====================================
Computing circuit for xaddb %al, %bh

.target:
movzbl %ah, %edx
xaddb %bl, %dl
movb %dl, %ah
retq 

Initial state:
%rax/%al: %rax_xorb_rh_rh[63:8] ∘ 0x0₈
%rbx/%bh: %rbx_xorb_rh_rh

%cf: false
%pf: true
%af: %af_xorb_rh_rh
%zf: true
%sf: false
%of: false

State for specgen instruction: xaddb %bl, %ah:
%rax/%ah: %rax_xaddb_rh_r8[63:16] ∘ ((0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8])[63:8] ∘ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0])[7:0] ∘ %rax_xaddb_rh_r8[7:0]
%rbx/%bl: %rbx_xaddb_rh_r8[63:8] ∘ %rax_xaddb_rh_r8[15:8]

%cf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[8:8] = 0x1₁
%pf: !((0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rax_xaddb_rh_r8[11:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0] = 0x0₈
%sf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁
%of: (%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ %rbx_xaddb_rh_r8[7:7] = 0x1₁) ∧ !(%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)

Final state
%rax/%al: (%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8]
%rbx/%bh: %rbx_xorb_rh_rh[63:16] ∘ %rbx_xorb_rh_rh[15:8] ∘ %rbx_xorb_rh_rh[7:0]

%cf: false
%pf: !(%rbx_xorb_rh_rh[8:8] = 0x1₁ ⊕ %rbx_xorb_rh_rh[9:9] = 0x1₁ ⊕ %rbx_xorb_rh_rh[10:10] = 0x1₁ ⊕ %rbx_xorb_rh_rh[11:11] = 0x1₁ ⊕ %rbx_xorb_rh_rh[12:12] = 0x1₁ ⊕ %rbx_xorb_rh_rh[13:13] = 0x1₁ ⊕ %rbx_xorb_rh_rh[14:14] = 0x1₁ ⊕ %rbx_xorb_rh_rh[15:15] = 0x1₁)
%af: false
%zf: %rbx_xorb_rh_rh[15:8] = 0x0₈
%sf: %rbx_xorb_rh_rh[15:15] = 0x1₁
%of: (%rbx_xorb_rh_rh[15:15] = 0x1₁ ↔ false) ∧ !(%rbx_xorb_rh_rh[15:15] = 0x1₁ ↔ %rbx_xorb_rh_rh[15:15] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for movq $0x4, %rdi

Final state:
%rdi/%rdi: 0x4₆₄

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_shlb_r8_one ⊕ %rax_shlb_r8_one

%cf: false
%pf: !((%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][0:0] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][1:1] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][2:2] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][3:3] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][4:4] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][5:5] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][6:6] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][7:7] = 0x1₁)
%zf: (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one) = 0x0₆₄
%sf: (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: false

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][3:0] + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][7:7] = 0x1₁ ↔ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][7:7] = 0x1₁) ∧ !((%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:7] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for adcb %bl, %bl

Final state:
%rbx/%bl: %rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0]

%cf: ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[8:8] = 0x1₁
%pf: !(((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rbx_shlb_r8_one[7:0][3:0] + 0x0₁ ∘ %rbx_shlb_r8_one[7:0][3:0])[4:4] = 0x1₁
%zf: ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0] = 0x0₈
%sf: ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:7] = 0x1₁
%of: (%rbx_shlb_r8_one[7:0][7:7] = 0x1₁ ↔ %rbx_shlb_r8_one[7:0][7:7] = 0x1₁) ∧ !(%rbx_shlb_r8_one[7:0][7:7] = 0x1₁ ↔ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:7] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_bl

Final state:
%rax/%rax: (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0]
%rdx/%rdx: %rdx_shlb_r8_one

%xmm0: %ymm0_shlb_r8_one[127:0]
%xmm1: %ymm1_shlb_r8_one[127:0]

-------------------------------------
=====================================
Computing circuit for shlb $0x1, %dil

.target:
xorq %rax, %rax
clc 
adcb %al, %al
adcb %bl, %bl
callq .set_szp_for_bl
retq 

Initial state:
%rdi/%dil: 0x4₆₄

%cf: %cf_xorb_rh_r8
%pf: %pf_xorb_rh_r8
%zf: %zf_xorb_rh_r8
%sf: %sf_xorb_rh_r8
%of: %of_xorb_rh_r8

State for specgen instruction: shlb $0x1, %bl:
%rbx/%bl: %rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0]

%cf: ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[8:8] = 0x1₁
%pf: !((%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%zf: (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0] = 0x0₈
%sf: (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:7] = 0x1₁
%of: (%rbx_shlb_r8_one[7:0][7:7] = 0x1₁ ↔ %rbx_shlb_r8_one[7:0][7:7] = 0x1₁) ∧ !(%rbx_shlb_r8_one[7:0][7:7] = 0x1₁ ↔ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:7] = 0x1₁)

Register        -> %bl
  translates to => %dil
Value is               -> (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0]
  after renaming it is => 0x8₈

Final state
%rdi/%dil: 0x4₆₄[63:8] ∘ 0x8₈

%cf: false
%pf: false
%zf: false
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for xorq %r8, %r8

Final state:
%r8/%r8: %r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8

%cf: false
%pf: !((%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][0:0] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][1:1] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][2:2] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][3:3] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][4:4] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][5:5] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][6:6] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][7:7] = 0x1₁)
%zf: (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8) = 0x0₆₄
%sf: (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for movq $0x40, %rbx

Final state:
%rbx/%rbx: 0x40₆₄

-------------------------------------
-------------------------------------
Getting base circuit for movb %ah, %bl

Final state:
%rbx/%bl: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

-------------------------------------
=====================================
Computing circuit for movzbl %ah, %ebp

.target:
movq $0x40, %rbx
movb %ah, %bl
retq 

Initial state:
%rbp/%rbp: %rbp_xorb_r8_rh

State for specgen instruction: movzbl %ah, %ebx:
%rbx/%rbx: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

Register        -> %rbx
  translates to => %rbp
Value is               -> 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]
  after renaming it is => 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

Final state
%rbp/%rbp: 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

=====================================
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh

%cf: false
%pf: !((%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][0:0] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][1:1] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][2:2] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][3:3] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][4:4] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][5:5] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][6:6] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][7:7] = 0x1₁)
%zf: (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh) = 0x0₆₄
%sf: (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_cf_into_rcx

Final state:
%rax/%rax: %rax_setc_rh
%rdx/%rdx: %rdx_setc_rh

%xmm0: %ymm0_setc_rh[127:0]
%xmm1: %ymm1_setc_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movb %cl, %ah

Final state:
%rax/%ah: %rax_setc_rh[63:16] ∘ (0x0₆₃ ∘ (%cf_setc_rh ? 0x1₁ : 0x0₁))[7:0] ∘ %rax_setc_rh[7:0]

-------------------------------------
=====================================
Computing circuit for setc %bh

.target:
callq .read_cf_into_rcx
movb %cl, %ah
retq 

Initial state:
%rbx/%bh: %rbx_xorb_r8_rh

State for specgen instruction: setc %ah:
%rax/%ah: %rax_setc_rh[63:16] ∘ (0x0₆₃ ∘ (%cf_setc_rh ? 0x1₁ : 0x0₁))[7:0] ∘ %rax_setc_rh[7:0]

Register        -> %ah
  translates to => %bh
Value is               -> (%rax_setc_rh[63:16] ∘ (0x0₆₃ ∘ (%cf_setc_rh ? 0x1₁ : 0x0₁))[7:0] ∘ %rax_setc_rh[7:0])[15:8]
  after renaming it is => 0x0₈

Final state
%rbx/%bh: %rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0]

=====================================
-------------------------------------
Getting base circuit for movswq %bx, %rdx

Final state:
%rdx/%rdx: sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rbp, %rdx

Final state:
%rdx/%rdx: sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

%cf: false
%pf: !((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][0:0] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][1:1] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][2:2] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][3:3] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][4:4] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][5:5] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][6:6] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][7:7] = 0x1₁)
%zf: (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]) = 0x0₆₄
%sf: (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for movslq %edx, %rbx

Final state:
%rbx/%rbx: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_bl

Final state:
%rax/%rax: %rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh
%rdx/%rdx: sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

%xmm0: %ymm0_xorb_r8_rh[127:0]
%xmm1: %ymm1_xorb_r8_rh[127:0]

-------------------------------------
=====================================
Computing circuit for xorb %ah, %bl

.target:
movzbl %ah, %ebp
xorq %rax, %rax
setc %bh
movswq %bx, %rdx
xorq %rbp, %rdx
movslq %edx, %rbx
callq .set_szp_for_bl
retq 

Initial state:
%rbx/%bl: %rbx_xorb_rh_r8

%cf: false
%pf: !((%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][0:0] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][1:1] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][2:2] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][3:3] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][4:4] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][5:5] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][6:6] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][7:7] = 0x1₁)
%zf: (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8) = 0x0₆₄
%sf: (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[63:63] = 0x1₁
%of: false

State for specgen instruction: xorb %ah, %bl:
%rbx/%bl: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])

%cf: false
%pf: !(sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][0:0] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][1:1] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][2:2] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][3:3] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][4:4] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][5:5] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][6:6] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][7:7] = 0x1₁)
%zf: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0] = 0x0₈
%sf: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:7] = 0x1₁
%of: false

Register        -> %bl
  translates to => %bl
Value is               -> sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0]
  after renaming it is => %rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]

Final state
%rbx/%bl: %rbx_xorb_rh_r8[63:8] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8])

%cf: false
%pf: !((%rbx_xorb_rh_r8[0:0] ⊕ %rax_xorb_rh_r8[8:8]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[1:1] ⊕ %rax_xorb_rh_r8[9:9]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[2:2] ⊕ %rax_xorb_rh_r8[10:10]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[3:3] ⊕ %rax_xorb_rh_r8[11:11]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[4:4] ⊕ %rax_xorb_rh_r8[12:12]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[5:5] ⊕ %rax_xorb_rh_r8[13:13]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[6:6] ⊕ %rax_xorb_rh_r8[14:14]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁)
%zf: (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) = 0x0₈
%sf: (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁
%of: false

=====================================
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16

%cf: false
%pf: !((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][0:0] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][1:1] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][2:2] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][3:3] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][4:4] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][5:5] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][6:6] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][7:7] = 0x1₁)
%zf: (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16) = 0x0₆₄
%sf: (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: false

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for adcw %cx, %ax

Final state:
%rax/%ax: (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0]

%cf: ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[16:16] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_popcntw_r16_r16[15:0][3:0] + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0] = 0x0₁₆
%sf: ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][15:15] = 0x1₁
%of: (%rcx_popcntw_r16_r16[15:0][15:15] = 0x1₁ ↔ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0][15:15] = 0x1₁) ∧ !(%rcx_popcntw_r16_r16[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:15] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for popcntq %rax, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][1:0][0:0]))))) + 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][1:0][0:0])))))

%cf: false
%pf: false
%af: false
%zf: (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0] = 0x0₆₄
%sf: false
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: false

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
=====================================
Computing circuit for popcntw %r8w, %ax

.target:
xorq %rax, %rax
clc 
adcw %cx, %ax
popcntq %rax, %rbx
clc 
retq 

Initial state:
%rax/%ax: %rax_xorb_rh_r8

%cf: false
%pf: !((%rbx_xorb_rh_r8[0:0] ⊕ %rax_xorb_rh_r8[8:8]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[1:1] ⊕ %rax_xorb_rh_r8[9:9]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[2:2] ⊕ %rax_xorb_rh_r8[10:10]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[3:3] ⊕ %rax_xorb_rh_r8[11:11]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[4:4] ⊕ %rax_xorb_rh_r8[12:12]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[5:5] ⊕ %rax_xorb_rh_r8[13:13]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[6:6] ⊕ %rax_xorb_rh_r8[14:14]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁)
%af: TMP_BOOL_118
%zf: (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) = 0x0₈
%sf: (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁
%of: false

State for specgen instruction: popcntw %cx, %bx:
%rbx/%bx: 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][1:0][0:0]))))) + 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][1:0][0:0])))))

%cf: false
%pf: false
%af: false
%zf: (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0] = 0x0₆₄
%sf: false
%of: false

Register        -> %bx
  translates to => %ax
Value is               -> (0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][1:0][0:0]))))) + 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][1:0][0:0]))))))[15:0]
  after renaming it is => 0x0₁₆

Final state
%rax/%ax: %rax_xorb_rh_r8[63:16] ∘ 0x0₁₆

%cf: false
%pf: false
%af: false
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rcx

Final state:
%rcx/%rcx: %rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh

%cf: false
%pf: !((%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][0:0] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][1:1] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][2:2] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][3:3] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][4:4] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][5:5] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][6:6] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][7:7] = 0x1₁)
%zf: (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh) = 0x0₆₄
%sf: (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_sf_into_rbx

Final state:
%rax/%rax: %rax_movzbw_r16_rh
%rdx/%rdx: %rdx_movzbw_r16_rh

%xmm0: %ymm0_movzbw_r16_rh[127:0]
%xmm1: %ymm1_movzbw_r16_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movb %ah, %bl

Final state:
%rbx/%bl: (0x0₆₃ ∘ ((%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[63:63] = 0x1₁ ? 0x1₁ : 0x0₁))[63:8] ∘ %rax_movzbw_r16_rh[15:8]

-------------------------------------
=====================================
Computing circuit for movzbw %ah, %si

.target:
xorq %rcx, %rcx
callq .read_sf_into_rbx
movb %ah, %bl
retq 

Initial state:
%rsi/%si: %rsi_xaddb_r8_rh

State for specgen instruction: movzbw %ah, %bx:
%rbx/%bx: (0x0₆₃ ∘ ((%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[63:63] = 0x1₁ ? 0x1₁ : 0x0₁))[63:8] ∘ %rax_movzbw_r16_rh[15:8]

Register        -> %bx
  translates to => %si
Value is               -> ((0x0₆₃ ∘ ((%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[63:63] = 0x1₁ ? 0x1₁ : 0x0₁))[63:8] ∘ %rax_movzbw_r16_rh[15:8])[15:0]
  after renaming it is => 0x0₈ ∘ %rax_xaddb_r8_rh[15:8]

Final state
%rsi/%si: %rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8])

=====================================
-------------------------------------
Getting base circuit for movq $0x0, %rbx

Final state:
%rbx/%rbx: 0x0₆₄

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: %cf_movzbq_r64_r8

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for movsbq %cl, %rdi

Final state:
%rdi/%rdi: sign-extend-64(%rcx_movzbq_r64_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for adcb %dil, %bl

Final state:
%rbx/%bl: 0x0₆₄[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0][3:0] + 0x0₁ ∘ 0x0₆₄[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:7] = 0x1₁
%of: (sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0][7:7] = 0x1₁ ↔ 0x0₆₄[7:0][7:7] = 0x1₁) ∧ !(sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for movzbq %bl, %r12

.target:
movq $0x0, %rbx
clc 
movsbq %cl, %rdi
adcb %dil, %bl
retq 

Initial state:
%r12/%r12: %r12_xaddb_r8_rh

State for specgen instruction: movzbq %cl, %rbx:
%rbx/%rbx: 0x0₆₄[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0]

Register        -> %rbx
  translates to => %r12
Value is               -> 0x0₆₄[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0]
  after renaming it is => 0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0]

Final state
%r12/%r12: 0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0]

=====================================
-------------------------------------
Getting base circuit for movslq %r12d, %rdx

Final state:
%rdx/%rdx: sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_dx_r8b_r9b

Final state:
%rax/%rax: %rax_xaddb_r8_rh
%rdx/%rdx: sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])

%xmm0: %ymm0_xaddb_r8_rh[127:0]
%xmm1: %ymm1_xaddb_r8_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_of

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_of_into_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movsbq %cl, %r10

Final state:
%r10/%r10: sign-extend-64(%rcx_movsbl_r32_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
=====================================
Computing circuit for movsbl %r12b, %ebx

.target:
callq .set_of
callq .read_of_into_rbx
callq .move_064_032_rbx_r10d_r11d
movsbq %cl, %r10
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%rbx/%rbx: %rbx_xaddb_r8_rh

State for specgen instruction: movsbl %cl, %ebx:
%rbx/%rbx: (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]

Register        -> %rbx
  translates to => %rbx
Value is               -> (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0]

Final state
%rbx/%rbx: 0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0]

=====================================
-------------------------------------
Getting base circuit for movb %dl, %ah

Final state:
%rax/%ah: %rax_xaddb_r8_rh[63:16] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[7:0] ∘ %rax_xaddb_r8_rh[7:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r9b_to_byte_6_of_rbx

Final state:
%rax/%rax: %rax_xaddb_r8_rh[63:16] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[7:0] ∘ %rax_xaddb_r8_rh[7:0]
%rdx/%rdx: sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])

%xmm0: %ymm0_xaddb_r8_rh[127:0]
%xmm1: %ymm1_xaddb_r8_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for popcntq %rdx, %r9

Final state:
%r9/%r9: 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][3:0][1:0][0:0]))))) + 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][3:0][1:0][0:0])))))

%cf: false
%pf: false
%af: false
%zf: sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0]) = 0x0₆₄
%sf: false
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %sil, %bl

Final state:
%rbx/%bl: ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[63:8] ∘ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0][3:0] + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:7] = 0x1₁
%of: ((%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0][7:7] = 0x1₁ ↔ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0][7:7] = 0x1₁) ∧ !((%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for xaddb %ah, %bl

.target:
movzbw %ah, %si
movzbq %bl, %r12
movslq %r12d, %rdx
callq .move_016_008_dx_r8b_r9b
movsbl %r12b, %ebx
movb %dl, %ah
callq .move_r9b_to_byte_6_of_rbx
popcntq %rdx, %r9
adcb %sil, %bl
retq 

Initial state:
%rax/%ah: %rax_xorb_rh_r8[63:16] ∘ 0x0₁₆
%rbx/%bl: %rbx_xorb_rh_r8[63:8] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8])

%cf: false
%pf: false
%af: false
%zf: true
%sf: false
%of: false

State for specgen instruction: xaddb %ah, %bl:
%rax/%ah: %rax_xaddb_r8_rh[63:16] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[7:0] ∘ %rax_xaddb_r8_rh[7:0]
%rbx/%bl: ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[63:8] ∘ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0][3:0] + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:7] = 0x1₁
%of: ((%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0][7:7] = 0x1₁ ↔ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0][7:7] = 0x1₁) ∧ !((%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:7] = 0x1₁)

Final state
%rax/%ah: (%rax_xorb_rh_r8[63:16] ∘ 0x0₁₆)[63:16] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) ∘ (%rax_xorb_rh_r8[63:16] ∘ 0x0₁₆)[7:0]
%rbx/%bl: (%rbx_xorb_rh_r8[63:8] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]))[63:8] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8])

%cf: false
%pf: !((%rbx_xorb_rh_r8[0:0] ⊕ %rax_xorb_rh_r8[8:8]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[1:1] ⊕ %rax_xorb_rh_r8[9:9]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[2:2] ⊕ %rax_xorb_rh_r8[10:10]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[3:3] ⊕ %rax_xorb_rh_r8[11:11]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[4:4] ⊕ %rax_xorb_rh_r8[12:12]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[5:5] ⊕ %rax_xorb_rh_r8[13:13]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[6:6] ⊕ %rax_xorb_rh_r8[14:14]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁)
%af: false
%zf: (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) = 0x0₈
%sf: (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁
%of: (false ↔ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁) ∧ !(false ↔ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_rcll_r32_one[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for adcl %ebx, %ebx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0]

%cf: ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[32:32] = 0x1₁
%pf: !(((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][3:0] + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][3:0])[4:4] = 0x1₁
%zf: ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0] = 0x0₃₂
%sf: ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][31:31] = 0x1₁
%of: (sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][31:31] = 0x1₁ ↔ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][31:31] = 0x1₁) ∧ !(sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][31:31] = 0x1₁ ↔ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:31] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for rcll $0x1, %edi

.target:
movslq %ebx, %rbx
adcl %ebx, %ebx
retq 

Initial state:
%rdi/%rdi: 0x4₆₄[63:8] ∘ 0x8₈

%cf: false
%of: (false ↔ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁) ∧ !(false ↔ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁)

State for specgen instruction: rcll $0x1, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0]

%cf: ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[32:32] = 0x1₁
%of: (sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][31:31] = 0x1₁ ↔ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][31:31] = 0x1₁) ∧ !(sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][31:31] = 0x1₁ ↔ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:31] = 0x1₁)

Register        -> %rbx
  translates to => %rdi
Value is               -> 0x0₃₂ ∘ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0]
  after renaming it is => 0x10₆₄

Final state
%rdi/%rdi: 0x10₆₄

%cf: false
%of: false

=====================================
=====================================
Computing circuit for xorb %al, %ah

.target:
movq $0x4, %rdi
shlb $0x1, %dil
xorq %r8, %r8
xorb %ah, %bl
popcntw %r8w, %ax
xaddb %ah, %bl
rcll $0x1, %edi
retq 

Initial state:
%rax/%ah: (%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8]

%cf: false
%pf: !(%rbx_xorb_rh_rh[8:8] = 0x1₁ ⊕ %rbx_xorb_rh_rh[9:9] = 0x1₁ ⊕ %rbx_xorb_rh_rh[10:10] = 0x1₁ ⊕ %rbx_xorb_rh_rh[11:11] = 0x1₁ ⊕ %rbx_xorb_rh_rh[12:12] = 0x1₁ ⊕ %rbx_xorb_rh_rh[13:13] = 0x1₁ ⊕ %rbx_xorb_rh_rh[14:14] = 0x1₁ ⊕ %rbx_xorb_rh_rh[15:15] = 0x1₁)
%zf: %rbx_xorb_rh_rh[15:8] = 0x0₈
%sf: %rbx_xorb_rh_rh[15:15] = 0x1₁
%of: (%rbx_xorb_rh_rh[15:15] = 0x1₁ ↔ false) ∧ !(%rbx_xorb_rh_rh[15:15] = 0x1₁ ↔ %rbx_xorb_rh_rh[15:15] = 0x1₁)

State for specgen instruction: xorb %bl, %ah:
%rax/%ah: (%rax_xorb_rh_r8[63:16] ∘ 0x0₁₆)[63:16] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) ∘ (%rax_xorb_rh_r8[63:16] ∘ 0x0₁₆)[7:0]

%cf: false
%pf: !((%rbx_xorb_rh_r8[0:0] ⊕ %rax_xorb_rh_r8[8:8]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[1:1] ⊕ %rax_xorb_rh_r8[9:9]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[2:2] ⊕ %rax_xorb_rh_r8[10:10]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[3:3] ⊕ %rax_xorb_rh_r8[11:11]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[4:4] ⊕ %rax_xorb_rh_r8[12:12]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[5:5] ⊕ %rax_xorb_rh_r8[13:13]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[6:6] ⊕ %rax_xorb_rh_r8[14:14]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁)
%zf: (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) = 0x0₈
%sf: (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁
%of: false

Register        -> %ah
  translates to => %ah
Value is               -> ((%rax_xorb_rh_r8[63:16] ∘ 0x0₁₆)[63:16] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) ∘ (%rax_xorb_rh_r8[63:16] ∘ 0x0₁₆)[7:0])[15:8]
  after renaming it is => %rbx_xorb_rh_rh[15:8] ⊕ %rax_xorb_rh_rh[15:8]

Final state
%rax/%ah: ((%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8])[63:16] ∘ (%rbx_xorb_rh_rh[15:8] ⊕ %rax_xorb_rh_rh[15:8]) ∘ ((%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8])[7:0]

%cf: false
%pf: !((%rbx_xorb_rh_rh[8:8] ⊕ %rax_xorb_rh_rh[8:8]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[9:9] ⊕ %rax_xorb_rh_rh[9:9]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[10:10] ⊕ %rax_xorb_rh_rh[10:10]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[11:11] ⊕ %rax_xorb_rh_rh[11:11]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[12:12] ⊕ %rax_xorb_rh_rh[12:12]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[13:13] ⊕ %rax_xorb_rh_rh[13:13]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[14:14] ⊕ %rax_xorb_rh_rh[14:14]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[15:15] ⊕ %rax_xorb_rh_rh[15:15]) = 0x1₁)
%zf: (%rbx_xorb_rh_rh[15:8] ⊕ %rax_xorb_rh_rh[15:8]) = 0x0₈
%sf: (%rbx_xorb_rh_rh[15:15] ⊕ %rax_xorb_rh_rh[15:15]) = 0x1₁
%of: false

=====================================
=====================================
Computing circuit for xorb %bh, %bh

.target:
xorb %al, %al
xaddb %al, %bh
xorb %al, %ah
retq 

Initial state:
%rbx/%bh: ((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆)

%cf: %cf_cmc
%pf: !((%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁)
%zf: (%cf_cmc ? 0x0₁₆ : 0xffff₁₆) = 0x0₁₆
%sf: (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁
%of: false ∧ !(false ↔ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁)

State for specgen instruction: xorb %bh, %ah:
%rax/%ah: ((%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8])[63:16] ∘ (%rbx_xorb_rh_rh[15:8] ⊕ %rax_xorb_rh_rh[15:8]) ∘ ((%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8])[7:0]

%cf: false
%pf: !((%rbx_xorb_rh_rh[8:8] ⊕ %rax_xorb_rh_rh[8:8]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[9:9] ⊕ %rax_xorb_rh_rh[9:9]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[10:10] ⊕ %rax_xorb_rh_rh[10:10]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[11:11] ⊕ %rax_xorb_rh_rh[11:11]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[12:12] ⊕ %rax_xorb_rh_rh[12:12]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[13:13] ⊕ %rax_xorb_rh_rh[13:13]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[14:14] ⊕ %rax_xorb_rh_rh[14:14]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[15:15] ⊕ %rax_xorb_rh_rh[15:15]) = 0x1₁)
%zf: (%rbx_xorb_rh_rh[15:8] ⊕ %rax_xorb_rh_rh[15:8]) = 0x0₈
%sf: (%rbx_xorb_rh_rh[15:15] ⊕ %rax_xorb_rh_rh[15:15]) = 0x1₁
%of: false

Register        -> %ah
  translates to => %bh
Value is               -> (((%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8])[63:16] ∘ (%rbx_xorb_rh_rh[15:8] ⊕ %rax_xorb_rh_rh[15:8]) ∘ ((%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8])[7:0])[15:8]
  after renaming it is => 0x0₈

Final state
%rbx/%bh: (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0]

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for adcb %bl, %bl

Final state:
%rbx/%bl: ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[63:8] ∘ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0][3:0] + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:7] = 0x1₁
%of: (((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0][7:7] = 0x1₁ ↔ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0][7:7] = 0x1₁) ∧ !(((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for cmc 

.target:
callq .read_cf_into_rbx
callq .move_064_032_rbx_r8d_r9d
callq .move_r8b_to_byte_5_of_rbx
decw %bx
xorb %bh, %bh
adcb %bl, %bl
retq 

Initial state:
%cf: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[64:64] = 0x1₁

State for specgen instruction: cmc :
%cf: ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[8:8] = 0x1₁

Final state
%cf: (((0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %rbx_subq_r64_r64)[64:64] = 0x1₁ ? 0x0₉ : 0xff₉) + ((0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %rbx_subq_r64_r64)[64:64] = 0x1₁ ? 0x0₉ : 0xff₉))[8:8] = 0x1₁

=====================================
=====================================
Computing circuit for subq %r9, %r11

.target:
stc 
notq %rcx
adcq %rcx, %rbx
cmc 
retq 

Initial state:
%r11/%r11: %ymm2_vpsubq_xmm_xmm_xmm[127:0][127:64]

%cf: %cf_vpsubq_xmm_xmm_xmm
%pf: %pf_vpsubq_xmm_xmm_xmm
%af: %af_vpsubq_xmm_xmm_xmm
%zf: %zf_vpsubq_xmm_xmm_xmm
%sf: %sf_vpsubq_xmm_xmm_xmm
%of: %of_vpsubq_xmm_xmm_xmm

State for specgen instruction: subq %rcx, %rbx:
%rbx/%rbx: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0]

%cf: (((0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %rbx_subq_r64_r64)[64:64] = 0x1₁ ? 0x0₉ : 0xff₉) + ((0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %rbx_subq_r64_r64)[64:64] = 0x1₁ ? 0x0₉ : 0xff₉))[8:8] = 0x1₁
%pf: !(((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][0:0] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][1:1] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][2:2] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][3:3] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][4:4] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][5:5] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][6:6] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)[3:0] + 0x0₁ ∘ %rbx_subq_r64_r64[3:0])[4:4] = 0x1₁
%zf: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0] = 0x0₆₄
%sf: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][63:63] = 0x1₁
%of: ((%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)[63:63] = 0x1₁ ↔ %rbx_subq_r64_r64[63:63] = 0x1₁) ∧ !((%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)[63:63] = 0x1₁ ↔ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r11
Value is               -> ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0]
  after renaming it is => (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[63:0]

Final state
%r11/%r11: (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[63:0]

%cf: (((0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[64:64] = 0x1₁ ? 0x0₉ : 0xff₉) + ((0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[64:64] = 0x1₁ ? 0x0₉ : 0xff₉))[8:8] = 0x1₁
%pf: !((0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[7:7] = 0x1₁)
%af: (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[67:64] ⊕ 0xf₄) + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[67:64])[4:4] = 0x1₁
%zf: (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[63:63] = 0x1₁
%of: ((%ymm3_vpsubq_xmm_xmm_xmm[127:127] ⊕ 0x1₁) = 0x1₁ ↔ %ymm2_vpsubq_xmm_xmm_xmm[127:127] = 0x1₁) ∧ !((%ymm3_vpsubq_xmm_xmm_xmm[127:127] ⊕ 0x1₁) = 0x1₁ ↔ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .set_cf

Final state:
%rax/%rax: %rax_stc
%rdx/%rdx: %rdx_stc

%xmm0: %ymm0_stc[127:0]
%xmm1: %ymm1_stc[127:0]

-------------------------------------
=====================================
Computing circuit for stc 

.target:
callq .set_cf
retq 

Initial state:
%cf: %cf_subq_r64_r64

State for specgen instruction: stc :
%cf: true

Final state
%cf: true

=====================================
-------------------------------------
Getting base circuit for movq $0xfffffffffffffffe, %rdx

Final state:
%rdx/%rdx: 0xfffffffffffffffe₆₄

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_incb_r8 ⊕ %rax_incb_r8

%cf: false
%pf: !((%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][0:0] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][1:1] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][2:2] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][3:3] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][4:4] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][5:5] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][6:6] = 0x1₁ ⊕ (%rax_incb_r8 ⊕ %rax_incb_r8)[7:0][7:7] = 0x1₁)
%zf: (%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄
%sf: (%rax_incb_r8 ⊕ %rax_incb_r8)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: false

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for callq .read_zf_into_rcx

Final state:
%rax/%rax: %rax_incb_r8 ⊕ %rax_incb_r8
%rdx/%rdx: %rdx_incb_r8

%xmm0: %ymm0_incb_r8[127:0]
%xmm1: %ymm1_incb_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for adcb %cl, %bl

Final state:
%rbx/%bl: %rbx_incb_r8[63:8] ∘ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0][3:0] + 0x0₁ ∘ %rbx_incb_r8[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:7] = 0x1₁
%of: ((0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0][7:7] = 0x1₁ ↔ %rbx_incb_r8[7:0][7:7] = 0x1₁) ∧ !((0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for incb %dl

.target:
xorq %rax, %rax
clc 
callq .read_zf_into_rcx
adcb %cl, %bl
retq 

Initial state:
%rdx/%dl: 0xfffffffffffffffe₆₄

%pf: %pf_notq_r64
%af: %af_notq_r64
%zf: %zf_notq_r64
%sf: %sf_notq_r64
%of: %of_notq_r64

State for specgen instruction: incb %bl:
%rbx/%bl: %rbx_incb_r8[63:8] ∘ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0]

%pf: !(((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0][3:0] + 0x0₁ ∘ %rbx_incb_r8[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0][7:7] = 0x1₁
%of: ((0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0][7:7] = 0x1₁ ↔ %rbx_incb_r8[7:0][7:7] = 0x1₁) ∧ !((0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:7] = 0x1₁)

Register        -> %bl
  translates to => %dl
Value is               -> (%rbx_incb_r8[63:8] ∘ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0] + 0x1₉ : 0x0₁ ∘ (0x0₆₃ ∘ ((%rax_incb_r8 ⊕ %rax_incb_r8) = 0x0₆₄ ? 0x1₁ : 0x0₁))[7:0]) + 0x0₁ ∘ %rbx_incb_r8[7:0])[7:0])[7:0]
  after renaming it is => 0xff₈

Final state
%rdx/%dl: 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈

%pf: true
%af: false
%zf: false
%sf: true
%of: false

=====================================
-------------------------------------
Getting base circuit for xorq %rdx, %rbx

Final state:
%rbx/%rbx: %rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈

%cf: false
%pf: !((%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][0:0] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][1:1] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][2:2] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][3:3] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][4:4] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][5:5] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][6:6] = 0x1₁ ⊕ (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[7:0][7:7] = 0x1₁)
%zf: (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈) = 0x0₆₄
%sf: (%rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈)[63:63] = 0x1₁
%of: false

-------------------------------------
=====================================
Computing circuit for notq %rcx

.target:
movq $0xfffffffffffffffe, %rdx
incb %dl
xorq %rdx, %rbx
retq 

Initial state:
%rcx/%rcx: %rcx_subq_r64_r64

State for specgen instruction: notq %rbx:
%rbx/%rbx: %rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈

Register        -> %rbx
  translates to => %rcx
Value is               -> %rbx_notq_r64 ⊕ 0xfffffffffffffffe₆₄[63:8] ∘ 0xff₈
  after renaming it is => %rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄

Final state
%rcx/%rcx: %rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄

=====================================
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0]

%cf: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[64:64] = 0x1₁
%pf: !(((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][0:0] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][1:1] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][2:2] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][3:3] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][4:4] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][5:5] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][6:6] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)[3:0] + 0x0₁ ∘ %rbx_subq_r64_r64[3:0])[4:4] = 0x1₁
%zf: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0] = 0x0₆₄
%sf: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][63:63] = 0x1₁
%of: ((%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)[63:63] = 0x1₁ ↔ %rbx_subq_r64_r64[63:63] = 0x1₁) ∧ !((%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)[63:63] = 0x1₁ ↔ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:63] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_cf_into_rbx

Final state:
%rax/%rax: %rax_cmc
%rdx/%rdx: %rdx_cmc

%xmm0: %ymm0_cmc[127:0]
%xmm1: %ymm1_cmc[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r8d_r9d

Final state:
%rax/%rax: %rax_cmc
%rdx/%rdx: %rdx_cmc

%xmm0: %ymm0_cmc[127:0]
%xmm1: %ymm1_cmc[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r8b_to_byte_5_of_rbx

Final state:
%rax/%rax: %rax_cmc
%rdx/%rdx: %rdx_cmc

%xmm0: %ymm0_cmc[127:0]
%xmm1: %ymm1_cmc[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_decw_r16 ⊕ %rax_decw_r16

%cf: false
%pf: !((%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][0:0] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][1:1] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][2:2] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][3:3] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][4:4] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][5:5] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][6:6] = 0x1₁ ⊕ (%rax_decw_r16 ⊕ %rax_decw_r16)[7:0][7:7] = 0x1₁)
%zf: (%rax_decw_r16 ⊕ %rax_decw_r16) = 0x0₆₄
%sf: (%rax_decw_r16 ⊕ %rax_decw_r16)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for movq $0xffffffffffffffff, %rsi

Final state:
%rsi/%rsi: 0xffffffffffffffff₆₄

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r10b_r11b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_cx_r8b_r9b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r10b_r11b_cx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r8b_r9b_bx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for xchgw %ax, %bx

.target:
callq .move_016_008_bx_r10b_r11b
callq .move_016_008_cx_r8b_r9b
callq .move_008_016_r10b_r11b_cx
callq .move_008_016_r8b_r9b_bx
retq 

Initial state:
%rax/%ax: %rax_decw_r16 ⊕ %rax_decw_r16
%rbx/%bx: %rbx_decw_r16

State for specgen instruction: xchgw %cx, %bx:
%rcx/%cx: %rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])
%rbx/%bx: %rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])

Register        -> %cx
  translates to => %ax
Value is               -> (%rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => %rbx_decw_r16[15:0]

Register        -> %bx
  translates to => %bx
Value is               -> (%rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => 0x0₁₆

Final state
%rax/%ax: (%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0]
%rbx/%bx: %rbx_decw_r16[63:16] ∘ 0x0₁₆

=====================================
-------------------------------------
Getting base circuit for callq .read_cf_into_rbx

Final state:
%rax/%rax: (%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0]
%rdx/%rdx: %rdx_decw_r16

%xmm0: %ymm0_decw_r16[127:0]
%xmm1: %ymm1_decw_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for adcw %bx, %ax

Final state:
%rax/%ax: ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[63:16] ∘ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0]

%cf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[16:16] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0][3:0] + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0] = 0x0₁₆
%sf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][15:15] = 0x1₁
%of: ((0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0][15:15] = 0x1₁ ↔ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0][15:15] = 0x1₁) ∧ !((0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:15] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: %cf_addw_r16_r16

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for adcw %cx, %bx

Final state:
%rbx/%bx: %rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[16:16] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addw_r16_r16[15:0][3:0] + 0x0₁ ∘ %rbx_addw_r16_r16[15:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0] = 0x0₁₆
%sf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][15:15] = 0x1₁
%of: (%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ %rbx_addw_r16_r16[15:0][15:15] = 0x1₁) ∧ !(%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:15] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_bx

Final state:
%rax/%rax: %rax_addw_r16_r16
%rdx/%rdx: %rdx_addw_r16_r16

%xmm0: %ymm0_addw_r16_r16[127:0]
%xmm1: %ymm1_addw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for addw %ax, %si

.target:
clc 
adcw %cx, %bx
callq .set_szp_for_bx
retq 

Initial state:
%rsi/%si: 0xffffffffffffffff₆₄

%cf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[16:16] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0][3:0] + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0] = 0x0₁₆
%sf: ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:0][15:15] = 0x1₁
%of: ((0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0][15:15] = 0x1₁ ↔ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0][15:15] = 0x1₁) ∧ !((0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0] + 0x1₁₇ : 0x0₁ ∘ (0x0₆₃ ∘ (false ? 0x1₁ : 0x0₁))[15:0]) + 0x0₁ ∘ ((%rax_decw_r16 ⊕ %rax_decw_r16)[63:16] ∘ %rbx_decw_r16[15:0])[15:0])[15:15] = 0x1₁)

State for specgen instruction: addw %cx, %bx:
%rbx/%bx: %rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[16:16] = 0x1₁
%pf: !((%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addw_r16_r16[15:0][3:0] + 0x0₁ ∘ %rbx_addw_r16_r16[15:0][3:0])[4:4] = 0x1₁
%zf: (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0] = 0x0₁₆
%sf: (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][15:15] = 0x1₁
%of: (%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ %rbx_addw_r16_r16[15:0][15:15] = 0x1₁) ∧ !(%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:15] = 0x1₁)

Register        -> %bx
  translates to => %si
Value is               -> (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0]
  after renaming it is => (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0]

Final state
%rsi/%si: 0xffffffffffffffff₆₄[63:16] ∘ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0]

%cf: (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[16:16] = 0x1₁
%pf: !((0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rbx_decw_r16[3:0] + 0xf₅)[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0] = 0x0₁₆
%sf: (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:15] = 0x1₁
%of: (%rbx_decw_r16[15:15] = 0x1₁ ↔ true) ∧ !(%rbx_decw_r16[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:15] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for movswq %si, %rbx

Final state:
%rbx/%rbx: sign-extend-64((0xffffffffffffffff₆₄[63:16] ∘ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0])[15:0])

-------------------------------------
=====================================
Computing circuit for decw %bx

.target:
xorq %rax, %rax
movq $0xffffffffffffffff, %rsi
xchgw %ax, %bx
callq .read_cf_into_rbx
adcw %bx, %ax
addw %ax, %si
movswq %si, %rbx
retq 

Initial state:
%rbx/%bx: (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0]

%pf: %pf_cmc
%af: %af_cmc
%zf: %zf_cmc
%sf: %sf_cmc
%of: %of_cmc

State for specgen instruction: decw %bx:
%rbx/%bx: sign-extend-64((0xffffffffffffffff₆₄[63:16] ∘ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0])[15:0])

%pf: !((0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rbx_decw_r16[3:0] + 0xf₅)[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0] = 0x0₁₆
%sf: (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:15] = 0x1₁
%of: (%rbx_decw_r16[15:15] = 0x1₁ ↔ true) ∧ !(%rbx_decw_r16[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:15] = 0x1₁)

Register        -> %bx
  translates to => %bx
Value is               -> sign-extend-64((0xffffffffffffffff₆₄[63:16] ∘ (0x0₁ ∘ %rbx_decw_r16[15:0] + 0xffff₁₇)[15:0])[15:0])[15:0]
  after renaming it is => %cf_cmc ? 0x0₁₆ : 0xffff₁₆

Final state
%rbx/%bx: ((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆)

%pf: !((%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁)
%af: (%cf_cmc ? 0x1₁ : 0x0₁) = 0x1₁
%zf: (%cf_cmc ? 0x0₁₆ : 0xffff₁₆) = 0x0₁₆
%sf: (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁
%of: false ∧ !(false ↔ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for movb %cl, %bh

Final state:
%rbx/%bh: %rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq $0x40, %rbx

Final state:
%rbx/%rbx: 0x40₆₄

-------------------------------------
-------------------------------------
Getting base circuit for movb %ah, %bl

Final state:
%rbx/%bl: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

-------------------------------------
=====================================
Computing circuit for movzbl %ah, %ebp

.target:
movq $0x40, %rbx
movb %ah, %bl
retq 

Initial state:
%rbp/%rbp: %rbp_xorb_r8_rh

State for specgen instruction: movzbl %ah, %ebx:
%rbx/%rbx: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

Register        -> %rbx
  translates to => %rbp
Value is               -> 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]
  after renaming it is => 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

Final state
%rbp/%rbp: 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

=====================================
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh

%cf: false
%pf: !((%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][0:0] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][1:1] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][2:2] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][3:3] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][4:4] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][5:5] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][6:6] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][7:7] = 0x1₁)
%zf: (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh) = 0x0₆₄
%sf: (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_cf_into_rcx

Final state:
%rax/%rax: %rax_setc_rh
%rdx/%rdx: %rdx_setc_rh

%xmm0: %ymm0_setc_rh[127:0]
%xmm1: %ymm1_setc_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movb %cl, %ah

Final state:
%rax/%ah: %rax_setc_rh[63:16] ∘ (0x0₆₃ ∘ (%cf_setc_rh ? 0x1₁ : 0x0₁))[7:0] ∘ %rax_setc_rh[7:0]

-------------------------------------
=====================================
Computing circuit for setc %bh

.target:
callq .read_cf_into_rcx
movb %cl, %ah
retq 

Initial state:
%rbx/%bh: %rbx_xorb_r8_rh

State for specgen instruction: setc %ah:
%rax/%ah: %rax_setc_rh[63:16] ∘ (0x0₆₃ ∘ (%cf_setc_rh ? 0x1₁ : 0x0₁))[7:0] ∘ %rax_setc_rh[7:0]

Register        -> %ah
  translates to => %bh
Value is               -> (%rax_setc_rh[63:16] ∘ (0x0₆₃ ∘ (%cf_setc_rh ? 0x1₁ : 0x0₁))[7:0] ∘ %rax_setc_rh[7:0])[15:8]
  after renaming it is => 0x0₈

Final state
%rbx/%bh: %rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0]

=====================================
-------------------------------------
Getting base circuit for movswq %bx, %rdx

Final state:
%rdx/%rdx: sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rbp, %rdx

Final state:
%rdx/%rdx: sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

%cf: false
%pf: !((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][0:0] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][1:1] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][2:2] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][3:3] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][4:4] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][5:5] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][6:6] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][7:7] = 0x1₁)
%zf: (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]) = 0x0₆₄
%sf: (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for movslq %edx, %rbx

Final state:
%rbx/%rbx: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_bl

Final state:
%rax/%rax: %rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh
%rdx/%rdx: sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

%xmm0: %ymm0_xorb_r8_rh[127:0]
%xmm1: %ymm1_xorb_r8_rh[127:0]

-------------------------------------
=====================================
Computing circuit for xorb %bh, %bl

.target:
movzbl %ah, %ebp
xorq %rax, %rax
setc %bh
movswq %bx, %rdx
xorq %rbp, %rdx
movslq %edx, %rbx
callq .set_szp_for_bl
retq 

Initial state:
%rbx/%bl: %rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0]

%cf: %cf_xorb_r8_r8
%pf: %pf_xorb_r8_r8
%zf: %zf_xorb_r8_r8
%sf: %sf_xorb_r8_r8
%of: %of_xorb_r8_r8

State for specgen instruction: xorb %ah, %bl:
%rbx/%bl: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])

%cf: false
%pf: !(sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][0:0] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][1:1] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][2:2] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][3:3] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][4:4] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][5:5] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][6:6] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][7:7] = 0x1₁)
%zf: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0] = 0x0₈
%sf: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:7] = 0x1₁
%of: false

Register        -> %bl
  translates to => %bl
Value is               -> sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0]
  after renaming it is => %rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]

Final state
%rbx/%bl: (%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0])

%cf: false
%pf: !((%rbx_xorb_r8_r8[0:0] ⊕ %rcx_xorb_r8_r8[0:0]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[1:1] ⊕ %rcx_xorb_r8_r8[1:1]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[2:2] ⊕ %rcx_xorb_r8_r8[2:2]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[3:3] ⊕ %rcx_xorb_r8_r8[3:3]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[4:4] ⊕ %rcx_xorb_r8_r8[4:4]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[5:5] ⊕ %rcx_xorb_r8_r8[5:5]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[6:6] ⊕ %rcx_xorb_r8_r8[6:6]) = 0x1₁ ⊕ (%rbx_xorb_r8_r8[7:7] ⊕ %rcx_xorb_r8_r8[7:7]) = 0x1₁)
%zf: (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]) = 0x0₈
%sf: (%rbx_xorb_r8_r8[7:7] ⊕ %rcx_xorb_r8_r8[7:7]) = 0x1₁
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .set_szp_for_bl

Final state:
%rax/%rax: %rax_xorb_r8_r8
%rdx/%rdx: %rdx_xorb_r8_r8

%xmm0: %ymm0_xorb_r8_r8[127:0]
%xmm1: %ymm1_xorb_r8_r8[127:0]

-------------------------------------
=====================================
Computing circuit for xorb %al, %al

.target:
movb %cl, %bh
xorb %bh, %bl
callq .set_szp_for_bl
retq 

Initial state:
%rax/%al: %rax_xorb_rh_rh

%cf: %cf_xorb_rh_rh
%pf: %pf_xorb_rh_rh
%zf: %zf_xorb_rh_rh
%sf: %sf_xorb_rh_rh
%of: %of_xorb_rh_rh

State for specgen instruction: xorb %cl, %bl:
%rbx/%bl: (%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0])

%cf: false
%pf: !(((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][0:0] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][1:1] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][2:2] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][3:3] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][4:4] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][5:5] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][6:6] = 0x1₁ ⊕ ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:0][7:7] = 0x1₁)
%zf: ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0] = 0x0₈
%sf: ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0][7:7] = 0x1₁
%of: false

Register        -> %bl
  translates to => %al
Value is               -> ((%rbx_xorb_r8_r8[63:16] ∘ %rcx_xorb_r8_r8[7:0] ∘ %rbx_xorb_r8_r8[7:0])[63:8] ∘ (%rbx_xorb_r8_r8[7:0] ⊕ %rcx_xorb_r8_r8[7:0]))[7:0]
  after renaming it is => 0x0₈

Final state
%rax/%al: %rax_xorb_rh_rh[63:8] ∘ 0x0₈

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for movq $0x40, %rbx

Final state:
%rbx/%rbx: 0x40₆₄

-------------------------------------
-------------------------------------
Getting base circuit for movb %ah, %bl

Final state:
%rbx/%bl: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

-------------------------------------
=====================================
Computing circuit for movzbl %ah, %edx

.target:
movq $0x40, %rbx
movb %ah, %bl
retq 

Initial state:
%rdx/%rdx: %rdx_xaddb_rh_r8

State for specgen instruction: movzbl %ah, %ebx:
%rbx/%rbx: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

Register        -> %rbx
  translates to => %rdx
Value is               -> 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]
  after renaming it is => 0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8]

Final state
%rdx/%rdx: 0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8]

=====================================
-------------------------------------
Getting base circuit for callq .clear_cf

Final state:
%rax/%rax: %rax_xaddb_r8_r8
%rdx/%rdx: %rdx_xaddb_r8_r8

%xmm0: %ymm0_xaddb_r8_r8[127:0]
%xmm1: %ymm1_xaddb_r8_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_of

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_of_into_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movsbq %cl, %r10

Final state:
%r10/%r10: sign-extend-64(%rcx_movsbl_r32_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
=====================================
Computing circuit for movsbl %cl, %r13d

.target:
callq .set_of
callq .read_of_into_rbx
callq .move_064_032_rbx_r10d_r11d
movsbq %cl, %r10
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r13/%r13: %r13_xaddb_r8_r8

State for specgen instruction: movsbl %cl, %ebx:
%rbx/%rbx: (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r13
Value is               -> (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0]

Final state
%r13/%r13: 0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0]

=====================================
-------------------------------------
Getting base circuit for callq .set_of

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_of_into_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movsbq %cl, %r10

Final state:
%r10/%r10: sign-extend-64(%rcx_movsbl_r32_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
=====================================
Computing circuit for movsbl %bl, %r15d

.target:
callq .set_of
callq .read_of_into_rbx
callq .move_064_032_rbx_r10d_r11d
movsbq %cl, %r10
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r15/%r15: %r15_xaddb_r8_r8

State for specgen instruction: movsbl %cl, %ebx:
%rbx/%rbx: (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r15
Value is               -> (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0]

Final state
%r15/%r15: 0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0]

=====================================
-------------------------------------
Getting base circuit for movsbq %r15b, %rcx

Final state:
%rcx/%rcx: sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for adcb %cl, %r13b

Final state:
%r13/%r13b: (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][3:0] + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁
%of: (sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][7:7] = 0x1₁) ∧ !(sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:7] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r13d, %rbx

Final state:
%rbx/%rbx: sign-extend-64(((0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0])[31:0])

-------------------------------------
=====================================
Computing circuit for xaddb %bl, %dl

.target:
callq .clear_cf
movsbl %cl, %r13d
movsbl %bl, %r15d
movsbq %r15b, %rcx
adcb %cl, %r13b
movslq %r13d, %rbx
retq 

Initial state:
%rdx/%dl: 0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8]
%rbx/%bl: %rbx_xaddb_rh_r8

%cf: %cf_xaddb_rh_r8
%pf: %pf_xaddb_rh_r8
%af: %af_xaddb_rh_r8
%zf: %zf_xaddb_rh_r8
%sf: %sf_xaddb_rh_r8
%of: %of_xaddb_rh_r8

State for specgen instruction: xaddb %cl, %bl:
%rcx/%cl: sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])
%rbx/%bl: sign-extend-64(((0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0])[31:0])

%cf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][3:0] + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁
%of: (sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][7:7] = 0x1₁) ∧ !(sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:7] = 0x1₁)

Final state
%rdx/%dl: (0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8])[63:8] ∘ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0]
%rbx/%bl: %rbx_xaddb_rh_r8[63:8] ∘ %rax_xaddb_rh_r8[15:8]

%cf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[8:8] = 0x1₁
%pf: !((0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rax_xaddb_rh_r8[11:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0] = 0x0₈
%sf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁
%of: (%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ %rbx_xaddb_rh_r8[7:7] = 0x1₁) ∧ !(%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for movb %dl, %ah

Final state:
%rax/%ah: %rax_xaddb_rh_r8[63:16] ∘ ((0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8])[63:8] ∘ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0])[7:0] ∘ %rax_xaddb_rh_r8[7:0]

-------------------------------------
=====================================
Computing circuit for xaddb %al, %bh

.target:
movzbl %ah, %edx
xaddb %bl, %dl
movb %dl, %ah
retq 

Initial state:
%rax/%al: %rax_xorb_rh_rh[63:8] ∘ 0x0₈
%rbx/%bh: %rbx_xorb_rh_rh

%cf: false
%pf: true
%af: %af_xorb_rh_rh
%zf: true
%sf: false
%of: false

State for specgen instruction: xaddb %bl, %ah:
%rax/%ah: %rax_xaddb_rh_r8[63:16] ∘ ((0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8])[63:8] ∘ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0])[7:0] ∘ %rax_xaddb_rh_r8[7:0]
%rbx/%bl: %rbx_xaddb_rh_r8[63:8] ∘ %rax_xaddb_rh_r8[15:8]

%cf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[8:8] = 0x1₁
%pf: !((0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rax_xaddb_rh_r8[11:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0] = 0x0₈
%sf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁
%of: (%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ %rbx_xaddb_rh_r8[7:7] = 0x1₁) ∧ !(%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)

Final state
%rax/%al: (%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8]
%rbx/%bh: %rbx_xorb_rh_rh[63:16] ∘ %rbx_xorb_rh_rh[15:8] ∘ %rbx_xorb_rh_rh[7:0]

%cf: false
%pf: !(%rbx_xorb_rh_rh[8:8] = 0x1₁ ⊕ %rbx_xorb_rh_rh[9:9] = 0x1₁ ⊕ %rbx_xorb_rh_rh[10:10] = 0x1₁ ⊕ %rbx_xorb_rh_rh[11:11] = 0x1₁ ⊕ %rbx_xorb_rh_rh[12:12] = 0x1₁ ⊕ %rbx_xorb_rh_rh[13:13] = 0x1₁ ⊕ %rbx_xorb_rh_rh[14:14] = 0x1₁ ⊕ %rbx_xorb_rh_rh[15:15] = 0x1₁)
%af: false
%zf: %rbx_xorb_rh_rh[15:8] = 0x0₈
%sf: %rbx_xorb_rh_rh[15:15] = 0x1₁
%of: (%rbx_xorb_rh_rh[15:15] = 0x1₁ ↔ false) ∧ !(%rbx_xorb_rh_rh[15:15] = 0x1₁ ↔ %rbx_xorb_rh_rh[15:15] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for movq $0x4, %rdi

Final state:
%rdi/%rdi: 0x4₆₄

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_shlb_r8_one ⊕ %rax_shlb_r8_one

%cf: false
%pf: !((%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][0:0] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][1:1] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][2:2] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][3:3] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][4:4] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][5:5] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][6:6] = 0x1₁ ⊕ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][7:7] = 0x1₁)
%zf: (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one) = 0x0₆₄
%sf: (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: false

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][3:0] + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][7:7] = 0x1₁ ↔ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][7:7] = 0x1₁) ∧ !((%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:7] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for adcb %bl, %bl

Final state:
%rbx/%bl: %rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0]

%cf: ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[8:8] = 0x1₁
%pf: !(((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rbx_shlb_r8_one[7:0][3:0] + 0x0₁ ∘ %rbx_shlb_r8_one[7:0][3:0])[4:4] = 0x1₁
%zf: ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0] = 0x0₈
%sf: ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0][7:7] = 0x1₁
%of: (%rbx_shlb_r8_one[7:0][7:7] = 0x1₁ ↔ %rbx_shlb_r8_one[7:0][7:7] = 0x1₁) ∧ !(%rbx_shlb_r8_one[7:0][7:7] = 0x1₁ ↔ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:7] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_bl

Final state:
%rax/%rax: (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[7:0]
%rdx/%rdx: %rdx_shlb_r8_one

%xmm0: %ymm0_shlb_r8_one[127:0]
%xmm1: %ymm1_shlb_r8_one[127:0]

-------------------------------------
=====================================
Computing circuit for shlb $0x1, %dil

.target:
xorq %rax, %rax
clc 
adcb %al, %al
adcb %bl, %bl
callq .set_szp_for_bl
retq 

Initial state:
%rdi/%dil: 0x4₆₄

%cf: %cf_xorb_rh_r8
%pf: %pf_xorb_rh_r8
%zf: %zf_xorb_rh_r8
%sf: %sf_xorb_rh_r8
%of: %of_xorb_rh_r8

State for specgen instruction: shlb $0x1, %bl:
%rbx/%bl: %rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0]

%cf: ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[8:8] = 0x1₁
%pf: !((%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%zf: (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0] = 0x0₈
%sf: (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0][7:7] = 0x1₁
%of: (%rbx_shlb_r8_one[7:0][7:7] = 0x1₁ ↔ %rbx_shlb_r8_one[7:0][7:7] = 0x1₁) ∧ !(%rbx_shlb_r8_one[7:0][7:7] = 0x1₁ ↔ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:7] = 0x1₁)

Register        -> %bl
  translates to => %dil
Value is               -> (%rbx_shlb_r8_one[63:8] ∘ ((((false ? 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0]) + 0x0₁ ∘ (%rax_shlb_r8_one ⊕ %rax_shlb_r8_one)[7:0])[8:8] = 0x1₁ ? 0x0₁ ∘ %rbx_shlb_r8_one[7:0] + 0x1₉ : 0x0₁ ∘ %rbx_shlb_r8_one[7:0]) + 0x0₁ ∘ %rbx_shlb_r8_one[7:0])[7:0])[7:0]
  after renaming it is => 0x8₈

Final state
%rdi/%dil: 0x4₆₄[63:8] ∘ 0x8₈

%cf: false
%pf: false
%zf: false
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for xorq %r8, %r8

Final state:
%r8/%r8: %r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8

%cf: false
%pf: !((%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][0:0] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][1:1] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][2:2] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][3:3] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][4:4] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][5:5] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][6:6] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][7:7] = 0x1₁)
%zf: (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8) = 0x0₆₄
%sf: (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for movq $0x40, %rbx

Final state:
%rbx/%rbx: 0x40₆₄

-------------------------------------
-------------------------------------
Getting base circuit for movb %ah, %bl

Final state:
%rbx/%bl: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

-------------------------------------
=====================================
Computing circuit for movzbl %ah, %ebp

.target:
movq $0x40, %rbx
movb %ah, %bl
retq 

Initial state:
%rbp/%rbp: %rbp_xorb_r8_rh

State for specgen instruction: movzbl %ah, %ebx:
%rbx/%rbx: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

Register        -> %rbx
  translates to => %rbp
Value is               -> 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]
  after renaming it is => 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

Final state
%rbp/%rbp: 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

=====================================
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh

%cf: false
%pf: !((%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][0:0] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][1:1] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][2:2] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][3:3] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][4:4] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][5:5] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][6:6] = 0x1₁ ⊕ (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[7:0][7:7] = 0x1₁)
%zf: (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh) = 0x0₆₄
%sf: (%rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_cf_into_rcx

Final state:
%rax/%rax: %rax_setc_rh
%rdx/%rdx: %rdx_setc_rh

%xmm0: %ymm0_setc_rh[127:0]
%xmm1: %ymm1_setc_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movb %cl, %ah

Final state:
%rax/%ah: %rax_setc_rh[63:16] ∘ (0x0₆₃ ∘ (%cf_setc_rh ? 0x1₁ : 0x0₁))[7:0] ∘ %rax_setc_rh[7:0]

-------------------------------------
=====================================
Computing circuit for setc %bh

.target:
callq .read_cf_into_rcx
movb %cl, %ah
retq 

Initial state:
%rbx/%bh: %rbx_xorb_r8_rh

State for specgen instruction: setc %ah:
%rax/%ah: %rax_setc_rh[63:16] ∘ (0x0₆₃ ∘ (%cf_setc_rh ? 0x1₁ : 0x0₁))[7:0] ∘ %rax_setc_rh[7:0]

Register        -> %ah
  translates to => %bh
Value is               -> (%rax_setc_rh[63:16] ∘ (0x0₆₃ ∘ (%cf_setc_rh ? 0x1₁ : 0x0₁))[7:0] ∘ %rax_setc_rh[7:0])[15:8]
  after renaming it is => 0x0₈

Final state
%rbx/%bh: %rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0]

=====================================
-------------------------------------
Getting base circuit for movswq %bx, %rdx

Final state:
%rdx/%rdx: sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rbp, %rdx

Final state:
%rdx/%rdx: sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

%cf: false
%pf: !((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][0:0] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][1:1] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][2:2] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][3:3] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][4:4] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][5:5] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][6:6] = 0x1₁ ⊕ (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[7:0][7:7] = 0x1₁)
%zf: (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]) = 0x0₆₄
%sf: (sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for movslq %edx, %rbx

Final state:
%rbx/%rbx: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_bl

Final state:
%rax/%rax: %rax_xorb_r8_rh ⊕ %rax_xorb_r8_rh
%rdx/%rdx: sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8]

%xmm0: %ymm0_xorb_r8_rh[127:0]
%xmm1: %ymm1_xorb_r8_rh[127:0]

-------------------------------------
=====================================
Computing circuit for xorb %ah, %bl

.target:
movzbl %ah, %ebp
xorq %rax, %rax
setc %bh
movswq %bx, %rdx
xorq %rbp, %rdx
movslq %edx, %rbx
callq .set_szp_for_bl
retq 

Initial state:
%rbx/%bl: %rbx_xorb_rh_r8

%cf: false
%pf: !((%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][0:0] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][1:1] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][2:2] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][3:3] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][4:4] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][5:5] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][6:6] = 0x1₁ ⊕ (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[7:0][7:7] = 0x1₁)
%zf: (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8) = 0x0₆₄
%sf: (%r8_xorb_rh_r8 ⊕ %r8_xorb_rh_r8)[63:63] = 0x1₁
%of: false

State for specgen instruction: xorb %ah, %bl:
%rbx/%bl: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])

%cf: false
%pf: !(sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][0:0] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][1:1] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][2:2] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][3:3] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][4:4] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][5:5] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][6:6] = 0x1₁ ⊕ sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:0][7:7] = 0x1₁)
%zf: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0] = 0x0₈
%sf: sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0][7:7] = 0x1₁
%of: false

Register        -> %bl
  translates to => %bl
Value is               -> sign-extend-64((sign-extend-64((%rbx_xorb_r8_rh[63:16] ∘ 0x0₈ ∘ %rbx_xorb_r8_rh[7:0])[15:0]) ⊕ 0x0₅₆ ∘ %rax_xorb_r8_rh[15:8])[31:0])[7:0]
  after renaming it is => %rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]

Final state
%rbx/%bl: %rbx_xorb_rh_r8[63:8] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8])

%cf: false
%pf: !((%rbx_xorb_rh_r8[0:0] ⊕ %rax_xorb_rh_r8[8:8]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[1:1] ⊕ %rax_xorb_rh_r8[9:9]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[2:2] ⊕ %rax_xorb_rh_r8[10:10]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[3:3] ⊕ %rax_xorb_rh_r8[11:11]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[4:4] ⊕ %rax_xorb_rh_r8[12:12]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[5:5] ⊕ %rax_xorb_rh_r8[13:13]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[6:6] ⊕ %rax_xorb_rh_r8[14:14]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁)
%zf: (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) = 0x0₈
%sf: (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁
%of: false

=====================================
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16

%cf: false
%pf: !((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][0:0] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][1:1] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][2:2] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][3:3] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][4:4] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][5:5] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][6:6] = 0x1₁ ⊕ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[7:0][7:7] = 0x1₁)
%zf: (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16) = 0x0₆₄
%sf: (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: false

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for adcw %cx, %ax

Final state:
%rax/%ax: (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0]

%cf: ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[16:16] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_popcntw_r16_r16[15:0][3:0] + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0] = 0x0₁₆
%sf: ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0][15:15] = 0x1₁
%of: (%rcx_popcntw_r16_r16[15:0][15:15] = 0x1₁ ↔ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0][15:15] = 0x1₁) ∧ !(%rcx_popcntw_r16_r16[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:15] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for popcntq %rax, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][1:0][0:0]))))) + 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][1:0][0:0])))))

%cf: false
%pf: false
%af: false
%zf: (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0] = 0x0₆₄
%sf: false
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: false

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
=====================================
Computing circuit for popcntw %r8w, %ax

.target:
xorq %rax, %rax
clc 
adcw %cx, %ax
popcntq %rax, %rbx
clc 
retq 

Initial state:
%rax/%ax: %rax_xorb_rh_r8

%cf: false
%pf: !((%rbx_xorb_rh_r8[0:0] ⊕ %rax_xorb_rh_r8[8:8]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[1:1] ⊕ %rax_xorb_rh_r8[9:9]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[2:2] ⊕ %rax_xorb_rh_r8[10:10]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[3:3] ⊕ %rax_xorb_rh_r8[11:11]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[4:4] ⊕ %rax_xorb_rh_r8[12:12]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[5:5] ⊕ %rax_xorb_rh_r8[13:13]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[6:6] ⊕ %rax_xorb_rh_r8[14:14]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁)
%af: TMP_BOOL_135
%zf: (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) = 0x0₈
%sf: (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁
%of: false

State for specgen instruction: popcntw %cx, %bx:
%rbx/%bx: 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][1:0][0:0]))))) + 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][1:0][0:0])))))

%cf: false
%pf: false
%af: false
%zf: (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0] = 0x0₆₄
%sf: false
%of: false

Register        -> %bx
  translates to => %ax
Value is               -> (0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[63:32][15:0][7:0][3:0][1:0][0:0]))))) + 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ ((%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_popcntw_r16_r16[15:0]) + 0x0₁ ∘ (%rax_popcntw_r16_r16 ⊕ %rax_popcntw_r16_r16)[15:0])[15:0])[31:0][15:0][7:0][3:0][1:0][0:0]))))))[15:0]
  after renaming it is => 0x0₁₆

Final state
%rax/%ax: %rax_xorb_rh_r8[63:16] ∘ 0x0₁₆

%cf: false
%pf: false
%af: false
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rcx

Final state:
%rcx/%rcx: %rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh

%cf: false
%pf: !((%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][0:0] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][1:1] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][2:2] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][3:3] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][4:4] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][5:5] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][6:6] = 0x1₁ ⊕ (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[7:0][7:7] = 0x1₁)
%zf: (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh) = 0x0₆₄
%sf: (%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_sf_into_rbx

Final state:
%rax/%rax: %rax_movzbw_r16_rh
%rdx/%rdx: %rdx_movzbw_r16_rh

%xmm0: %ymm0_movzbw_r16_rh[127:0]
%xmm1: %ymm1_movzbw_r16_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movb %ah, %bl

Final state:
%rbx/%bl: (0x0₆₃ ∘ ((%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[63:63] = 0x1₁ ? 0x1₁ : 0x0₁))[63:8] ∘ %rax_movzbw_r16_rh[15:8]

-------------------------------------
=====================================
Computing circuit for movzbw %ah, %si

.target:
xorq %rcx, %rcx
callq .read_sf_into_rbx
movb %ah, %bl
retq 

Initial state:
%rsi/%si: %rsi_xaddb_r8_rh

State for specgen instruction: movzbw %ah, %bx:
%rbx/%bx: (0x0₆₃ ∘ ((%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[63:63] = 0x1₁ ? 0x1₁ : 0x0₁))[63:8] ∘ %rax_movzbw_r16_rh[15:8]

Register        -> %bx
  translates to => %si
Value is               -> ((0x0₆₃ ∘ ((%rcx_movzbw_r16_rh ⊕ %rcx_movzbw_r16_rh)[63:63] = 0x1₁ ? 0x1₁ : 0x0₁))[63:8] ∘ %rax_movzbw_r16_rh[15:8])[15:0]
  after renaming it is => 0x0₈ ∘ %rax_xaddb_r8_rh[15:8]

Final state
%rsi/%si: %rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8])

=====================================
-------------------------------------
Getting base circuit for movq $0x0, %rbx

Final state:
%rbx/%rbx: 0x0₆₄

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: %cf_movzbq_r64_r8

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for movsbq %cl, %rdi

Final state:
%rdi/%rdi: sign-extend-64(%rcx_movzbq_r64_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for adcb %dil, %bl

Final state:
%rbx/%bl: 0x0₆₄[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0][3:0] + 0x0₁ ∘ 0x0₆₄[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:7] = 0x1₁
%of: (sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0][7:7] = 0x1₁ ↔ 0x0₆₄[7:0][7:7] = 0x1₁) ∧ !(sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for movzbq %bl, %r12

.target:
movq $0x0, %rbx
clc 
movsbq %cl, %rdi
adcb %dil, %bl
retq 

Initial state:
%r12/%r12: %r12_xaddb_r8_rh

State for specgen instruction: movzbq %cl, %rbx:
%rbx/%rbx: 0x0₆₄[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0]

Register        -> %rbx
  translates to => %r12
Value is               -> 0x0₆₄[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0]
  after renaming it is => 0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0]

Final state
%r12/%r12: 0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0]

=====================================
-------------------------------------
Getting base circuit for movslq %r12d, %rdx

Final state:
%rdx/%rdx: sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_dx_r8b_r9b

Final state:
%rax/%rax: %rax_xaddb_r8_rh
%rdx/%rdx: sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])

%xmm0: %ymm0_xaddb_r8_rh[127:0]
%xmm1: %ymm1_xaddb_r8_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_of

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_of_into_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movsbq %cl, %r10

Final state:
%r10/%r10: sign-extend-64(%rcx_movsbl_r32_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
=====================================
Computing circuit for movsbl %r12b, %ebx

.target:
callq .set_of
callq .read_of_into_rbx
callq .move_064_032_rbx_r10d_r11d
movsbq %cl, %r10
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%rbx/%rbx: %rbx_xaddb_r8_rh

State for specgen instruction: movsbl %cl, %ebx:
%rbx/%rbx: (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]

Register        -> %rbx
  translates to => %rbx
Value is               -> (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0]

Final state
%rbx/%rbx: 0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0]

=====================================
-------------------------------------
Getting base circuit for movb %dl, %ah

Final state:
%rax/%ah: %rax_xaddb_r8_rh[63:16] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[7:0] ∘ %rax_xaddb_r8_rh[7:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r9b_to_byte_6_of_rbx

Final state:
%rax/%rax: %rax_xaddb_r8_rh[63:16] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[7:0] ∘ %rax_xaddb_r8_rh[7:0]
%rdx/%rdx: sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])

%xmm0: %ymm0_xaddb_r8_rh[127:0]
%xmm1: %ymm1_xaddb_r8_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for popcntq %rdx, %r9

Final state:
%r9/%r9: 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[63:32][15:0][7:0][3:0][1:0][0:0]))))) + 0x0₃₂ ∘ (0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][31:16][7:0][3:0][1:0][0:0])))) + 0x0₁₆ ∘ (0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][15:8][3:0][1:0][0:0]))) + 0x0₈ ∘ (0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][7:4][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][7:4][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][7:4][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][7:4][1:0][0:0])) + 0x0₄ ∘ (0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][3:0][3:2][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][3:0][3:2][0:0]) + 0x0₂ ∘ (0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][3:0][1:0][1:1] + 0x0₁ ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[31:0][15:0][7:0][3:0][1:0][0:0])))))

%cf: false
%pf: false
%af: false
%zf: sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0]) = 0x0₆₄
%sf: false
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %sil, %bl

Final state:
%rbx/%bl: ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[63:8] ∘ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0][3:0] + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:7] = 0x1₁
%of: ((%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0][7:7] = 0x1₁ ↔ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0][7:7] = 0x1₁) ∧ !((%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for xaddb %ah, %bl

.target:
movzbw %ah, %si
movzbq %bl, %r12
movslq %r12d, %rdx
callq .move_016_008_dx_r8b_r9b
movsbl %r12b, %ebx
movb %dl, %ah
callq .move_r9b_to_byte_6_of_rbx
popcntq %rdx, %r9
adcb %sil, %bl
retq 

Initial state:
%rax/%ah: %rax_xorb_rh_r8[63:16] ∘ 0x0₁₆
%rbx/%bl: %rbx_xorb_rh_r8[63:8] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8])

%cf: false
%pf: false
%af: false
%zf: true
%sf: false
%of: false

State for specgen instruction: xaddb %ah, %bl:
%rax/%ah: %rax_xaddb_r8_rh[63:16] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[7:0] ∘ %rax_xaddb_r8_rh[7:0]
%rbx/%bl: ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[63:8] ∘ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0][3:0] + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:0][7:7] = 0x1₁
%of: ((%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0][7:7] = 0x1₁ ↔ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0][7:7] = 0x1₁) ∧ !((%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0] + 0x1₉ : 0x0₁ ∘ (%rsi_xaddb_r8_rh[63:16] ∘ (0x0₈ ∘ %rax_xaddb_r8_rh[15:8]))[7:0]) + 0x0₁ ∘ ((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[63:56] ∘ (%r9_xaddb_r8_rh[63:8] ∘ sign-extend-64((0x0₅₆ ∘ %rbx_xaddb_r8_rh[7:0])[31:0])[15:0][15:8])[7:0] ∘ (0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_rh[7:0])[31:0])[47:0])[7:0])[7:7] = 0x1₁)

Final state
%rax/%ah: (%rax_xorb_rh_r8[63:16] ∘ 0x0₁₆)[63:16] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) ∘ (%rax_xorb_rh_r8[63:16] ∘ 0x0₁₆)[7:0]
%rbx/%bl: (%rbx_xorb_rh_r8[63:8] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]))[63:8] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8])

%cf: false
%pf: !((%rbx_xorb_rh_r8[0:0] ⊕ %rax_xorb_rh_r8[8:8]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[1:1] ⊕ %rax_xorb_rh_r8[9:9]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[2:2] ⊕ %rax_xorb_rh_r8[10:10]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[3:3] ⊕ %rax_xorb_rh_r8[11:11]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[4:4] ⊕ %rax_xorb_rh_r8[12:12]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[5:5] ⊕ %rax_xorb_rh_r8[13:13]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[6:6] ⊕ %rax_xorb_rh_r8[14:14]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁)
%af: false
%zf: (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) = 0x0₈
%sf: (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁
%of: (false ↔ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁) ∧ !(false ↔ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_rcll_r32_one[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for adcl %ebx, %ebx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0]

%cf: ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[32:32] = 0x1₁
%pf: !(((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][3:0] + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][3:0])[4:4] = 0x1₁
%zf: ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0] = 0x0₃₂
%sf: ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0][31:31] = 0x1₁
%of: (sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][31:31] = 0x1₁ ↔ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][31:31] = 0x1₁) ∧ !(sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][31:31] = 0x1₁ ↔ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:31] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for rcll $0x1, %edi

.target:
movslq %ebx, %rbx
adcl %ebx, %ebx
retq 

Initial state:
%rdi/%rdi: 0x4₆₄[63:8] ∘ 0x8₈

%cf: false
%of: (false ↔ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁) ∧ !(false ↔ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁)

State for specgen instruction: rcll $0x1, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0]

%cf: ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[32:32] = 0x1₁
%of: (sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][31:31] = 0x1₁ ↔ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][31:31] = 0x1₁) ∧ !(sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0][31:31] = 0x1₁ ↔ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:31] = 0x1₁)

Register        -> %rbx
  translates to => %rdi
Value is               -> 0x0₃₂ ∘ ((%cf_rcll_r32_one ? 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0] + 0x1₃₃ : 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0]) + 0x0₁ ∘ sign-extend-64(%rbx_rcll_r32_one[31:0])[31:0])[31:0]
  after renaming it is => 0x10₆₄

Final state
%rdi/%rdi: 0x10₆₄

%cf: false
%of: false

=====================================
=====================================
Computing circuit for xorb %al, %ah

.target:
movq $0x4, %rdi
shlb $0x1, %dil
xorq %r8, %r8
xorb %ah, %bl
popcntw %r8w, %ax
xaddb %ah, %bl
rcll $0x1, %edi
retq 

Initial state:
%rax/%ah: (%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8]

%cf: false
%pf: !(%rbx_xorb_rh_rh[8:8] = 0x1₁ ⊕ %rbx_xorb_rh_rh[9:9] = 0x1₁ ⊕ %rbx_xorb_rh_rh[10:10] = 0x1₁ ⊕ %rbx_xorb_rh_rh[11:11] = 0x1₁ ⊕ %rbx_xorb_rh_rh[12:12] = 0x1₁ ⊕ %rbx_xorb_rh_rh[13:13] = 0x1₁ ⊕ %rbx_xorb_rh_rh[14:14] = 0x1₁ ⊕ %rbx_xorb_rh_rh[15:15] = 0x1₁)
%zf: %rbx_xorb_rh_rh[15:8] = 0x0₈
%sf: %rbx_xorb_rh_rh[15:15] = 0x1₁
%of: (%rbx_xorb_rh_rh[15:15] = 0x1₁ ↔ false) ∧ !(%rbx_xorb_rh_rh[15:15] = 0x1₁ ↔ %rbx_xorb_rh_rh[15:15] = 0x1₁)

State for specgen instruction: xorb %bl, %ah:
%rax/%ah: (%rax_xorb_rh_r8[63:16] ∘ 0x0₁₆)[63:16] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) ∘ (%rax_xorb_rh_r8[63:16] ∘ 0x0₁₆)[7:0]

%cf: false
%pf: !((%rbx_xorb_rh_r8[0:0] ⊕ %rax_xorb_rh_r8[8:8]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[1:1] ⊕ %rax_xorb_rh_r8[9:9]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[2:2] ⊕ %rax_xorb_rh_r8[10:10]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[3:3] ⊕ %rax_xorb_rh_r8[11:11]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[4:4] ⊕ %rax_xorb_rh_r8[12:12]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[5:5] ⊕ %rax_xorb_rh_r8[13:13]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[6:6] ⊕ %rax_xorb_rh_r8[14:14]) = 0x1₁ ⊕ (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁)
%zf: (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) = 0x0₈
%sf: (%rbx_xorb_rh_r8[7:7] ⊕ %rax_xorb_rh_r8[15:15]) = 0x1₁
%of: false

Register        -> %ah
  translates to => %ah
Value is               -> ((%rax_xorb_rh_r8[63:16] ∘ 0x0₁₆)[63:16] ∘ (%rbx_xorb_rh_r8[7:0] ⊕ %rax_xorb_rh_r8[15:8]) ∘ (%rax_xorb_rh_r8[63:16] ∘ 0x0₁₆)[7:0])[15:8]
  after renaming it is => %rbx_xorb_rh_rh[15:8] ⊕ %rax_xorb_rh_rh[15:8]

Final state
%rax/%ah: ((%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8])[63:16] ∘ (%rbx_xorb_rh_rh[15:8] ⊕ %rax_xorb_rh_rh[15:8]) ∘ ((%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8])[7:0]

%cf: false
%pf: !((%rbx_xorb_rh_rh[8:8] ⊕ %rax_xorb_rh_rh[8:8]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[9:9] ⊕ %rax_xorb_rh_rh[9:9]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[10:10] ⊕ %rax_xorb_rh_rh[10:10]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[11:11] ⊕ %rax_xorb_rh_rh[11:11]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[12:12] ⊕ %rax_xorb_rh_rh[12:12]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[13:13] ⊕ %rax_xorb_rh_rh[13:13]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[14:14] ⊕ %rax_xorb_rh_rh[14:14]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[15:15] ⊕ %rax_xorb_rh_rh[15:15]) = 0x1₁)
%zf: (%rbx_xorb_rh_rh[15:8] ⊕ %rax_xorb_rh_rh[15:8]) = 0x0₈
%sf: (%rbx_xorb_rh_rh[15:15] ⊕ %rax_xorb_rh_rh[15:15]) = 0x1₁
%of: false

=====================================
=====================================
Computing circuit for xorb %bh, %bh

.target:
xorb %al, %al
xaddb %al, %bh
xorb %al, %ah
retq 

Initial state:
%rbx/%bh: ((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆)

%cf: %cf_cmc
%pf: !((%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁ ⊕ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁)
%zf: (%cf_cmc ? 0x0₁₆ : 0xffff₁₆) = 0x0₁₆
%sf: (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁
%of: false ∧ !(false ↔ (%cf_cmc ? 0x0₁ : 0x1₁) = 0x1₁)

State for specgen instruction: xorb %bh, %ah:
%rax/%ah: ((%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8])[63:16] ∘ (%rbx_xorb_rh_rh[15:8] ⊕ %rax_xorb_rh_rh[15:8]) ∘ ((%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8])[7:0]

%cf: false
%pf: !((%rbx_xorb_rh_rh[8:8] ⊕ %rax_xorb_rh_rh[8:8]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[9:9] ⊕ %rax_xorb_rh_rh[9:9]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[10:10] ⊕ %rax_xorb_rh_rh[10:10]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[11:11] ⊕ %rax_xorb_rh_rh[11:11]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[12:12] ⊕ %rax_xorb_rh_rh[12:12]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[13:13] ⊕ %rax_xorb_rh_rh[13:13]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[14:14] ⊕ %rax_xorb_rh_rh[14:14]) = 0x1₁ ⊕ (%rbx_xorb_rh_rh[15:15] ⊕ %rax_xorb_rh_rh[15:15]) = 0x1₁)
%zf: (%rbx_xorb_rh_rh[15:8] ⊕ %rax_xorb_rh_rh[15:8]) = 0x0₈
%sf: (%rbx_xorb_rh_rh[15:15] ⊕ %rax_xorb_rh_rh[15:15]) = 0x1₁
%of: false

Register        -> %ah
  translates to => %bh
Value is               -> (((%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8])[63:16] ∘ (%rbx_xorb_rh_rh[15:8] ⊕ %rax_xorb_rh_rh[15:8]) ∘ ((%rax_xorb_rh_rh[63:8] ∘ 0x0₈)[63:8] ∘ %rbx_xorb_rh_rh[15:8])[7:0])[15:8]
  after renaming it is => 0x0₈

Final state
%rbx/%bh: (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0]

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for adcb %bl, %bl

Final state:
%rbx/%bl: ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[63:8] ∘ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0][3:0] + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:0][7:7] = 0x1₁
%of: (((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0][7:7] = 0x1₁ ↔ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0][7:7] = 0x1₁) ∧ !(((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for cmc 

.target:
callq .read_cf_into_rbx
callq .move_064_032_rbx_r8d_r9d
callq .move_r8b_to_byte_5_of_rbx
decw %bx
xorb %bh, %bh
adcb %bl, %bl
retq 

Initial state:
%cf: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[64:64] = 0x1₁

State for specgen instruction: cmc :
%cf: ((false ? 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0]) + 0x0₁ ∘ ((((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[63:16] ∘ 0x0₈ ∘ (((0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[63:48] ∘ (0x0₃₂ ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[31:0])[7:0] ∘ (0x0₆₃ ∘ (%cf_cmc ? 0x1₁ : 0x0₁))[39:0])[63:16] ∘ (%cf_cmc ? 0x0₁₆ : 0xffff₁₆))[7:0])[7:0])[8:8] = 0x1₁

Final state
%cf: (((0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %rbx_subq_r64_r64)[64:64] = 0x1₁ ? 0x0₉ : 0xff₉) + ((0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %rbx_subq_r64_r64)[64:64] = 0x1₁ ? 0x0₉ : 0xff₉))[8:8] = 0x1₁

=====================================
=====================================
Computing circuit for subq %r8, %r10

.target:
stc 
notq %rcx
adcq %rcx, %rbx
cmc 
retq 

Initial state:
%r10/%r10: %ymm2_vpsubq_xmm_xmm_xmm[127:0][63:0]

%cf: (((0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[64:64] = 0x1₁ ? 0x0₉ : 0xff₉) + ((0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[64:64] = 0x1₁ ? 0x0₉ : 0xff₉))[8:8] = 0x1₁
%pf: !((0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[7:7] = 0x1₁)
%af: (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[67:64] ⊕ 0xf₄) + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[67:64])[4:4] = 0x1₁
%zf: (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[63:63] = 0x1₁
%of: ((%ymm3_vpsubq_xmm_xmm_xmm[127:127] ⊕ 0x1₁) = 0x1₁ ↔ %ymm2_vpsubq_xmm_xmm_xmm[127:127] = 0x1₁) ∧ !((%ymm3_vpsubq_xmm_xmm_xmm[127:127] ⊕ 0x1₁) = 0x1₁ ↔ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[63:63] = 0x1₁)

State for specgen instruction: subq %rcx, %rbx:
%rbx/%rbx: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0]

%cf: (((0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %rbx_subq_r64_r64)[64:64] = 0x1₁ ? 0x0₉ : 0xff₉) + ((0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %rbx_subq_r64_r64)[64:64] = 0x1₁ ? 0x0₉ : 0xff₉))[8:8] = 0x1₁
%pf: !(((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][0:0] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][1:1] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][2:2] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][3:3] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][4:4] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][5:5] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][6:6] = 0x1₁ ⊕ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)[3:0] + 0x0₁ ∘ %rbx_subq_r64_r64[3:0])[4:4] = 0x1₁
%zf: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0] = 0x0₆₄
%sf: ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0][63:63] = 0x1₁
%of: ((%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)[63:63] = 0x1₁ ↔ %rbx_subq_r64_r64[63:63] = 0x1₁) ∧ !((%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)[63:63] = 0x1₁ ↔ ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r10
Value is               -> ((true ? 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ : 0x0₁ ∘ (%rcx_subq_r64_r64 ⊕ 0xffffffffffffffff₆₄)) + 0x0₁ ∘ %rbx_subq_r64_r64)[63:0]
  after renaming it is => (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[63:0]

Final state
%r10/%r10: (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[63:0]

%cf: (((0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[64:64] = 0x1₁ ? 0x0₉ : 0xff₉) + ((0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[64:64] = 0x1₁ ? 0x0₉ : 0xff₉))[8:8] = 0x1₁
%pf: !((0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[3:0] ⊕ 0xf₄) + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[63:63] = 0x1₁
%of: ((%ymm3_vpsubq_xmm_xmm_xmm[63:63] ⊕ 0x1₁) = 0x1₁ ↔ %ymm2_vpsubq_xmm_xmm_xmm[63:63] = 0x1₁) ∧ !((%ymm3_vpsubq_xmm_xmm_xmm[63:63] ⊕ 0x1₁) = 0x1₁ ↔ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpsubq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpsubq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[63:0][63:0] ∘ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpsubq %xmm3, %xmm5, %xmm9

.target:
callq .move_128_064_xmm2_r10_r11
callq .move_128_064_xmm3_r8_r9
vzeroall 
subq %r9, %r11
subq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_pmovsxwd_xmm_xmm

State for specgen instruction: vpsubq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[127:64] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[127:64])[63:0][63:0] ∘ (0x0₁ ∘ (%ymm3_vpsubq_xmm_xmm_xmm[63:0] ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ %ymm2_vpsubq_xmm_xmm_xmm[63:0])[63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ ((0x0₁ ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[47:32]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]))[15:0])))[63:0] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[15:0]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[15:0])))[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_movaps_xmm_xmm
%rdx/%rdx: %rdx_movaps_xmm_xmm

%xmm0: %ymm0_movaps_xmm_xmm[127:0]
%xmm1: %ymm1_movaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1

Final state:
%rax/%rax: %rax_movaps_xmm_xmm
%rdx/%rdx: %rdx_movaps_xmm_xmm

%xmm0: %ymm0_movaps_xmm_xmm[127:0]
%xmm1: (%ymm1_movaps_xmm_xmm[255:128] ∘ ((%ymm7_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm6_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm5_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (%ymm4_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][31:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movaps %xmm9, %xmm1

.target:
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1
retq 

Initial state:
%xmm1: %ymm1_pmovsxwd_xmm_xmm[127:0]

State for specgen instruction: movaps %xmm2, %xmm1:
%xmm1: (%ymm1_movaps_xmm_xmm[255:128] ∘ ((%ymm7_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm6_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm5_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (%ymm4_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][31:0]))[127:0][31:0]))[127:0]

Final state
%xmm1: (%ymm1_pmovsxwd_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[47:32]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]))[15:0])))[63:0] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[15:0]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[15:0])))[63:32] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[15:0]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[15:0])))[31:0]))[127:0]

=====================================
=====================================
Computing circuit for pmovsxwd %xmm11, %xmm12

.target:
vmovsd %xmm2, %xmm2, %xmm0
vmaxsd %xmm0, %xmm0, %xmm15
pmovzxwd %xmm15, %xmm3
vpaddd %xmm2, %xmm2, %xmm2
vpmovzxwd %xmm2, %ymm5
vpsubq %xmm3, %xmm5, %xmm9
movaps %xmm9, %xmm1
retq 

Initial state:
%xmm12: (%ymm12_vpmovsxwd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vpmovsxwd_ymm_xmm[127:0][63:0]))[127:0]

State for specgen instruction: pmovsxwd %xmm2, %xmm1:
%xmm1: (%ymm1_pmovsxwd_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[47:32]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[63:32] ∘ %ymm2_pmovsxwd_xmm_xmm[63:32]))[15:0])))[63:0] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[15:0]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[15:0])))[63:32] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovsxwd_xmm_xmm[15:0]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_pmovsxwd_xmm_xmm[31:0] ∘ %ymm2_pmovsxwd_xmm_xmm[31:0]))[15:0])))[31:0]))[127:0]

Final state
%xmm12: ((%ymm12_vpmovsxwd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vpmovsxwd_ymm_xmm[127:0][63:0]))[255:128] ∘ ((0x0₁ ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[47:32]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[63:32] ∘ %ymm2_vpmovsxwd_ymm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[63:32] ∘ %ymm2_vpmovsxwd_ymm_xmm[63:32]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[63:32] ∘ %ymm2_vpmovsxwd_ymm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[63:32] ∘ %ymm2_vpmovsxwd_ymm_xmm[63:32]))[15:0])))[63:0] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[15:0]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[31:0] ∘ %ymm2_vpmovsxwd_ymm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[31:0] ∘ %ymm2_vpmovsxwd_ymm_xmm[31:0]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[31:0] ∘ %ymm2_vpmovsxwd_ymm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[31:0] ∘ %ymm2_vpmovsxwd_ymm_xmm[31:0]))[15:0])))[63:32] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[15:0]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[31:0] ∘ %ymm2_vpmovsxwd_ymm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[31:0] ∘ %ymm2_vpmovsxwd_ymm_xmm[31:0]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[31:0] ∘ %ymm2_vpmovsxwd_ymm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[31:0] ∘ %ymm2_vpmovsxwd_ymm_xmm[31:0]))[15:0])))[31:0]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm3

Final state:
%rax/%rax: %rax_vpmovsxwd_ymm_xmm
%rdx/%rdx: %rdx_vpmovsxwd_ymm_xmm

%xmm0: %ymm0_vpmovsxwd_ymm_xmm[127:0]
%xmm1: %ymm1_vpmovsxwd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm2, %ymm1

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovaps_ymm_ymm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm1: %ymm2_vmovaps_ymm_ymm

=====================================
=====================================
Computing circuit for vmovaps %ymm3, %ymm1

.target:
vmovdqa %ymm2, %ymm1
retq 

Initial state:
%ymm1: %ymm1_vpmovsxwd_ymm_xmm

State for specgen instruction: vmovaps %ymm2, %ymm1:
%ymm1: %ymm2_vmovaps_ymm_ymm

Final state
%ymm1: (0x0₁ ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[127:112] ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[111:96]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[127:96] ∘ %ymm2_vpmovsxwd_ymm_xmm[127:96]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[127:96] ∘ %ymm2_vpmovsxwd_ymm_xmm[127:96]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[127:96] ∘ %ymm2_vpmovsxwd_ymm_xmm[127:96]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[127:96] ∘ %ymm2_vpmovsxwd_ymm_xmm[127:96]))[15:0])))[63:0] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[95:80] ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[79:64]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[95:64] ∘ %ymm2_vpmovsxwd_ymm_xmm[95:64]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[95:64] ∘ %ymm2_vpmovsxwd_ymm_xmm[95:64]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[95:64] ∘ %ymm2_vpmovsxwd_ymm_xmm[95:64]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[95:64] ∘ %ymm2_vpmovsxwd_ymm_xmm[95:64]))[15:0])))[63:32] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[95:80] ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[79:64]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[95:64] ∘ %ymm2_vpmovsxwd_ymm_xmm[95:64]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[95:64] ∘ %ymm2_vpmovsxwd_ymm_xmm[95:64]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[95:64] ∘ %ymm2_vpmovsxwd_ymm_xmm[95:64]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[95:64] ∘ %ymm2_vpmovsxwd_ymm_xmm[95:64]))[15:0])))[31:0] ∘ ((0x0₁ ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[47:32]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[63:32] ∘ %ymm2_vpmovsxwd_ymm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[63:32] ∘ %ymm2_vpmovsxwd_ymm_xmm[63:32]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[63:32] ∘ %ymm2_vpmovsxwd_ymm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[63:32] ∘ %ymm2_vpmovsxwd_ymm_xmm[63:32]))[15:0])))[63:0] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[15:0]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[31:0] ∘ %ymm2_vpmovsxwd_ymm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[31:0] ∘ %ymm2_vpmovsxwd_ymm_xmm[31:0]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[31:0] ∘ %ymm2_vpmovsxwd_ymm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[31:0] ∘ %ymm2_vpmovsxwd_ymm_xmm[31:0]))[15:0])))[63:32] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[15:0]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[31:0] ∘ %ymm2_vpmovsxwd_ymm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[31:0] ∘ %ymm2_vpmovsxwd_ymm_xmm[31:0]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[31:0] ∘ %ymm2_vpmovsxwd_ymm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[31:0] ∘ %ymm2_vpmovsxwd_ymm_xmm[31:0]))[15:0])))[31:0])

=====================================
=====================================
Computing circuit for vpmovsxwd %xmm2, %ymm1

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vmovq %xmm12, %xmm11
pmovsxwd %xmm13, %xmm13
pmovsxwd %xmm11, %xmm12
callq .move_128_256_xmm12_xmm13_ymm3
vmovaps %ymm3, %ymm1
retq 

Initial state:
%ymm1: %ymm1

State for specgen instruction: vpmovsxwd %xmm2, %ymm1:
%ymm1: (0x0₁ ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[127:112] ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[111:96]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[127:96] ∘ %ymm2_vpmovsxwd_ymm_xmm[127:96]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[127:96] ∘ %ymm2_vpmovsxwd_ymm_xmm[127:96]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[127:96] ∘ %ymm2_vpmovsxwd_ymm_xmm[127:96]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[127:96] ∘ %ymm2_vpmovsxwd_ymm_xmm[127:96]))[15:0])))[63:0] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[95:80] ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[79:64]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[95:64] ∘ %ymm2_vpmovsxwd_ymm_xmm[95:64]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[95:64] ∘ %ymm2_vpmovsxwd_ymm_xmm[95:64]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[95:64] ∘ %ymm2_vpmovsxwd_ymm_xmm[95:64]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[95:64] ∘ %ymm2_vpmovsxwd_ymm_xmm[95:64]))[15:0])))[63:32] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[95:80] ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[79:64]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[95:64] ∘ %ymm2_vpmovsxwd_ymm_xmm[95:64]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[95:64] ∘ %ymm2_vpmovsxwd_ymm_xmm[95:64]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[95:64] ∘ %ymm2_vpmovsxwd_ymm_xmm[95:64]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[95:64] ∘ %ymm2_vpmovsxwd_ymm_xmm[95:64]))[15:0])))[31:0] ∘ ((0x0₁ ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[47:32]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[63:32] ∘ %ymm2_vpmovsxwd_ymm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[63:32] ∘ %ymm2_vpmovsxwd_ymm_xmm[63:32]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[63:32] ∘ %ymm2_vpmovsxwd_ymm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[63:32] ∘ %ymm2_vpmovsxwd_ymm_xmm[63:32]))[15:0])))[63:0] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[15:0]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[31:0] ∘ %ymm2_vpmovsxwd_ymm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[31:0] ∘ %ymm2_vpmovsxwd_ymm_xmm[31:0]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[31:0] ∘ %ymm2_vpmovsxwd_ymm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[31:0] ∘ %ymm2_vpmovsxwd_ymm_xmm[31:0]))[15:0])))[63:32] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovsxwd_ymm_xmm[15:0]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[31:0] ∘ %ymm2_vpmovsxwd_ymm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[31:0] ∘ %ymm2_vpmovsxwd_ymm_xmm[31:0]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[31:0] ∘ %ymm2_vpmovsxwd_ymm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_vpmovsxwd_ymm_xmm[31:0] ∘ %ymm2_vpmovsxwd_ymm_xmm[31:0]))[15:0])))[31:0])

Final state
%ymm1: (0x0₁ ∘ (0x0₁₆ ∘ %ymm2[127:112] ∘ (0x0₁₆ ∘ %ymm2[111:96]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2[127:96] ∘ %ymm2[127:96]) + 0x0₁ ∘ (%ymm2[127:96] ∘ %ymm2[127:96]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2[127:96] ∘ %ymm2[127:96]) + 0x0₁ ∘ (%ymm2[127:96] ∘ %ymm2[127:96]))[15:0])))[63:0] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2[95:80] ∘ (0x0₁₆ ∘ %ymm2[79:64]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2[95:64] ∘ %ymm2[95:64]) + 0x0₁ ∘ (%ymm2[95:64] ∘ %ymm2[95:64]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2[95:64] ∘ %ymm2[95:64]) + 0x0₁ ∘ (%ymm2[95:64] ∘ %ymm2[95:64]))[15:0])))[63:32] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2[95:80] ∘ (0x0₁₆ ∘ %ymm2[79:64]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2[95:64] ∘ %ymm2[95:64]) + 0x0₁ ∘ (%ymm2[95:64] ∘ %ymm2[95:64]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2[95:64] ∘ %ymm2[95:64]) + 0x0₁ ∘ (%ymm2[95:64] ∘ %ymm2[95:64]))[15:0])))[31:0] ∘ ((0x0₁ ∘ (0x0₁₆ ∘ %ymm2[63:48] ∘ (0x0₁₆ ∘ %ymm2[47:32]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2[63:32] ∘ %ymm2[63:32]) + 0x0₁ ∘ (%ymm2[63:32] ∘ %ymm2[63:32]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2[63:32] ∘ %ymm2[63:32]) + 0x0₁ ∘ (%ymm2[63:32] ∘ %ymm2[63:32]))[15:0])))[63:0] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2[31:16] ∘ (0x0₁₆ ∘ %ymm2[15:0]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2[31:0] ∘ %ymm2[31:0]) + 0x0₁ ∘ (%ymm2[31:0] ∘ %ymm2[31:0]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2[31:0] ∘ %ymm2[31:0]) + 0x0₁ ∘ (%ymm2[31:0] ∘ %ymm2[31:0]))[15:0])))[63:32] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2[31:16] ∘ (0x0₁₆ ∘ %ymm2[15:0]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2[31:0] ∘ %ymm2[31:0]) + 0x0₁ ∘ (%ymm2[31:0] ∘ %ymm2[31:0]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2[31:0] ∘ %ymm2[31:0]) + 0x0₁ ∘ (%ymm2[31:0] ∘ %ymm2[31:0]))[15:0])))[31:0])

=====================================
Circuits:

%ymm1  : (0x0₁ ∘ (0x0₁₆ ∘ %ymm2[127:112] ∘ (0x0₁₆ ∘ %ymm2[111:96]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2[127:96] ∘ %ymm2[127:96]) + 0x0₁ ∘ (%ymm2[127:96] ∘ %ymm2[127:96]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2[127:96] ∘ %ymm2[127:96]) + 0x0₁ ∘ (%ymm2[127:96] ∘ %ymm2[127:96]))[15:0])))[63:0] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2[95:80] ∘ (0x0₁₆ ∘ %ymm2[79:64]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2[95:64] ∘ %ymm2[95:64]) + 0x0₁ ∘ (%ymm2[95:64] ∘ %ymm2[95:64]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2[95:64] ∘ %ymm2[95:64]) + 0x0₁ ∘ (%ymm2[95:64] ∘ %ymm2[95:64]))[15:0])))[63:32] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2[95:80] ∘ (0x0₁₆ ∘ %ymm2[79:64]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2[95:64] ∘ %ymm2[95:64]) + 0x0₁ ∘ (%ymm2[95:64] ∘ %ymm2[95:64]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2[95:64] ∘ %ymm2[95:64]) + 0x0₁ ∘ (%ymm2[95:64] ∘ %ymm2[95:64]))[15:0])))[31:0] ∘ ((0x0₁ ∘ (0x0₁₆ ∘ %ymm2[63:48] ∘ (0x0₁₆ ∘ %ymm2[47:32]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2[63:32] ∘ %ymm2[63:32]) + 0x0₁ ∘ (%ymm2[63:32] ∘ %ymm2[63:32]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2[63:32] ∘ %ymm2[63:32]) + 0x0₁ ∘ (%ymm2[63:32] ∘ %ymm2[63:32]))[15:0])))[63:0] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2[31:16] ∘ (0x0₁₆ ∘ %ymm2[15:0]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2[31:0] ∘ %ymm2[31:0]) + 0x0₁ ∘ (%ymm2[31:0] ∘ %ymm2[31:0]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2[31:0] ∘ %ymm2[31:0]) + 0x0₁ ∘ (%ymm2[31:0] ∘ %ymm2[31:0]))[15:0])))[63:32] ∘ (0x0₁ ∘ (0x0₁₆ ∘ %ymm2[31:16] ∘ (0x0₁₆ ∘ %ymm2[15:0]) ⊕ 0xffffffffffffffff₆₄) + 0x1₆₅ + 0x0₁ ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2[31:0] ∘ %ymm2[31:0]) + 0x0₁ ∘ (%ymm2[31:0] ∘ %ymm2[31:0]))[31:16] ∘ (0x0₁₆ ∘ (0x0₁ ∘ (%ymm2[31:0] ∘ %ymm2[31:0]) + 0x0₁ ∘ (%ymm2[31:0] ∘ %ymm2[31:0]))[15:0])))[31:0])

sigfpe  : sigfpe
sigbus  : sigbus
sigsegv : sigsegv

*/