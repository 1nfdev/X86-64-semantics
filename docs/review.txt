Brief Summary 
==============

The paper aims to convert stripped binary (without debug metadata) to a high
level compiler IR and try to recover the variables (both for scalars or
    arrays), which will in turn help in various analysis, transformations  and
optimizations ( like data flow analysis, symbolic execution or automatic
    parallelization (by recovering the stack resident induction variable).

At the very onset the paper describes the several motivations of such reverse
engineering.  To name a few: Analyzing code for vulnerabilities, recovering
source code of legacy software, optimizing un-optimized binaries or porting
legacy code to different configurations. 

The major contribution comes from symbol promotion  after deconstruction of
physical stack frame to local (per procedure) stack frames. Also they clearly
mention a scenario where another state of the art method like Divine can
recognize the abstract location but cannot go for symbol promotion because of
potentially aliasing memory references. Also interesting is the way they
incorporated a cost metric to decide when it is beneficial to do symbol
promotion.  Their framework allows stack modification which in-turn provides
compile time security enforcement. 

At the end they show the effectiveness of there implementation by testing different features. Some are
1. Run time of rewritten binary w.r.t. run time of un optimized binary 
2. Run time of rewritten binary w.r.t. run time of  optimized binary 
3. How well the symbol promotion is doing based on number of symbols promoted
w.r.t the symbolic references obtained from source via debug information.
4. Impact of promoted symbols in terms of improved data flow graph and
effective symbolic execution on recovered IR ( using KLEE).

Strong points
-----------------------

In my opinion the major strong points are promotion of array variables and
Extension to other ISA.  Added with the fact that their rewritten binaries are
fully functional proves the effectiveness and generality of their strategy.
Another  interesting strong point is the improvements in the symbol promotion
strategy like variable argument external procedure and Aliased Stack Locations.
The paper also added substantial experimental results to prove the effectiveness of their
approach.

Major weak points. 
-----------------------
1. Section 2: Contributions : Deconstruction of physical stack frame

The author mentions that 

"Our analysis in Section 5 defines a source-level stack model and checks if the
executable conforms to this model. This model checks where a runtime stack is
maintained, and stack activation records are created upon procedure entry and
destroyed upon exit. If the model is verified for a procedure, the analysis
discovers the arguments statically when possible, but when not possible, embeds
run-time checks in IR to maintain the correctness of inter-procedural
data-flow.  Otherwise, stack abstraction is discontinued only in that
procedure."

If the stack abstraction is like Fig 1(c), (i.e. without global pointers), then
it is  not clear how are you going to discontinue stack abstraction only in a
particular procedure without affecting the rest.  Needed some elaboration.


2. Section 5.1: Representing the local stack frame

Please elaborate: 
"Neither can multiple local arrays, one per such stack increment, be allocated
since IR optimizations and compiler backend can modify their relative layout
thereby invalidating the stack arithmetic."

3. I believe while doing the testing they are also checking if the output
obtained from input binary is the same as that generated by rewritten binary.
This helps in strengthening  the fact the the recovered IR is fully functional.
But I could not find a mention of that.

4. In page 22 of 41, last paragraph: if the Balance Number value is determined
as 0, then how line 4 be a direct access to a-loc at offset 16.  I think Line 2
is the direct access to offset 16, not Line 4.

5. It would to nice  to show the effectiveness of promotion of stack array
variables, in isolation to promotion of scalar variables,  in enhancing the
precision of some static analysis.  These results would demonstrate the quality
of array variable promotions in isolation. Right now it is not clear what is
the contribution of array variable promotion in enhancing the precision of
Symbolic Execution (section 9.8) and Automatic Parallelization (section 9.9) 

6. I am not sure about the purpose of  comparing of analysis time of
SecondWrite with compilation time of original source-code with gcc.  In my
opinion it would make more sense to compare with compilation time of original
source-code with same compiler tool chain like LLVM.

7. Section: Results
[ Not very important, but some people might be interested to know] what are the
other advanced instructions which are not yet supported. 

8. Section 9.5: Un-optimized input binaries
Is there any specific reason for having the input binaries generated using gcc
and comparing the run time of those with that of re-written binaries compiled
using LLVM.  I think compiling both input and re-written binaries with the same
compiler tool chain makes comparison result more useful.

9. Section 9.2: Symbol Promotion
It is not clear why only 30% of the array variables are promoted? Are the
remaining 70% arrays recognized (by variable detection technique [Balakrishnan
    and Reps 2007]) but not promoted, OR they are not recognized at all.

10. Section 9.6: Optimized input binary

This sections shows the normalized execution time of each rewritten binary
compared to an input binary produced using gcc with the highest-available level
of optimization (-O3 flag). In this case, they obtain an average improvement of
6.5% in execution time.  Which optimization level of llvm-opt are authors using
while re-writing the binary?

Also the authors mentioned that for hmmer (spec 2006), they got 38% improvement
  because LLVM opt did some optimization which gcc (-O3) missed to do. It would
  be  nice to have the normalized execution time of each rewritten binary
  compared to an input binary produced using LLVM with the highest-available
level of optimization (-O3 flag)

It would be interesting here to know if the re-written binary opens up
opportunities of LLVM optimizations which are otherwise not possible in the
input binary (already optimized with llvm to highest)

11. Section 9.7: Impact of symbol promotion 

It is mentioned that symbol promotion is responsible for improving the average
performance of rewritten binary w.r.t both optimized and unoptimized versions
binary. It will make sense to mention the threshold used for symbol promotion
at this place. I believe the improvement comes from the fact that after symbol
promotion direct stack  memory access get promoted to  symbol accesses and that
depends on the threshold of promotion. With no threshold, the framework can
achieve 100% symbol promotion, at the cost of  high overhead in the rewritten
binaries due to Promoting Loads and Promoting Stores.

12. While comparing with DIVINE, the authors clearly mention the scenarios
where DIVINE cannot do variable promotion even after identifying them due to
presence of potentially aliasing memory references. In those cases, this work 
adds promoting loads and stores to promote the memory access to symbol.

It would be nice to compare the scalar/array variable identification and promotion method
mentioned in this paper with DIVINE's strategy of variable recovery (including aggregates). This will give an idea about
how often are the situation when DIVINE fail to do promotion. This will also help 
us to understand the overhead of adding promoting load and stores in cases of potentially aliasing memory references.
