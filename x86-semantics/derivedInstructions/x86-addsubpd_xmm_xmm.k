// Autogenerated using stratification.
requires "x86-configuration.k"

module ADDSUBPD-XMM-XMM
  imports X86-CONFIGURATION

  rule <k>
    execinstr (addsubpd R1:Xmm, R2:Xmm,  .Typedoperands) => .
  ...</k>
    <regstate>
RSMap:Map => updateMap(RSMap,
convToRegKeys(R2) |-> (concatenateMInt(extractMInt(getParentValue(R2, RSMap), 0, 128), concatenateMInt(Float2MInt( ( MInt2Float(extractMInt(getParentValue(R1, RSMap), 128, 192), 53, 11)  +Float  MInt2Float(extractMInt(getParentValue(R2, RSMap), 128, 192), 53, 11) ) , 64), Float2MInt( ( MInt2Float(extractMInt(getParentValue(R2, RSMap), 192, 256), 53, 11)  -Float  MInt2Float(extractMInt(getParentValue(R1, RSMap), 192, 256), 53, 11) ) , 64))) )


)

    </regstate>
endmodule

module ADDSUBPD-XMM-XMM-SEMANTICS
  imports ADDSUBPD-XMM-XMM
endmodule
/*
TargetInstr:
addsubpd %xmm2, %xmm1
RWSet:
maybe read:{ %xmm1 %xmm2 }
must read:{ %xmm1 %xmm2 }
maybe write:{ %xmm1 }
must write:{ %xmm1 }
maybe undef:{ }
must undef:{ }
required flags:{ pni }

Circuit:
circuit:callq .move_byte_6_of_ymm1_to_r8b  #  1     0     5      OPC=callq_label
circuit:vsubsd %xmm2, %xmm1, %xmm3         #  2     0x5   4      OPC=vsubsd_xmm_xmm_xmm
circuit:callq .move_r8b_to_byte_4_of_ymm1  #  3     0x9   5      OPC=callq_label
circuit:vsqrtss %xmm1, %xmm2, %xmm13       #  4     0xe   4      OPC=vsqrtss_xmm_xmm_xmm
circuit:addpd %xmm13, %xmm1                #  5     0x12  5      OPC=addpd_xmm_xmm
circuit:movsd %xmm3, %xmm1                 #  6     0x17  4      OPC=movsd_xmm_xmm
BVF:
WARNING: No live out values provided, assuming { }
WARNING: No def in values provided; assuming { %mxcsr::rc[0] }
Target

addsubpd %xmm2, %xmm1

  maybe read:      { %xmm1 %xmm2 }
  must read:       { %xmm1 %xmm2 }
  maybe write:     { %xmm1 }
  must write:      { %xmm1 }
  maybe undef:     { }
  must undef:      { }
  required flags:  { pni }

-------------------------------------
Getting base circuit for callq .move_byte_6_of_ymm1_to_r8b

Final state:
%rax/%rax: %rax_addsubpd_xmm_xmm
%rdx/%rdx: %rdx_addsubpd_xmm_xmm

%xmm0: %ymm0_addsubpd_xmm_xmm[127:0]
%xmm1: %ymm1_addsubpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vsubsd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vsubsd_xmm_xmm_xmm

%xmm0: %ymm0_vsubsd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vsubsd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vsubpd_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vsubpd_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm3, %xmm7

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm7: %ymm7_vsubpd_xmm_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm7: 0x0₁₂₈ ∘ %ymm3_vsubpd_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vsubpd %ymm7, %ymm1, %ymm1

Final state:
%ymm1: sub_double((0x0₁₂₈ ∘ %ymm2_vsubpd_xmm_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm3_vsubpd_xmm_xmm_xmm[127:0])[255:192]) ∘ (sub_double((0x0₁₂₈ ∘ %ymm2_vsubpd_xmm_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm3_vsubpd_xmm_xmm_xmm[127:0])[191:128]) ∘ (sub_double((0x0₁₂₈ ∘ %ymm2_vsubpd_xmm_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm3_vsubpd_xmm_xmm_xmm[127:0])[127:64]) ∘ sub_double((0x0₁₂₈ ∘ %ymm2_vsubpd_xmm_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm3_vsubpd_xmm_xmm_xmm[127:0])[63:0])))

-------------------------------------
=====================================
Computing circuit for vsubpd %xmm3, %xmm8, %xmm0

.target:
vmovupd %xmm2, %xmm1
vmovaps %xmm3, %xmm7
vsubpd %ymm7, %ymm1, %ymm1
retq 

Initial state:
%ymm0: %ymm0_vsubsd_xmm_xmm_xmm

State for specgen instruction: vsubpd %xmm3, %xmm2, %xmm1:
%ymm1: sub_double((0x0₁₂₈ ∘ %ymm2_vsubpd_xmm_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm3_vsubpd_xmm_xmm_xmm[127:0])[255:192]) ∘ (sub_double((0x0₁₂₈ ∘ %ymm2_vsubpd_xmm_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm3_vsubpd_xmm_xmm_xmm[127:0])[191:128]) ∘ (sub_double((0x0₁₂₈ ∘ %ymm2_vsubpd_xmm_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm3_vsubpd_xmm_xmm_xmm[127:0])[127:64]) ∘ sub_double((0x0₁₂₈ ∘ %ymm2_vsubpd_xmm_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm3_vsubpd_xmm_xmm_xmm[127:0])[63:0])))

Final state
%ymm0: 0x0₆₄ ∘ (0x0₆₄ ∘ (sub_double(0x0₆₄, %ymm3_vsubsd_xmm_xmm_xmm[127:64]) ∘ sub_double(%ymm2_vsubsd_xmm_xmm_xmm[63:0], %ymm3_vsubsd_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm9, %xmm0, %xmm1

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vsubsd_xmm_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vsubsd_xmm_xmm_xmm[127:64] ∘ sub_double(%ymm2_vsubsd_xmm_xmm_xmm[63:0], %ymm3_vsubsd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vsubsd %xmm2, %xmm1, %xmm3

.target:
callq .move_128_64_xmm2_xmm8_xmm9
vsubpd %xmm3, %xmm8, %xmm0
vunpcklpd %xmm9, %xmm0, %xmm1
retq 

Initial state:
%ymm3: %ymm3_addsubpd_xmm_xmm

State for specgen instruction: vsubsd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vsubsd_xmm_xmm_xmm[127:64] ∘ sub_double(%ymm2_vsubsd_xmm_xmm_xmm[63:0], %ymm3_vsubsd_xmm_xmm_xmm[63:0]))

Final state
%ymm3: 0x0₁₂₈ ∘ (%ymm1_addsubpd_xmm_xmm[127:64] ∘ sub_double(%ymm1_addsubpd_xmm_xmm[63:0], %ymm2_addsubpd_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_r8b_to_byte_4_of_ymm1

Final state:
%rax/%rax: %rax_addsubpd_xmm_xmm
%rdx/%rdx: %rdx_addsubpd_xmm_xmm

%xmm0: %ymm0_addsubpd_xmm_xmm[127:0]
%xmm1: (%ymm1_addsubpd_xmm_xmm[255:40] ∘ (%r8_addsubpd_xmm_xmm[63:8] ∘ %ymm1_addsubpd_xmm_xmm[55:48])[7:0] ∘ %ymm1_addsubpd_xmm_xmm[31:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vsqrtss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vsqrtss_xmm_xmm_xmm

%xmm0: %ymm0_vsqrtss_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vsqrtss_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: %ymm0_vmovups_xmm_xmm[127:0]
%xmm1: %ymm1_vmovups_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovups %xmm3, %xmm9

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmulss_xmm_xmm_xmm

State for specgen instruction: vmovups %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ %ymm3_vmulss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm1, %xmm0

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm0: %ymm0_mulss_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm0: (%ymm0_mulss_xmm_xmm[255:128] ∘ %ymm1_mulss_xmm_xmm[127:0])[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_mulss_xmm_xmm
%rdx/%rdx: %rdx_mulss_xmm_xmm

%xmm0: (%ymm0_mulss_xmm_xmm[255:128] ∘ %ymm1_mulss_xmm_xmm[127:0])[127:0]
%xmm1: %ymm1_mulss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vmulps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmulps_xmm_xmm_xmm

%xmm0: %ymm0_vmulps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vmulps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmulps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmulps_xmm_xmm_xmm

%xmm0: %ymm0_vmulps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vmulps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vmulps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmulps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vmulps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmulps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vmulps %ymm1, %ymm2, %ymm1

Final state:
%ymm1: mul_single((0x0₂₅₆[255:128] ∘ (%ymm2_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[255:224], (0x0₂₅₆[255:128] ∘ (%ymm3_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (mul_single((0x0₂₅₆[255:128] ∘ (%ymm2_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[223:192], (0x0₂₅₆[255:128] ∘ (%ymm3_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (mul_single((0x0₂₅₆[255:128] ∘ (%ymm2_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[191:160], (0x0₂₅₆[255:128] ∘ (%ymm3_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (mul_single((0x0₂₅₆[255:128] ∘ (%ymm2_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[159:128], (0x0₂₅₆[255:128] ∘ (%ymm3_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (mul_single((0x0₂₅₆[255:128] ∘ (%ymm2_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[127:96], (0x0₂₅₆[255:128] ∘ (%ymm3_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (mul_single((0x0₂₅₆[255:128] ∘ (%ymm2_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[95:64], (0x0₂₅₆[255:128] ∘ (%ymm3_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (mul_single((0x0₂₅₆[255:128] ∘ (%ymm2_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[63:32], (0x0₂₅₆[255:128] ∘ (%ymm3_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ mul_single((0x0₂₅₆[255:128] ∘ (%ymm2_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[31:0], (0x0₂₅₆[255:128] ∘ (%ymm3_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmulps %xmm2, %xmm0, %xmm8

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r10_r11_xmm1
callq .move_064_128_r8_r9_xmm2
vmulps %ymm1, %ymm2, %ymm1
retq 

Initial state:
%ymm8: %ymm8_mulss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_mulss_xmm_xmm[127:0][31:0])

State for specgen instruction: vmulps %xmm3, %xmm2, %xmm1:
%ymm1: mul_single((0x0₂₅₆[255:128] ∘ (%ymm2_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[255:224], (0x0₂₅₆[255:128] ∘ (%ymm3_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (mul_single((0x0₂₅₆[255:128] ∘ (%ymm2_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[223:192], (0x0₂₅₆[255:128] ∘ (%ymm3_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (mul_single((0x0₂₅₆[255:128] ∘ (%ymm2_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[191:160], (0x0₂₅₆[255:128] ∘ (%ymm3_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (mul_single((0x0₂₅₆[255:128] ∘ (%ymm2_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[159:128], (0x0₂₅₆[255:128] ∘ (%ymm3_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (mul_single((0x0₂₅₆[255:128] ∘ (%ymm2_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[127:96], (0x0₂₅₆[255:128] ∘ (%ymm3_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (mul_single((0x0₂₅₆[255:128] ∘ (%ymm2_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[95:64], (0x0₂₅₆[255:128] ∘ (%ymm3_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (mul_single((0x0₂₅₆[255:128] ∘ (%ymm2_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[63:32], (0x0₂₅₆[255:128] ∘ (%ymm3_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ mul_single((0x0₂₅₆[255:128] ∘ (%ymm2_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[31:0], (0x0₂₅₆[255:128] ∘ (%ymm3_vmulps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmulps_xmm_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

Final state
%ymm8: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (mul_single(%ymm1_mulss_xmm_xmm[127:96], %ymm2_mulss_xmm_xmm[127:96]) ∘ (mul_single(%ymm1_mulss_xmm_xmm[95:64], %ymm2_mulss_xmm_xmm[95:64]) ∘ (mul_single(%ymm1_mulss_xmm_xmm[63:32], %ymm2_mulss_xmm_xmm[63:32]) ∘ mul_single(%ymm1_mulss_xmm_xmm[31:0], %ymm2_mulss_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_mulss_xmm_xmm
%rdx/%rdx: %rdx_mulss_xmm_xmm

%xmm0: (%ymm0_mulss_xmm_xmm[255:128] ∘ %ymm1_mulss_xmm_xmm[127:0])[127:0]
%xmm1: (%ymm1_mulss_xmm_xmm[255:128] ∘ ((%ymm11_mulss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_mulss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_mulss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_mulss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_mulss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_mulss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (mul_single(%ymm1_mulss_xmm_xmm[127:96], %ymm2_mulss_xmm_xmm[127:96]) ∘ (mul_single(%ymm1_mulss_xmm_xmm[95:64], %ymm2_mulss_xmm_xmm[95:64]) ∘ (mul_single(%ymm1_mulss_xmm_xmm[63:32], %ymm2_mulss_xmm_xmm[63:32]) ∘ mul_single(%ymm1_mulss_xmm_xmm[31:0], %ymm2_mulss_xmm_xmm[31:0]))))))))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for mulss %xmm9, %xmm2

.target:
movdqa %xmm1, %xmm0
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmulps %xmm2, %xmm0, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm2: %ymm2_vmulss_xmm_xmm_xmm[127:0]

State for specgen instruction: mulss %xmm2, %xmm1:
%xmm1: (%ymm1_mulss_xmm_xmm[255:128] ∘ ((%ymm11_mulss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_mulss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_mulss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_mulss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_mulss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_mulss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (mul_single(%ymm1_mulss_xmm_xmm[127:96], %ymm2_mulss_xmm_xmm[127:96]) ∘ (mul_single(%ymm1_mulss_xmm_xmm[95:64], %ymm2_mulss_xmm_xmm[95:64]) ∘ (mul_single(%ymm1_mulss_xmm_xmm[63:32], %ymm2_mulss_xmm_xmm[63:32]) ∘ mul_single(%ymm1_mulss_xmm_xmm[31:0], %ymm2_mulss_xmm_xmm[31:0]))))))))[127:0][31:0]))[127:0]

Final state
%xmm2: (%ymm2_vmulss_xmm_xmm_xmm[255:128] ∘ (%ymm2_vmulss_xmm_xmm_xmm[127:32] ∘ mul_single(%ymm2_vmulss_xmm_xmm_xmm[31:0], %ymm3_vmulss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmulss_xmm_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmulss_xmm_xmm_xmm[127:32] ∘ mul_single(%ymm2_vmulss_xmm_xmm_xmm[31:0], %ymm3_vmulss_xmm_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmulss %xmm2, %xmm2, %xmm1

.target:
vmovups %xmm3, %xmm9
mulss %xmm9, %xmm2
vmovaps %xmm2, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vsqrtss_xmm_xmm_xmm

State for specgen instruction: vmulss %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmulss_xmm_xmm_xmm[127:32] ∘ mul_single(%ymm2_vmulss_xmm_xmm_xmm[31:0], %ymm3_vmulss_xmm_xmm_xmm[31:0]))

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vsqrtss_xmm_xmm_xmm[127:32] ∘ mul_single(%ymm2_vsqrtss_xmm_xmm_xmm[31:0], %ymm2_vsqrtss_xmm_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_sqrtss_xmm_xmm
%rdx/%rdx: %rdx_sqrtss_xmm_xmm

%xmm0: %ymm0_sqrtss_xmm_xmm[127:0]
%xmm1: %ymm1_sqrtss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm4

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm4: %ymm4_sqrtps_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm4: 0x0₁₂₈ ∘ %ymm2_sqrtps_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vsqrtps %ymm4, %ymm7

Final state:
%ymm7: sqrt_single((0x0₁₂₈ ∘ %ymm2_sqrtps_xmm_xmm[127:0])[255:224]) ∘ (sqrt_single((0x0₁₂₈ ∘ %ymm2_sqrtps_xmm_xmm[127:0])[223:192]) ∘ (sqrt_single((0x0₁₂₈ ∘ %ymm2_sqrtps_xmm_xmm[127:0])[191:160]) ∘ (sqrt_single((0x0₁₂₈ ∘ %ymm2_sqrtps_xmm_xmm[127:0])[159:128]) ∘ (sqrt_single((0x0₁₂₈ ∘ %ymm2_sqrtps_xmm_xmm[127:0])[127:96]) ∘ (sqrt_single((0x0₁₂₈ ∘ %ymm2_sqrtps_xmm_xmm[127:0])[95:64]) ∘ (sqrt_single((0x0₁₂₈ ∘ %ymm2_sqrtps_xmm_xmm[127:0])[63:32]) ∘ sqrt_single((0x0₁₂₈ ∘ %ymm2_sqrtps_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm7, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_sqrtps_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_sqrtps_xmm_xmm[255:128] ∘ (sqrt_single(%ymm2_sqrtps_xmm_xmm[127:96]) ∘ (sqrt_single(%ymm2_sqrtps_xmm_xmm[95:64]) ∘ (sqrt_single(%ymm2_sqrtps_xmm_xmm[63:32]) ∘ sqrt_single(%ymm2_sqrtps_xmm_xmm[31:0])))))[127:0]

=====================================
=====================================
Computing circuit for sqrtps %xmm8, %xmm4

.target:
vmovdqu %xmm2, %xmm4
vsqrtps %ymm4, %ymm7
movdqa %xmm7, %xmm1
retq 

Initial state:
%xmm4: %ymm4_sqrtss_xmm_xmm[127:0]

State for specgen instruction: sqrtps %xmm2, %xmm1:
%xmm1: (%ymm1_sqrtps_xmm_xmm[255:128] ∘ (sqrt_single(%ymm2_sqrtps_xmm_xmm[127:96]) ∘ (sqrt_single(%ymm2_sqrtps_xmm_xmm[95:64]) ∘ (sqrt_single(%ymm2_sqrtps_xmm_xmm[63:32]) ∘ sqrt_single(%ymm2_sqrtps_xmm_xmm[31:0])))))[127:0]

Final state
%xmm4: (%ymm4_sqrtss_xmm_xmm[255:128] ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ sqrt_single(%ymm2_sqrtss_xmm_xmm[31:0])))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm4, %xmm1, %xmm7

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm7: %ymm7_sqrtss_xmm_xmm

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm7: 0x0₁₂₈ ∘ (%ymm1_sqrtss_xmm_xmm[127:32] ∘ sqrt_single(%ymm2_sqrtss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_movups_xmm_xmm
%rdx/%rdx: %rdx_movups_xmm_xmm

%xmm0: %ymm0_movups_xmm_xmm[127:0]
%xmm1: %ymm1_movups_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1

Final state:
%rax/%rax: %rax_movups_xmm_xmm
%rdx/%rdx: %rdx_movups_xmm_xmm

%xmm0: %ymm0_movups_xmm_xmm[127:0]
%xmm1: (%ymm1_movups_xmm_xmm[255:128] ∘ ((%ymm7_movups_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movups_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm6_movups_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movups_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm5_movups_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movups_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (%ymm4_movups_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movups_xmm_xmm[127:0][31:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movups %xmm7, %xmm1

.target:
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1
retq 

Initial state:
%xmm1: %ymm1_sqrtss_xmm_xmm[127:0]

State for specgen instruction: movups %xmm2, %xmm1:
%xmm1: (%ymm1_movups_xmm_xmm[255:128] ∘ ((%ymm7_movups_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movups_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm6_movups_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movups_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm5_movups_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movups_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (%ymm4_movups_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movups_xmm_xmm[127:0][31:0]))[127:0][31:0]))[127:0]

Final state
%xmm1: (%ymm1_sqrtss_xmm_xmm[255:128] ∘ (%ymm1_sqrtss_xmm_xmm[127:32] ∘ sqrt_single(%ymm2_sqrtss_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for sqrtss %xmm12, %xmm1

.target:
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
sqrtps %xmm8, %xmm4
vmovss %xmm4, %xmm1, %xmm7
movups %xmm7, %xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ (%ymm2_vsqrtss_xmm_xmm_xmm[127:32] ∘ mul_single(%ymm2_vsqrtss_xmm_xmm_xmm[31:0], %ymm2_vsqrtss_xmm_xmm_xmm[31:0])))[127:0]

State for specgen instruction: sqrtss %xmm2, %xmm1:
%xmm1: (%ymm1_sqrtss_xmm_xmm[255:128] ∘ (%ymm1_sqrtss_xmm_xmm[127:32] ∘ sqrt_single(%ymm2_sqrtss_xmm_xmm[31:0])))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vsqrtss_xmm_xmm_xmm[127:32] ∘ mul_single(%ymm2_vsqrtss_xmm_xmm_xmm[31:0], %ymm2_vsqrtss_xmm_xmm_xmm[31:0])))[255:128] ∘ (%ymm2_vsqrtss_xmm_xmm_xmm[127:32] ∘ sqrt_single(%ymm3_vsqrtss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vsqrtss %xmm1, %xmm2, %xmm13

.target:
callq .move_128_64_xmm3_xmm12_xmm13
vmulss %xmm2, %xmm2, %xmm1
sqrtss %xmm12, %xmm1
retq 

Initial state:
%ymm13: %ymm13_addsubpd_xmm_xmm

State for specgen instruction: vsqrtss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vsqrtss_xmm_xmm_xmm[127:32] ∘ mul_single(%ymm2_vsqrtss_xmm_xmm_xmm[31:0], %ymm2_vsqrtss_xmm_xmm_xmm[31:0])))[255:128] ∘ (%ymm2_vsqrtss_xmm_xmm_xmm[127:32] ∘ sqrt_single(%ymm3_vsqrtss_xmm_xmm_xmm[31:0]))

Final state
%ymm13: 0x0₁₂₈ ∘ (%ymm2_addsubpd_xmm_xmm[127:32] ∘ sqrt_single(%ymm1_addsubpd_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vaddpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vaddpd_xmm_xmm_xmm

%xmm0: %ymm0_vaddpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vaddpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vaddpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vaddpd_xmm_xmm_xmm

%xmm0: %ymm0_vaddpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vaddpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vaddpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vaddpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vaddpd_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vaddpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm3

Final state:
%rax/%rax: %rax_vaddpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vaddpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vaddpd_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vaddpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vaddpd %ymm3, %ymm1, %ymm1

Final state:
%ymm1: add_double((0x0₂₅₆[255:128] ∘ (%ymm2_vaddpd_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vaddpd_xmm_xmm_xmm[127:0][63:0][63:0]))[255:192], (0x0₂₅₆[255:128] ∘ (%ymm3_vaddpd_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vaddpd_xmm_xmm_xmm[127:0][63:0][63:0]))[255:192]) ∘ (add_double((0x0₂₅₆[255:128] ∘ (%ymm2_vaddpd_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vaddpd_xmm_xmm_xmm[127:0][63:0][63:0]))[191:128], (0x0₂₅₆[255:128] ∘ (%ymm3_vaddpd_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vaddpd_xmm_xmm_xmm[127:0][63:0][63:0]))[191:128]) ∘ (add_double((0x0₂₅₆[255:128] ∘ (%ymm2_vaddpd_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vaddpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:64], (0x0₂₅₆[255:128] ∘ (%ymm3_vaddpd_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vaddpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:64]) ∘ add_double((0x0₂₅₆[255:128] ∘ (%ymm2_vaddpd_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vaddpd_xmm_xmm_xmm[127:0][63:0][63:0]))[63:0], (0x0₂₅₆[255:128] ∘ (%ymm3_vaddpd_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vaddpd_xmm_xmm_xmm[127:0][63:0][63:0]))[63:0])))

-------------------------------------
=====================================
Computing circuit for vaddpd %xmm2, %xmm1, %xmm9

.target:
callq .move_128_064_xmm2_r10_r11
callq .move_128_064_xmm3_r8_r9
vzeroall 
callq .move_064_128_r10_r11_xmm1
callq .move_064_128_r8_r9_xmm3
vaddpd %ymm3, %ymm1, %ymm1
retq 

Initial state:
%ymm9: %ymm9_addpd_xmm_xmm

State for specgen instruction: vaddpd %xmm3, %xmm2, %xmm1:
%ymm1: add_double((0x0₂₅₆[255:128] ∘ (%ymm2_vaddpd_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vaddpd_xmm_xmm_xmm[127:0][63:0][63:0]))[255:192], (0x0₂₅₆[255:128] ∘ (%ymm3_vaddpd_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vaddpd_xmm_xmm_xmm[127:0][63:0][63:0]))[255:192]) ∘ (add_double((0x0₂₅₆[255:128] ∘ (%ymm2_vaddpd_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vaddpd_xmm_xmm_xmm[127:0][63:0][63:0]))[191:128], (0x0₂₅₆[255:128] ∘ (%ymm3_vaddpd_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vaddpd_xmm_xmm_xmm[127:0][63:0][63:0]))[191:128]) ∘ (add_double((0x0₂₅₆[255:128] ∘ (%ymm2_vaddpd_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vaddpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:64], (0x0₂₅₆[255:128] ∘ (%ymm3_vaddpd_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vaddpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:64]) ∘ add_double((0x0₂₅₆[255:128] ∘ (%ymm2_vaddpd_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vaddpd_xmm_xmm_xmm[127:0][63:0][63:0]))[63:0], (0x0₂₅₆[255:128] ∘ (%ymm3_vaddpd_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vaddpd_xmm_xmm_xmm[127:0][63:0][63:0]))[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (add_double(%ymm1_addpd_xmm_xmm[127:64], %ymm2_addpd_xmm_xmm[127:64]) ∘ add_double(%ymm1_addpd_xmm_xmm[63:0], %ymm2_addpd_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm9, %ymm9, %ymm12

Final state:
%ymm12: (mincmp_double((0x0₆₄ ∘ (0x0₆₄ ∘ (add_double(%ymm1_addpd_xmm_xmm[127:64], %ymm2_addpd_xmm_xmm[127:64]) ∘ add_double(%ymm1_addpd_xmm_xmm[63:0], %ymm2_addpd_xmm_xmm[63:0]))))[255:192], (0x0₆₄ ∘ (0x0₆₄ ∘ (add_double(%ymm1_addpd_xmm_xmm[127:64], %ymm2_addpd_xmm_xmm[127:64]) ∘ add_double(%ymm1_addpd_xmm_xmm[63:0], %ymm2_addpd_xmm_xmm[63:0]))))[255:192])[0:0] = 0x1₁ ? (0x0₆₄ ∘ (0x0₆₄ ∘ (add_double(%ymm1_addpd_xmm_xmm[127:64], %ymm2_addpd_xmm_xmm[127:64]) ∘ add_double(%ymm1_addpd_xmm_xmm[63:0], %ymm2_addpd_xmm_xmm[63:0]))))[255:192] : (0x0₆₄ ∘ (0x0₆₄ ∘ (add_double(%ymm1_addpd_xmm_xmm[127:64], %ymm2_addpd_xmm_xmm[127:64]) ∘ add_double(%ymm1_addpd_xmm_xmm[63:0], %ymm2_addpd_xmm_xmm[63:0]))))[255:192]) ∘ ((mincmp_double((0x0₆₄ ∘ (0x0₆₄ ∘ (add_double(%ymm1_addpd_xmm_xmm[127:64], %ymm2_addpd_xmm_xmm[127:64]) ∘ add_double(%ymm1_addpd_xmm_xmm[63:0], %ymm2_addpd_xmm_xmm[63:0]))))[191:128], (0x0₆₄ ∘ (0x0₆₄ ∘ (add_double(%ymm1_addpd_xmm_xmm[127:64], %ymm2_addpd_xmm_xmm[127:64]) ∘ add_double(%ymm1_addpd_xmm_xmm[63:0], %ymm2_addpd_xmm_xmm[63:0]))))[191:128])[0:0] = 0x1₁ ? (0x0₆₄ ∘ (0x0₆₄ ∘ (add_double(%ymm1_addpd_xmm_xmm[127:64], %ymm2_addpd_xmm_xmm[127:64]) ∘ add_double(%ymm1_addpd_xmm_xmm[63:0], %ymm2_addpd_xmm_xmm[63:0]))))[191:128] : (0x0₆₄ ∘ (0x0₆₄ ∘ (add_double(%ymm1_addpd_xmm_xmm[127:64], %ymm2_addpd_xmm_xmm[127:64]) ∘ add_double(%ymm1_addpd_xmm_xmm[63:0], %ymm2_addpd_xmm_xmm[63:0]))))[191:128]) ∘ ((mincmp_double((0x0₆₄ ∘ (0x0₆₄ ∘ (add_double(%ymm1_addpd_xmm_xmm[127:64], %ymm2_addpd_xmm_xmm[127:64]) ∘ add_double(%ymm1_addpd_xmm_xmm[63:0], %ymm2_addpd_xmm_xmm[63:0]))))[127:64], (0x0₆₄ ∘ (0x0₆₄ ∘ (add_double(%ymm1_addpd_xmm_xmm[127:64], %ymm2_addpd_xmm_xmm[127:64]) ∘ add_double(%ymm1_addpd_xmm_xmm[63:0], %ymm2_addpd_xmm_xmm[63:0]))))[127:64])[0:0] = 0x1₁ ? (0x0₆₄ ∘ (0x0₆₄ ∘ (add_double(%ymm1_addpd_xmm_xmm[127:64], %ymm2_addpd_xmm_xmm[127:64]) ∘ add_double(%ymm1_addpd_xmm_xmm[63:0], %ymm2_addpd_xmm_xmm[63:0]))))[127:64] : (0x0₆₄ ∘ (0x0₆₄ ∘ (add_double(%ymm1_addpd_xmm_xmm[127:64], %ymm2_addpd_xmm_xmm[127:64]) ∘ add_double(%ymm1_addpd_xmm_xmm[63:0], %ymm2_addpd_xmm_xmm[63:0]))))[127:64]) ∘ (mincmp_double((0x0₆₄ ∘ (0x0₆₄ ∘ (add_double(%ymm1_addpd_xmm_xmm[127:64], %ymm2_addpd_xmm_xmm[127:64]) ∘ add_double(%ymm1_addpd_xmm_xmm[63:0], %ymm2_addpd_xmm_xmm[63:0]))))[63:0], (0x0₆₄ ∘ (0x0₆₄ ∘ (add_double(%ymm1_addpd_xmm_xmm[127:64], %ymm2_addpd_xmm_xmm[127:64]) ∘ add_double(%ymm1_addpd_xmm_xmm[63:0], %ymm2_addpd_xmm_xmm[63:0]))))[63:0])[0:0] = 0x1₁ ? (0x0₆₄ ∘ (0x0₆₄ ∘ (add_double(%ymm1_addpd_xmm_xmm[127:64], %ymm2_addpd_xmm_xmm[127:64]) ∘ add_double(%ymm1_addpd_xmm_xmm[63:0], %ymm2_addpd_xmm_xmm[63:0]))))[63:0] : (0x0₆₄ ∘ (0x0₆₄ ∘ (add_double(%ymm1_addpd_xmm_xmm[127:64], %ymm2_addpd_xmm_xmm[127:64]) ∘ add_double(%ymm1_addpd_xmm_xmm[63:0], %ymm2_addpd_xmm_xmm[63:0]))))[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_movaps_xmm_xmm
%rdx/%rdx: %rdx_movaps_xmm_xmm

%xmm0: %ymm0_movaps_xmm_xmm[127:0]
%xmm1: %ymm1_movaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1

Final state:
%rax/%rax: %rax_movaps_xmm_xmm
%rdx/%rdx: %rdx_movaps_xmm_xmm

%xmm0: %ymm0_movaps_xmm_xmm[127:0]
%xmm1: (%ymm1_movaps_xmm_xmm[255:128] ∘ ((%ymm7_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm6_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm5_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (%ymm4_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][31:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movaps %xmm12, %xmm1

.target:
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1
retq 

Initial state:
%xmm1: %ymm1_addpd_xmm_xmm[127:0]

State for specgen instruction: movaps %xmm2, %xmm1:
%xmm1: (%ymm1_movaps_xmm_xmm[255:128] ∘ ((%ymm7_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm6_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm5_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (%ymm4_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][31:0]))[127:0][31:0]))[127:0]

Final state
%xmm1: (%ymm1_addpd_xmm_xmm[255:128] ∘ (add_double(%ymm1_addpd_xmm_xmm[127:64], %ymm2_addpd_xmm_xmm[127:64]) ∘ add_double(%ymm1_addpd_xmm_xmm[63:0], %ymm2_addpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for addpd %xmm13, %xmm1

.target:
vaddpd %xmm2, %xmm1, %xmm9
vminpd %ymm9, %ymm9, %ymm12
movaps %xmm12, %xmm1
retq 

Initial state:
%xmm1: (%ymm1_addsubpd_xmm_xmm[255:40] ∘ (%r8_addsubpd_xmm_xmm[63:8] ∘ %ymm1_addsubpd_xmm_xmm[55:48])[7:0] ∘ %ymm1_addsubpd_xmm_xmm[31:0])[127:0]

State for specgen instruction: addpd %xmm2, %xmm1:
%xmm1: (%ymm1_addpd_xmm_xmm[255:128] ∘ (add_double(%ymm1_addpd_xmm_xmm[127:64], %ymm2_addpd_xmm_xmm[127:64]) ∘ add_double(%ymm1_addpd_xmm_xmm[63:0], %ymm2_addpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm1: ((%ymm1_addsubpd_xmm_xmm[255:40] ∘ (%r8_addsubpd_xmm_xmm[63:8] ∘ %ymm1_addsubpd_xmm_xmm[55:48])[7:0] ∘ %ymm1_addsubpd_xmm_xmm[31:0])[255:128] ∘ (add_double(%ymm1_addsubpd_xmm_xmm[127:64], %ymm2_addsubpd_xmm_xmm[127:64]) ∘ add_double(%ymm1_addsubpd_xmm_xmm[63:40] ∘ %ymm1_addsubpd_xmm_xmm[55:48] ∘ %ymm1_addsubpd_xmm_xmm[31:0], %ymm2_addsubpd_xmm_xmm[63:32] ∘ sqrt_single(%ymm1_addsubpd_xmm_xmm[31:0]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_movsd_xmm_xmm
%rdx/%rdx: %rdx_movsd_xmm_xmm

%xmm0: %ymm0_movsd_xmm_xmm[127:0]
%xmm1: %ymm1_movsd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_movups_xmm_xmm
%rdx/%rdx: %rdx_movups_xmm_xmm

%xmm0: %ymm0_movups_xmm_xmm[127:0]
%xmm1: %ymm1_movups_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1

Final state:
%rax/%rax: %rax_movups_xmm_xmm
%rdx/%rdx: %rdx_movups_xmm_xmm

%xmm0: %ymm0_movups_xmm_xmm[127:0]
%xmm1: (%ymm1_movups_xmm_xmm[255:128] ∘ ((%ymm7_movups_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movups_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm6_movups_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movups_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm5_movups_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movups_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (%ymm4_movups_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movups_xmm_xmm[127:0][31:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movups %xmm2, %xmm8

.target:
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1
retq 

Initial state:
%xmm8: (%ymm8_movsd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm1_movsd_xmm_xmm[127:0][63:0]))[127:0]

State for specgen instruction: movups %xmm2, %xmm1:
%xmm1: (%ymm1_movups_xmm_xmm[255:128] ∘ ((%ymm7_movups_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movups_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm6_movups_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movups_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm5_movups_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movups_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (%ymm4_movups_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movups_xmm_xmm[127:0][31:0]))[127:0][31:0]))[127:0]

Final state
%xmm8: ((%ymm8_movsd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm1_movsd_xmm_xmm[127:0][63:0]))[255:128] ∘ %ymm2_movsd_xmm_xmm[127:0])[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_movsd_xmm_xmm
%rdx/%rdx: %rdx_movsd_xmm_xmm

%xmm0: %ymm0_movsd_xmm_xmm[127:0]
%xmm1: (%ymm1_movsd_xmm_xmm[255:128] ∘ ((%ymm9_movsd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm1_movsd_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ ((%ymm8_movsd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm1_movsd_xmm_xmm[127:0][63:0]))[255:128] ∘ %ymm2_movsd_xmm_xmm[127:0])[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movsd %xmm3, %xmm1

.target:
callq .move_128_64_xmm1_xmm8_xmm9
movups %xmm2, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm1: ((%ymm1_addsubpd_xmm_xmm[255:40] ∘ (%r8_addsubpd_xmm_xmm[63:8] ∘ %ymm1_addsubpd_xmm_xmm[55:48])[7:0] ∘ %ymm1_addsubpd_xmm_xmm[31:0])[255:128] ∘ (add_double(%ymm1_addsubpd_xmm_xmm[127:64], %ymm2_addsubpd_xmm_xmm[127:64]) ∘ add_double(%ymm1_addsubpd_xmm_xmm[63:40] ∘ %ymm1_addsubpd_xmm_xmm[55:48] ∘ %ymm1_addsubpd_xmm_xmm[31:0], %ymm2_addsubpd_xmm_xmm[63:32] ∘ sqrt_single(%ymm1_addsubpd_xmm_xmm[31:0]))))[127:0]

State for specgen instruction: movsd %xmm2, %xmm1:
%xmm1: (%ymm1_movsd_xmm_xmm[255:128] ∘ ((%ymm9_movsd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm1_movsd_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ ((%ymm8_movsd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm1_movsd_xmm_xmm[127:0][63:0]))[255:128] ∘ %ymm2_movsd_xmm_xmm[127:0])[127:0][63:0]))[127:0]

Final state
%xmm1: (((%ymm1_addsubpd_xmm_xmm[255:40] ∘ (%r8_addsubpd_xmm_xmm[63:8] ∘ %ymm1_addsubpd_xmm_xmm[55:48])[7:0] ∘ %ymm1_addsubpd_xmm_xmm[31:0])[255:128] ∘ (add_double(%ymm1_addsubpd_xmm_xmm[127:64], %ymm2_addsubpd_xmm_xmm[127:64]) ∘ add_double(%ymm1_addsubpd_xmm_xmm[63:40] ∘ %ymm1_addsubpd_xmm_xmm[55:48] ∘ %ymm1_addsubpd_xmm_xmm[31:0], %ymm2_addsubpd_xmm_xmm[63:32] ∘ sqrt_single(%ymm1_addsubpd_xmm_xmm[31:0]))))[255:128] ∘ (add_double(%ymm1_addsubpd_xmm_xmm[127:64], %ymm2_addsubpd_xmm_xmm[127:64]) ∘ sub_double(%ymm1_addsubpd_xmm_xmm[63:0], %ymm2_addsubpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for addsubpd %xmm2, %xmm1

.target:
callq .move_byte_6_of_ymm1_to_r8b
vsubsd %xmm2, %xmm1, %xmm3
callq .move_r8b_to_byte_4_of_ymm1
vsqrtss %xmm1, %xmm2, %xmm13
addpd %xmm13, %xmm1
movsd %xmm3, %xmm1
retq 

Initial state:
%xmm1: %ymm1[127:0]

State for specgen instruction: addsubpd %xmm2, %xmm1:
%xmm1: (((%ymm1_addsubpd_xmm_xmm[255:40] ∘ (%r8_addsubpd_xmm_xmm[63:8] ∘ %ymm1_addsubpd_xmm_xmm[55:48])[7:0] ∘ %ymm1_addsubpd_xmm_xmm[31:0])[255:128] ∘ (add_double(%ymm1_addsubpd_xmm_xmm[127:64], %ymm2_addsubpd_xmm_xmm[127:64]) ∘ add_double(%ymm1_addsubpd_xmm_xmm[63:40] ∘ %ymm1_addsubpd_xmm_xmm[55:48] ∘ %ymm1_addsubpd_xmm_xmm[31:0], %ymm2_addsubpd_xmm_xmm[63:32] ∘ sqrt_single(%ymm1_addsubpd_xmm_xmm[31:0]))))[255:128] ∘ (add_double(%ymm1_addsubpd_xmm_xmm[127:64], %ymm2_addsubpd_xmm_xmm[127:64]) ∘ sub_double(%ymm1_addsubpd_xmm_xmm[63:0], %ymm2_addsubpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm1: (%ymm1[255:128] ∘ (add_double(%ymm1[127:64], %ymm2[127:64]) ∘ sub_double(%ymm1[63:0], %ymm2[63:0])))[127:0]

=====================================
Circuits:

%ymm1  : %ymm1[255:128] ∘ (add_double(%ymm1[127:64], %ymm2[127:64]) ∘ sub_double(%ymm1[63:0], %ymm2[63:0]))

sigfpe  : sigfpe
sigbus  : sigbus
sigsegv : sigsegv

*/