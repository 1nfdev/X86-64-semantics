// Autogenerated using stratification.
requires "x86-configuration.k"

module ADDSUBPS-XMM-XMM
  imports X86-CONFIGURATION

  rule <k>
    execinstr (addsubps R1:Xmm, R2:Xmm,  .Typedoperands) => .
  ...</k>
    <regstate>
RSMap:Map => updateMap(RSMap,
convToRegKeys(R2) |-> (concatenateMInt(extractMInt(getParentValue(R2, RSMap), 0, 128), concatenateMInt(concatenateMInt(Float2MInt( ( MInt2Float(extractMInt(getParentValue(R1, RSMap), 128, 160), 24, 8)  +Float  MInt2Float(extractMInt(getParentValue(R2, RSMap), 128, 160), 24, 8) ) , 32), Float2MInt( ( MInt2Float(extractMInt(getParentValue(R2, RSMap), 160, 192), 24, 8)  -Float  MInt2Float(extractMInt(getParentValue(R1, RSMap), 160, 192), 24, 8) ) , 32)), concatenateMInt(Float2MInt( ( MInt2Float(extractMInt(getParentValue(R1, RSMap), 192, 224), 24, 8)  +Float  MInt2Float(extractMInt(getParentValue(R2, RSMap), 192, 224), 24, 8) ) , 32), Float2MInt( ( MInt2Float(extractMInt(getParentValue(R2, RSMap), 224, 256), 24, 8)  -Float  MInt2Float(extractMInt(getParentValue(R1, RSMap), 224, 256), 24, 8) ) , 32)))) )


)

    </regstate>
endmodule

module ADDSUBPS-XMM-XMM-SEMANTICS
  imports ADDSUBPS-XMM-XMM
endmodule
/*
TargetInstr:
addsubps %xmm2, %xmm1
RWSet:
maybe read:{ %xmm1 %xmm2 }
must read:{ %xmm1 %xmm2 }
maybe write:{ %xmm1 }
must write:{ %xmm1 }
maybe undef:{ }
must undef:{ }
required flags:{ pni }

Circuit:
circuit:vaddps %xmm2, %xmm1, %xmm3                      #  1     0     4      OPC=vaddps_xmm_xmm_xmm
circuit:callq .move_128_032_xmm3_xmm4_xmm5_xmm6_xmm7    #  2     0x4   5      OPC=callq_label
circuit:vsubps %xmm2, %xmm1, %xmm4                      #  3     0x9   4      OPC=vsubps_xmm_xmm_xmm
circuit:vunpckhpd %ymm4, %ymm4, %ymm6                   #  4     0xd   4      OPC=vunpckhpd_ymm_ymm_ymm
circuit:callq .move_128_032_xmm3_xmm8_xmm9_xmm10_xmm11  #  5     0x11  5      OPC=callq_label
circuit:vmovss %xmm11, %xmm10, %xmm7                    #  6     0x16  5      OPC=vmovss_xmm_xmm_xmm
circuit:callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1    #  7     0x1b  5      OPC=callq_label
BVF:
WARNING: No live out values provided, assuming { }
WARNING: No def in values provided; assuming { %mxcsr::rc[0] }
Target

addsubps %xmm2, %xmm1

  maybe read:      { %xmm1 %xmm2 }
  must read:       { %xmm1 %xmm2 }
  maybe write:     { %xmm1 }
  must write:      { %xmm1 }
  maybe undef:     { }
  must undef:      { }
  required flags:  { pni }

-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm10

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm10: %ymm10_vaddps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm10: 0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: %ymm0_vmovups_xmm_xmm[127:0]
%xmm1: %ymm1_vmovups_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovups %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm11: %ymm11_vaddps_xmm_xmm_xmm

State for specgen instruction: vmovups %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vaddps %ymm10, %ymm11, %ymm3

Final state:
%ymm3: add_single((0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0])[255:224]) ∘ (add_single((0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0])[223:192]) ∘ (add_single((0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0])[191:160]) ∘ (add_single((0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0])[159:128]) ∘ (add_single((0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0])[127:96]) ∘ (add_single((0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0])[95:64]) ∘ (add_single((0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0])[63:32]) ∘ add_single((0x0₁₂₈ ∘ %ymm2_vaddps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vaddps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vaddps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (add_single(%ymm2_vaddps_xmm_xmm_xmm[127:96], %ymm3_vaddps_xmm_xmm_xmm[127:96]) ∘ (add_single(%ymm2_vaddps_xmm_xmm_xmm[95:64], %ymm3_vaddps_xmm_xmm_xmm[95:64]) ∘ (add_single(%ymm2_vaddps_xmm_xmm_xmm[63:32], %ymm3_vaddps_xmm_xmm_xmm[63:32]) ∘ add_single(%ymm2_vaddps_xmm_xmm_xmm[31:0], %ymm3_vaddps_xmm_xmm_xmm[31:0]))))

=====================================
=====================================
Computing circuit for vaddps %xmm2, %xmm1, %xmm3

.target:
vmovdqu %xmm3, %xmm10
vmovups %xmm2, %xmm11
vaddps %ymm10, %ymm11, %ymm3
vmovdqa %xmm3, %xmm1
retq 

Initial state:
%ymm3: %ymm3_addsubps_xmm_xmm

State for specgen instruction: vaddps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (add_single(%ymm2_vaddps_xmm_xmm_xmm[127:96], %ymm3_vaddps_xmm_xmm_xmm[127:96]) ∘ (add_single(%ymm2_vaddps_xmm_xmm_xmm[95:64], %ymm3_vaddps_xmm_xmm_xmm[95:64]) ∘ (add_single(%ymm2_vaddps_xmm_xmm_xmm[63:32], %ymm3_vaddps_xmm_xmm_xmm[63:32]) ∘ add_single(%ymm2_vaddps_xmm_xmm_xmm[31:0], %ymm3_vaddps_xmm_xmm_xmm[31:0]))))

Final state
%ymm3: 0x0₁₂₈ ∘ (add_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ (add_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]) ∘ (add_single(%ymm1_addsubps_xmm_xmm[63:32], %ymm2_addsubps_xmm_xmm[63:32]) ∘ add_single(%ymm1_addsubps_xmm_xmm[31:0], %ymm2_addsubps_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm3_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_addsubps_xmm_xmm
%rdx/%rdx: %rdx_addsubps_xmm_xmm

%xmm0: %ymm0_addsubps_xmm_xmm[127:0]
%xmm1: %ymm1_addsubps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm14

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm14: %ymm14_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm14: 0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminps %ymm1, %ymm14, %ymm1

Final state:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vminps %xmm2, %xmm2, %xmm5

.target:
vmovdqa %xmm3, %xmm1
vmovdqu %xmm2, %xmm14
vminps %ymm1, %ymm14, %ymm1
retq 

Initial state:
%ymm5: %ymm5_vsubps_xmm_xmm_xmm

State for specgen instruction: vminps %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm5: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_subps_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm14

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm14: %ymm14_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm14: 0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminps %ymm1, %ymm14, %ymm1

Final state:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vminps %xmm1, %xmm1, %xmm4

.target:
vmovdqa %xmm3, %xmm1
vmovdqu %xmm2, %xmm14
vminps %ymm1, %ymm14, %ymm1
retq 

Initial state:
%ymm4: %ymm4_subps_xmm_xmm

State for specgen instruction: vminps %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm4: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for vsubps %ymm10, %ymm4, %ymm2

Final state:
%ymm2: sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[255:224], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[255:224]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[223:192], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[223:192]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[191:160], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[191:160]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[159:128], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[159:128]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[127:96], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[127:96]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[95:64], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[95:64]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[63:32], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[63:32]) ∘ sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[31:0], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_subps_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_subps_xmm_xmm[255:128] ∘ (sub_single(%ymm1_subps_xmm_xmm[127:96], %ymm2_subps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_subps_xmm_xmm[95:64], %ymm2_subps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_subps_xmm_xmm[63:32], %ymm2_subps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_subps_xmm_xmm[31:0], %ymm2_subps_xmm_xmm[31:0])))))[127:0]

=====================================
=====================================
Computing circuit for subps %xmm3, %xmm5

.target:
vmovaps %xmm2, %xmm10
vminps %xmm1, %xmm1, %xmm4
vsubps %ymm10, %ymm4, %ymm2
movdqu %xmm2, %xmm1
retq 

Initial state:
%xmm5: (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0]))))[127:0]

State for specgen instruction: subps %xmm2, %xmm1:
%xmm1: (%ymm1_subps_xmm_xmm[255:128] ∘ (sub_single(%ymm1_subps_xmm_xmm[127:96], %ymm2_subps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_subps_xmm_xmm[95:64], %ymm2_subps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_subps_xmm_xmm[63:32], %ymm2_subps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_subps_xmm_xmm[31:0], %ymm2_subps_xmm_xmm[31:0])))))[127:0]

Final state
%xmm5: ((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0]))))[255:128] ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0])))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm5, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vsubps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0]))))

=====================================
=====================================
Computing circuit for vsubps %xmm2, %xmm1, %xmm4

.target:
vminps %xmm2, %xmm2, %xmm5
subps %xmm3, %xmm5
vmovdqu %xmm5, %xmm1
retq 

Initial state:
%ymm4: %ymm4_addsubps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (0x0₁₂₈ ∘ (add_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ (add_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]) ∘ (add_single(%ymm1_addsubps_xmm_xmm[63:32], %ymm2_addsubps_xmm_xmm[63:32]) ∘ add_single(%ymm1_addsubps_xmm_xmm[31:0], %ymm2_addsubps_xmm_xmm[31:0])))))[127:0][31:0])

State for specgen instruction: vsubps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0]))))

Final state
%ymm4: 0x0₁₂₈ ∘ (sub_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_addsubps_xmm_xmm[63:32], %ymm2_addsubps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_addsubps_xmm_xmm[31:0], %ymm2_addsubps_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_256_128_ymm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vunpckhpd_ymm_ymm_ymm

%xmm0: %ymm0_vunpckhpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vunpckhpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vunpckhpd_ymm_ymm_ymm

%xmm0: %ymm0_vunpckhpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vunpckhpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm8

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm8: (%ymm8_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:0])[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm8: ((%ymm8_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:0])[255:128] ∘ (%ymm3_vunpckhpd_ymm_ymm_ymm[127:64] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm11, %xmm9

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm9: (%ymm9_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:128])[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm9: ((%ymm9_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:128])[255:128] ∘ (%ymm3_vunpckhpd_ymm_ymm_ymm[255:192] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:192]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vunpckhpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vunpckhpd_ymm_ymm_ymm

%xmm0: %ymm0_vunpckhpd_ymm_ymm_ymm[127:0]
%xmm1: (((%ymm9_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:128])[255:128] ∘ (%ymm3_vunpckhpd_ymm_ymm_ymm[255:192] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:192]))[127:0][127:0] ∘ ((%ymm8_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:0])[255:128] ∘ (%ymm3_vunpckhpd_ymm_ymm_ymm[127:64] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:64]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhpd %ymm4, %ymm4, %ymm6

.target:
callq .move_256_128_ymm2_xmm8_xmm9
callq .move_256_128_ymm3_xmm10_xmm11
unpckhpd %xmm3, %xmm8
unpckhpd %xmm11, %xmm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_addsubps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (0x0₁₂₈ ∘ (add_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ (add_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]) ∘ (add_single(%ymm1_addsubps_xmm_xmm[63:32], %ymm2_addsubps_xmm_xmm[63:32]) ∘ add_single(%ymm1_addsubps_xmm_xmm[31:0], %ymm2_addsubps_xmm_xmm[31:0])))))[127:0][95:64])

State for specgen instruction: vunpckhpd %ymm3, %ymm2, %ymm1:
%ymm1: ((%ymm9_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:128])[255:128] ∘ (%ymm3_vunpckhpd_ymm_ymm_ymm[255:192] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:192]))[127:0][127:0] ∘ ((%ymm8_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:0])[255:128] ∘ (%ymm3_vunpckhpd_ymm_ymm_ymm[127:64] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:64]))[127:0][127:0]

Final state
%ymm6: 0x0₆₄ ∘ 0x0₆₄ ∘ (sub_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm3_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_addsubps_xmm_xmm
%rdx/%rdx: %rdx_addsubps_xmm_xmm

%xmm0: %ymm0_addsubps_xmm_xmm[127:0]
%xmm1: %ymm1_addsubps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm10, %xmm7

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm7: %ymm7_addsubps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (0x0₁₂₈ ∘ (add_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ (add_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]) ∘ (add_single(%ymm1_addsubps_xmm_xmm[63:32], %ymm2_addsubps_xmm_xmm[63:32]) ∘ add_single(%ymm1_addsubps_xmm_xmm[31:0], %ymm2_addsubps_xmm_xmm[31:0])))))[127:0][127:96])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm7: 0x0₁₂₈ ∘ (0x0₉₆ ∘ add_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1

Final state:
%rax/%rax: %rax_addsubps_xmm_xmm
%rdx/%rdx: %rdx_addsubps_xmm_xmm

%xmm0: %ymm0_addsubps_xmm_xmm[127:0]
%xmm1: (%ymm1_addsubps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₉₆ ∘ add_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96])))[127:0][31:0] ∘ (0x0₆₄ ∘ 0x0₆₄ ∘ (sub_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]))))[127:0][31:0] ∘ (%ymm5_addsubps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (0x0₁₂₈ ∘ (add_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ (add_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]) ∘ (add_single(%ymm1_addsubps_xmm_xmm[63:32], %ymm2_addsubps_xmm_xmm[63:32]) ∘ add_single(%ymm1_addsubps_xmm_xmm[31:0], %ymm2_addsubps_xmm_xmm[31:0])))))[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (sub_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_addsubps_xmm_xmm[63:32], %ymm2_addsubps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_addsubps_xmm_xmm[31:0], %ymm2_addsubps_xmm_xmm[31:0])))))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for addsubps %xmm2, %xmm1

.target:
vaddps %xmm2, %xmm1, %xmm3
callq .move_128_032_xmm3_xmm4_xmm5_xmm6_xmm7
vsubps %xmm2, %xmm1, %xmm4
vunpckhpd %ymm4, %ymm4, %ymm6
callq .move_128_032_xmm3_xmm8_xmm9_xmm10_xmm11
vmovss %xmm11, %xmm10, %xmm7
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1
retq 

Initial state:
%xmm1: %ymm1[127:0]

State for specgen instruction: addsubps %xmm2, %xmm1:
%xmm1: (%ymm1_addsubps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₉₆ ∘ add_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96])))[127:0][31:0] ∘ (0x0₆₄ ∘ 0x0₆₄ ∘ (sub_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]))))[127:0][31:0] ∘ (%ymm5_addsubps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (0x0₁₂₈ ∘ (add_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ (add_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]) ∘ (add_single(%ymm1_addsubps_xmm_xmm[63:32], %ymm2_addsubps_xmm_xmm[63:32]) ∘ add_single(%ymm1_addsubps_xmm_xmm[31:0], %ymm2_addsubps_xmm_xmm[31:0])))))[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (sub_single(%ymm1_addsubps_xmm_xmm[127:96], %ymm2_addsubps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_addsubps_xmm_xmm[95:64], %ymm2_addsubps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_addsubps_xmm_xmm[63:32], %ymm2_addsubps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_addsubps_xmm_xmm[31:0], %ymm2_addsubps_xmm_xmm[31:0])))))[127:0][31:0]))[127:0]

Final state
%xmm1: (%ymm1[255:128] ∘ (add_single(%ymm1[127:96], %ymm2[127:96]) ∘ sub_single(%ymm1[95:64], %ymm2[95:64]) ∘ add_single(%ymm1[63:32], %ymm2[63:32]) ∘ sub_single(%ymm1[31:0], %ymm2[31:0])))[127:0]

=====================================
Circuits:

%ymm1  : %ymm1[255:128] ∘ (add_single(%ymm1[127:96], %ymm2[127:96]) ∘ sub_single(%ymm1[95:64], %ymm2[95:64]) ∘ add_single(%ymm1[63:32], %ymm2[63:32]) ∘ sub_single(%ymm1[31:0], %ymm2[31:0]))

sigfpe  : sigfpe
sigbus  : sigbus
sigsegv : sigsegv

*/