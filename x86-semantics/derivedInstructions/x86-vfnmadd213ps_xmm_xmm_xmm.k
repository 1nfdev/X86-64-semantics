// Autogenerated using stratification.
requires "x86-configuration.k"

module VFNMADD213PS-XMM-XMM-XMM
  imports X86-CONFIGURATION

  rule <k>
    execinstr (vfnmadd213ps R1:Xmm, R2:Xmm, R3:Xmm,  .Typedoperands) => .
  ...</k>
    <regstate>
RSMap:Map => updateMap(RSMap,
convToRegKeys(R3) |-> (concatenateMInt(concatenateMInt(Float2MInt( ( Float@FLOAT-SYNTAX(#"0e+00f")  +Float  negateFloat(Float@FLOAT-SYNTAX(#"0e+00f")) ) , 32), concatenateMInt(Float2MInt( ( Float@FLOAT-SYNTAX(#"0e+00f")  +Float  negateFloat(Float@FLOAT-SYNTAX(#"0e+00f")) ) , 32), concatenateMInt(Float2MInt( ( Float@FLOAT-SYNTAX(#"0e+00f")  +Float  negateFloat(Float@FLOAT-SYNTAX(#"0e+00f")) ) , 32), Float2MInt( ( Float@FLOAT-SYNTAX(#"0e+00f")  +Float  negateFloat(Float@FLOAT-SYNTAX(#"0e+00f")) ) , 32)))), concatenateMInt(Float2MInt( ( MInt2Float(extractMInt(getParentValue(R1, RSMap), 128, 160), 24, 8)  +Float  negateFloat( ( MInt2Float(extractMInt(getParentValue(R2, RSMap), 128, 160), 24, 8)  *Float  MInt2Float(orMInt(extractMInt(getParentValue(R3, RSMap), 128, 160), mi(32, 0)), 24, 8) ) ) ) , 32), concatenateMInt(Float2MInt( ( MInt2Float(extractMInt(getParentValue(R1, RSMap), 160, 192), 24, 8)  +Float  negateFloat( ( MInt2Float(extractMInt(getParentValue(R2, RSMap), 160, 192), 24, 8)  *Float  MInt2Float(orMInt(extractMInt(getParentValue(R3, RSMap), 160, 192), mi(32, 0)), 24, 8) ) ) ) , 32), concatenateMInt(Float2MInt( ( MInt2Float(extractMInt(getParentValue(R1, RSMap), 192, 224), 24, 8)  +Float  negateFloat( ( MInt2Float(extractMInt(getParentValue(R2, RSMap), 192, 224), 24, 8)  *Float  MInt2Float(extractMInt(getParentValue(R3, RSMap), 192, 224), 24, 8) ) ) ) , 32), Float2MInt( ( MInt2Float(extractMInt(getParentValue(R1, RSMap), 224, 256), 24, 8)  +Float  negateFloat( ( MInt2Float(extractMInt(getParentValue(R2, RSMap), 224, 256), 24, 8)  *Float  MInt2Float(extractMInt(getParentValue(R3, RSMap), 224, 256), 24, 8) ) ) ) , 32))))) )


)

    </regstate>
endmodule

module VFNMADD213PS-XMM-XMM-XMM-SEMANTICS
  imports VFNMADD213PS-XMM-XMM-XMM
endmodule
/*
TargetInstr:
vfnmadd213ps %xmm3, %xmm2, %xmm1
RWSet:
maybe read:{ %xmm1 %xmm2 %xmm3 }
must read:{ %xmm1 %xmm2 %xmm3 }
maybe write:{ %ymm1 }
must write:{ %ymm1 }
maybe undef:{ }
must undef:{ }
required flags:{ fma }

Circuit:
circuit:vmovapd %xmm2, %xmm13               #  1     0     4      OPC=vmovapd_xmm_xmm
circuit:callq .move_128_64_xmm1_xmm8_xmm9   #  2     0x4   5      OPC=callq_label
circuit:vorps %xmm8, %xmm1, %xmm14          #  3     0x9   5      OPC=vorps_xmm_xmm_xmm
circuit:vmovdqu %xmm3, %xmm1                #  4     0xe   4      OPC=vmovdqu_xmm_xmm
circuit:vfnmadd231ps %ymm14, %ymm13, %ymm1  #  5     0x12  5      OPC=vfnmadd231ps_ymm_ymm_ymm
BVF:
WARNING: No live out values provided, assuming { }
WARNING: No def in values provided; assuming { %mxcsr::rc[0] }
Target

vfnmadd213ps %xmm3, %xmm2, %xmm1

  maybe read:      { %xmm1 %xmm2 %xmm3 }
  must read:       { %xmm1 %xmm2 %xmm3 }
  maybe write:     { %ymm1 }
  must write:      { %ymm1 }
  maybe undef:     { }
  must undef:      { }
  required flags:  { fma }

-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm2, %xmm13

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm13: %ymm13_vfnmadd213ps_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm13: 0x0₁₂₈ ∘ %ymm2_vfnmadd213ps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vfnmadd213ps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vfnmadd213ps_xmm_xmm_xmm

%xmm0: %ymm0_vfnmadd213ps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vfnmadd213ps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm8, %xmm1, %xmm14

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm14: %ymm14_vfnmadd213ps_xmm_xmm_xmm

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ ((0x0₆₄ | %ymm1_vfnmadd213ps_xmm_xmm_xmm[127:64]) ∘ %ymm1_vfnmadd213ps_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vfnmadd213ps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vfnmadd213ps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vfnmadd132ps %ymm3, %ymm1, %ymm2

Final state:
%ymm2: vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[255:224], %ymm1_vfnmadd231ps_ymm_ymm_ymm[255:224], %ymm3_vfnmadd231ps_ymm_ymm_ymm[255:224]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[223:192], %ymm1_vfnmadd231ps_ymm_ymm_ymm[223:192], %ymm3_vfnmadd231ps_ymm_ymm_ymm[223:192]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[191:160], %ymm1_vfnmadd231ps_ymm_ymm_ymm[191:160], %ymm3_vfnmadd231ps_ymm_ymm_ymm[191:160]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[159:128], %ymm1_vfnmadd231ps_ymm_ymm_ymm[159:128], %ymm3_vfnmadd231ps_ymm_ymm_ymm[159:128]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[127:96], %ymm1_vfnmadd231ps_ymm_ymm_ymm[127:96], %ymm3_vfnmadd231ps_ymm_ymm_ymm[127:96]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[95:64], %ymm1_vfnmadd231ps_ymm_ymm_ymm[95:64], %ymm3_vfnmadd231ps_ymm_ymm_ymm[95:64]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[63:32], %ymm1_vfnmadd231ps_ymm_ymm_ymm[63:32], %ymm3_vfnmadd231ps_ymm_ymm_ymm[63:32]) ∘ vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[31:0], %ymm1_vfnmadd231ps_ymm_ymm_ymm[31:0], %ymm3_vfnmadd231ps_ymm_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vfnmadd231ps_ymm_ymm_ymm
%rdx/%rdx: %rdx_vfnmadd231ps_ymm_ymm_ymm

%xmm0: %ymm0_vfnmadd231ps_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vfnmadd231ps_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vfnmadd231ps_ymm_ymm_ymm
%rdx/%rdx: %rdx_vfnmadd231ps_ymm_ymm_ymm

%xmm0: %ymm0_vfnmadd231ps_ymm_ymm_ymm[127:0]
%xmm1: ((%ymm13_vfnmadd231ps_ymm_ymm_ymm[255:128] ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[255:224], %ymm1_vfnmadd231ps_ymm_ymm_ymm[255:224], %ymm3_vfnmadd231ps_ymm_ymm_ymm[255:224]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[223:192], %ymm1_vfnmadd231ps_ymm_ymm_ymm[223:192], %ymm3_vfnmadd231ps_ymm_ymm_ymm[223:192]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[191:160], %ymm1_vfnmadd231ps_ymm_ymm_ymm[191:160], %ymm3_vfnmadd231ps_ymm_ymm_ymm[191:160]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[159:128], %ymm1_vfnmadd231ps_ymm_ymm_ymm[159:128], %ymm3_vfnmadd231ps_ymm_ymm_ymm[159:128]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[127:96], %ymm1_vfnmadd231ps_ymm_ymm_ymm[127:96], %ymm3_vfnmadd231ps_ymm_ymm_ymm[127:96]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[95:64], %ymm1_vfnmadd231ps_ymm_ymm_ymm[95:64], %ymm3_vfnmadd231ps_ymm_ymm_ymm[95:64]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[63:32], %ymm1_vfnmadd231ps_ymm_ymm_ymm[63:32], %ymm3_vfnmadd231ps_ymm_ymm_ymm[63:32]) ∘ vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[31:0], %ymm1_vfnmadd231ps_ymm_ymm_ymm[31:0], %ymm3_vfnmadd231ps_ymm_ymm_ymm[31:0]))))))))[255:128])[127:0][127:0] ∘ (%ymm12_vfnmadd231ps_ymm_ymm_ymm[255:128] ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[255:224], %ymm1_vfnmadd231ps_ymm_ymm_ymm[255:224], %ymm3_vfnmadd231ps_ymm_ymm_ymm[255:224]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[223:192], %ymm1_vfnmadd231ps_ymm_ymm_ymm[223:192], %ymm3_vfnmadd231ps_ymm_ymm_ymm[223:192]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[191:160], %ymm1_vfnmadd231ps_ymm_ymm_ymm[191:160], %ymm3_vfnmadd231ps_ymm_ymm_ymm[191:160]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[159:128], %ymm1_vfnmadd231ps_ymm_ymm_ymm[159:128], %ymm3_vfnmadd231ps_ymm_ymm_ymm[159:128]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[127:96], %ymm1_vfnmadd231ps_ymm_ymm_ymm[127:96], %ymm3_vfnmadd231ps_ymm_ymm_ymm[127:96]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[95:64], %ymm1_vfnmadd231ps_ymm_ymm_ymm[95:64], %ymm3_vfnmadd231ps_ymm_ymm_ymm[95:64]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[63:32], %ymm1_vfnmadd231ps_ymm_ymm_ymm[63:32], %ymm3_vfnmadd231ps_ymm_ymm_ymm[63:32]) ∘ vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[31:0], %ymm1_vfnmadd231ps_ymm_ymm_ymm[31:0], %ymm3_vfnmadd231ps_ymm_ymm_ymm[31:0]))))))))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vfnmadd231ps %ymm14, %ymm13, %ymm1

.target:
vfnmadd132ps %ymm3, %ymm1, %ymm2
callq .move_256_128_ymm2_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: 0x0₁₂₈ ∘ %ymm3_vfnmadd213ps_xmm_xmm_xmm[127:0]

State for specgen instruction: vfnmadd231ps %ymm3, %ymm2, %ymm1:
%ymm1: (%ymm13_vfnmadd231ps_ymm_ymm_ymm[255:128] ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[255:224], %ymm1_vfnmadd231ps_ymm_ymm_ymm[255:224], %ymm3_vfnmadd231ps_ymm_ymm_ymm[255:224]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[223:192], %ymm1_vfnmadd231ps_ymm_ymm_ymm[223:192], %ymm3_vfnmadd231ps_ymm_ymm_ymm[223:192]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[191:160], %ymm1_vfnmadd231ps_ymm_ymm_ymm[191:160], %ymm3_vfnmadd231ps_ymm_ymm_ymm[191:160]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[159:128], %ymm1_vfnmadd231ps_ymm_ymm_ymm[159:128], %ymm3_vfnmadd231ps_ymm_ymm_ymm[159:128]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[127:96], %ymm1_vfnmadd231ps_ymm_ymm_ymm[127:96], %ymm3_vfnmadd231ps_ymm_ymm_ymm[127:96]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[95:64], %ymm1_vfnmadd231ps_ymm_ymm_ymm[95:64], %ymm3_vfnmadd231ps_ymm_ymm_ymm[95:64]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[63:32], %ymm1_vfnmadd231ps_ymm_ymm_ymm[63:32], %ymm3_vfnmadd231ps_ymm_ymm_ymm[63:32]) ∘ vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[31:0], %ymm1_vfnmadd231ps_ymm_ymm_ymm[31:0], %ymm3_vfnmadd231ps_ymm_ymm_ymm[31:0]))))))))[255:128])[127:0][127:0] ∘ (%ymm12_vfnmadd231ps_ymm_ymm_ymm[255:128] ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[255:224], %ymm1_vfnmadd231ps_ymm_ymm_ymm[255:224], %ymm3_vfnmadd231ps_ymm_ymm_ymm[255:224]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[223:192], %ymm1_vfnmadd231ps_ymm_ymm_ymm[223:192], %ymm3_vfnmadd231ps_ymm_ymm_ymm[223:192]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[191:160], %ymm1_vfnmadd231ps_ymm_ymm_ymm[191:160], %ymm3_vfnmadd231ps_ymm_ymm_ymm[191:160]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[159:128], %ymm1_vfnmadd231ps_ymm_ymm_ymm[159:128], %ymm3_vfnmadd231ps_ymm_ymm_ymm[159:128]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[127:96], %ymm1_vfnmadd231ps_ymm_ymm_ymm[127:96], %ymm3_vfnmadd231ps_ymm_ymm_ymm[127:96]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[95:64], %ymm1_vfnmadd231ps_ymm_ymm_ymm[95:64], %ymm3_vfnmadd231ps_ymm_ymm_ymm[95:64]) ∘ (vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[63:32], %ymm1_vfnmadd231ps_ymm_ymm_ymm[63:32], %ymm3_vfnmadd231ps_ymm_ymm_ymm[63:32]) ∘ vfnmadd132_single(%ymm2_vfnmadd231ps_ymm_ymm_ymm[31:0], %ymm1_vfnmadd231ps_ymm_ymm_ymm[31:0], %ymm3_vfnmadd231ps_ymm_ymm_ymm[31:0]))))))))[127:0])[127:0][127:0]

Final state
%ymm1: vfnmadd132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ (vfnmadd132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ (vfnmadd132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ vfnmadd132_single(0x0₃₂, 0x0₃₂, 0x0₃₂))) ∘ (vfnmadd132_single(%ymm2_vfnmadd213ps_xmm_xmm_xmm[127:96], %ymm3_vfnmadd213ps_xmm_xmm_xmm[127:96], 0x0₃₂ | %ymm1_vfnmadd213ps_xmm_xmm_xmm[127:96]) ∘ (vfnmadd132_single(%ymm2_vfnmadd213ps_xmm_xmm_xmm[95:64], %ymm3_vfnmadd213ps_xmm_xmm_xmm[95:64], 0x0₃₂ | %ymm1_vfnmadd213ps_xmm_xmm_xmm[95:64]) ∘ (vfnmadd132_single(%ymm2_vfnmadd213ps_xmm_xmm_xmm[63:32], %ymm3_vfnmadd213ps_xmm_xmm_xmm[63:32], %ymm1_vfnmadd213ps_xmm_xmm_xmm[63:32]) ∘ vfnmadd132_single(%ymm2_vfnmadd213ps_xmm_xmm_xmm[31:0], %ymm3_vfnmadd213ps_xmm_xmm_xmm[31:0], %ymm1_vfnmadd213ps_xmm_xmm_xmm[31:0]))))

=====================================
=====================================
Computing circuit for vfnmadd213ps %xmm3, %xmm2, %xmm1

.target:
vmovapd %xmm2, %xmm13
callq .move_128_64_xmm1_xmm8_xmm9
vorps %xmm8, %xmm1, %xmm14
vmovdqu %xmm3, %xmm1
vfnmadd231ps %ymm14, %ymm13, %ymm1
retq 

Initial state:
%ymm1: %ymm1

State for specgen instruction: vfnmadd213ps %xmm3, %xmm2, %xmm1:
%ymm1: vfnmadd132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ (vfnmadd132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ (vfnmadd132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ vfnmadd132_single(0x0₃₂, 0x0₃₂, 0x0₃₂))) ∘ (vfnmadd132_single(%ymm2_vfnmadd213ps_xmm_xmm_xmm[127:96], %ymm3_vfnmadd213ps_xmm_xmm_xmm[127:96], 0x0₃₂ | %ymm1_vfnmadd213ps_xmm_xmm_xmm[127:96]) ∘ (vfnmadd132_single(%ymm2_vfnmadd213ps_xmm_xmm_xmm[95:64], %ymm3_vfnmadd213ps_xmm_xmm_xmm[95:64], 0x0₃₂ | %ymm1_vfnmadd213ps_xmm_xmm_xmm[95:64]) ∘ (vfnmadd132_single(%ymm2_vfnmadd213ps_xmm_xmm_xmm[63:32], %ymm3_vfnmadd213ps_xmm_xmm_xmm[63:32], %ymm1_vfnmadd213ps_xmm_xmm_xmm[63:32]) ∘ vfnmadd132_single(%ymm2_vfnmadd213ps_xmm_xmm_xmm[31:0], %ymm3_vfnmadd213ps_xmm_xmm_xmm[31:0], %ymm1_vfnmadd213ps_xmm_xmm_xmm[31:0]))))

Final state
%ymm1: vfnmadd132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ (vfnmadd132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ (vfnmadd132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ vfnmadd132_single(0x0₃₂, 0x0₃₂, 0x0₃₂))) ∘ (vfnmadd132_single(%ymm2[127:96], %ymm3[127:96], 0x0₃₂ | %ymm1[127:96]) ∘ (vfnmadd132_single(%ymm2[95:64], %ymm3[95:64], 0x0₃₂ | %ymm1[95:64]) ∘ (vfnmadd132_single(%ymm2[63:32], %ymm3[63:32], %ymm1[63:32]) ∘ vfnmadd132_single(%ymm2[31:0], %ymm3[31:0], %ymm1[31:0]))))

=====================================
Circuits:

%ymm1  : vfnmadd132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ (vfnmadd132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ (vfnmadd132_single(0x0₃₂, 0x0₃₂, 0x0₃₂) ∘ vfnmadd132_single(0x0₃₂, 0x0₃₂, 0x0₃₂))) ∘ (vfnmadd132_single(%ymm2[127:96], %ymm3[127:96], 0x0₃₂ | %ymm1[127:96]) ∘ (vfnmadd132_single(%ymm2[95:64], %ymm3[95:64], 0x0₃₂ | %ymm1[95:64]) ∘ (vfnmadd132_single(%ymm2[63:32], %ymm3[63:32], %ymm1[63:32]) ∘ vfnmadd132_single(%ymm2[31:0], %ymm3[31:0], %ymm1[31:0]))))

sigfpe  : sigfpe
sigbus  : sigbus
sigsegv : sigsegv

*/