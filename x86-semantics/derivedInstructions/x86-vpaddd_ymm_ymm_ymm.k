// Autogenerated using stratification.
requires "x86-configuration.k"

module VPADDD-YMM-YMM-YMM
  imports X86-CONFIGURATION

  rule <k>
    execinstr (vpaddd R1:Ymm, R2:Ymm, R3:Ymm,  .Typedoperands) => .
  ...</k>
    <regstate>
RSMap:Map => updateMap(RSMap,
convToRegKeys(R3) |-> (concatenateMInt(concatenateMInt(concatenateMInt(extractMInt(addMInt(concatenateMInt(mi(32, 0), extractMInt(getParentValue(R2, RSMap), 0, 32)), concatenateMInt(mi(32, 0), extractMInt(getParentValue(R1, RSMap), 0, 32))), 32, 64), extractMInt(addMInt(concatenateMInt(extractMInt(getParentValue(R2, RSMap), 32, 64), extractMInt(getParentValue(R1, RSMap), 32, 64)), concatenateMInt(mi(32, 0), extractMInt(getParentValue(R2, RSMap), 32, 64))), 32, 64)), concatenateMInt(extractMInt(addMInt(concatenateMInt(extractMInt(getParentValue(R1, RSMap), 64, 96), extractMInt(getParentValue(R1, RSMap), 64, 96)), concatenateMInt(extractMInt(getParentValue(R1, RSMap), 64, 96), extractMInt(getParentValue(R2, RSMap), 64, 96))), 32, 64), extractMInt(addMInt(concatenateMInt(extractMInt(getParentValue(R1, RSMap), 96, 128), extractMInt(getParentValue(R1, RSMap), 96, 128)), concatenateMInt(extractMInt(getParentValue(R1, RSMap), 96, 128), extractMInt(getParentValue(R2, RSMap), 96, 128))), 32, 64))), concatenateMInt(concatenateMInt(extractMInt(addMInt(concatenateMInt(mi(32, 0), extractMInt(getParentValue(R2, RSMap), 128, 160)), concatenateMInt(mi(32, 0), extractMInt(getParentValue(R1, RSMap), 128, 160))), 32, 64), extractMInt(addMInt(concatenateMInt(extractMInt(getParentValue(R2, RSMap), 160, 192), extractMInt(getParentValue(R1, RSMap), 160, 192)), concatenateMInt(mi(32, 0), extractMInt(getParentValue(R2, RSMap), 160, 192))), 32, 64)), concatenateMInt(extractMInt(addMInt(concatenateMInt(extractMInt(getParentValue(R1, RSMap), 192, 224), extractMInt(getParentValue(R1, RSMap), 192, 224)), concatenateMInt(extractMInt(getParentValue(R1, RSMap), 192, 224), extractMInt(getParentValue(R2, RSMap), 192, 224))), 32, 64), extractMInt(addMInt(concatenateMInt(extractMInt(getParentValue(R1, RSMap), 224, 256), extractMInt(getParentValue(R1, RSMap), 224, 256)), concatenateMInt(extractMInt(getParentValue(R1, RSMap), 224, 256), extractMInt(getParentValue(R2, RSMap), 224, 256))), 32, 64)))) )


)

    </regstate>
endmodule

module VPADDD-YMM-YMM-YMM-SEMANTICS
  imports VPADDD-YMM-YMM-YMM
endmodule
/*
TargetInstr:
vpaddd %ymm3, %ymm2, %ymm1
RWSet:
maybe read:{ %ymm2 %ymm3 }
must read:{ %ymm2 %ymm3 }
maybe write:{ %ymm1 }
must write:{ %ymm1 }
maybe undef:{ }
must undef:{ }
required flags:{ avx2 }

Circuit:
circuit:callq .move_256_128_ymm2_xmm12_xmm13  #  1     0     5      OPC=callq_label
circuit:callq .move_256_128_ymm3_xmm10_xmm11  #  2     0x5   5      OPC=callq_label
circuit:paddd %xmm3, %xmm12                   #  3     0xa   5      OPC=paddd_xmm_xmm
circuit:paddd %xmm11, %xmm13                  #  4     0xf   5      OPC=paddd_xmm_xmm
circuit:callq .move_128_256_xmm12_xmm13_ymm1  #  5     0x14  5      OPC=callq_label
BVF:
WARNING: No live out values provided, assuming { }
WARNING: No def in values provided; assuming { %mxcsr::rc[0] }
Target

vpaddd %ymm3, %ymm2, %ymm1

  maybe read:      { %ymm2 %ymm3 }
  must read:       { %ymm2 %ymm3 }
  maybe write:     { %ymm1 }
  must write:      { %ymm1 }
  maybe undef:     { }
  must undef:      { }
  required flags:  { avx2 }

-------------------------------------
Getting base circuit for callq .move_256_128_ymm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vpaddd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vpaddd_ymm_ymm_ymm

%xmm0: %ymm0_vpaddd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vpaddd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpaddd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vpaddd_ymm_ymm_ymm

%xmm0: %ymm0_vpaddd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vpaddd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm2

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm2: %ymm2_vunpckhps_xmm_xmm_xmm[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm2: (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpckhps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm9, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vunpckhps_xmm_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: %ymm0_vmovq_xmm_xmm[127:0]
%xmm1: %ymm1_vmovq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movswq %bx, %r10

Final state:
%r10/%r10: sign-extend-64(%rbx_xchgl_r32_r32[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_xchgl_r32_r32[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ecx_r8w_r9w

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %rcx

Final state:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r8w_r9w_ebx

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xchgl %ebx, %ecx

.target:
movswq %bx, %r10
movslq %ebx, %rbx
callq .move_032_016_ecx_r8w_r9w
callq .move_064_032_rbx_r10d_r11d
movq %r10, %rcx
callq .move_016_032_r8w_r9w_ebx
retq 

Initial state:
%rcx/%rcx: %rcx_xorl_r32_r32
%rbx/%rbx: %rbx_xorl_r32_r32

State for specgen instruction: xchgl %ecx, %ebx:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
%rbx/%rbx: 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])

Register        -> %rcx
  translates to => %rbx
Value is               -> 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
  after renaming it is => 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

Register        -> %rbx
  translates to => %rcx
Value is               -> 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])
  after renaming it is => 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

Final state
%rcx/%rcx: 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]) = 0x0₆₄
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_ebx

Final state:
%rax/%rax: %rax_xorl_r32_r32
%rdx/%rdx: %rdx_xorl_r32_r32

%xmm0: %ymm0_xorl_r32_r32[127:0]
%xmm1: %ymm1_xorl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xorl %r13d, %r13d

.target:
xchgl %ebx, %ecx
xorq %rcx, %rbx
callq .set_szp_for_ebx
retq 

Initial state:
%r13/%r13: %ymm2_vmovq_xmm_xmm[127:0][127:64]

%cf: %cf_vmovq_xmm_xmm
%pf: %pf_vmovq_xmm_xmm
%zf: %zf_vmovq_xmm_xmm
%sf: %sf_vmovq_xmm_xmm
%of: %of_vmovq_xmm_xmm

State for specgen instruction: xorl %ecx, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0] = 0x0₃₂
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][31:31] = 0x1₁
%of: false

Register        -> %rbx
  translates to => %r13
Value is               -> 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
  after renaming it is => 0x0₆₄

Final state
%r13/%r13: 0x0₆₄

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
xorl %r13d, %r13d
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][95:64])

State for specgen instruction: vmovq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhps %xmm1, %xmm2, %xmm10

.target:
unpckhpd %xmm3, %xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovddup %xmm9, %xmm1
vmovq %xmm1, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm10: %ymm10_paddd_xmm_xmm

State for specgen instruction: vunpckhps %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_paddd_xmm_xmm[127:96] ∘ %ymm2_paddd_xmm_xmm[127:96] ∘ %ymm1_paddd_xmm_xmm[95:64] ∘ %ymm2_paddd_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm2, %xmm1

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm1: %ymm1_paddd_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm1: (%ymm1_paddd_xmm_xmm[255:128] ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm1_paddd_xmm_xmm[63:32] ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm1_paddd_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_movshdup_xmm_xmm
%rdx/%rdx: %rdx_movshdup_xmm_xmm

%xmm0: %ymm0_movshdup_xmm_xmm[127:0]
%xmm1: %ymm1_movshdup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_movshdup_xmm_xmm
%rdx/%rdx: %rdx_movshdup_xmm_xmm

%xmm0: %ymm0_movshdup_xmm_xmm[127:0]
%xmm1: (%ymm1_movshdup_xmm_xmm[255:128] ∘ (%ymm2_movshdup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movshdup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovshdup_xmm_xmm
%rdx/%rdx: %rdx_vmovshdup_xmm_xmm

%xmm0: %ymm0_vmovshdup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovshdup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm11, %xmm11

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm11: %ymm11_vmovshdup_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovshdup_xmm_xmm[127:0][127:96])

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm11: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (%ymm2_vmovshdup_xmm_xmm[127:96] ∘ %ymm2_vmovshdup_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm11, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmovshdup_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (%ymm2_vmovshdup_xmm_xmm[127:96] ∘ %ymm2_vmovshdup_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm9, %xmm1

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovshdup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (%ymm2_vmovshdup_xmm_xmm[63:32] ∘ %ymm2_vmovshdup_xmm_xmm[63:32]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpcklpd_xmm_xmm
%rdx/%rdx: %rdx_unpcklpd_xmm_xmm

%xmm0: %ymm0_unpcklpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpcklpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm11: %ymm11_unpcklpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm1_unpcklpd_xmm_xmm[127:0][127:64])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_unpcklpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_unpcklpd_xmm_xmm
%rdx/%rdx: %rdx_unpcklpd_xmm_xmm

%xmm0: %ymm0_unpcklpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpcklpd_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ %ymm2_unpcklpd_xmm_xmm[127:0])[127:0][63:0] ∘ (%ymm10_unpcklpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm1_unpcklpd_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpcklpd %xmm3, %xmm1

.target:
callq .move_128_64_xmm1_xmm10_xmm11
vmovdqu %xmm2, %xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ (0x0₆₄ ∘ (%ymm2_vmovshdup_xmm_xmm[63:32] ∘ %ymm2_vmovshdup_xmm_xmm[63:32])))[127:0]

State for specgen instruction: unpcklpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklpd_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ %ymm2_unpcklpd_xmm_xmm[127:0])[127:0][63:0] ∘ (%ymm10_unpcklpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm1_unpcklpd_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ (0x0₆₄ ∘ (%ymm2_vmovshdup_xmm_xmm[63:32] ∘ %ymm2_vmovshdup_xmm_xmm[63:32])))[255:128] ∘ (%ymm2_vmovshdup_xmm_xmm[127:96] ∘ %ymm2_vmovshdup_xmm_xmm[127:96] ∘ (%ymm2_vmovshdup_xmm_xmm[63:32] ∘ %ymm2_vmovshdup_xmm_xmm[63:32])))[127:0]

=====================================
=====================================
Computing circuit for vmovshdup %xmm1, %xmm8

.target:
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovsldup %xmm11, %xmm11
vmovdqa %xmm11, %xmm3
vmovsldup %xmm9, %xmm1
unpcklpd %xmm3, %xmm1
retq 

Initial state:
%ymm8: %ymm8_movshdup_xmm_xmm

State for specgen instruction: vmovshdup %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₆₄ ∘ (%ymm2_vmovshdup_xmm_xmm[63:32] ∘ %ymm2_vmovshdup_xmm_xmm[63:32])))[255:128] ∘ (%ymm2_vmovshdup_xmm_xmm[127:96] ∘ %ymm2_vmovshdup_xmm_xmm[127:96] ∘ (%ymm2_vmovshdup_xmm_xmm[63:32] ∘ %ymm2_vmovshdup_xmm_xmm[63:32]))

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_movshdup_xmm_xmm[127:96] ∘ %ymm2_movshdup_xmm_xmm[127:96] ∘ (%ymm2_movshdup_xmm_xmm[63:32] ∘ %ymm2_movshdup_xmm_xmm[63:32]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_movaps_xmm_xmm
%rdx/%rdx: %rdx_movaps_xmm_xmm

%xmm0: %ymm0_movaps_xmm_xmm[127:0]
%xmm1: %ymm1_movaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1

Final state:
%rax/%rax: %rax_movaps_xmm_xmm
%rdx/%rdx: %rdx_movaps_xmm_xmm

%xmm0: %ymm0_movaps_xmm_xmm[127:0]
%xmm1: (%ymm1_movaps_xmm_xmm[255:128] ∘ ((%ymm7_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm6_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm5_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (%ymm4_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][31:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movaps %xmm8, %xmm1

.target:
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1
retq 

Initial state:
%xmm1: (%ymm1_movshdup_xmm_xmm[255:128] ∘ (%ymm2_movshdup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movshdup_xmm_xmm[127:0][63:0][63:0]))[127:0]

State for specgen instruction: movaps %xmm2, %xmm1:
%xmm1: (%ymm1_movaps_xmm_xmm[255:128] ∘ ((%ymm7_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm6_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm5_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (%ymm4_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][31:0]))[127:0][31:0]))[127:0]

Final state
%xmm1: ((%ymm1_movshdup_xmm_xmm[255:128] ∘ (%ymm2_movshdup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movshdup_xmm_xmm[127:0][63:0][63:0]))[255:128] ∘ (%ymm2_movshdup_xmm_xmm[127:96] ∘ %ymm2_movshdup_xmm_xmm[127:96] ∘ %ymm2_movshdup_xmm_xmm[63:32] ∘ %ymm2_movshdup_xmm_xmm[63:32]))[127:0]

=====================================
=====================================
Computing circuit for movshdup %xmm1, %xmm0

.target:
callq .move_128_064_xmm2_r10_r11
callq .move_064_128_r10_r11_xmm1
vmovshdup %xmm1, %xmm8
movaps %xmm8, %xmm1
retq 

Initial state:
%xmm0: %ymm0_phaddd_xmm_xmm[127:0]

State for specgen instruction: movshdup %xmm2, %xmm1:
%xmm1: ((%ymm1_movshdup_xmm_xmm[255:128] ∘ (%ymm2_movshdup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movshdup_xmm_xmm[127:0][63:0][63:0]))[255:128] ∘ (%ymm2_movshdup_xmm_xmm[127:96] ∘ %ymm2_movshdup_xmm_xmm[127:96] ∘ %ymm2_movshdup_xmm_xmm[63:32] ∘ %ymm2_movshdup_xmm_xmm[63:32]))[127:0]

Final state
%xmm0: (%ymm0_phaddd_xmm_xmm[255:128] ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_phaddd_xmm_xmm
%rdx/%rdx: %rdx_phaddd_xmm_xmm

%xmm0: (%ymm0_phaddd_xmm_xmm[255:128] ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]))[127:0]
%xmm1: %ymm1_phaddd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r8_r9

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r10, %r8

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r8/%r8: %ymm1_paddq_xmm_xmm[127:0][63:0]

%cf: %cf_paddq_xmm_xmm
%pf: %pf_paddq_xmm_xmm
%af: %af_paddq_xmm_xmm
%zf: %zf_paddq_xmm_xmm
%sf: %sf_paddq_xmm_xmm
%of: %of_paddq_xmm_xmm

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r8
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

Final state
%r8/%r8: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r10b_r11b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_cx_r8b_r9b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r10b_r11b_cx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r8b_r9b_bx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for xchgw %r8w, %r8w

.target:
callq .move_016_008_bx_r10b_r11b
callq .move_016_008_cx_r8b_r9b
callq .move_008_016_r10b_r11b_cx
callq .move_008_016_r8b_r9b_bx
retq 

Initial state:
%r8/%r8w: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

State for specgen instruction: xchgw %cx, %bx:
%rcx/%cx: %rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])
%rbx/%bx: %rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])

Register        -> %cx
  translates to => %r8w
Value is               -> (%rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Register        -> %bx
  translates to => %r8w
Value is               -> (%rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Final state
%r8/%r8w: ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

=====================================
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r11, %r9

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r9/%r9: %ymm1_paddq_xmm_xmm[127:0][127:64]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r9
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

Final state
%r9/%r9: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[67:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[67:64])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[127:127] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for paddq %xmm0, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
callq .move_128_064_xmm1_r8_r9
addq %r10, %r8
xchgw %r8w, %r8w
addq %r11, %r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_phaddd_xmm_xmm[127:0]

State for specgen instruction: paddq %xmm2, %xmm1:
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

Final state
%xmm1: (%ymm1_phaddd_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[63:0])[63:0]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r8_r9

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r10, %r8

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r8/%r8: %ymm1_paddq_xmm_xmm[127:0][63:0]

%cf: %cf_paddq_xmm_xmm
%pf: %pf_paddq_xmm_xmm
%af: %af_paddq_xmm_xmm
%zf: %zf_paddq_xmm_xmm
%sf: %sf_paddq_xmm_xmm
%of: %of_paddq_xmm_xmm

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r8
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

Final state
%r8/%r8: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r10b_r11b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_cx_r8b_r9b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r10b_r11b_cx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r8b_r9b_bx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for xchgw %r8w, %r8w

.target:
callq .move_016_008_bx_r10b_r11b
callq .move_016_008_cx_r8b_r9b
callq .move_008_016_r10b_r11b_cx
callq .move_008_016_r8b_r9b_bx
retq 

Initial state:
%r8/%r8w: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

State for specgen instruction: xchgw %cx, %bx:
%rcx/%cx: %rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])
%rbx/%bx: %rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])

Register        -> %cx
  translates to => %r8w
Value is               -> (%rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Register        -> %bx
  translates to => %r8w
Value is               -> (%rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Final state
%r8/%r8w: ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

=====================================
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r11, %r9

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r9/%r9: %ymm1_paddq_xmm_xmm[127:0][127:64]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r9
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

Final state
%r9/%r9: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[67:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[67:64])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[127:127] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for paddq %xmm2, %xmm3

.target:
callq .move_128_064_xmm2_r10_r11
callq .move_128_064_xmm1_r8_r9
addq %r10, %r8
xchgw %r8w, %r8w
addq %r11, %r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm3: %ymm3_vpaddq_xmm_xmm_xmm[127:0]

State for specgen instruction: paddq %xmm2, %xmm1:
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

Final state
%xmm3: (%ymm3_vpaddq_xmm_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: %ymm0_vmovups_xmm_xmm[127:0]
%xmm1: %ymm1_vmovups_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovups %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpaddq_xmm_xmm_xmm

State for specgen instruction: vmovups %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0])

=====================================
=====================================
Computing circuit for vpaddq %xmm9, %xmm2, %xmm6

.target:
paddq %xmm2, %xmm3
vmovups %xmm3, %xmm1
retq 

Initial state:
%ymm6: %ymm6_phaddd_xmm_xmm

State for specgen instruction: vpaddq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0])

Final state
%ymm6: 0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_phaddd_xmm_xmm[127:64] + 0x0₁ ∘ 0x0₆₄)[63:0] ∘ (0x0₁ ∘ %ymm2_phaddd_xmm_xmm[63:0] + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[63:32]))[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm9, %xmm1, %xmm4

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm4: %ymm4_phaddd_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm4: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[63:32] ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[63:0])[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vmovhlps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovhlps_xmm_xmm_xmm

%xmm0: %ymm0_vmovhlps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vmovhlps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovhlps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovhlps_xmm_xmm_xmm

%xmm0: %ymm0_vmovhlps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vmovhlps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r11, %r12

Final state:
%r12/%r12: %ymm3_vmovhlps_xmm_xmm_xmm[127:0][127:64]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovhlps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovhlps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovhlps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmovhlps_xmm_xmm_xmm[127:0][127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovhlps %xmm1, %xmm8, %xmm5

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r12_r13
vzeroall 
movq %r11, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm5: %ymm5_phaddd_xmm_xmm

State for specgen instruction: vmovhlps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovhlps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmovhlps_xmm_xmm_xmm[127:0][127:64][63:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[127:64])[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r8_r9

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r10, %r8

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r8/%r8: %ymm1_paddq_xmm_xmm[127:0][63:0]

%cf: %cf_paddq_xmm_xmm
%pf: %pf_paddq_xmm_xmm
%af: %af_paddq_xmm_xmm
%zf: %zf_paddq_xmm_xmm
%sf: %sf_paddq_xmm_xmm
%of: %of_paddq_xmm_xmm

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r8
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

Final state
%r8/%r8: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r10b_r11b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_cx_r8b_r9b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r10b_r11b_cx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r8b_r9b_bx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for xchgw %r8w, %r8w

.target:
callq .move_016_008_bx_r10b_r11b
callq .move_016_008_cx_r8b_r9b
callq .move_008_016_r10b_r11b_cx
callq .move_008_016_r8b_r9b_bx
retq 

Initial state:
%r8/%r8w: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

State for specgen instruction: xchgw %cx, %bx:
%rcx/%cx: %rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])
%rbx/%bx: %rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])

Register        -> %cx
  translates to => %r8w
Value is               -> (%rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Register        -> %bx
  translates to => %r8w
Value is               -> (%rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Final state
%r8/%r8w: ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

=====================================
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r11, %r9

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r9/%r9: %ymm1_paddq_xmm_xmm[127:0][127:64]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r9
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

Final state
%r9/%r9: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[67:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[67:64])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[127:127] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for paddq %xmm2, %xmm3

.target:
callq .move_128_064_xmm2_r10_r11
callq .move_128_064_xmm1_r8_r9
addq %r10, %r8
xchgw %r8w, %r8w
addq %r11, %r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm3: %ymm3_vpaddq_xmm_xmm_xmm[127:0]

State for specgen instruction: paddq %xmm2, %xmm1:
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

Final state
%xmm3: (%ymm3_vpaddq_xmm_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: %ymm0_vmovups_xmm_xmm[127:0]
%xmm1: %ymm1_vmovups_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovups %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpaddq_xmm_xmm_xmm

State for specgen instruction: vmovups %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0])

=====================================
=====================================
Computing circuit for vpaddq %xmm10, %xmm11, %xmm7

.target:
paddq %xmm2, %xmm3
vmovups %xmm3, %xmm1
retq 

Initial state:
%ymm7: %ymm7_phaddd_xmm_xmm

State for specgen instruction: vpaddq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0])

Final state
%ymm7: 0x0₁₂₈ ∘ ((0x0₁ ∘ 0x0₆₄ + 0x0₁ ∘ 0x0₆₄)[63:0] ∘ (0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[95:64]))[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1

Final state:
%rax/%rax: %rax_phaddd_xmm_xmm
%rdx/%rdx: %rdx_phaddd_xmm_xmm

%xmm0: (%ymm0_phaddd_xmm_xmm[255:128] ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]))[127:0]
%xmm1: ((%ymm1_phaddd_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[63:0])[63:0]))[255:128] ∘ ((0x0₁₂₈ ∘ ((0x0₁ ∘ 0x0₆₄ + 0x0₁ ∘ 0x0₆₄)[63:0] ∘ (0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[95:64]))[63:0]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_phaddd_xmm_xmm[127:64] + 0x0₁ ∘ 0x0₆₄)[63:0] ∘ (0x0₁ ∘ %ymm2_phaddd_xmm_xmm[63:0] + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[63:32]))[63:0]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[127:64])[63:0]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[63:32] ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[63:0])[63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for phaddd %xmm10, %xmm1

.target:
movshdup %xmm1, %xmm0
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
paddq %xmm0, %xmm1
vpaddq %xmm9, %xmm2, %xmm6
vunpcklpd %xmm9, %xmm1, %xmm4
vmovhlps %xmm1, %xmm8, %xmm5
vpaddq %xmm10, %xmm11, %xmm7
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1
retq 

Initial state:
%xmm1: (%ymm1_paddd_xmm_xmm[255:128] ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm1_paddd_xmm_xmm[63:32] ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm1_paddd_xmm_xmm[31:0])))[127:0]

State for specgen instruction: phaddd %xmm2, %xmm1:
%xmm1: ((%ymm1_phaddd_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[63:0])[63:0]))[255:128] ∘ ((0x0₁₂₈ ∘ ((0x0₁ ∘ 0x0₆₄ + 0x0₁ ∘ 0x0₆₄)[63:0] ∘ (0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[95:64]))[63:0]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_phaddd_xmm_xmm[127:64] + 0x0₁ ∘ 0x0₆₄)[63:0] ∘ (0x0₁ ∘ %ymm2_phaddd_xmm_xmm[63:0] + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[63:32]))[63:0]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[127:64])[63:0]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[63:32] ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[63:0])[63:0]))[127:0][31:0]))[127:0]

Final state
%xmm1: ((%ymm1_paddd_xmm_xmm[255:128] ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm1_paddd_xmm_xmm[63:32] ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm1_paddd_xmm_xmm[31:0])))[255:128] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm1_paddd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_paddd_xmm_xmm[127:96]))[31:0] ∘ (0x0₁ ∘ (%ymm1_paddd_xmm_xmm[95:64] ∘ %ymm2_paddd_xmm_xmm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm1_paddd_xmm_xmm[95:64]))[31:0] ∘ (0x0₁ ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm2_paddd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm1_paddd_xmm_xmm[63:32]))[31:0] ∘ (0x0₁ ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm2_paddd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm1_paddd_xmm_xmm[31:0]))[31:0]))[127:0]

=====================================
=====================================
Computing circuit for paddd %xmm3, %xmm12

.target:
vunpckhps %xmm1, %xmm2, %xmm10
unpcklps %xmm2, %xmm1
phaddd %xmm10, %xmm1
retq 

Initial state:
%xmm12: (%ymm12_vpaddd_ymm_ymm_ymm[255:128] ∘ %ymm2_vpaddd_ymm_ymm_ymm[127:0])[127:0]

State for specgen instruction: paddd %xmm2, %xmm1:
%xmm1: ((%ymm1_paddd_xmm_xmm[255:128] ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm1_paddd_xmm_xmm[63:32] ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm1_paddd_xmm_xmm[31:0])))[255:128] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm1_paddd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_paddd_xmm_xmm[127:96]))[31:0] ∘ (0x0₁ ∘ (%ymm1_paddd_xmm_xmm[95:64] ∘ %ymm2_paddd_xmm_xmm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm1_paddd_xmm_xmm[95:64]))[31:0] ∘ (0x0₁ ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm2_paddd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm1_paddd_xmm_xmm[63:32]))[31:0] ∘ (0x0₁ ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm2_paddd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm1_paddd_xmm_xmm[31:0]))[31:0]))[127:0]

Final state
%xmm12: ((%ymm12_vpaddd_ymm_ymm_ymm[255:128] ∘ %ymm2_vpaddd_ymm_ymm_ymm[127:0])[255:128] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_ymm_ymm_ymm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm3_vpaddd_ymm_ymm_ymm[127:96]))[31:0] ∘ (0x0₁ ∘ (%ymm2_vpaddd_ymm_ymm_ymm[95:64] ∘ %ymm3_vpaddd_ymm_ymm_ymm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_ymm_ymm_ymm[95:64]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_ymm_ymm_ymm[63:32] ∘ %ymm3_vpaddd_ymm_ymm_ymm[63:32]) + 0x0₁ ∘ (%ymm3_vpaddd_ymm_ymm_ymm[63:32] ∘ %ymm2_vpaddd_ymm_ymm_ymm[63:32]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_ymm_ymm_ymm[31:0] ∘ %ymm3_vpaddd_ymm_ymm_ymm[31:0]) + 0x0₁ ∘ (%ymm3_vpaddd_ymm_ymm_ymm[31:0] ∘ %ymm2_vpaddd_ymm_ymm_ymm[31:0]))[31:0]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm2

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm2: %ymm2_vunpckhps_xmm_xmm_xmm[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm2: (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpckhps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm9, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vunpckhps_xmm_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: %ymm0_vmovq_xmm_xmm[127:0]
%xmm1: %ymm1_vmovq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movswq %bx, %r10

Final state:
%r10/%r10: sign-extend-64(%rbx_xchgl_r32_r32[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_xchgl_r32_r32[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ecx_r8w_r9w

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %rcx

Final state:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r8w_r9w_ebx

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xchgl %ebx, %ecx

.target:
movswq %bx, %r10
movslq %ebx, %rbx
callq .move_032_016_ecx_r8w_r9w
callq .move_064_032_rbx_r10d_r11d
movq %r10, %rcx
callq .move_016_032_r8w_r9w_ebx
retq 

Initial state:
%rcx/%rcx: %rcx_xorl_r32_r32
%rbx/%rbx: %rbx_xorl_r32_r32

State for specgen instruction: xchgl %ecx, %ebx:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
%rbx/%rbx: 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])

Register        -> %rcx
  translates to => %rbx
Value is               -> 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
  after renaming it is => 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

Register        -> %rbx
  translates to => %rcx
Value is               -> 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])
  after renaming it is => 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

Final state
%rcx/%rcx: 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]) = 0x0₆₄
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_ebx

Final state:
%rax/%rax: %rax_xorl_r32_r32
%rdx/%rdx: %rdx_xorl_r32_r32

%xmm0: %ymm0_xorl_r32_r32[127:0]
%xmm1: %ymm1_xorl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xorl %r13d, %r13d

.target:
xchgl %ebx, %ecx
xorq %rcx, %rbx
callq .set_szp_for_ebx
retq 

Initial state:
%r13/%r13: %ymm2_vmovq_xmm_xmm[127:0][127:64]

%cf: %cf_vmovq_xmm_xmm
%pf: %pf_vmovq_xmm_xmm
%zf: %zf_vmovq_xmm_xmm
%sf: %sf_vmovq_xmm_xmm
%of: %of_vmovq_xmm_xmm

State for specgen instruction: xorl %ecx, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0] = 0x0₃₂
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][31:31] = 0x1₁
%of: false

Register        -> %rbx
  translates to => %r13
Value is               -> 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
  after renaming it is => 0x0₆₄

Final state
%r13/%r13: 0x0₆₄

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
xorl %r13d, %r13d
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][95:64])

State for specgen instruction: vmovq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhps %xmm1, %xmm2, %xmm10

.target:
unpckhpd %xmm3, %xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovddup %xmm9, %xmm1
vmovq %xmm1, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm10: %ymm10_paddd_xmm_xmm

State for specgen instruction: vunpckhps %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_paddd_xmm_xmm[127:96] ∘ %ymm2_paddd_xmm_xmm[127:96] ∘ %ymm1_paddd_xmm_xmm[95:64] ∘ %ymm2_paddd_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm2, %xmm1

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm1: %ymm1_paddd_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm1: (%ymm1_paddd_xmm_xmm[255:128] ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm1_paddd_xmm_xmm[63:32] ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm1_paddd_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_movshdup_xmm_xmm
%rdx/%rdx: %rdx_movshdup_xmm_xmm

%xmm0: %ymm0_movshdup_xmm_xmm[127:0]
%xmm1: %ymm1_movshdup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_movshdup_xmm_xmm
%rdx/%rdx: %rdx_movshdup_xmm_xmm

%xmm0: %ymm0_movshdup_xmm_xmm[127:0]
%xmm1: (%ymm1_movshdup_xmm_xmm[255:128] ∘ (%ymm2_movshdup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movshdup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovshdup_xmm_xmm
%rdx/%rdx: %rdx_vmovshdup_xmm_xmm

%xmm0: %ymm0_vmovshdup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovshdup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm11, %xmm11

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm11: %ymm11_vmovshdup_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovshdup_xmm_xmm[127:0][127:96])

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm11: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (%ymm2_vmovshdup_xmm_xmm[127:96] ∘ %ymm2_vmovshdup_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm11, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmovshdup_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (%ymm2_vmovshdup_xmm_xmm[127:96] ∘ %ymm2_vmovshdup_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm9, %xmm1

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovshdup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (%ymm2_vmovshdup_xmm_xmm[63:32] ∘ %ymm2_vmovshdup_xmm_xmm[63:32]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpcklpd_xmm_xmm
%rdx/%rdx: %rdx_unpcklpd_xmm_xmm

%xmm0: %ymm0_unpcklpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpcklpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm11: %ymm11_unpcklpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm1_unpcklpd_xmm_xmm[127:0][127:64])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_unpcklpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_unpcklpd_xmm_xmm
%rdx/%rdx: %rdx_unpcklpd_xmm_xmm

%xmm0: %ymm0_unpcklpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpcklpd_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ %ymm2_unpcklpd_xmm_xmm[127:0])[127:0][63:0] ∘ (%ymm10_unpcklpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm1_unpcklpd_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpcklpd %xmm3, %xmm1

.target:
callq .move_128_64_xmm1_xmm10_xmm11
vmovdqu %xmm2, %xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ (0x0₆₄ ∘ (%ymm2_vmovshdup_xmm_xmm[63:32] ∘ %ymm2_vmovshdup_xmm_xmm[63:32])))[127:0]

State for specgen instruction: unpcklpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklpd_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ %ymm2_unpcklpd_xmm_xmm[127:0])[127:0][63:0] ∘ (%ymm10_unpcklpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm1_unpcklpd_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ (0x0₆₄ ∘ (%ymm2_vmovshdup_xmm_xmm[63:32] ∘ %ymm2_vmovshdup_xmm_xmm[63:32])))[255:128] ∘ (%ymm2_vmovshdup_xmm_xmm[127:96] ∘ %ymm2_vmovshdup_xmm_xmm[127:96] ∘ (%ymm2_vmovshdup_xmm_xmm[63:32] ∘ %ymm2_vmovshdup_xmm_xmm[63:32])))[127:0]

=====================================
=====================================
Computing circuit for vmovshdup %xmm1, %xmm8

.target:
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovsldup %xmm11, %xmm11
vmovdqa %xmm11, %xmm3
vmovsldup %xmm9, %xmm1
unpcklpd %xmm3, %xmm1
retq 

Initial state:
%ymm8: %ymm8_movshdup_xmm_xmm

State for specgen instruction: vmovshdup %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₆₄ ∘ (%ymm2_vmovshdup_xmm_xmm[63:32] ∘ %ymm2_vmovshdup_xmm_xmm[63:32])))[255:128] ∘ (%ymm2_vmovshdup_xmm_xmm[127:96] ∘ %ymm2_vmovshdup_xmm_xmm[127:96] ∘ (%ymm2_vmovshdup_xmm_xmm[63:32] ∘ %ymm2_vmovshdup_xmm_xmm[63:32]))

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_movshdup_xmm_xmm[127:96] ∘ %ymm2_movshdup_xmm_xmm[127:96] ∘ (%ymm2_movshdup_xmm_xmm[63:32] ∘ %ymm2_movshdup_xmm_xmm[63:32]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_movaps_xmm_xmm
%rdx/%rdx: %rdx_movaps_xmm_xmm

%xmm0: %ymm0_movaps_xmm_xmm[127:0]
%xmm1: %ymm1_movaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1

Final state:
%rax/%rax: %rax_movaps_xmm_xmm
%rdx/%rdx: %rdx_movaps_xmm_xmm

%xmm0: %ymm0_movaps_xmm_xmm[127:0]
%xmm1: (%ymm1_movaps_xmm_xmm[255:128] ∘ ((%ymm7_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm6_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm5_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (%ymm4_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][31:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movaps %xmm8, %xmm1

.target:
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1
retq 

Initial state:
%xmm1: (%ymm1_movshdup_xmm_xmm[255:128] ∘ (%ymm2_movshdup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movshdup_xmm_xmm[127:0][63:0][63:0]))[127:0]

State for specgen instruction: movaps %xmm2, %xmm1:
%xmm1: (%ymm1_movaps_xmm_xmm[255:128] ∘ ((%ymm7_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm6_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm5_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (%ymm4_movaps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_movaps_xmm_xmm[127:0][31:0]))[127:0][31:0]))[127:0]

Final state
%xmm1: ((%ymm1_movshdup_xmm_xmm[255:128] ∘ (%ymm2_movshdup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movshdup_xmm_xmm[127:0][63:0][63:0]))[255:128] ∘ (%ymm2_movshdup_xmm_xmm[127:96] ∘ %ymm2_movshdup_xmm_xmm[127:96] ∘ %ymm2_movshdup_xmm_xmm[63:32] ∘ %ymm2_movshdup_xmm_xmm[63:32]))[127:0]

=====================================
=====================================
Computing circuit for movshdup %xmm1, %xmm0

.target:
callq .move_128_064_xmm2_r10_r11
callq .move_064_128_r10_r11_xmm1
vmovshdup %xmm1, %xmm8
movaps %xmm8, %xmm1
retq 

Initial state:
%xmm0: %ymm0_phaddd_xmm_xmm[127:0]

State for specgen instruction: movshdup %xmm2, %xmm1:
%xmm1: ((%ymm1_movshdup_xmm_xmm[255:128] ∘ (%ymm2_movshdup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movshdup_xmm_xmm[127:0][63:0][63:0]))[255:128] ∘ (%ymm2_movshdup_xmm_xmm[127:96] ∘ %ymm2_movshdup_xmm_xmm[127:96] ∘ %ymm2_movshdup_xmm_xmm[63:32] ∘ %ymm2_movshdup_xmm_xmm[63:32]))[127:0]

Final state
%xmm0: (%ymm0_phaddd_xmm_xmm[255:128] ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_phaddd_xmm_xmm
%rdx/%rdx: %rdx_phaddd_xmm_xmm

%xmm0: (%ymm0_phaddd_xmm_xmm[255:128] ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]))[127:0]
%xmm1: %ymm1_phaddd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r8_r9

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r10, %r8

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r8/%r8: %ymm1_paddq_xmm_xmm[127:0][63:0]

%cf: %cf_paddq_xmm_xmm
%pf: %pf_paddq_xmm_xmm
%af: %af_paddq_xmm_xmm
%zf: %zf_paddq_xmm_xmm
%sf: %sf_paddq_xmm_xmm
%of: %of_paddq_xmm_xmm

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r8
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

Final state
%r8/%r8: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r10b_r11b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_cx_r8b_r9b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r10b_r11b_cx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r8b_r9b_bx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for xchgw %r8w, %r8w

.target:
callq .move_016_008_bx_r10b_r11b
callq .move_016_008_cx_r8b_r9b
callq .move_008_016_r10b_r11b_cx
callq .move_008_016_r8b_r9b_bx
retq 

Initial state:
%r8/%r8w: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

State for specgen instruction: xchgw %cx, %bx:
%rcx/%cx: %rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])
%rbx/%bx: %rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])

Register        -> %cx
  translates to => %r8w
Value is               -> (%rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Register        -> %bx
  translates to => %r8w
Value is               -> (%rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Final state
%r8/%r8w: ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

=====================================
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r11, %r9

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r9/%r9: %ymm1_paddq_xmm_xmm[127:0][127:64]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r9
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

Final state
%r9/%r9: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[67:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[67:64])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[127:127] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for paddq %xmm0, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
callq .move_128_064_xmm1_r8_r9
addq %r10, %r8
xchgw %r8w, %r8w
addq %r11, %r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_phaddd_xmm_xmm[127:0]

State for specgen instruction: paddq %xmm2, %xmm1:
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

Final state
%xmm1: (%ymm1_phaddd_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[63:0])[63:0]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r8_r9

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r10, %r8

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r8/%r8: %ymm1_paddq_xmm_xmm[127:0][63:0]

%cf: %cf_paddq_xmm_xmm
%pf: %pf_paddq_xmm_xmm
%af: %af_paddq_xmm_xmm
%zf: %zf_paddq_xmm_xmm
%sf: %sf_paddq_xmm_xmm
%of: %of_paddq_xmm_xmm

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r8
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

Final state
%r8/%r8: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r10b_r11b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_cx_r8b_r9b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r10b_r11b_cx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r8b_r9b_bx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for xchgw %r8w, %r8w

.target:
callq .move_016_008_bx_r10b_r11b
callq .move_016_008_cx_r8b_r9b
callq .move_008_016_r10b_r11b_cx
callq .move_008_016_r8b_r9b_bx
retq 

Initial state:
%r8/%r8w: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

State for specgen instruction: xchgw %cx, %bx:
%rcx/%cx: %rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])
%rbx/%bx: %rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])

Register        -> %cx
  translates to => %r8w
Value is               -> (%rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Register        -> %bx
  translates to => %r8w
Value is               -> (%rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Final state
%r8/%r8w: ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

=====================================
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r11, %r9

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r9/%r9: %ymm1_paddq_xmm_xmm[127:0][127:64]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r9
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

Final state
%r9/%r9: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[67:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[67:64])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[127:127] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for paddq %xmm2, %xmm3

.target:
callq .move_128_064_xmm2_r10_r11
callq .move_128_064_xmm1_r8_r9
addq %r10, %r8
xchgw %r8w, %r8w
addq %r11, %r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm3: %ymm3_vpaddq_xmm_xmm_xmm[127:0]

State for specgen instruction: paddq %xmm2, %xmm1:
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

Final state
%xmm3: (%ymm3_vpaddq_xmm_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: %ymm0_vmovups_xmm_xmm[127:0]
%xmm1: %ymm1_vmovups_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovups %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpaddq_xmm_xmm_xmm

State for specgen instruction: vmovups %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0])

=====================================
=====================================
Computing circuit for vpaddq %xmm9, %xmm2, %xmm6

.target:
paddq %xmm2, %xmm3
vmovups %xmm3, %xmm1
retq 

Initial state:
%ymm6: %ymm6_phaddd_xmm_xmm

State for specgen instruction: vpaddq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0])

Final state
%ymm6: 0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_phaddd_xmm_xmm[127:64] + 0x0₁ ∘ 0x0₆₄)[63:0] ∘ (0x0₁ ∘ %ymm2_phaddd_xmm_xmm[63:0] + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[63:32]))[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm9, %xmm1, %xmm4

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm4: %ymm4_phaddd_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm4: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[63:32] ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[63:0])[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vmovhlps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovhlps_xmm_xmm_xmm

%xmm0: %ymm0_vmovhlps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vmovhlps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovhlps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovhlps_xmm_xmm_xmm

%xmm0: %ymm0_vmovhlps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vmovhlps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r11, %r12

Final state:
%r12/%r12: %ymm3_vmovhlps_xmm_xmm_xmm[127:0][127:64]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovhlps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovhlps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovhlps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmovhlps_xmm_xmm_xmm[127:0][127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovhlps %xmm1, %xmm8, %xmm5

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r12_r13
vzeroall 
movq %r11, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm5: %ymm5_phaddd_xmm_xmm

State for specgen instruction: vmovhlps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovhlps_xmm_xmm_xmm[127:0][127:64][63:0] ∘ %ymm3_vmovhlps_xmm_xmm_xmm[127:0][127:64][63:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[127:64])[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r8_r9

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r10, %r8

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r8/%r8: %ymm1_paddq_xmm_xmm[127:0][63:0]

%cf: %cf_paddq_xmm_xmm
%pf: %pf_paddq_xmm_xmm
%af: %af_paddq_xmm_xmm
%zf: %zf_paddq_xmm_xmm
%sf: %sf_paddq_xmm_xmm
%of: %of_paddq_xmm_xmm

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r8
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

Final state
%r8/%r8: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r10b_r11b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_cx_r8b_r9b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r10b_r11b_cx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r8b_r9b_bx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for xchgw %r8w, %r8w

.target:
callq .move_016_008_bx_r10b_r11b
callq .move_016_008_cx_r8b_r9b
callq .move_008_016_r10b_r11b_cx
callq .move_008_016_r8b_r9b_bx
retq 

Initial state:
%r8/%r8w: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

State for specgen instruction: xchgw %cx, %bx:
%rcx/%cx: %rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])
%rbx/%bx: %rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])

Register        -> %cx
  translates to => %r8w
Value is               -> (%rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Register        -> %bx
  translates to => %r8w
Value is               -> (%rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Final state
%r8/%r8w: ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

=====================================
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r11, %r9

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r9/%r9: %ymm1_paddq_xmm_xmm[127:0][127:64]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r9
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

Final state
%r9/%r9: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[67:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[67:64])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[127:127] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for paddq %xmm2, %xmm3

.target:
callq .move_128_064_xmm2_r10_r11
callq .move_128_064_xmm1_r8_r9
addq %r10, %r8
xchgw %r8w, %r8w
addq %r11, %r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm3: %ymm3_vpaddq_xmm_xmm_xmm[127:0]

State for specgen instruction: paddq %xmm2, %xmm1:
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

Final state
%xmm3: (%ymm3_vpaddq_xmm_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: %ymm0_vmovups_xmm_xmm[127:0]
%xmm1: %ymm1_vmovups_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovups %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpaddq_xmm_xmm_xmm

State for specgen instruction: vmovups %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0])

=====================================
=====================================
Computing circuit for vpaddq %xmm10, %xmm11, %xmm7

.target:
paddq %xmm2, %xmm3
vmovups %xmm3, %xmm1
retq 

Initial state:
%ymm7: %ymm7_phaddd_xmm_xmm

State for specgen instruction: vpaddq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0])

Final state
%ymm7: 0x0₁₂₈ ∘ ((0x0₁ ∘ 0x0₆₄ + 0x0₁ ∘ 0x0₆₄)[63:0] ∘ (0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[95:64]))[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1

Final state:
%rax/%rax: %rax_phaddd_xmm_xmm
%rdx/%rdx: %rdx_phaddd_xmm_xmm

%xmm0: (%ymm0_phaddd_xmm_xmm[255:128] ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]))[127:0]
%xmm1: ((%ymm1_phaddd_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[63:0])[63:0]))[255:128] ∘ ((0x0₁₂₈ ∘ ((0x0₁ ∘ 0x0₆₄ + 0x0₁ ∘ 0x0₆₄)[63:0] ∘ (0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[95:64]))[63:0]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_phaddd_xmm_xmm[127:64] + 0x0₁ ∘ 0x0₆₄)[63:0] ∘ (0x0₁ ∘ %ymm2_phaddd_xmm_xmm[63:0] + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[63:32]))[63:0]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[127:64])[63:0]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[63:32] ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[63:0])[63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for phaddd %xmm10, %xmm1

.target:
movshdup %xmm1, %xmm0
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
paddq %xmm0, %xmm1
vpaddq %xmm9, %xmm2, %xmm6
vunpcklpd %xmm9, %xmm1, %xmm4
vmovhlps %xmm1, %xmm8, %xmm5
vpaddq %xmm10, %xmm11, %xmm7
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm1
retq 

Initial state:
%xmm1: (%ymm1_paddd_xmm_xmm[255:128] ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm1_paddd_xmm_xmm[63:32] ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm1_paddd_xmm_xmm[31:0])))[127:0]

State for specgen instruction: phaddd %xmm2, %xmm1:
%xmm1: ((%ymm1_phaddd_xmm_xmm[255:128] ∘ ((0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[63:0])[63:0]))[255:128] ∘ ((0x0₁₂₈ ∘ ((0x0₁ ∘ 0x0₆₄ + 0x0₁ ∘ 0x0₆₄)[63:0] ∘ (0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[95:64]))[63:0]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_phaddd_xmm_xmm[127:64] + 0x0₁ ∘ 0x0₆₄)[63:0] ∘ (0x0₁ ∘ %ymm2_phaddd_xmm_xmm[63:0] + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[63:32]))[63:0]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[127:96] ∘ %ymm1_phaddd_xmm_xmm[127:96]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[127:64])[63:0]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_phaddd_xmm_xmm[63:32] ∘ (0x0₁ ∘ (%ymm1_phaddd_xmm_xmm[63:32] ∘ %ymm1_phaddd_xmm_xmm[63:32]) + 0x0₁ ∘ %ymm1_phaddd_xmm_xmm[63:0])[63:0]))[127:0][31:0]))[127:0]

Final state
%xmm1: ((%ymm1_paddd_xmm_xmm[255:128] ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm1_paddd_xmm_xmm[63:32] ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm1_paddd_xmm_xmm[31:0])))[255:128] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm1_paddd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_paddd_xmm_xmm[127:96]))[31:0] ∘ (0x0₁ ∘ (%ymm1_paddd_xmm_xmm[95:64] ∘ %ymm2_paddd_xmm_xmm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm1_paddd_xmm_xmm[95:64]))[31:0] ∘ (0x0₁ ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm2_paddd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm1_paddd_xmm_xmm[63:32]))[31:0] ∘ (0x0₁ ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm2_paddd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm1_paddd_xmm_xmm[31:0]))[31:0]))[127:0]

=====================================
=====================================
Computing circuit for paddd %xmm11, %xmm13

.target:
vunpckhps %xmm1, %xmm2, %xmm10
unpcklps %xmm2, %xmm1
phaddd %xmm10, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_vpaddd_ymm_ymm_ymm[255:128] ∘ %ymm2_vpaddd_ymm_ymm_ymm[255:128])[127:0]

State for specgen instruction: paddd %xmm2, %xmm1:
%xmm1: ((%ymm1_paddd_xmm_xmm[255:128] ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm1_paddd_xmm_xmm[63:32] ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm1_paddd_xmm_xmm[31:0])))[255:128] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm1_paddd_xmm_xmm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_paddd_xmm_xmm[127:96]))[31:0] ∘ (0x0₁ ∘ (%ymm1_paddd_xmm_xmm[95:64] ∘ %ymm2_paddd_xmm_xmm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm1_paddd_xmm_xmm[95:64]))[31:0] ∘ (0x0₁ ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm2_paddd_xmm_xmm[63:32]) + 0x0₁ ∘ (%ymm2_paddd_xmm_xmm[63:32] ∘ %ymm1_paddd_xmm_xmm[63:32]))[31:0] ∘ (0x0₁ ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm2_paddd_xmm_xmm[31:0]) + 0x0₁ ∘ (%ymm2_paddd_xmm_xmm[31:0] ∘ %ymm1_paddd_xmm_xmm[31:0]))[31:0]))[127:0]

Final state
%xmm13: ((%ymm13_vpaddd_ymm_ymm_ymm[255:128] ∘ %ymm2_vpaddd_ymm_ymm_ymm[255:128])[255:128] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_ymm_ymm_ymm[255:224]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm3_vpaddd_ymm_ymm_ymm[255:224]))[31:0] ∘ (0x0₁ ∘ (%ymm2_vpaddd_ymm_ymm_ymm[223:192] ∘ %ymm3_vpaddd_ymm_ymm_ymm[223:192]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_ymm_ymm_ymm[223:192]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_ymm_ymm_ymm[191:160] ∘ %ymm3_vpaddd_ymm_ymm_ymm[191:160]) + 0x0₁ ∘ (%ymm3_vpaddd_ymm_ymm_ymm[191:160] ∘ %ymm2_vpaddd_ymm_ymm_ymm[191:160]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_ymm_ymm_ymm[159:128] ∘ %ymm3_vpaddd_ymm_ymm_ymm[159:128]) + 0x0₁ ∘ (%ymm3_vpaddd_ymm_ymm_ymm[159:128] ∘ %ymm2_vpaddd_ymm_ymm_ymm[159:128]))[31:0]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vpaddd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vpaddd_ymm_ymm_ymm

%xmm0: %ymm0_vpaddd_ymm_ymm_ymm[127:0]
%xmm1: (((%ymm13_vpaddd_ymm_ymm_ymm[255:128] ∘ %ymm2_vpaddd_ymm_ymm_ymm[255:128])[255:128] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_ymm_ymm_ymm[255:224]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm3_vpaddd_ymm_ymm_ymm[255:224]))[31:0] ∘ (0x0₁ ∘ (%ymm2_vpaddd_ymm_ymm_ymm[223:192] ∘ %ymm3_vpaddd_ymm_ymm_ymm[223:192]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_ymm_ymm_ymm[223:192]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_ymm_ymm_ymm[191:160] ∘ %ymm3_vpaddd_ymm_ymm_ymm[191:160]) + 0x0₁ ∘ (%ymm3_vpaddd_ymm_ymm_ymm[191:160] ∘ %ymm2_vpaddd_ymm_ymm_ymm[191:160]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_ymm_ymm_ymm[159:128] ∘ %ymm3_vpaddd_ymm_ymm_ymm[159:128]) + 0x0₁ ∘ (%ymm3_vpaddd_ymm_ymm_ymm[159:128] ∘ %ymm2_vpaddd_ymm_ymm_ymm[159:128]))[31:0]))[127:0][127:0] ∘ ((%ymm12_vpaddd_ymm_ymm_ymm[255:128] ∘ %ymm2_vpaddd_ymm_ymm_ymm[127:0])[255:128] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_ymm_ymm_ymm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm3_vpaddd_ymm_ymm_ymm[127:96]))[31:0] ∘ (0x0₁ ∘ (%ymm2_vpaddd_ymm_ymm_ymm[95:64] ∘ %ymm3_vpaddd_ymm_ymm_ymm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_ymm_ymm_ymm[95:64]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_ymm_ymm_ymm[63:32] ∘ %ymm3_vpaddd_ymm_ymm_ymm[63:32]) + 0x0₁ ∘ (%ymm3_vpaddd_ymm_ymm_ymm[63:32] ∘ %ymm2_vpaddd_ymm_ymm_ymm[63:32]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_ymm_ymm_ymm[31:0] ∘ %ymm3_vpaddd_ymm_ymm_ymm[31:0]) + 0x0₁ ∘ (%ymm3_vpaddd_ymm_ymm_ymm[31:0] ∘ %ymm2_vpaddd_ymm_ymm_ymm[31:0]))[31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpaddd %ymm3, %ymm2, %ymm1

.target:
callq .move_256_128_ymm2_xmm12_xmm13
callq .move_256_128_ymm3_xmm10_xmm11
paddd %xmm3, %xmm12
paddd %xmm11, %xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1

State for specgen instruction: vpaddd %ymm3, %ymm2, %ymm1:
%ymm1: ((%ymm13_vpaddd_ymm_ymm_ymm[255:128] ∘ %ymm2_vpaddd_ymm_ymm_ymm[255:128])[255:128] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_ymm_ymm_ymm[255:224]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm3_vpaddd_ymm_ymm_ymm[255:224]))[31:0] ∘ (0x0₁ ∘ (%ymm2_vpaddd_ymm_ymm_ymm[223:192] ∘ %ymm3_vpaddd_ymm_ymm_ymm[223:192]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_ymm_ymm_ymm[223:192]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_ymm_ymm_ymm[191:160] ∘ %ymm3_vpaddd_ymm_ymm_ymm[191:160]) + 0x0₁ ∘ (%ymm3_vpaddd_ymm_ymm_ymm[191:160] ∘ %ymm2_vpaddd_ymm_ymm_ymm[191:160]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_ymm_ymm_ymm[159:128] ∘ %ymm3_vpaddd_ymm_ymm_ymm[159:128]) + 0x0₁ ∘ (%ymm3_vpaddd_ymm_ymm_ymm[159:128] ∘ %ymm2_vpaddd_ymm_ymm_ymm[159:128]))[31:0]))[127:0][127:0] ∘ ((%ymm12_vpaddd_ymm_ymm_ymm[255:128] ∘ %ymm2_vpaddd_ymm_ymm_ymm[127:0])[255:128] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_ymm_ymm_ymm[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm3_vpaddd_ymm_ymm_ymm[127:96]))[31:0] ∘ (0x0₁ ∘ (%ymm2_vpaddd_ymm_ymm_ymm[95:64] ∘ %ymm3_vpaddd_ymm_ymm_ymm[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2_vpaddd_ymm_ymm_ymm[95:64]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_ymm_ymm_ymm[63:32] ∘ %ymm3_vpaddd_ymm_ymm_ymm[63:32]) + 0x0₁ ∘ (%ymm3_vpaddd_ymm_ymm_ymm[63:32] ∘ %ymm2_vpaddd_ymm_ymm_ymm[63:32]))[31:0] ∘ (0x0₁ ∘ (%ymm3_vpaddd_ymm_ymm_ymm[31:0] ∘ %ymm3_vpaddd_ymm_ymm_ymm[31:0]) + 0x0₁ ∘ (%ymm3_vpaddd_ymm_ymm_ymm[31:0] ∘ %ymm2_vpaddd_ymm_ymm_ymm[31:0]))[31:0]))[127:0][127:0]

Final state
%ymm1: (0x0₁ ∘ (0x0₃₂ ∘ %ymm2[255:224]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm3[255:224]))[31:0] ∘ (0x0₁ ∘ (%ymm2[223:192] ∘ %ymm3[223:192]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2[223:192]))[31:0] ∘ (0x0₁ ∘ (%ymm3[191:160] ∘ %ymm3[191:160]) + 0x0₁ ∘ (%ymm3[191:160] ∘ %ymm2[191:160]))[31:0] ∘ (0x0₁ ∘ (%ymm3[159:128] ∘ %ymm3[159:128]) + 0x0₁ ∘ (%ymm3[159:128] ∘ %ymm2[159:128]))[31:0] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm2[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm3[127:96]))[31:0] ∘ (0x0₁ ∘ (%ymm2[95:64] ∘ %ymm3[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2[95:64]))[31:0] ∘ (0x0₁ ∘ (%ymm3[63:32] ∘ %ymm3[63:32]) + 0x0₁ ∘ (%ymm3[63:32] ∘ %ymm2[63:32]))[31:0] ∘ (0x0₁ ∘ (%ymm3[31:0] ∘ %ymm3[31:0]) + 0x0₁ ∘ (%ymm3[31:0] ∘ %ymm2[31:0]))[31:0])

=====================================
Circuits:

%ymm1  : (0x0₁ ∘ (0x0₃₂ ∘ %ymm2[255:224]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm3[255:224]))[31:0] ∘ (0x0₁ ∘ (%ymm2[223:192] ∘ %ymm3[223:192]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2[223:192]))[31:0] ∘ (0x0₁ ∘ (%ymm3[191:160] ∘ %ymm3[191:160]) + 0x0₁ ∘ (%ymm3[191:160] ∘ %ymm2[191:160]))[31:0] ∘ (0x0₁ ∘ (%ymm3[159:128] ∘ %ymm3[159:128]) + 0x0₁ ∘ (%ymm3[159:128] ∘ %ymm2[159:128]))[31:0] ∘ ((0x0₁ ∘ (0x0₃₂ ∘ %ymm2[127:96]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm3[127:96]))[31:0] ∘ (0x0₁ ∘ (%ymm2[95:64] ∘ %ymm3[95:64]) + 0x0₁ ∘ (0x0₃₂ ∘ %ymm2[95:64]))[31:0] ∘ (0x0₁ ∘ (%ymm3[63:32] ∘ %ymm3[63:32]) + 0x0₁ ∘ (%ymm3[63:32] ∘ %ymm2[63:32]))[31:0] ∘ (0x0₁ ∘ (%ymm3[31:0] ∘ %ymm3[31:0]) + 0x0₁ ∘ (%ymm3[31:0] ∘ %ymm2[31:0]))[31:0])

sigfpe  : sigfpe
sigbus  : sigbus
sigsegv : sigsegv

*/