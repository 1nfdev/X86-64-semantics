// Autogenerated using stratification.
requires "x86-configuration.k"

module VPADDQ-XMM-XMM-XMM
  imports X86-CONFIGURATION

  rule <k>
    execinstr (vpaddq R1:Xmm, R2:Xmm, R3:Xmm,  .Typedoperands) => .
  ...</k>
    <regstate>
RSMap:Map => updateMap(RSMap,
convToRegKeys(R3) |-> (concatenateMInt(mi(128, 0), concatenateMInt(extractMInt(addMInt(concatenateMInt(mi(1, 0), extractMInt(getParentValue(R2, RSMap), 128, 192)), concatenateMInt(mi(1, 0), extractMInt(getParentValue(R1, RSMap), 128, 192))), 1, 65), extractMInt(addMInt(concatenateMInt(mi(1, 0), extractMInt(getParentValue(R2, RSMap), 192, 256)), concatenateMInt(mi(1, 0), extractMInt(getParentValue(R1, RSMap), 192, 256))), 1, 65))) )


)

    </regstate>
endmodule

module VPADDQ-XMM-XMM-XMM-SEMANTICS
  imports VPADDQ-XMM-XMM-XMM
endmodule
/*
TargetInstr:
vpaddq %xmm3, %xmm2, %xmm1
RWSet:
maybe read:{ %xmm2 %xmm3 }
must read:{ %xmm2 %xmm3 }
maybe write:{ %ymm1 }
must write:{ %ymm1 }
maybe undef:{ }
must undef:{ }
required flags:{ avx }

Circuit:
circuit:paddq %xmm2, %xmm3    #  1     0    4      OPC=paddq_xmm_xmm
circuit:vmovups %xmm3, %xmm1  #  2     0x4  4      OPC=vmovups_xmm_xmm
BVF:
WARNING: No live out values provided, assuming { }
WARNING: No def in values provided; assuming { %mxcsr::rc[0] }
Target

vpaddq %xmm3, %xmm2, %xmm1

  maybe read:      { %xmm2 %xmm3 }
  must read:       { %xmm2 %xmm3 }
  maybe write:     { %ymm1 }
  must write:      { %ymm1 }
  maybe undef:     { }
  must undef:      { }
  required flags:  { avx }

-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r8_r9

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: %ymm1_paddq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r10, %r8

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r8/%r8: %ymm1_paddq_xmm_xmm[127:0][63:0]

%cf: %cf_paddq_xmm_xmm
%pf: %pf_paddq_xmm_xmm
%af: %af_paddq_xmm_xmm
%zf: %zf_paddq_xmm_xmm
%sf: %sf_paddq_xmm_xmm
%of: %of_paddq_xmm_xmm

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r8
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

Final state
%r8/%r8: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r10b_r11b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_cx_r8b_r9b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r10b_r11b_cx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r8b_r9b_bx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for xchgw %r8w, %r8w

.target:
callq .move_016_008_bx_r10b_r11b
callq .move_016_008_cx_r8b_r9b
callq .move_008_016_r10b_r11b_cx
callq .move_008_016_r8b_r9b_bx
retq 

Initial state:
%r8/%r8w: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0]

State for specgen instruction: xchgw %cx, %bx:
%rcx/%cx: %rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])
%rbx/%bx: %rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])

Register        -> %cx
  translates to => %r8w
Value is               -> (%rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Register        -> %bx
  translates to => %r8w
Value is               -> (%rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

Final state
%r8/%r8w: ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0]

=====================================
-------------------------------------
Getting base circuit for orq %rbx, %rbx

Final state:
%rbx/%rbx: %rbx_addq_r64_r64 | %rbx_addq_r64_r64

%cf: false
%pf: !((%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][0:0] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][1:1] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][2:2] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][3:3] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][4:4] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][5:5] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][6:6] = 0x1₁ ⊕ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[7:0][7:7] = 0x1₁)
%zf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64) = 0x0₆₄
%sf: (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcq %rcx, %rbx

Final state:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for addq %r11, %r9

.target:
orq %rbx, %rbx
adcq %rcx, %rbx
retq 

Initial state:
%r9/%r9: %ymm1_paddq_xmm_xmm[127:0][127:64]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[3:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[63:63] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[63:63] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:63] = 0x1₁)

State for specgen instruction: addq %rcx, %rbx:
%rbx/%rbx: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[64:64] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addq_r64_r64[3:0] + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0] = 0x0₆₄
%sf: ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0][63:63] = 0x1₁
%of: (%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64)[63:63] = 0x1₁) ∧ !(%rcx_addq_r64_r64[63:63] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:63] = 0x1₁)

Register        -> %rbx
  translates to => %r9
Value is               -> ((false ? 0x0₁ ∘ %rcx_addq_r64_r64 + 0x1₆₅ : 0x0₁ ∘ %rcx_addq_r64_r64) + 0x0₁ ∘ (%rbx_addq_r64_r64 | %rbx_addq_r64_r64))[63:0]
  after renaming it is => (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

Final state
%r9/%r9: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0]

%cf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[64:64] = 0x1₁
%pf: !((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[67:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[67:64])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0] = 0x0₆₄
%sf: (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁
%of: (%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ %ymm1_paddq_xmm_xmm[127:127] = 0x1₁) ∧ !(%ymm2_paddq_xmm_xmm[127:127] = 0x1₁ ↔ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:63] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_paddq_xmm_xmm
%rdx/%rdx: %rdx_paddq_xmm_xmm

%xmm0: %ymm0_paddq_xmm_xmm[127:0]
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for paddq %xmm2, %xmm3

.target:
callq .move_128_064_xmm2_r10_r11
callq .move_128_064_xmm1_r8_r9
addq %r10, %r8
xchgw %r8w, %r8w
addq %r11, %r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm3: %ymm3_vpaddq_xmm_xmm_xmm[127:0]

State for specgen instruction: paddq %xmm2, %xmm1:
%xmm1: (%ymm1_paddq_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_paddq_xmm_xmm[127:64] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[127:64])[63:0][63:0] ∘ (((0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[63:0][63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:16] ∘ (0x0₁ ∘ %ymm2_paddq_xmm_xmm[63:0] + 0x0₁ ∘ %ymm1_paddq_xmm_xmm[63:0])[15:0])[63:0]))[127:0]

Final state
%xmm3: (%ymm3_vpaddq_xmm_xmm_xmm[255:128] ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: %ymm0_vmovups_xmm_xmm[127:0]
%xmm1: %ymm1_vmovups_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovups %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpaddq_xmm_xmm_xmm

State for specgen instruction: vmovups %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0])

=====================================
=====================================
Computing circuit for vpaddq %xmm3, %xmm2, %xmm1

.target:
paddq %xmm2, %xmm3
vmovups %xmm3, %xmm1
retq 

Initial state:
%ymm1: %ymm1

State for specgen instruction: vpaddq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[127:64] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2_vpaddq_xmm_xmm_xmm[63:0] + 0x0₁ ∘ %ymm3_vpaddq_xmm_xmm_xmm[63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2[127:64] + 0x0₁ ∘ %ymm3[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2[63:0] + 0x0₁ ∘ %ymm3[63:0])[63:0])

=====================================
Circuits:

%ymm1  : 0x0₁₂₈ ∘ ((0x0₁ ∘ %ymm2[127:64] + 0x0₁ ∘ %ymm3[127:64])[63:0] ∘ (0x0₁ ∘ %ymm2[63:0] + 0x0₁ ∘ %ymm3[63:0])[63:0])

sigfpe  : sigfpe
sigbus  : sigbus
sigsegv : sigsegv

*/