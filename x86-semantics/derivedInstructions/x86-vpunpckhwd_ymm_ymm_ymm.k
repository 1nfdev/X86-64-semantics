// Autogenerated using stratification.
requires "x86-configuration.k"

module VPUNPCKHWD-YMM-YMM-YMM
  imports X86-CONFIGURATION

  rule <k>
    execinstr (vpunpckhwd R1:Ymm, R2:Ymm, R3:Ymm,  .Typedoperands) => .
  ...</k>
    <regstate>
RSMap:Map => updateMap(RSMap,
convToRegKeys(R3) |-> (concatenateMInt(concatenateMInt(xorMInt(xorMInt(orMInt(concatenateMInt(concatenateMInt(mi(16, 0), extractMInt(getParentValue(R1, RSMap), 16, 32)), concatenateMInt(mi(16, 0), extractMInt(getParentValue(R1, RSMap), 16, 32))), concatenateMInt(extractMInt(getParentValue(R1, RSMap), 0, 32), concatenateMInt(extractMInt(getParentValue(R1, RSMap), 16, 32), extractMInt(getParentValue(R1, RSMap), 16, 32)))), concatenateMInt(concatenateMInt(mi(16, 0), extractMInt(getParentValue(R1, RSMap), 16, 32)), concatenateMInt(mi(16, 0), extractMInt(getParentValue(R1, RSMap), 16, 32)))), concatenateMInt(concatenateMInt(mi(16, 0), extractMInt(getParentValue(R2, RSMap), 0, 16)), concatenateMInt(mi(16, 0), extractMInt(getParentValue(R2, RSMap), 16, 32)))), xorMInt(xorMInt(orMInt(concatenateMInt(concatenateMInt(mi(16, 0), extractMInt(getParentValue(R1, RSMap), 48, 64)), concatenateMInt(mi(16, 0), extractMInt(getParentValue(R1, RSMap), 48, 64))), concatenateMInt(extractMInt(getParentValue(R1, RSMap), 32, 64), concatenateMInt(extractMInt(getParentValue(R1, RSMap), 48, 64), extractMInt(getParentValue(R1, RSMap), 48, 64)))), concatenateMInt(concatenateMInt(mi(16, 0), extractMInt(getParentValue(R1, RSMap), 48, 64)), concatenateMInt(mi(16, 0), extractMInt(getParentValue(R1, RSMap), 48, 64)))), concatenateMInt(concatenateMInt(mi(16, 0), extractMInt(getParentValue(R2, RSMap), 32, 48)), concatenateMInt(mi(16, 0), extractMInt(getParentValue(R2, RSMap), 48, 64))))), concatenateMInt(xorMInt(xorMInt(orMInt(concatenateMInt(concatenateMInt(mi(16, 0), extractMInt(getParentValue(R1, RSMap), 144, 160)), concatenateMInt(mi(16, 0), extractMInt(getParentValue(R1, RSMap), 144, 160))), concatenateMInt(extractMInt(getParentValue(R1, RSMap), 128, 160), concatenateMInt(extractMInt(getParentValue(R1, RSMap), 144, 160), extractMInt(getParentValue(R1, RSMap), 144, 160)))), concatenateMInt(concatenateMInt(mi(16, 0), extractMInt(getParentValue(R1, RSMap), 144, 160)), concatenateMInt(mi(16, 0), extractMInt(getParentValue(R1, RSMap), 144, 160)))), concatenateMInt(concatenateMInt(mi(16, 0), extractMInt(getParentValue(R2, RSMap), 128, 144)), concatenateMInt(mi(16, 0), extractMInt(getParentValue(R2, RSMap), 144, 160)))), xorMInt(xorMInt(orMInt(concatenateMInt(concatenateMInt(mi(16, 0), extractMInt(getParentValue(R1, RSMap), 176, 192)), concatenateMInt(mi(16, 0), extractMInt(getParentValue(R1, RSMap), 176, 192))), concatenateMInt(extractMInt(getParentValue(R1, RSMap), 160, 192), concatenateMInt(extractMInt(getParentValue(R1, RSMap), 176, 192), extractMInt(getParentValue(R1, RSMap), 176, 192)))), concatenateMInt(concatenateMInt(mi(16, 0), extractMInt(getParentValue(R1, RSMap), 176, 192)), concatenateMInt(mi(16, 0), extractMInt(getParentValue(R1, RSMap), 176, 192)))), concatenateMInt(concatenateMInt(mi(16, 0), extractMInt(getParentValue(R2, RSMap), 160, 176)), concatenateMInt(mi(16, 0), extractMInt(getParentValue(R2, RSMap), 176, 192)))))) )


)

    </regstate>
endmodule

module VPUNPCKHWD-YMM-YMM-YMM-SEMANTICS
  imports VPUNPCKHWD-YMM-YMM-YMM
endmodule
/*
TargetInstr:
vpunpckhwd %ymm3, %ymm2, %ymm1
RWSet:
maybe read:{ %ymm2 %ymm3 }
must read:{ %ymm2 %ymm3 }
maybe write:{ %ymm1 }
must write:{ %ymm1 }
maybe undef:{ }
must undef:{ }
required flags:{ avx2 }

Circuit:
circuit:vpunpckhqdq %ymm3, %ymm2, %ymm4  #  1     0    4      OPC=vpunpckhqdq_ymm_ymm_ymm
circuit:vunpckhpd %ymm4, %ymm4, %ymm5    #  2     0x4  4      OPC=vunpckhpd_ymm_ymm_ymm
circuit:vpunpcklwd %ymm5, %ymm4, %ymm1   #  3     0x8  4      OPC=vpunpcklwd_ymm_ymm_ymm
BVF:
WARNING: No live out values provided, assuming { }
WARNING: No def in values provided; assuming { %mxcsr::rc[0] }
Target

vpunpckhwd %ymm3, %ymm2, %ymm1

  maybe read:      { %ymm2 %ymm3 }
  must read:       { %ymm2 %ymm3 }
  maybe write:     { %ymm1 }
  must write:      { %ymm1 }
  maybe undef:     { }
  must undef:      { }
  required flags:  { avx2 }

-------------------------------------
Getting base circuit for callq .move_256_128_ymm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vunpckhpd_ymm_ymm_ymm

%xmm0: %ymm0_vunpckhpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vunpckhpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vunpckhpd_ymm_ymm_ymm

%xmm0: %ymm0_vunpckhpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vunpckhpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm8

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm8: (%ymm8_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:0])[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm8: ((%ymm8_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:0])[255:128] ∘ (%ymm3_vunpckhpd_ymm_ymm_ymm[127:64] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm11, %xmm9

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm9: (%ymm9_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:128])[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm9: ((%ymm9_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:128])[255:128] ∘ (%ymm3_vunpckhpd_ymm_ymm_ymm[255:192] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:192]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vunpckhpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vunpckhpd_ymm_ymm_ymm

%xmm0: %ymm0_vunpckhpd_ymm_ymm_ymm[127:0]
%xmm1: (((%ymm9_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:128])[255:128] ∘ (%ymm3_vunpckhpd_ymm_ymm_ymm[255:192] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:192]))[127:0][127:0] ∘ ((%ymm8_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:0])[255:128] ∘ (%ymm3_vunpckhpd_ymm_ymm_ymm[127:64] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:64]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhpd %ymm3, %ymm2, %ymm1

.target:
callq .move_256_128_ymm2_xmm8_xmm9
callq .move_256_128_ymm3_xmm10_xmm11
unpckhpd %xmm3, %xmm8
unpckhpd %xmm11, %xmm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckhqdq_ymm_ymm_ymm

State for specgen instruction: vunpckhpd %ymm3, %ymm2, %ymm1:
%ymm1: ((%ymm9_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:128])[255:128] ∘ (%ymm3_vunpckhpd_ymm_ymm_ymm[255:192] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:192]))[127:0][127:0] ∘ ((%ymm8_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:0])[255:128] ∘ (%ymm3_vunpckhpd_ymm_ymm_ymm[127:64] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:64]))[127:0][127:0]

Final state
%ymm1: %ymm3_vpunpckhqdq_ymm_ymm_ymm[255:192] ∘ %ymm2_vpunpckhqdq_ymm_ymm_ymm[255:192] ∘ (%ymm3_vpunpckhqdq_ymm_ymm_ymm[127:64] ∘ %ymm2_vpunpckhqdq_ymm_ymm_ymm[127:64])

=====================================
=====================================
Computing circuit for vpunpckhqdq %ymm3, %ymm2, %ymm4

.target:
vunpckhpd %ymm3, %ymm2, %ymm1
retq 

Initial state:
%ymm4: %ymm4_vpunpckhwd_ymm_ymm_ymm

State for specgen instruction: vpunpckhqdq %ymm3, %ymm2, %ymm1:
%ymm1: %ymm3_vpunpckhqdq_ymm_ymm_ymm[255:192] ∘ %ymm2_vpunpckhqdq_ymm_ymm_ymm[255:192] ∘ (%ymm3_vpunpckhqdq_ymm_ymm_ymm[127:64] ∘ %ymm2_vpunpckhqdq_ymm_ymm_ymm[127:64])

Final state
%ymm4: %ymm3_vpunpckhwd_ymm_ymm_ymm[255:192] ∘ %ymm2_vpunpckhwd_ymm_ymm_ymm[255:192] ∘ (%ymm3_vpunpckhwd_ymm_ymm_ymm[127:64] ∘ %ymm2_vpunpckhwd_ymm_ymm_ymm[127:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_256_128_ymm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vunpckhpd_ymm_ymm_ymm

%xmm0: %ymm0_vunpckhpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vunpckhpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vunpckhpd_ymm_ymm_ymm

%xmm0: %ymm0_vunpckhpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vunpckhpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm8

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm8: (%ymm8_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:0])[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm8: ((%ymm8_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:0])[255:128] ∘ (%ymm3_vunpckhpd_ymm_ymm_ymm[127:64] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm11, %xmm9

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm9: (%ymm9_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:128])[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm9: ((%ymm9_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:128])[255:128] ∘ (%ymm3_vunpckhpd_ymm_ymm_ymm[255:192] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:192]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vunpckhpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vunpckhpd_ymm_ymm_ymm

%xmm0: %ymm0_vunpckhpd_ymm_ymm_ymm[127:0]
%xmm1: (((%ymm9_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:128])[255:128] ∘ (%ymm3_vunpckhpd_ymm_ymm_ymm[255:192] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:192]))[127:0][127:0] ∘ ((%ymm8_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:0])[255:128] ∘ (%ymm3_vunpckhpd_ymm_ymm_ymm[127:64] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:64]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhpd %ymm4, %ymm4, %ymm5

.target:
callq .move_256_128_ymm2_xmm8_xmm9
callq .move_256_128_ymm3_xmm10_xmm11
unpckhpd %xmm3, %xmm8
unpckhpd %xmm11, %xmm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm5: %ymm5_vpunpckhwd_ymm_ymm_ymm

State for specgen instruction: vunpckhpd %ymm3, %ymm2, %ymm1:
%ymm1: ((%ymm9_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:128])[255:128] ∘ (%ymm3_vunpckhpd_ymm_ymm_ymm[255:192] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[255:192]))[127:0][127:0] ∘ ((%ymm8_vunpckhpd_ymm_ymm_ymm[255:128] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:0])[255:128] ∘ (%ymm3_vunpckhpd_ymm_ymm_ymm[127:64] ∘ %ymm2_vunpckhpd_ymm_ymm_ymm[127:64]))[127:0][127:0]

Final state
%ymm5: %ymm3_vpunpckhwd_ymm_ymm_ymm[255:192] ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[255:192] ∘ (%ymm3_vpunpckhwd_ymm_ymm_ymm[127:64] ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[127:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_256_128_ymm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vpunpcklwd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vpunpcklwd_ymm_ymm_ymm

%xmm0: %ymm0_vpunpcklwd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vpunpcklwd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm8_xmm9

Final state:
%rax/%rax: %rax_vpunpcklwd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vpunpcklwd_ymm_ymm_ymm

%xmm0: %ymm0_vpunpcklwd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vpunpcklwd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %ymm10

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm10: %ymm10_pmovzxwd_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm10: %ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0] ∘ (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm3, %xmm8

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm8: %ymm8_vminpd_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm8: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: %ymm0_vmovups_xmm_xmm[127:0]
%xmm1: %ymm1_vmovups_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovups %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminpd_xmm_xmm_xmm

State for specgen instruction: vmovups %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm8, %ymm1, %ymm1

Final state:
%ymm1: (mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[255:192], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[255:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[255:192] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[255:192]) ∘ ((mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[191:128], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[191:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[191:128] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[191:128]) ∘ ((mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[127:64], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[127:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[127:64] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[127:64]) ∘ (mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[63:0], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[63:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[63:0] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vminpd %xmm2, %xmm1, %xmm3

.target:
vmaxps %xmm3, %xmm3, %xmm8
vmovups %xmm2, %xmm1
vminpd %ymm8, %ymm1, %ymm1
retq 

Initial state:
%ymm3: %ymm3_minpd_xmm_xmm

State for specgen instruction: vminpd %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[255:192], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[255:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[255:192] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[255:192]) ∘ ((mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[191:128], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[191:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[191:128] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[191:128]) ∘ ((mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[127:64], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[127:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[127:64] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[127:64]) ∘ (mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[63:0], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[63:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[63:0] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[63:0])))

Final state
%ymm3: 0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm3_xmm8_xmm9

Final state:
%rax/%rax: %rax_minpd_xmm_xmm
%rdx/%rdx: %rdx_minpd_xmm_xmm

%xmm0: %ymm0_minpd_xmm_xmm[127:0]
%xmm1: %ymm1_minpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_minpd_xmm_xmm
%rdx/%rdx: %rdx_minpd_xmm_xmm

%xmm0: %ymm0_minpd_xmm_xmm[127:0]
%xmm1: (%ymm1_minpd_xmm_xmm[255:128] ∘ ((%ymm9_minpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0]))))[127:0][127:64]))[127:0][63:0] ∘ (%ymm8_minpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0]))))[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for minpd %xmm10, %xmm10

.target:
vminpd %xmm2, %xmm1, %xmm3
callq .move_128_64_xmm3_xmm8_xmm9
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0] ∘ (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0]))[127:0]

State for specgen instruction: minpd %xmm2, %xmm1:
%xmm1: (%ymm1_minpd_xmm_xmm[255:128] ∘ ((%ymm9_minpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0]))))[127:0][127:64]))[127:0][63:0] ∘ (%ymm8_minpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0]))))[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0] ∘ (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vpmovzxwd_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwd_xmm_xmm

%xmm0: %ymm0_vpmovzxwd_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: %ymm0_vpmovzxwq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r12d_r13d_rdx

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_edx_r10w_r11w

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxwq %xmm5, %xmm13

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_128_064_xmm2_r10_r11
callq .move_032_064_r12d_r13d_rdx
callq .move_032_016_edx_r10w_r11w
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm13: %ymm13_vpmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0])

Final state
%ymm13: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movddup_xmm_xmm
%rdx/%rdx: %rdx_movddup_xmm_xmm

%xmm0: %ymm0_movddup_xmm_xmm[127:0]
%xmm1: %ymm1_movddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r12, %r13

Final state:
%r13/%r13: %ymm2_movddup_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movddup_xmm_xmm
%rdx/%rdx: %rdx_movddup_xmm_xmm

%xmm0: %ymm0_movddup_xmm_xmm[127:0]
%xmm1: (%ymm1_movddup_xmm_xmm[255:128] ∘ (%ymm2_movddup_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_movddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movddup %xmm4, %xmm4

.target:
callq .move_128_064_xmm2_r12_r13
movq %r12, %r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm4: (%ymm4_vpmovzxwd_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[127:0][31:0]))[127:0]

State for specgen instruction: movddup %xmm2, %xmm1:
%xmm1: (%ymm1_movddup_xmm_xmm[255:128] ∘ (%ymm2_movddup_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_movddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm4: ((%ymm4_vpmovzxwd_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[127:0][31:0]))[255:128] ∘ (0x0₃₂ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:0] ∘ (0x0₃₂ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm3

Final state:
%rax/%rax: %rax_vpmovzxwd_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwd_xmm_xmm

%xmm0: %ymm0_vpmovzxwd_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: %ymm0_vpmovzxwq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r12d_r13d_rdx

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_edx_r10w_r11w

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxwq %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_128_064_xmm2_r10_r11
callq .move_032_064_r12d_r13d_rdx
callq .move_032_016_edx_r10w_r11w
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm3, %ymm6

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm6: %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm3, %xmm6, %xmm9

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm3, %xmm2, %xmm14

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm14: %ymm14_vpor_xmm_xmm_xmm

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpor_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vpor %xmm9, %xmm9, %xmm7

.target:
vorps %xmm3, %xmm2, %xmm14
vmovapd %xmm14, %xmm1
retq 

Initial state:
%ymm7: %ymm7_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpor %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

Final state
%ymm7: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm7, %xmm2

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpckldq_xmm_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm2: (%ymm2_vpunpckldq_xmm_xmm_xmm[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm1, %xmm3

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm3: %ymm3_mulpd_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm8: %ymm8_mulpd_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmulpd %ymm8, %ymm3, %ymm6

Final state:
%ymm6: mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[255:192]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[191:128]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[127:64]) ∘ mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_mulpd_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for mulpd %xmm3, %xmm2

.target:
vmovapd %xmm1, %xmm3
vmovaps %xmm2, %xmm8
vmulpd %ymm8, %ymm3, %ymm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vmulpd_xmm_xmm_xmm[127:0]

State for specgen instruction: mulpd %xmm2, %xmm1:
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vmulpd_xmm_xmm_xmm[255:128] ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmulpd_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmulpd %xmm6, %xmm2, %xmm12

.target:
mulpd %xmm3, %xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm12: %ymm12_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vmulpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]) ∘ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm12, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vpunpckldq %xmm2, %xmm1, %xmm8

.target:
vpbroadcastq %xmm3, %ymm6
vunpcklpd %xmm3, %xmm6, %xmm9
vpor %xmm9, %xmm9, %xmm7
unpcklps %xmm7, %xmm2
vmulpd %xmm6, %xmm2, %xmm12
vxorps %xmm12, %xmm2, %xmm1
movdqu %xmm2, %xmm1
retq 

Initial state:
%ymm8: %ymm8_hsubps_xmm_xmm

State for specgen instruction: vpunpckldq %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0]))

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm2

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm2: %ymm2_vunpckhps_xmm_xmm_xmm[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm2: (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpckhps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm9, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vunpckhps_xmm_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: %ymm0_vmovq_xmm_xmm[127:0]
%xmm1: %ymm1_vmovq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movswq %bx, %r10

Final state:
%r10/%r10: sign-extend-64(%rbx_xchgl_r32_r32[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_xchgl_r32_r32[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ecx_r8w_r9w

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %rcx

Final state:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r8w_r9w_ebx

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xchgl %ebx, %ecx

.target:
movswq %bx, %r10
movslq %ebx, %rbx
callq .move_032_016_ecx_r8w_r9w
callq .move_064_032_rbx_r10d_r11d
movq %r10, %rcx
callq .move_016_032_r8w_r9w_ebx
retq 

Initial state:
%rcx/%rcx: %rcx_xorl_r32_r32
%rbx/%rbx: %rbx_xorl_r32_r32

State for specgen instruction: xchgl %ecx, %ebx:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
%rbx/%rbx: 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])

Register        -> %rcx
  translates to => %rbx
Value is               -> 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
  after renaming it is => 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

Register        -> %rbx
  translates to => %rcx
Value is               -> 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])
  after renaming it is => 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

Final state
%rcx/%rcx: 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]) = 0x0₆₄
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_ebx

Final state:
%rax/%rax: %rax_xorl_r32_r32
%rdx/%rdx: %rdx_xorl_r32_r32

%xmm0: %ymm0_xorl_r32_r32[127:0]
%xmm1: %ymm1_xorl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xorl %r13d, %r13d

.target:
xchgl %ebx, %ecx
xorq %rcx, %rbx
callq .set_szp_for_ebx
retq 

Initial state:
%r13/%r13: %ymm2_vmovq_xmm_xmm[127:0][127:64]

%cf: %cf_vmovq_xmm_xmm
%pf: %pf_vmovq_xmm_xmm
%zf: %zf_vmovq_xmm_xmm
%sf: %sf_vmovq_xmm_xmm
%of: %of_vmovq_xmm_xmm

State for specgen instruction: xorl %ecx, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0] = 0x0₃₂
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][31:31] = 0x1₁
%of: false

Register        -> %rbx
  translates to => %r13
Value is               -> 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
  after renaming it is => 0x0₆₄

Final state
%r13/%r13: 0x0₆₄

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
xorl %r13d, %r13d
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][95:64])

State for specgen instruction: vmovq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhps %xmm2, %xmm1, %xmm10

.target:
unpckhpd %xmm3, %xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovddup %xmm9, %xmm1
vmovq %xmm1, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm10: %ymm10_hsubps_xmm_xmm

State for specgen instruction: vunpckhps %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[127:96] ∘ %ymm1_hsubps_xmm_xmm[127:96] ∘ %ymm2_hsubps_xmm_xmm[95:64] ∘ %ymm1_hsubps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm3, %ymm6

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm6: %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm3, %xmm6, %xmm9

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm3, %xmm2, %xmm14

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm14: %ymm14_vpor_xmm_xmm_xmm

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpor_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vpor %xmm9, %xmm9, %xmm7

.target:
vorps %xmm3, %xmm2, %xmm14
vmovapd %xmm14, %xmm1
retq 

Initial state:
%ymm7: %ymm7_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpor %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

Final state
%ymm7: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm7, %xmm2

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpckldq_xmm_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm2: (%ymm2_vpunpckldq_xmm_xmm_xmm[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm1, %xmm3

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm3: %ymm3_mulpd_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm8: %ymm8_mulpd_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmulpd %ymm8, %ymm3, %ymm6

Final state:
%ymm6: mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[255:192]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[191:128]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[127:64]) ∘ mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_mulpd_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for mulpd %xmm3, %xmm2

.target:
vmovapd %xmm1, %xmm3
vmovaps %xmm2, %xmm8
vmulpd %ymm8, %ymm3, %ymm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vmulpd_xmm_xmm_xmm[127:0]

State for specgen instruction: mulpd %xmm2, %xmm1:
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vmulpd_xmm_xmm_xmm[255:128] ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmulpd_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmulpd %xmm6, %xmm2, %xmm12

.target:
mulpd %xmm3, %xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm12: %ymm12_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vmulpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]) ∘ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm12, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vpunpckldq %xmm10, %xmm8, %xmm15

.target:
vpbroadcastq %xmm3, %ymm6
vunpcklpd %xmm3, %xmm6, %xmm9
vpor %xmm9, %xmm9, %xmm7
unpcklps %xmm7, %xmm2
vmulpd %xmm6, %xmm2, %xmm12
vxorps %xmm12, %xmm2, %xmm1
movdqu %xmm2, %xmm1
retq 

Initial state:
%ymm15: %ymm15_hsubps_xmm_xmm

State for specgen instruction: vpunpckldq %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0]))

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[95:64] ∘ %ymm2_hsubps_xmm_xmm[31:0] ∘ (%ymm1_hsubps_xmm_xmm[95:64] ∘ %ymm1_hsubps_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm2

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm2: %ymm2_vunpckhps_xmm_xmm_xmm[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm2: (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpckhps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm9, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vunpckhps_xmm_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: %ymm0_vmovq_xmm_xmm[127:0]
%xmm1: %ymm1_vmovq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movswq %bx, %r10

Final state:
%r10/%r10: sign-extend-64(%rbx_xchgl_r32_r32[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_xchgl_r32_r32[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ecx_r8w_r9w

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %rcx

Final state:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r8w_r9w_ebx

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xchgl %ebx, %ecx

.target:
movswq %bx, %r10
movslq %ebx, %rbx
callq .move_032_016_ecx_r8w_r9w
callq .move_064_032_rbx_r10d_r11d
movq %r10, %rcx
callq .move_016_032_r8w_r9w_ebx
retq 

Initial state:
%rcx/%rcx: %rcx_xorl_r32_r32
%rbx/%rbx: %rbx_xorl_r32_r32

State for specgen instruction: xchgl %ecx, %ebx:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
%rbx/%rbx: 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])

Register        -> %rcx
  translates to => %rbx
Value is               -> 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
  after renaming it is => 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

Register        -> %rbx
  translates to => %rcx
Value is               -> 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])
  after renaming it is => 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

Final state
%rcx/%rcx: 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]) = 0x0₆₄
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_ebx

Final state:
%rax/%rax: %rax_xorl_r32_r32
%rdx/%rdx: %rdx_xorl_r32_r32

%xmm0: %ymm0_xorl_r32_r32[127:0]
%xmm1: %ymm1_xorl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xorl %r13d, %r13d

.target:
xchgl %ebx, %ecx
xorq %rcx, %rbx
callq .set_szp_for_ebx
retq 

Initial state:
%r13/%r13: %ymm2_vmovq_xmm_xmm[127:0][127:64]

%cf: %cf_vmovq_xmm_xmm
%pf: %pf_vmovq_xmm_xmm
%zf: %zf_vmovq_xmm_xmm
%sf: %sf_vmovq_xmm_xmm
%of: %of_vmovq_xmm_xmm

State for specgen instruction: xorl %ecx, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0] = 0x0₃₂
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][31:31] = 0x1₁
%of: false

Register        -> %rbx
  translates to => %r13
Value is               -> 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
  after renaming it is => 0x0₆₄

Final state
%r13/%r13: 0x0₆₄

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
xorl %r13d, %r13d
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][95:64])

State for specgen instruction: vmovq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhps %xmm2, %xmm1, %xmm8

.target:
unpckhpd %xmm3, %xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovddup %xmm9, %xmm1
vmovq %xmm1, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_punpckhdq_xmm_xmm

State for specgen instruction: vunpckhps %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ %ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm8, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_punpckhdq_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_punpckhdq_xmm_xmm[255:128] ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ (%ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])))[127:0]

=====================================
=====================================
Computing circuit for punpckhdq %xmm10, %xmm8

.target:
vunpckhps %xmm2, %xmm1, %xmm8
movdqu %xmm8, %xmm1
retq 

Initial state:
%xmm8: (0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0])))[127:0]

State for specgen instruction: punpckhdq %xmm2, %xmm1:
%xmm1: (%ymm1_punpckhdq_xmm_xmm[255:128] ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ (%ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])))[127:0]

Final state
%xmm8: ((0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0])))[255:128] ∘ (%ymm2_hsubps_xmm_xmm[127:96] ∘ %ymm2_hsubps_xmm_xmm[63:32] ∘ (%ymm1_hsubps_xmm_xmm[127:96] ∘ %ymm1_hsubps_xmm_xmm[63:32])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm14

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm14: %ymm14_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm14: 0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminps %ymm1, %ymm14, %ymm1

Final state:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vminps %xmm2, %xmm2, %xmm5

.target:
vmovdqa %xmm3, %xmm1
vmovdqu %xmm2, %xmm14
vminps %ymm1, %ymm14, %ymm1
retq 

Initial state:
%ymm5: %ymm5_vsubps_xmm_xmm_xmm

State for specgen instruction: vminps %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm5: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_subps_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm14

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm14: %ymm14_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm14: 0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminps %ymm1, %ymm14, %ymm1

Final state:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vminps %xmm1, %xmm1, %xmm4

.target:
vmovdqa %xmm3, %xmm1
vmovdqu %xmm2, %xmm14
vminps %ymm1, %ymm14, %ymm1
retq 

Initial state:
%ymm4: %ymm4_subps_xmm_xmm

State for specgen instruction: vminps %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm4: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for vsubps %ymm10, %ymm4, %ymm2

Final state:
%ymm2: sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[255:224], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[255:224]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[223:192], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[223:192]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[191:160], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[191:160]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[159:128], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[159:128]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[127:96], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[127:96]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[95:64], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[95:64]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[63:32], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[63:32]) ∘ sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[31:0], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_subps_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_subps_xmm_xmm[255:128] ∘ (sub_single(%ymm1_subps_xmm_xmm[127:96], %ymm2_subps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_subps_xmm_xmm[95:64], %ymm2_subps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_subps_xmm_xmm[63:32], %ymm2_subps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_subps_xmm_xmm[31:0], %ymm2_subps_xmm_xmm[31:0])))))[127:0]

=====================================
=====================================
Computing circuit for subps %xmm3, %xmm5

.target:
vmovaps %xmm2, %xmm10
vminps %xmm1, %xmm1, %xmm4
vsubps %ymm10, %ymm4, %ymm2
movdqu %xmm2, %xmm1
retq 

Initial state:
%xmm5: (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0]))))[127:0]

State for specgen instruction: subps %xmm2, %xmm1:
%xmm1: (%ymm1_subps_xmm_xmm[255:128] ∘ (sub_single(%ymm1_subps_xmm_xmm[127:96], %ymm2_subps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_subps_xmm_xmm[95:64], %ymm2_subps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_subps_xmm_xmm[63:32], %ymm2_subps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_subps_xmm_xmm[31:0], %ymm2_subps_xmm_xmm[31:0])))))[127:0]

Final state
%xmm5: ((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0]))))[255:128] ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0])))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm5, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vsubps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0]))))

=====================================
=====================================
Computing circuit for vsubps %xmm8, %xmm15, %xmm4

.target:
vminps %xmm2, %xmm2, %xmm5
subps %xmm3, %xmm5
vmovdqu %xmm5, %xmm1
retq 

Initial state:
%ymm4: %ymm4_hsubps_xmm_xmm

State for specgen instruction: vsubps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0]))))

Final state
%ymm4: 0x0₁₂₈ ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm4, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_hsubps_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_hsubps_xmm_xmm[255:128] ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))[127:0]

=====================================
=====================================
Computing circuit for hsubps %xmm3, %xmm2

.target:
vpunpckldq %xmm2, %xmm1, %xmm8
vunpckhps %xmm2, %xmm1, %xmm10
vpunpckldq %xmm10, %xmm8, %xmm15
punpckhdq %xmm10, %xmm8
vsubps %xmm8, %xmm15, %xmm4
movdqu %xmm4, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vhsubps_xmm_xmm_xmm[127:0]

State for specgen instruction: hsubps %xmm2, %xmm1:
%xmm1: (%ymm1_hsubps_xmm_xmm[255:128] ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))[127:0]

Final state
%xmm2: (%ymm2_vhsubps_xmm_xmm_xmm[255:128] ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vhsubps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vhsubps_xmm_xmm_xmm

%xmm0: %ymm0_vhsubps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vhsubps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vhsubps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vhsubps_xmm_xmm_xmm

%xmm0: %ymm0_vhsubps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vhsubps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vhsubps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32])))

=====================================
=====================================
Computing circuit for vhsubps %xmm13, %xmm1, %xmm1

.target:
hsubps %xmm3, %xmm2
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm1: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0]))

State for specgen instruction: vhsubps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32])))

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0])))

=====================================
=====================================
Computing circuit for vpmovzxwd %xmm10, %xmm14

.target:
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7
vpmovzxwq %xmm5, %xmm13
movddup %xmm4, %xmm4
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm3
vpmovzxwq %xmm3, %xmm1
vhsubps %xmm13, %xmm1, %xmm1
retq 

Initial state:
%ymm14: %ymm14_pmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwd %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0])))

Final state
%ymm14: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[15:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_pmovzxwd_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_pmovzxwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[15:0]))))[127:0]

=====================================
=====================================
Computing circuit for pmovzxwd %xmm2, %xmm5

.target:
vpbroadcastq %xmm2, %ymm10
minpd %xmm10, %xmm10
vpmovzxwd %xmm10, %xmm14
movapd %xmm14, %xmm1
retq 

Initial state:
%xmm5: %ymm5_punpcklwd_xmm_xmm[127:0]

State for specgen instruction: pmovzxwd %xmm2, %xmm1:
%xmm1: (%ymm1_pmovzxwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[15:0]))))[127:0]

Final state
%xmm5: (%ymm5_punpcklwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %ymm10

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm10: %ymm10_pmovzxwd_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm10: %ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0] ∘ (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm3, %xmm8

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm8: %ymm8_vminpd_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm8: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: %ymm0_vmovups_xmm_xmm[127:0]
%xmm1: %ymm1_vmovups_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovups %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminpd_xmm_xmm_xmm

State for specgen instruction: vmovups %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm8, %ymm1, %ymm1

Final state:
%ymm1: (mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[255:192], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[255:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[255:192] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[255:192]) ∘ ((mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[191:128], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[191:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[191:128] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[191:128]) ∘ ((mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[127:64], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[127:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[127:64] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[127:64]) ∘ (mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[63:0], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[63:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[63:0] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vminpd %xmm2, %xmm1, %xmm3

.target:
vmaxps %xmm3, %xmm3, %xmm8
vmovups %xmm2, %xmm1
vminpd %ymm8, %ymm1, %ymm1
retq 

Initial state:
%ymm3: %ymm3_minpd_xmm_xmm

State for specgen instruction: vminpd %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[255:192], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[255:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[255:192] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[255:192]) ∘ ((mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[191:128], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[191:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[191:128] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[191:128]) ∘ ((mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[127:64], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[127:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[127:64] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[127:64]) ∘ (mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[63:0], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[63:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[63:0] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[63:0])))

Final state
%ymm3: 0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm3_xmm8_xmm9

Final state:
%rax/%rax: %rax_minpd_xmm_xmm
%rdx/%rdx: %rdx_minpd_xmm_xmm

%xmm0: %ymm0_minpd_xmm_xmm[127:0]
%xmm1: %ymm1_minpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_minpd_xmm_xmm
%rdx/%rdx: %rdx_minpd_xmm_xmm

%xmm0: %ymm0_minpd_xmm_xmm[127:0]
%xmm1: (%ymm1_minpd_xmm_xmm[255:128] ∘ ((%ymm9_minpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0]))))[127:0][127:64]))[127:0][63:0] ∘ (%ymm8_minpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0]))))[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for minpd %xmm10, %xmm10

.target:
vminpd %xmm2, %xmm1, %xmm3
callq .move_128_64_xmm3_xmm8_xmm9
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0] ∘ (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0]))[127:0]

State for specgen instruction: minpd %xmm2, %xmm1:
%xmm1: (%ymm1_minpd_xmm_xmm[255:128] ∘ ((%ymm9_minpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0]))))[127:0][127:64]))[127:0][63:0] ∘ (%ymm8_minpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0]))))[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0] ∘ (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vpmovzxwd_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwd_xmm_xmm

%xmm0: %ymm0_vpmovzxwd_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: %ymm0_vpmovzxwq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r12d_r13d_rdx

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_edx_r10w_r11w

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxwq %xmm5, %xmm13

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_128_064_xmm2_r10_r11
callq .move_032_064_r12d_r13d_rdx
callq .move_032_016_edx_r10w_r11w
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm13: %ymm13_vpmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0])

Final state
%ymm13: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movddup_xmm_xmm
%rdx/%rdx: %rdx_movddup_xmm_xmm

%xmm0: %ymm0_movddup_xmm_xmm[127:0]
%xmm1: %ymm1_movddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r12, %r13

Final state:
%r13/%r13: %ymm2_movddup_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movddup_xmm_xmm
%rdx/%rdx: %rdx_movddup_xmm_xmm

%xmm0: %ymm0_movddup_xmm_xmm[127:0]
%xmm1: (%ymm1_movddup_xmm_xmm[255:128] ∘ (%ymm2_movddup_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_movddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movddup %xmm4, %xmm4

.target:
callq .move_128_064_xmm2_r12_r13
movq %r12, %r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm4: (%ymm4_vpmovzxwd_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[127:0][31:0]))[127:0]

State for specgen instruction: movddup %xmm2, %xmm1:
%xmm1: (%ymm1_movddup_xmm_xmm[255:128] ∘ (%ymm2_movddup_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_movddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm4: ((%ymm4_vpmovzxwd_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[127:0][31:0]))[255:128] ∘ (0x0₃₂ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:0] ∘ (0x0₃₂ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm3

Final state:
%rax/%rax: %rax_vpmovzxwd_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwd_xmm_xmm

%xmm0: %ymm0_vpmovzxwd_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: %ymm0_vpmovzxwq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r12d_r13d_rdx

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_edx_r10w_r11w

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxwq %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_128_064_xmm2_r10_r11
callq .move_032_064_r12d_r13d_rdx
callq .move_032_016_edx_r10w_r11w
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm3, %ymm6

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm6: %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm3, %xmm6, %xmm9

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm3, %xmm2, %xmm14

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm14: %ymm14_vpor_xmm_xmm_xmm

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpor_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vpor %xmm9, %xmm9, %xmm7

.target:
vorps %xmm3, %xmm2, %xmm14
vmovapd %xmm14, %xmm1
retq 

Initial state:
%ymm7: %ymm7_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpor %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

Final state
%ymm7: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm7, %xmm2

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpckldq_xmm_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm2: (%ymm2_vpunpckldq_xmm_xmm_xmm[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm1, %xmm3

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm3: %ymm3_mulpd_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm8: %ymm8_mulpd_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmulpd %ymm8, %ymm3, %ymm6

Final state:
%ymm6: mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[255:192]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[191:128]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[127:64]) ∘ mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_mulpd_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for mulpd %xmm3, %xmm2

.target:
vmovapd %xmm1, %xmm3
vmovaps %xmm2, %xmm8
vmulpd %ymm8, %ymm3, %ymm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vmulpd_xmm_xmm_xmm[127:0]

State for specgen instruction: mulpd %xmm2, %xmm1:
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vmulpd_xmm_xmm_xmm[255:128] ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmulpd_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmulpd %xmm6, %xmm2, %xmm12

.target:
mulpd %xmm3, %xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm12: %ymm12_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vmulpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]) ∘ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm12, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vpunpckldq %xmm2, %xmm1, %xmm8

.target:
vpbroadcastq %xmm3, %ymm6
vunpcklpd %xmm3, %xmm6, %xmm9
vpor %xmm9, %xmm9, %xmm7
unpcklps %xmm7, %xmm2
vmulpd %xmm6, %xmm2, %xmm12
vxorps %xmm12, %xmm2, %xmm1
movdqu %xmm2, %xmm1
retq 

Initial state:
%ymm8: %ymm8_hsubps_xmm_xmm

State for specgen instruction: vpunpckldq %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0]))

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm2

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm2: %ymm2_vunpckhps_xmm_xmm_xmm[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm2: (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpckhps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm9, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vunpckhps_xmm_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: %ymm0_vmovq_xmm_xmm[127:0]
%xmm1: %ymm1_vmovq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movswq %bx, %r10

Final state:
%r10/%r10: sign-extend-64(%rbx_xchgl_r32_r32[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_xchgl_r32_r32[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ecx_r8w_r9w

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %rcx

Final state:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r8w_r9w_ebx

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xchgl %ebx, %ecx

.target:
movswq %bx, %r10
movslq %ebx, %rbx
callq .move_032_016_ecx_r8w_r9w
callq .move_064_032_rbx_r10d_r11d
movq %r10, %rcx
callq .move_016_032_r8w_r9w_ebx
retq 

Initial state:
%rcx/%rcx: %rcx_xorl_r32_r32
%rbx/%rbx: %rbx_xorl_r32_r32

State for specgen instruction: xchgl %ecx, %ebx:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
%rbx/%rbx: 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])

Register        -> %rcx
  translates to => %rbx
Value is               -> 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
  after renaming it is => 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

Register        -> %rbx
  translates to => %rcx
Value is               -> 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])
  after renaming it is => 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

Final state
%rcx/%rcx: 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]) = 0x0₆₄
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_ebx

Final state:
%rax/%rax: %rax_xorl_r32_r32
%rdx/%rdx: %rdx_xorl_r32_r32

%xmm0: %ymm0_xorl_r32_r32[127:0]
%xmm1: %ymm1_xorl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xorl %r13d, %r13d

.target:
xchgl %ebx, %ecx
xorq %rcx, %rbx
callq .set_szp_for_ebx
retq 

Initial state:
%r13/%r13: %ymm2_vmovq_xmm_xmm[127:0][127:64]

%cf: %cf_vmovq_xmm_xmm
%pf: %pf_vmovq_xmm_xmm
%zf: %zf_vmovq_xmm_xmm
%sf: %sf_vmovq_xmm_xmm
%of: %of_vmovq_xmm_xmm

State for specgen instruction: xorl %ecx, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0] = 0x0₃₂
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][31:31] = 0x1₁
%of: false

Register        -> %rbx
  translates to => %r13
Value is               -> 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
  after renaming it is => 0x0₆₄

Final state
%r13/%r13: 0x0₆₄

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
xorl %r13d, %r13d
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][95:64])

State for specgen instruction: vmovq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhps %xmm2, %xmm1, %xmm10

.target:
unpckhpd %xmm3, %xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovddup %xmm9, %xmm1
vmovq %xmm1, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm10: %ymm10_hsubps_xmm_xmm

State for specgen instruction: vunpckhps %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[127:96] ∘ %ymm1_hsubps_xmm_xmm[127:96] ∘ %ymm2_hsubps_xmm_xmm[95:64] ∘ %ymm1_hsubps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm3, %ymm6

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm6: %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm3, %xmm6, %xmm9

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm3, %xmm2, %xmm14

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm14: %ymm14_vpor_xmm_xmm_xmm

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpor_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vpor %xmm9, %xmm9, %xmm7

.target:
vorps %xmm3, %xmm2, %xmm14
vmovapd %xmm14, %xmm1
retq 

Initial state:
%ymm7: %ymm7_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpor %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

Final state
%ymm7: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm7, %xmm2

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpckldq_xmm_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm2: (%ymm2_vpunpckldq_xmm_xmm_xmm[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm1, %xmm3

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm3: %ymm3_mulpd_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm8: %ymm8_mulpd_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmulpd %ymm8, %ymm3, %ymm6

Final state:
%ymm6: mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[255:192]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[191:128]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[127:64]) ∘ mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_mulpd_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for mulpd %xmm3, %xmm2

.target:
vmovapd %xmm1, %xmm3
vmovaps %xmm2, %xmm8
vmulpd %ymm8, %ymm3, %ymm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vmulpd_xmm_xmm_xmm[127:0]

State for specgen instruction: mulpd %xmm2, %xmm1:
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vmulpd_xmm_xmm_xmm[255:128] ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmulpd_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmulpd %xmm6, %xmm2, %xmm12

.target:
mulpd %xmm3, %xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm12: %ymm12_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vmulpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]) ∘ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm12, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vpunpckldq %xmm10, %xmm8, %xmm15

.target:
vpbroadcastq %xmm3, %ymm6
vunpcklpd %xmm3, %xmm6, %xmm9
vpor %xmm9, %xmm9, %xmm7
unpcklps %xmm7, %xmm2
vmulpd %xmm6, %xmm2, %xmm12
vxorps %xmm12, %xmm2, %xmm1
movdqu %xmm2, %xmm1
retq 

Initial state:
%ymm15: %ymm15_hsubps_xmm_xmm

State for specgen instruction: vpunpckldq %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0]))

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[95:64] ∘ %ymm2_hsubps_xmm_xmm[31:0] ∘ (%ymm1_hsubps_xmm_xmm[95:64] ∘ %ymm1_hsubps_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm2

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm2: %ymm2_vunpckhps_xmm_xmm_xmm[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm2: (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpckhps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm9, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vunpckhps_xmm_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: %ymm0_vmovq_xmm_xmm[127:0]
%xmm1: %ymm1_vmovq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movswq %bx, %r10

Final state:
%r10/%r10: sign-extend-64(%rbx_xchgl_r32_r32[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_xchgl_r32_r32[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ecx_r8w_r9w

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %rcx

Final state:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r8w_r9w_ebx

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xchgl %ebx, %ecx

.target:
movswq %bx, %r10
movslq %ebx, %rbx
callq .move_032_016_ecx_r8w_r9w
callq .move_064_032_rbx_r10d_r11d
movq %r10, %rcx
callq .move_016_032_r8w_r9w_ebx
retq 

Initial state:
%rcx/%rcx: %rcx_xorl_r32_r32
%rbx/%rbx: %rbx_xorl_r32_r32

State for specgen instruction: xchgl %ecx, %ebx:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
%rbx/%rbx: 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])

Register        -> %rcx
  translates to => %rbx
Value is               -> 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
  after renaming it is => 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

Register        -> %rbx
  translates to => %rcx
Value is               -> 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])
  after renaming it is => 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

Final state
%rcx/%rcx: 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]) = 0x0₆₄
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_ebx

Final state:
%rax/%rax: %rax_xorl_r32_r32
%rdx/%rdx: %rdx_xorl_r32_r32

%xmm0: %ymm0_xorl_r32_r32[127:0]
%xmm1: %ymm1_xorl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xorl %r13d, %r13d

.target:
xchgl %ebx, %ecx
xorq %rcx, %rbx
callq .set_szp_for_ebx
retq 

Initial state:
%r13/%r13: %ymm2_vmovq_xmm_xmm[127:0][127:64]

%cf: %cf_vmovq_xmm_xmm
%pf: %pf_vmovq_xmm_xmm
%zf: %zf_vmovq_xmm_xmm
%sf: %sf_vmovq_xmm_xmm
%of: %of_vmovq_xmm_xmm

State for specgen instruction: xorl %ecx, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0] = 0x0₃₂
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][31:31] = 0x1₁
%of: false

Register        -> %rbx
  translates to => %r13
Value is               -> 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
  after renaming it is => 0x0₆₄

Final state
%r13/%r13: 0x0₆₄

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
xorl %r13d, %r13d
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][95:64])

State for specgen instruction: vmovq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhps %xmm2, %xmm1, %xmm8

.target:
unpckhpd %xmm3, %xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovddup %xmm9, %xmm1
vmovq %xmm1, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_punpckhdq_xmm_xmm

State for specgen instruction: vunpckhps %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ %ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm8, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_punpckhdq_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_punpckhdq_xmm_xmm[255:128] ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ (%ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])))[127:0]

=====================================
=====================================
Computing circuit for punpckhdq %xmm10, %xmm8

.target:
vunpckhps %xmm2, %xmm1, %xmm8
movdqu %xmm8, %xmm1
retq 

Initial state:
%xmm8: (0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0])))[127:0]

State for specgen instruction: punpckhdq %xmm2, %xmm1:
%xmm1: (%ymm1_punpckhdq_xmm_xmm[255:128] ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ (%ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])))[127:0]

Final state
%xmm8: ((0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0])))[255:128] ∘ (%ymm2_hsubps_xmm_xmm[127:96] ∘ %ymm2_hsubps_xmm_xmm[63:32] ∘ (%ymm1_hsubps_xmm_xmm[127:96] ∘ %ymm1_hsubps_xmm_xmm[63:32])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm14

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm14: %ymm14_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm14: 0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminps %ymm1, %ymm14, %ymm1

Final state:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vminps %xmm2, %xmm2, %xmm5

.target:
vmovdqa %xmm3, %xmm1
vmovdqu %xmm2, %xmm14
vminps %ymm1, %ymm14, %ymm1
retq 

Initial state:
%ymm5: %ymm5_vsubps_xmm_xmm_xmm

State for specgen instruction: vminps %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm5: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_subps_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm14

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm14: %ymm14_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm14: 0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminps %ymm1, %ymm14, %ymm1

Final state:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vminps %xmm1, %xmm1, %xmm4

.target:
vmovdqa %xmm3, %xmm1
vmovdqu %xmm2, %xmm14
vminps %ymm1, %ymm14, %ymm1
retq 

Initial state:
%ymm4: %ymm4_subps_xmm_xmm

State for specgen instruction: vminps %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm4: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for vsubps %ymm10, %ymm4, %ymm2

Final state:
%ymm2: sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[255:224], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[255:224]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[223:192], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[223:192]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[191:160], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[191:160]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[159:128], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[159:128]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[127:96], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[127:96]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[95:64], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[95:64]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[63:32], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[63:32]) ∘ sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[31:0], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_subps_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_subps_xmm_xmm[255:128] ∘ (sub_single(%ymm1_subps_xmm_xmm[127:96], %ymm2_subps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_subps_xmm_xmm[95:64], %ymm2_subps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_subps_xmm_xmm[63:32], %ymm2_subps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_subps_xmm_xmm[31:0], %ymm2_subps_xmm_xmm[31:0])))))[127:0]

=====================================
=====================================
Computing circuit for subps %xmm3, %xmm5

.target:
vmovaps %xmm2, %xmm10
vminps %xmm1, %xmm1, %xmm4
vsubps %ymm10, %ymm4, %ymm2
movdqu %xmm2, %xmm1
retq 

Initial state:
%xmm5: (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0]))))[127:0]

State for specgen instruction: subps %xmm2, %xmm1:
%xmm1: (%ymm1_subps_xmm_xmm[255:128] ∘ (sub_single(%ymm1_subps_xmm_xmm[127:96], %ymm2_subps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_subps_xmm_xmm[95:64], %ymm2_subps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_subps_xmm_xmm[63:32], %ymm2_subps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_subps_xmm_xmm[31:0], %ymm2_subps_xmm_xmm[31:0])))))[127:0]

Final state
%xmm5: ((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0]))))[255:128] ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0])))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm5, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vsubps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0]))))

=====================================
=====================================
Computing circuit for vsubps %xmm8, %xmm15, %xmm4

.target:
vminps %xmm2, %xmm2, %xmm5
subps %xmm3, %xmm5
vmovdqu %xmm5, %xmm1
retq 

Initial state:
%ymm4: %ymm4_hsubps_xmm_xmm

State for specgen instruction: vsubps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0]))))

Final state
%ymm4: 0x0₁₂₈ ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm4, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_hsubps_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_hsubps_xmm_xmm[255:128] ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))[127:0]

=====================================
=====================================
Computing circuit for hsubps %xmm3, %xmm2

.target:
vpunpckldq %xmm2, %xmm1, %xmm8
vunpckhps %xmm2, %xmm1, %xmm10
vpunpckldq %xmm10, %xmm8, %xmm15
punpckhdq %xmm10, %xmm8
vsubps %xmm8, %xmm15, %xmm4
movdqu %xmm4, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vhsubps_xmm_xmm_xmm[127:0]

State for specgen instruction: hsubps %xmm2, %xmm1:
%xmm1: (%ymm1_hsubps_xmm_xmm[255:128] ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))[127:0]

Final state
%xmm2: (%ymm2_vhsubps_xmm_xmm_xmm[255:128] ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vhsubps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vhsubps_xmm_xmm_xmm

%xmm0: %ymm0_vhsubps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vhsubps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vhsubps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vhsubps_xmm_xmm_xmm

%xmm0: %ymm0_vhsubps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vhsubps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vhsubps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32])))

=====================================
=====================================
Computing circuit for vhsubps %xmm13, %xmm1, %xmm1

.target:
hsubps %xmm3, %xmm2
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm1: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0]))

State for specgen instruction: vhsubps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32])))

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0])))

=====================================
=====================================
Computing circuit for vpmovzxwd %xmm10, %xmm14

.target:
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7
vpmovzxwq %xmm5, %xmm13
movddup %xmm4, %xmm4
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm3
vpmovzxwq %xmm3, %xmm1
vhsubps %xmm13, %xmm1, %xmm1
retq 

Initial state:
%ymm14: %ymm14_pmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwd %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0])))

Final state
%ymm14: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[15:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_pmovzxwd_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_pmovzxwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[15:0]))))[127:0]

=====================================
=====================================
Computing circuit for pmovzxwd %xmm1, %xmm1

.target:
vpbroadcastq %xmm2, %ymm10
minpd %xmm10, %xmm10
vpmovzxwd %xmm10, %xmm14
movapd %xmm14, %xmm1
retq 

Initial state:
%xmm1: %ymm1_punpcklwd_xmm_xmm[127:0]

State for specgen instruction: pmovzxwd %xmm2, %xmm1:
%xmm1: (%ymm1_pmovzxwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[15:0]))))[127:0]

Final state
%xmm1: (%ymm1_punpcklwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[15:0]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vpbroadcastw_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_xmm_xmm

%xmm0: %ymm0_vpbroadcastw_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastw_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r10w_r11w_ebx

Final state:
%rax/%rax: %rax_vpbroadcastw_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_xmm_xmm

%xmm0: %ymm0_vpbroadcastw_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastw_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r8b_r9b

Final state:
%rax/%rax: %rax_vpbroadcastw_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_xmm_xmm

%xmm0: %ymm0_vpbroadcastw_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastw_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r9b_to_byte_3_of_rbx

Final state:
%rax/%rax: %rax_vpbroadcastw_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_xmm_xmm

%xmm0: %ymm0_vpbroadcastw_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastw_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r8b_r9b

Final state:
%rax/%rax: %rax_vmovd_xmm_r32
%rdx/%rdx: %rdx_vmovd_xmm_r32

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r8b_to_byte_0_of_ymm1

Final state:
%rax/%rax: %rax_vmovd_xmm_r32
%rdx/%rdx: %rdx_vmovd_xmm_r32

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r9b_to_byte_1_of_ymm1

Final state:
%rax/%rax: %rax_vmovd_xmm_r32
%rdx/%rdx: %rdx_vmovd_xmm_r32

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq $0x0, %rbx

Final state:
%rbx/%rbx: 0x0₆₄

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: %cf_movzbq_r64_r8

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for movsbq %cl, %rdi

Final state:
%rdi/%rdi: sign-extend-64(%rcx_movzbq_r64_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for adcb %dil, %bl

Final state:
%rbx/%bl: 0x0₆₄[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0][3:0] + 0x0₁ ∘ 0x0₆₄[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:7] = 0x1₁
%of: (sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0][7:7] = 0x1₁ ↔ 0x0₆₄[7:0][7:7] = 0x1₁) ∧ !(sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for movzbq %bl, %r8

.target:
movq $0x0, %rbx
clc 
movsbq %cl, %rdi
adcb %dil, %bl
retq 

Initial state:
%r8/%r8: %r8_xchgb_r8_r8

State for specgen instruction: movzbq %cl, %rbx:
%rbx/%rbx: 0x0₆₄[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0]

Register        -> %rbx
  translates to => %r8
Value is               -> 0x0₆₄[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0]
  after renaming it is => 0x0₅₆ ∘ %rbx_xchgb_r8_r8[7:0]

Final state
%r8/%r8: 0x0₅₆ ∘ %rbx_xchgb_r8_r8[7:0]

=====================================
-------------------------------------
Getting base circuit for movq $0x5, %rbx

Final state:
%rbx/%rbx: 0x5₆₄

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r12d_r13d

Final state:
%rax/%rax: %rax_movzbw_r16_r8
%rdx/%rdx: %rdx_movzbw_r16_r8

%xmm0: %ymm0_movzbw_r16_r8[127:0]
%xmm1: %ymm1_movzbw_r16_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movsbq %cl, %r12

Final state:
%r12/%r12: sign-extend-64(%rcx_movzbw_r16_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r12b_r13b_bx

Final state:
%rax/%rax: %rax_movzbw_r16_r8
%rdx/%rdx: %rdx_movzbw_r16_r8

%xmm0: %ymm0_movzbw_r16_r8[127:0]
%xmm1: %ymm1_movzbw_r16_r8[127:0]

-------------------------------------
=====================================
Computing circuit for movzbw %cl, %cx

.target:
movq $0x5, %rbx
callq .move_064_032_rbx_r12d_r13d
movsbq %cl, %r12
callq .move_008_016_r12b_r13b_bx
retq 

Initial state:
%rcx/%cx: %rcx_xchgb_r8_r8

State for specgen instruction: movzbw %cl, %bx:
%rbx/%bx: 0x5₆₄[63:16] ∘ ((0x0₃₂ ∘ 0x5₆₄[63:32])[7:0][7:0] ∘ sign-extend-64(%rcx_movzbw_r16_r8[7:0])[7:0][7:0])

Register        -> %bx
  translates to => %cx
Value is               -> (0x5₆₄[63:16] ∘ ((0x0₃₂ ∘ 0x5₆₄[63:32])[7:0][7:0] ∘ sign-extend-64(%rcx_movzbw_r16_r8[7:0])[7:0][7:0]))[15:0]
  after renaming it is => 0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]

Final state
%rcx/%cx: %rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0])

=====================================
-------------------------------------
Getting base circuit for movq $0x40, %rbx

Final state:
%rbx/%rbx: 0x40₆₄

-------------------------------------
-------------------------------------
Getting base circuit for movb %ah, %bl

Final state:
%rbx/%bl: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

-------------------------------------
=====================================
Computing circuit for movzbl %bh, %edx

.target:
movq $0x40, %rbx
movb %ah, %bl
retq 

Initial state:
%rdx/%rdx: %rdx_movb_rh_rh

State for specgen instruction: movzbl %ah, %ebx:
%rbx/%rbx: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

Register        -> %rbx
  translates to => %rdx
Value is               -> 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]
  after renaming it is => 0x0₅₆ ∘ %rbx_movb_rh_rh[15:8]

Final state
%rdx/%rdx: 0x0₅₆ ∘ %rbx_movb_rh_rh[15:8]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_032_rdx_r8d_r9d

Final state:
%rax/%rax: %rax_movb_rh_rh
%rdx/%rdx: 0x0₅₆ ∘ %rbx_movb_rh_rh[15:8]

%xmm0: %ymm0_movb_rh_rh[127:0]
%xmm1: %ymm1_movb_rh_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r8d_r9d_rcx

Final state:
%rax/%rax: %rax_movb_rh_rh
%rdx/%rdx: 0x0₅₆ ∘ %rbx_movb_rh_rh[15:8]

%xmm0: %ymm0_movb_rh_rh[127:0]
%xmm1: %ymm1_movb_rh_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movb %cl, %ah

Final state:
%rax/%ah: %rax_movb_rh_rh[63:16] ∘ ((0x0₃₂ ∘ (0x0₅₆ ∘ %rbx_movb_rh_rh[15:8])[63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ (0x0₅₆ ∘ %rbx_movb_rh_rh[15:8])[31:0])[31:0][31:0])[7:0] ∘ %rax_movb_rh_rh[7:0]

-------------------------------------
=====================================
Computing circuit for movb %ch, %bh

.target:
movzbl %bh, %edx
callq .move_064_032_rdx_r8d_r9d
callq .move_032_064_r8d_r9d_rcx
movb %cl, %ah
retq 

Initial state:
%rbx/%bh: %rbx_xchgb_r8_r8

State for specgen instruction: movb %bh, %ah:
%rax/%ah: %rax_movb_rh_rh[63:16] ∘ ((0x0₃₂ ∘ (0x0₅₆ ∘ %rbx_movb_rh_rh[15:8])[63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ (0x0₅₆ ∘ %rbx_movb_rh_rh[15:8])[31:0])[31:0][31:0])[7:0] ∘ %rax_movb_rh_rh[7:0]

Register        -> %ah
  translates to => %bh
Value is               -> (%rax_movb_rh_rh[63:16] ∘ ((0x0₃₂ ∘ (0x0₅₆ ∘ %rbx_movb_rh_rh[15:8])[63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ (0x0₅₆ ∘ %rbx_movb_rh_rh[15:8])[31:0])[31:0][31:0])[7:0] ∘ %rax_movb_rh_rh[7:0])[15:8]
  after renaming it is => 0x0₈

Final state
%rbx/%bh: %rbx_xchgb_r8_r8[63:16] ∘ 0x0₈ ∘ %rbx_xchgb_r8_r8[7:0]

=====================================
-------------------------------------
Getting base circuit for movq $0x40, %rbx

Final state:
%rbx/%rbx: 0x40₆₄

-------------------------------------
-------------------------------------
Getting base circuit for movb %ah, %bl

Final state:
%rbx/%bl: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

-------------------------------------
=====================================
Computing circuit for movzbl %ah, %edx

.target:
movq $0x40, %rbx
movb %ah, %bl
retq 

Initial state:
%rdx/%rdx: %rdx_xaddb_rh_r8

State for specgen instruction: movzbl %ah, %ebx:
%rbx/%rbx: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

Register        -> %rbx
  translates to => %rdx
Value is               -> 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]
  after renaming it is => 0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8]

Final state
%rdx/%rdx: 0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8]

=====================================
-------------------------------------
Getting base circuit for callq .clear_cf

Final state:
%rax/%rax: %rax_xaddb_r8_r8
%rdx/%rdx: %rdx_xaddb_r8_r8

%xmm0: %ymm0_xaddb_r8_r8[127:0]
%xmm1: %ymm1_xaddb_r8_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_of

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_of_into_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movsbq %cl, %r10

Final state:
%r10/%r10: sign-extend-64(%rcx_movsbl_r32_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
=====================================
Computing circuit for movsbl %cl, %r13d

.target:
callq .set_of
callq .read_of_into_rbx
callq .move_064_032_rbx_r10d_r11d
movsbq %cl, %r10
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r13/%r13: %r13_xaddb_r8_r8

State for specgen instruction: movsbl %cl, %ebx:
%rbx/%rbx: (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r13
Value is               -> (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0]

Final state
%r13/%r13: 0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0]

=====================================
-------------------------------------
Getting base circuit for callq .set_of

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_of_into_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movsbq %cl, %r10

Final state:
%r10/%r10: sign-extend-64(%rcx_movsbl_r32_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
=====================================
Computing circuit for movsbl %bl, %r15d

.target:
callq .set_of
callq .read_of_into_rbx
callq .move_064_032_rbx_r10d_r11d
movsbq %cl, %r10
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r15/%r15: %r15_xaddb_r8_r8

State for specgen instruction: movsbl %cl, %ebx:
%rbx/%rbx: (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r15
Value is               -> (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0]

Final state
%r15/%r15: 0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0]

=====================================
-------------------------------------
Getting base circuit for movsbq %r15b, %rcx

Final state:
%rcx/%rcx: sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for adcb %cl, %r13b

Final state:
%r13/%r13b: (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][3:0] + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁
%of: (sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][7:7] = 0x1₁) ∧ !(sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:7] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r13d, %rbx

Final state:
%rbx/%rbx: sign-extend-64(((0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0])[31:0])

-------------------------------------
=====================================
Computing circuit for xaddb %bl, %dl

.target:
callq .clear_cf
movsbl %cl, %r13d
movsbl %bl, %r15d
movsbq %r15b, %rcx
adcb %cl, %r13b
movslq %r13d, %rbx
retq 

Initial state:
%rdx/%dl: 0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8]
%rbx/%bl: %rbx_xaddb_rh_r8

%cf: %cf_xaddb_rh_r8
%pf: %pf_xaddb_rh_r8
%af: %af_xaddb_rh_r8
%zf: %zf_xaddb_rh_r8
%sf: %sf_xaddb_rh_r8
%of: %of_xaddb_rh_r8

State for specgen instruction: xaddb %cl, %bl:
%rcx/%cl: sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])
%rbx/%bl: sign-extend-64(((0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0])[31:0])

%cf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][3:0] + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁
%of: (sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][7:7] = 0x1₁) ∧ !(sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:7] = 0x1₁)

Final state
%rdx/%dl: (0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8])[63:8] ∘ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0]
%rbx/%bl: %rbx_xaddb_rh_r8[63:8] ∘ %rax_xaddb_rh_r8[15:8]

%cf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[8:8] = 0x1₁
%pf: !((0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rax_xaddb_rh_r8[11:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0] = 0x0₈
%sf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁
%of: (%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ %rbx_xaddb_rh_r8[7:7] = 0x1₁) ∧ !(%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for movb %dl, %ah

Final state:
%rax/%ah: %rax_xaddb_rh_r8[63:16] ∘ ((0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8])[63:8] ∘ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0])[7:0] ∘ %rax_xaddb_rh_r8[7:0]

-------------------------------------
=====================================
Computing circuit for xaddb %bl, %ch

.target:
movzbl %ah, %edx
xaddb %bl, %dl
movb %dl, %ah
retq 

Initial state:
%rcx/%ch: %rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0])
%rbx/%bl: %rbx_xchgb_r8_r8[63:16] ∘ 0x0₈ ∘ %rbx_xchgb_r8_r8[7:0]

%cf: %cf_xchgb_r8_r8
%pf: %pf_xchgb_r8_r8
%af: %af_xchgb_r8_r8
%zf: %zf_xchgb_r8_r8
%sf: %sf_xchgb_r8_r8
%of: %of_xchgb_r8_r8

State for specgen instruction: xaddb %bl, %ah:
%rax/%ah: %rax_xaddb_rh_r8[63:16] ∘ ((0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8])[63:8] ∘ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0])[7:0] ∘ %rax_xaddb_rh_r8[7:0]
%rbx/%bl: %rbx_xaddb_rh_r8[63:8] ∘ %rax_xaddb_rh_r8[15:8]

%cf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[8:8] = 0x1₁
%pf: !((0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rax_xaddb_rh_r8[11:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0] = 0x0₈
%sf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁
%of: (%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ %rbx_xaddb_rh_r8[7:7] = 0x1₁) ∧ !(%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)

Final state
%rcx/%ch: (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ %rbx_xchgb_r8_r8[7:0] ∘ (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[7:0]
%rbx/%bl: (%rbx_xchgb_r8_r8[63:16] ∘ 0x0₈ ∘ %rbx_xchgb_r8_r8[7:0])[63:8] ∘ 0x0₈

%cf: false
%pf: !(%rbx_xchgb_r8_r8[0:0] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[1:1] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[2:2] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[3:3] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[4:4] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[5:5] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[6:6] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[7:7] = 0x1₁)
%af: false
%zf: %rbx_xchgb_r8_r8[7:0] = 0x0₈
%sf: %rbx_xchgb_r8_r8[7:7] = 0x1₁
%of: (false ↔ %rbx_xchgb_r8_r8[7:7] = 0x1₁) ∧ !(false ↔ %rbx_xchgb_r8_r8[7:7] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r10b_r11b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_cx_r8b_r9b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r10b_r11b_cx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r8b_r9b_bx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for xchgw %cx, %bx

.target:
callq .move_016_008_bx_r10b_r11b
callq .move_016_008_cx_r8b_r9b
callq .move_008_016_r10b_r11b_cx
callq .move_008_016_r8b_r9b_bx
retq 

Initial state:
%rcx/%cx: %rcx_xaddw_r16_r16
%rbx/%bx: %rbx_xaddw_r16_r16

State for specgen instruction: xchgw %cx, %bx:
%rcx/%cx: %rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])
%rbx/%bx: %rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])

Register        -> %cx
  translates to => %cx
Value is               -> (%rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => %rbx_xaddw_r16_r16[15:0]

Register        -> %bx
  translates to => %bx
Value is               -> (%rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => %rcx_xaddw_r16_r16[15:0]

Final state
%rcx/%cx: %rcx_xaddw_r16_r16[63:16] ∘ %rbx_xaddw_r16_r16[15:0]
%rbx/%bx: %rbx_xaddw_r16_r16[63:16] ∘ %rcx_xaddw_r16_r16[15:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: %cf_addw_r16_r16

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for adcw %cx, %bx

Final state:
%rbx/%bx: %rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[16:16] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addw_r16_r16[15:0][3:0] + 0x0₁ ∘ %rbx_addw_r16_r16[15:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0] = 0x0₁₆
%sf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][15:15] = 0x1₁
%of: (%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ %rbx_addw_r16_r16[15:0][15:15] = 0x1₁) ∧ !(%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:15] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_bx

Final state:
%rax/%rax: %rax_addw_r16_r16
%rdx/%rdx: %rdx_addw_r16_r16

%xmm0: %ymm0_addw_r16_r16[127:0]
%xmm1: %ymm1_addw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for addw %cx, %bx

.target:
clc 
adcw %cx, %bx
callq .set_szp_for_bx
retq 

Initial state:
%rbx/%bx: %rbx_xaddw_r16_r16[63:16] ∘ %rcx_xaddw_r16_r16[15:0]

%cf: %cf_xaddw_r16_r16
%pf: %pf_xaddw_r16_r16
%af: %af_xaddw_r16_r16
%zf: %zf_xaddw_r16_r16
%sf: %sf_xaddw_r16_r16
%of: %of_xaddw_r16_r16

State for specgen instruction: addw %cx, %bx:
%rbx/%bx: %rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[16:16] = 0x1₁
%pf: !((%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addw_r16_r16[15:0][3:0] + 0x0₁ ∘ %rbx_addw_r16_r16[15:0][3:0])[4:4] = 0x1₁
%zf: (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0] = 0x0₁₆
%sf: (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][15:15] = 0x1₁
%of: (%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ %rbx_addw_r16_r16[15:0][15:15] = 0x1₁) ∧ !(%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:15] = 0x1₁)

Register        -> %bx
  translates to => %bx
Value is               -> (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0]
  after renaming it is => (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:0]

Final state
%rbx/%bx: (%rbx_xaddw_r16_r16[63:16] ∘ %rcx_xaddw_r16_r16[15:0])[63:16] ∘ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:0]

%cf: (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[16:16] = 0x1₁
%pf: !((0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rbx_xaddw_r16_r16[3:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:0] = 0x0₁₆
%sf: (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:15] = 0x1₁
%of: (%rbx_xaddw_r16_r16[15:15] = 0x1₁ ↔ %rcx_xaddw_r16_r16[15:15] = 0x1₁) ∧ !(%rbx_xaddw_r16_r16[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:15] = 0x1₁)

=====================================
=====================================
Computing circuit for xaddw %bx, %cx

.target:
xchgw %cx, %bx
addw %cx, %bx
retq 

Initial state:
%rcx/%cx: (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ %rbx_xchgb_r8_r8[7:0] ∘ (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[7:0]
%rbx/%bx: (%rbx_xchgb_r8_r8[63:16] ∘ 0x0₈ ∘ %rbx_xchgb_r8_r8[7:0])[63:8] ∘ 0x0₈

%cf: false
%pf: !(%rbx_xchgb_r8_r8[0:0] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[1:1] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[2:2] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[3:3] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[4:4] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[5:5] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[6:6] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[7:7] = 0x1₁)
%af: false
%zf: %rbx_xchgb_r8_r8[7:0] = 0x0₈
%sf: %rbx_xchgb_r8_r8[7:7] = 0x1₁
%of: (false ↔ %rbx_xchgb_r8_r8[7:7] = 0x1₁) ∧ !(false ↔ %rbx_xchgb_r8_r8[7:7] = 0x1₁)

State for specgen instruction: xaddw %cx, %bx:
%rcx/%cx: %rcx_xaddw_r16_r16[63:16] ∘ %rbx_xaddw_r16_r16[15:0]
%rbx/%bx: (%rbx_xaddw_r16_r16[63:16] ∘ %rcx_xaddw_r16_r16[15:0])[63:16] ∘ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:0]

%cf: (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[16:16] = 0x1₁
%pf: !((0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rbx_xaddw_r16_r16[3:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:0] = 0x0₁₆
%sf: (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:15] = 0x1₁
%of: (%rbx_xaddw_r16_r16[15:15] = 0x1₁ ↔ %rcx_xaddw_r16_r16[15:15] = 0x1₁) ∧ !(%rbx_xaddw_r16_r16[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:15] = 0x1₁)

Final state
%rcx/%cx: ((%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ %rbx_xchgb_r8_r8[7:0] ∘ (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[7:0])[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0])
%rbx/%bx: ((%rbx_xchgb_r8_r8[63:16] ∘ 0x0₈ ∘ %rbx_xchgb_r8_r8[7:0])[63:8] ∘ 0x0₈)[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0])

%cf: false
%pf: !(%rcx_xchgb_r8_r8[0:0] = 0x1₁ ⊕ %rcx_xchgb_r8_r8[1:1] = 0x1₁ ⊕ %rcx_xchgb_r8_r8[2:2] = 0x1₁ ⊕ %rcx_xchgb_r8_r8[3:3] = 0x1₁ ⊕ %rcx_xchgb_r8_r8[4:4] = 0x1₁ ⊕ %rcx_xchgb_r8_r8[5:5] = 0x1₁ ⊕ %rcx_xchgb_r8_r8[6:6] = 0x1₁ ⊕ %rcx_xchgb_r8_r8[7:7] = 0x1₁)
%af: false
%zf: %rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0] = 0x0₁₆
%sf: %rbx_xchgb_r8_r8[7:7] = 0x1₁
%of: (%rbx_xchgb_r8_r8[7:7] = 0x1₁ ↔ false) ∧ !(%rbx_xchgb_r8_r8[7:7] = 0x1₁ ↔ %rbx_xchgb_r8_r8[7:7] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r10b_r11b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_cx_r8b_r9b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r10b_r11b_cx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r8b_r9b_bx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for xchgw %cx, %r8w

.target:
callq .move_016_008_bx_r10b_r11b
callq .move_016_008_cx_r8b_r9b
callq .move_008_016_r10b_r11b_cx
callq .move_008_016_r8b_r9b_bx
retq 

Initial state:
%rcx/%cx: ((%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ %rbx_xchgb_r8_r8[7:0] ∘ (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[7:0])[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0])
%r8/%r8w: 0x0₅₆ ∘ %rbx_xchgb_r8_r8[7:0]

State for specgen instruction: xchgw %cx, %bx:
%rcx/%cx: %rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])
%rbx/%bx: %rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])

Register        -> %cx
  translates to => %cx
Value is               -> (%rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => 0x0₈ ∘ %rbx_xchgb_r8_r8[7:0]

Register        -> %bx
  translates to => %r8w
Value is               -> (%rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => %rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0]

Final state
%rcx/%cx: (((%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ %rbx_xchgb_r8_r8[7:0] ∘ (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[7:0])[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ (0x0₈ ∘ %rbx_xchgb_r8_r8[7:0])
%r8/%r8w: (0x0₅₆ ∘ %rbx_xchgb_r8_r8[7:0])[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0])

=====================================
=====================================
Computing circuit for xchgb %r8b, %bl

.target:
movzbq %bl, %r8
movzbw %cl, %cx
movb %ch, %bh
xaddb %bl, %ch
xaddw %bx, %cx
xchgw %cx, %r8w
retq 

Initial state:
%rbx/%bl: %rbx_vmovd_xmm_r32
%r8/%r8b: %r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0]

State for specgen instruction: xchgb %cl, %bl:
%rcx/%cl: (((%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ %rbx_xchgb_r8_r8[7:0] ∘ (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[7:0])[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ (0x0₈ ∘ %rbx_xchgb_r8_r8[7:0])
%rbx/%bl: ((%rbx_xchgb_r8_r8[63:16] ∘ 0x0₈ ∘ %rbx_xchgb_r8_r8[7:0])[63:8] ∘ 0x0₈)[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0])

Register        -> %cl
  translates to => %r8b
Value is               -> ((((%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ %rbx_xchgb_r8_r8[7:0] ∘ (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[7:0])[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ (0x0₈ ∘ %rbx_xchgb_r8_r8[7:0]))[7:0]
  after renaming it is => %rbx_vmovd_xmm_r32[7:0]

Register        -> %bl
  translates to => %bl
Value is               -> (((%rbx_xchgb_r8_r8[63:16] ∘ 0x0₈ ∘ %rbx_xchgb_r8_r8[7:0])[63:8] ∘ 0x0₈)[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0]))[7:0]
  after renaming it is => %rbx_vmovd_xmm_r32[7:0]

Final state
%rbx/%bl: %rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0]
%r8/%r8b: (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[63:8] ∘ %rbx_vmovd_xmm_r32[7:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_r9b_to_byte_3_of_ymm1

Final state:
%rax/%rax: %rax_vmovd_xmm_r32
%rdx/%rdx: %rdx_vmovd_xmm_r32

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ebx_r8w_r9w

Final state:
%rax/%rax: %rax_vmovd_xmm_r32
%rdx/%rdx: %rdx_vmovd_xmm_r32

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_3_of_rbx_to_r8b

Final state:
%rax/%rax: %rax_vmovd_xmm_r32
%rdx/%rdx: %rdx_vmovd_xmm_r32

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r9b_to_byte_2_of_ymm1

Final state:
%rax/%rax: %rax_vmovd_xmm_r32
%rdx/%rdx: %rdx_vmovd_xmm_r32

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[255:24] ∘ ((%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[63:16] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:0][31:16])[7:0] ∘ (((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[15:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r8b_to_byte_3_of_ymm1

Final state:
%rax/%rax: %rax_vmovd_xmm_r32
%rdx/%rdx: %rdx_vmovd_xmm_r32

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (((((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[255:24] ∘ ((%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[63:16] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:0][31:16])[7:0] ∘ (((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[15:0])[255:32] ∘ ((((%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[63:16] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:0][15:0])[63:8] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:24])[7:0] ∘ ((((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[255:24] ∘ ((%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[63:16] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:0][31:16])[7:0] ∘ (((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[15:0])[23:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovd %ebx, %xmm1

.target:
vzeroall 
callq .move_016_008_bx_r8b_r9b
callq .move_r8b_to_byte_0_of_ymm1
callq .move_r9b_to_byte_1_of_ymm1
xchgb %r8b, %bl
callq .move_r9b_to_byte_3_of_ymm1
callq .move_032_016_ebx_r8w_r9w
callq .move_byte_3_of_rbx_to_r8b
callq .move_r9b_to_byte_2_of_ymm1
callq .move_r8b_to_byte_3_of_ymm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastw_xmm_xmm

State for specgen instruction: vmovd %ebx, %xmm1:
%ymm1: ((((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[255:24] ∘ ((%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[63:16] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:0][31:16])[7:0] ∘ (((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[15:0])[255:32] ∘ ((((%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[63:16] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:0][15:0])[63:8] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:24])[7:0] ∘ ((((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[255:24] ∘ ((%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[63:16] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:0][31:16])[7:0] ∘ (((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[15:0])[23:0]

Final state
%ymm1: 0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_r9b_to_byte_19_of_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastw_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_xmm_xmm

%xmm0: %ymm0_vpbroadcastw_xmm_xmm[127:0]
%xmm1: ((0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[255:160] ∘ (%r9_vpbroadcastw_xmm_xmm[63:8] ∘ (0x0₃₂ ∘ ((0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][63:32])[15:0][15:0] ∘ (0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][31:0])[15:0][15:0]))[15:0][15:8])[7:0] ∘ (0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[151:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r8b_to_byte_2_of_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastw_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_xmm_xmm

%xmm0: %ymm0_vpbroadcastw_xmm_xmm[127:0]
%xmm1: (((0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[255:160] ∘ (%r9_vpbroadcastw_xmm_xmm[63:8] ∘ (0x0₃₂ ∘ ((0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][63:32])[15:0][15:0] ∘ (0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][31:0])[15:0][15:0]))[15:0][15:8])[7:0] ∘ (0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[151:0])[255:24] ∘ (%r8_vpbroadcastw_xmm_xmm[63:8] ∘ (0x0₃₂ ∘ ((0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][63:32])[15:0][15:0] ∘ (0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][31:0])[15:0][15:0]))[15:0][7:0])[7:0] ∘ ((0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[255:160] ∘ (%r9_vpbroadcastw_xmm_xmm[63:8] ∘ (0x0₃₂ ∘ ((0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][63:32])[15:0][15:0] ∘ (0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][31:0])[15:0][15:0]))[15:0][15:8])[7:0] ∘ (0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[151:0])[15:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm1, %xmm1

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm1: ((0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[255:160] ∘ (%r9_vpbroadcastw_xmm_xmm[63:8] ∘ (0x0₃₂ ∘ ((0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][63:32])[15:0][15:0] ∘ (0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][31:0])[15:0][15:0]))[15:0][15:8])[7:0] ∘ (0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[151:0])[255:24] ∘ (%r8_vpbroadcastw_xmm_xmm[63:8] ∘ (0x0₃₂ ∘ ((0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][63:32])[15:0][15:0] ∘ (0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][31:0])[15:0][15:0]))[15:0][7:0])[7:0] ∘ ((0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[255:160] ∘ (%r9_vpbroadcastw_xmm_xmm[63:8] ∘ (0x0₃₂ ∘ ((0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][63:32])[15:0][15:0] ∘ (0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][31:0])[15:0][15:0]))[15:0][15:8])[7:0] ∘ (0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[151:0])[15:0]

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ (%ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]) ∘ (%ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]) ∘ (%ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))

=====================================
=====================================
Computing circuit for vpbroadcastw %xmm5, %xmm0

.target:
callq .move_128_032_xmm2_r10d_r11d_r12d_r13d
callq .move_016_032_r10w_r11w_ebx
callq .move_016_008_bx_r8b_r9b
callq .move_r9b_to_byte_3_of_rbx
vmovd %ebx, %xmm1
callq .move_r9b_to_byte_19_of_ymm1
callq .move_r8b_to_byte_2_of_ymm1
vbroadcastss %xmm1, %xmm1
retq 

Initial state:
%ymm0: %ymm0_punpcklwd_xmm_xmm

State for specgen instruction: vpbroadcastw %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ (%ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]) ∘ (%ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]) ∘ (%ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0] ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm5, %xmm14

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm14: %ymm14_punpcklwd_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_punpcklwd_xmm_xmm
%rdx/%rdx: %rdx_punpcklwd_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0] ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0])))[127:0]
%xmm1: (%ymm1_punpcklwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[15:0]))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vbroadcastss_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastss_ymm_xmm

%xmm0: %ymm0_vbroadcastss_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastss_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm3

Final state:
%rax/%rax: %rax_vbroadcastss_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastss_ymm_xmm

%xmm0: %ymm0_vbroadcastss_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastss_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm3, %xmm1

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vbroadcastss_ymm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_r8b_to_byte_23_of_ymm1

Final state:
%rax/%rax: %rax_vbroadcastss_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastss_ymm_xmm

%xmm0: %ymm0_vbroadcastss_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]))[255:192] ∘ %ymm2_vbroadcastss_ymm_xmm[127:0][63:0][7:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]))[183:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]))[255:192] ∘ %ymm2_vbroadcastss_ymm_xmm[127:0][63:0][7:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]))[183:0]

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm1: %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]) ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vbroadcastss %xmm2, %ymm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm3
vbroadcastss %xmm3, %xmm1
callq .move_r8b_to_byte_23_of_ymm1
vbroadcastsd %xmm1, %ymm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastw_ymm_xmm

State for specgen instruction: vbroadcastss %xmm2, %ymm1:
%ymm1: %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]) ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]))

Final state
%ymm1: %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_byte_1_of_ymm1_to_r8b

Final state:
%rax/%rax: %rax_vpbroadcastw_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_ymm_xmm

%xmm0: %ymm0_vpbroadcastw_ymm_xmm[127:0]
%xmm1: (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_0_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpbroadcastw_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_ymm_xmm

%xmm0: %ymm0_vpbroadcastw_ymm_xmm[127:0]
%xmm1: (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r8b_to_byte_3_of_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastw_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_ymm_xmm

%xmm0: %ymm0_vpbroadcastw_ymm_xmm[127:0]
%xmm1: ((%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[255:32] ∘ (%r8_vpbroadcastw_ymm_xmm[63:8] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[15:8])[7:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[23:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r9b_to_byte_2_of_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastw_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_ymm_xmm

%xmm0: %ymm0_vpbroadcastw_ymm_xmm[127:0]
%xmm1: (((%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[255:32] ∘ (%r8_vpbroadcastw_ymm_xmm[63:8] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[15:8])[7:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[23:0])[255:24] ∘ (%r9_vpbroadcastw_ymm_xmm[63:8] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[7:0])[7:0] ∘ ((%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[255:32] ∘ (%r8_vpbroadcastw_ymm_xmm[63:8] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[15:8])[7:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[23:0])[15:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vbroadcastss_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastss_ymm_xmm

%xmm0: %ymm0_vbroadcastss_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastss_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm3

Final state:
%rax/%rax: %rax_vbroadcastss_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastss_ymm_xmm

%xmm0: %ymm0_vbroadcastss_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastss_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm3, %xmm1

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vbroadcastss_ymm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_r8b_to_byte_23_of_ymm1

Final state:
%rax/%rax: %rax_vbroadcastss_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastss_ymm_xmm

%xmm0: %ymm0_vbroadcastss_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]))[255:192] ∘ %ymm2_vbroadcastss_ymm_xmm[127:0][63:0][7:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]))[183:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]))[255:192] ∘ %ymm2_vbroadcastss_ymm_xmm[127:0][63:0][7:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]))[183:0]

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm1: %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]) ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vbroadcastss %xmm1, %ymm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm3
vbroadcastss %xmm3, %xmm1
callq .move_r8b_to_byte_23_of_ymm1
vbroadcastsd %xmm1, %ymm1
retq 

Initial state:
%ymm1: ((%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[255:32] ∘ (%r8_vpbroadcastw_ymm_xmm[63:8] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[15:8])[7:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[23:0])[255:24] ∘ (%r9_vpbroadcastw_ymm_xmm[63:8] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[7:0])[7:0] ∘ ((%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[255:32] ∘ (%r8_vpbroadcastw_ymm_xmm[63:8] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[15:8])[7:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[23:0])[15:0]

State for specgen instruction: vbroadcastss %xmm2, %ymm1:
%ymm1: %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]) ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]))

Final state
%ymm1: %ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0])) ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0])))

=====================================
=====================================
Computing circuit for vpbroadcastw %xmm5, %ymm3

.target:
vbroadcastss %xmm2, %ymm1
callq .move_byte_1_of_ymm1_to_r8b
callq .move_byte_0_of_ymm1_to_r9b
callq .move_r8b_to_byte_3_of_ymm1
callq .move_r9b_to_byte_2_of_ymm1
vbroadcastss %xmm1, %ymm1
retq 

Initial state:
%ymm3: %ymm3_punpcklwd_xmm_xmm

State for specgen instruction: vpbroadcastw %xmm2, %ymm1:
%ymm1: %ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0])) ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0])))

Final state
%ymm3: %ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32]) ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32])) ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32]) ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm3, %ymm6

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm6: %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm3, %xmm6, %xmm9

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm3, %xmm2, %xmm14

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm14: %ymm14_vpor_xmm_xmm_xmm

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpor_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vpor %xmm9, %xmm9, %xmm7

.target:
vorps %xmm3, %xmm2, %xmm14
vmovapd %xmm14, %xmm1
retq 

Initial state:
%ymm7: %ymm7_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpor %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

Final state
%ymm7: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm7, %xmm2

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpckldq_xmm_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm2: (%ymm2_vpunpckldq_xmm_xmm_xmm[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm1, %xmm3

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm3: %ymm3_mulpd_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm8: %ymm8_mulpd_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmulpd %ymm8, %ymm3, %ymm6

Final state:
%ymm6: mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[255:192]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[191:128]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[127:64]) ∘ mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_mulpd_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for mulpd %xmm3, %xmm2

.target:
vmovapd %xmm1, %xmm3
vmovaps %xmm2, %xmm8
vmulpd %ymm8, %ymm3, %ymm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vmulpd_xmm_xmm_xmm[127:0]

State for specgen instruction: mulpd %xmm2, %xmm1:
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vmulpd_xmm_xmm_xmm[255:128] ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmulpd_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmulpd %xmm6, %xmm2, %xmm12

.target:
mulpd %xmm3, %xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm12: %ymm12_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vmulpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]) ∘ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm12, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vpunpckldq %xmm3, %xmm0, %xmm0

.target:
vpbroadcastq %xmm3, %ymm6
vunpcklpd %xmm3, %xmm6, %xmm9
vpor %xmm9, %xmm9, %xmm7
unpcklps %xmm7, %xmm2
vmulpd %xmm6, %xmm2, %xmm12
vxorps %xmm12, %xmm2, %xmm1
movdqu %xmm2, %xmm1
retq 

Initial state:
%ymm0: 0x0₁₂₈ ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0] ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0]))

State for specgen instruction: vpunpckldq %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm3, %ymm6

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm6: %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm3, %xmm6, %xmm9

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm3, %xmm2, %xmm14

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm14: %ymm14_vpor_xmm_xmm_xmm

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpor_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vpor %xmm9, %xmm9, %xmm7

.target:
vorps %xmm3, %xmm2, %xmm14
vmovapd %xmm14, %xmm1
retq 

Initial state:
%ymm7: %ymm7_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpor %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

Final state
%ymm7: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm7, %xmm2

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpckldq_xmm_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm2: (%ymm2_vpunpckldq_xmm_xmm_xmm[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm1, %xmm3

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm3: %ymm3_mulpd_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm8: %ymm8_mulpd_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmulpd %ymm8, %ymm3, %ymm6

Final state:
%ymm6: mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[255:192]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[191:128]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[127:64]) ∘ mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_mulpd_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for mulpd %xmm3, %xmm2

.target:
vmovapd %xmm1, %xmm3
vmovaps %xmm2, %xmm8
vmulpd %ymm8, %ymm3, %ymm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vmulpd_xmm_xmm_xmm[127:0]

State for specgen instruction: mulpd %xmm2, %xmm1:
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vmulpd_xmm_xmm_xmm[255:128] ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmulpd_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmulpd %xmm6, %xmm2, %xmm12

.target:
mulpd %xmm3, %xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm12: %ymm12_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vmulpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]) ∘ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm12, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vpunpckldq %xmm2, %xmm0, %xmm13

.target:
vpbroadcastq %xmm3, %ymm6
vunpcklpd %xmm3, %xmm6, %xmm9
vpor %xmm9, %xmm9, %xmm7
unpcklps %xmm7, %xmm2
vmulpd %xmm6, %xmm2, %xmm12
vxorps %xmm12, %xmm2, %xmm1
movdqu %xmm2, %xmm1
retq 

Initial state:
%ymm13: %ymm13_punpcklwd_xmm_xmm

State for specgen instruction: vpunpckldq %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0]))

Final state
%ymm13: 0x0₁₂₈ ∘ (%ymm2_punpcklwd_xmm_xmm[63:32] ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32]) ∘ (%ymm2_punpcklwd_xmm_xmm[31:0] ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vandnpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vandnpd_ymm_ymm_ymm

%xmm0: %ymm0_vandnpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vandnpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm2, %xmm2

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm2: %ymm2_por_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm2: 0x0₁₂₈ ∘ %ymm2_por_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm1, %xmm2, %xmm3

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm3: %ymm3_por_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_por_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_por_xmm_xmm[255:128] ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for por %xmm1, %xmm2

.target:
vmovapd %xmm2, %xmm2
vorpd %xmm1, %xmm2, %xmm3
movdqa %xmm3, %xmm1
retq 

Initial state:
%xmm2: %ymm2_pandn_xmm_xmm[127:0]

State for specgen instruction: por %xmm2, %xmm1:
%xmm1: (%ymm1_por_xmm_xmm[255:128] ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_pandn_xmm_xmm[255:128] ∘ ((%ymm2_pandn_xmm_xmm[127:64] | %ymm1_pandn_xmm_xmm[127:64]) ∘ (%ymm2_pandn_xmm_xmm[63:0] | %ymm1_pandn_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm2, %xmm1, %xmm6

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm6: %ymm6_xorps_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm6: 0x0₁₂₈ ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_xorps_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_xorps_xmm_xmm[255:128] ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for xorps %xmm2, %xmm1

.target:
vxorps %xmm2, %xmm1, %xmm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm1: %ymm1_pxor_xmm_xmm[127:0]

State for specgen instruction: xorps %xmm2, %xmm1:
%xmm1: (%ymm1_xorps_xmm_xmm[255:128] ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0])))[127:0]

Final state
%xmm1: (%ymm1_pxor_xmm_xmm[255:128] ∘ ((%ymm1_pxor_xmm_xmm[127:64] ⊕ %ymm2_pxor_xmm_xmm[127:64]) ∘ (%ymm1_pxor_xmm_xmm[63:0] ⊕ %ymm2_pxor_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for pxor %xmm2, %xmm1

.target:
xorps %xmm2, %xmm1
retq 

Initial state:
%xmm1: %ymm1_pandn_xmm_xmm[127:0]

State for specgen instruction: pxor %xmm2, %xmm1:
%xmm1: (%ymm1_pxor_xmm_xmm[255:128] ∘ ((%ymm1_pxor_xmm_xmm[127:64] ⊕ %ymm2_pxor_xmm_xmm[127:64]) ∘ (%ymm1_pxor_xmm_xmm[63:0] ⊕ %ymm2_pxor_xmm_xmm[63:0])))[127:0]

Final state
%xmm1: (%ymm1_pandn_xmm_xmm[255:128] ∘ ((%ymm1_pandn_xmm_xmm[127:64] ⊕ (%ymm2_pandn_xmm_xmm[127:64] | %ymm1_pandn_xmm_xmm[127:64])) ∘ (%ymm1_pandn_xmm_xmm[63:0] ⊕ (%ymm2_pandn_xmm_xmm[63:0] | %ymm1_pandn_xmm_xmm[63:0]))))[127:0]

=====================================
=====================================
Computing circuit for pandn %xmm3, %xmm2

.target:
por %xmm1, %xmm2
pxor %xmm2, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vandnpd_ymm_ymm_ymm[127:0]

State for specgen instruction: pandn %xmm2, %xmm1:
%xmm1: (%ymm1_pandn_xmm_xmm[255:128] ∘ ((%ymm1_pandn_xmm_xmm[127:64] ⊕ (%ymm2_pandn_xmm_xmm[127:64] | %ymm1_pandn_xmm_xmm[127:64])) ∘ (%ymm1_pandn_xmm_xmm[63:0] ⊕ (%ymm2_pandn_xmm_xmm[63:0] | %ymm1_pandn_xmm_xmm[63:0]))))[127:0]

Final state
%xmm2: (%ymm2_vandnpd_ymm_ymm_ymm[255:128] ∘ ((%ymm2_vandnpd_ymm_ymm_ymm[127:64] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[127:64] | %ymm2_vandnpd_ymm_ymm_ymm[127:64])) ∘ (%ymm2_vandnpd_ymm_ymm_ymm[63:0] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[63:0] | %ymm2_vandnpd_ymm_ymm_ymm[63:0]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_256_128_ymm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vandnpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vandnpd_ymm_ymm_ymm

%xmm0: %ymm0_vandnpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vandnpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm10, %xmm14

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm14: %ymm14_vandnpd_ymm_ymm_ymm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm2_vandnpd_ymm_ymm_ymm[127:64] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[127:64] | %ymm2_vandnpd_ymm_ymm_ymm[127:64])) ∘ (%ymm2_vandnpd_ymm_ymm_ymm[63:0] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[63:0] | %ymm2_vandnpd_ymm_ymm_ymm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm2, %xmm3, %xmm12

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm12: %ymm12_vandnpd_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm12: 0x0₁₂₈ ∘ ((%ymm2_vandnpd_xmm_xmm_xmm[127:64] | %ymm3_vandnpd_xmm_xmm_xmm[127:64]) ∘ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] | %ymm3_vandnpd_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovupd_ymm_ymm
%rdx/%rdx: %rdx_vmovupd_ymm_ymm

%xmm0: %ymm0_vmovupd_ymm_ymm[127:0]
%xmm1: %ymm1_vmovupd_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vminps %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_single(%ymm2_vmovupd_ymm_ymm[255:224], %ymm2_vmovupd_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[255:224] : %ymm2_vmovupd_ymm_ymm[255:224]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[223:192], %ymm2_vmovupd_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[223:192] : %ymm2_vmovupd_ymm_ymm[223:192]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[191:160], %ymm2_vmovupd_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[191:160] : %ymm2_vmovupd_ymm_ymm[191:160]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[159:128], %ymm2_vmovupd_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[159:128] : %ymm2_vmovupd_ymm_ymm[159:128]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[127:96], %ymm2_vmovupd_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[127:96] : %ymm2_vmovupd_ymm_ymm[127:96]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[95:64], %ymm2_vmovupd_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[95:64] : %ymm2_vmovupd_ymm_ymm[95:64]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[63:32], %ymm2_vmovupd_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[63:32] : %ymm2_vmovupd_ymm_ymm[63:32]) ∘ (mincmp_single(%ymm2_vmovupd_ymm_ymm[31:0], %ymm2_vmovupd_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[31:0] : %ymm2_vmovupd_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovupd_ymm_ymm
%rdx/%rdx: %rdx_vmovupd_ymm_ymm

%xmm0: %ymm0_vmovupd_ymm_ymm[127:0]
%xmm1: (((mincmp_single(%ymm2_vmovupd_ymm_ymm[255:224], %ymm2_vmovupd_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[255:224] : %ymm2_vmovupd_ymm_ymm[255:224]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[223:192], %ymm2_vmovupd_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[223:192] : %ymm2_vmovupd_ymm_ymm[223:192]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[191:160], %ymm2_vmovupd_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[191:160] : %ymm2_vmovupd_ymm_ymm[191:160]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[159:128], %ymm2_vmovupd_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[159:128] : %ymm2_vmovupd_ymm_ymm[159:128]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[127:96], %ymm2_vmovupd_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[127:96] : %ymm2_vmovupd_ymm_ymm[127:96]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[95:64], %ymm2_vmovupd_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[95:64] : %ymm2_vmovupd_ymm_ymm[95:64]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[63:32], %ymm2_vmovupd_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[63:32] : %ymm2_vmovupd_ymm_ymm[63:32]) ∘ (mincmp_single(%ymm2_vmovupd_ymm_ymm[31:0], %ymm2_vmovupd_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[31:0] : %ymm2_vmovupd_ymm_ymm[31:0]))))))))[255:128] ∘ (%ymm2_vmovupd_ymm_ymm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_ymm_ymm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %ymm12, %ymm1

.target:
callq .move_128_064_xmm2_r12_r13
vminps %ymm2, %ymm2, %ymm1
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vandnpd_xmm_xmm_xmm

State for specgen instruction: vmovupd %ymm2, %ymm1:
%ymm1: ((mincmp_single(%ymm2_vmovupd_ymm_ymm[255:224], %ymm2_vmovupd_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[255:224] : %ymm2_vmovupd_ymm_ymm[255:224]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[223:192], %ymm2_vmovupd_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[223:192] : %ymm2_vmovupd_ymm_ymm[223:192]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[191:160], %ymm2_vmovupd_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[191:160] : %ymm2_vmovupd_ymm_ymm[191:160]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[159:128], %ymm2_vmovupd_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[159:128] : %ymm2_vmovupd_ymm_ymm[159:128]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[127:96], %ymm2_vmovupd_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[127:96] : %ymm2_vmovupd_ymm_ymm[127:96]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[95:64], %ymm2_vmovupd_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[95:64] : %ymm2_vmovupd_ymm_ymm[95:64]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[63:32], %ymm2_vmovupd_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[63:32] : %ymm2_vmovupd_ymm_ymm[63:32]) ∘ (mincmp_single(%ymm2_vmovupd_ymm_ymm[31:0], %ymm2_vmovupd_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[31:0] : %ymm2_vmovupd_ymm_ymm[31:0]))))))))[255:128] ∘ (%ymm2_vmovupd_ymm_ymm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_ymm_ymm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₃₂ ∘ (0x0₃₂ ∘ 0x0₆₄) ∘ ((%ymm2_vandnpd_xmm_xmm_xmm[127:64] | %ymm3_vandnpd_xmm_xmm_xmm[127:64]) ∘ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] | %ymm3_vandnpd_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm2, %xmm1, %xmm6

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm6: %ymm6_xorps_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm6: 0x0₁₂₈ ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_xorps_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_xorps_xmm_xmm[255:128] ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for xorps %xmm2, %xmm1

.target:
vxorps %xmm2, %xmm1, %xmm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm1: %ymm1_pxor_xmm_xmm[127:0]

State for specgen instruction: xorps %xmm2, %xmm1:
%xmm1: (%ymm1_xorps_xmm_xmm[255:128] ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0])))[127:0]

Final state
%xmm1: (%ymm1_pxor_xmm_xmm[255:128] ∘ ((%ymm1_pxor_xmm_xmm[127:64] ⊕ %ymm2_pxor_xmm_xmm[127:64]) ∘ (%ymm1_pxor_xmm_xmm[63:0] ⊕ %ymm2_pxor_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for pxor %xmm1, %xmm2

.target:
xorps %xmm2, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vandnpd_xmm_xmm_xmm[127:0]

State for specgen instruction: pxor %xmm2, %xmm1:
%xmm1: (%ymm1_pxor_xmm_xmm[255:128] ∘ ((%ymm1_pxor_xmm_xmm[127:64] ⊕ %ymm2_pxor_xmm_xmm[127:64]) ∘ (%ymm1_pxor_xmm_xmm[63:0] ⊕ %ymm2_pxor_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vandnpd_xmm_xmm_xmm[255:128] ∘ ((%ymm2_vandnpd_xmm_xmm_xmm[127:64] ⊕ (%ymm2_vandnpd_xmm_xmm_xmm[127:64] | %ymm3_vandnpd_xmm_xmm_xmm[127:64])) ∘ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] ⊕ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] | %ymm3_vandnpd_xmm_xmm_xmm[63:0]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: 0x0₃₂ ∘ (0x0₃₂ ∘ 0x0₆₄) ∘ ((%ymm2_vandnpd_xmm_xmm_xmm[127:64] | %ymm3_vandnpd_xmm_xmm_xmm[127:64]) ∘ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] | %ymm3_vandnpd_xmm_xmm_xmm[63:0]))

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm2_vandnpd_xmm_xmm_xmm[127:64] ⊕ (%ymm2_vandnpd_xmm_xmm_xmm[127:64] | %ymm3_vandnpd_xmm_xmm_xmm[127:64])) ∘ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] ⊕ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] | %ymm3_vandnpd_xmm_xmm_xmm[63:0])))

=====================================
=====================================
Computing circuit for vandnpd %xmm13, %xmm11, %xmm11

.target:
vorpd %xmm2, %xmm3, %xmm12
vmovupd %ymm12, %ymm1
pxor %xmm1, %xmm2
vmovdqa %xmm2, %xmm1
retq 

Initial state:
%ymm11: %ymm11_vandnpd_ymm_ymm_ymm[255:128] ∘ (%ymm2_vandnpd_ymm_ymm_ymm[255:128] ∘ ((%ymm2_vandnpd_ymm_ymm_ymm[127:64] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[127:64] | %ymm2_vandnpd_ymm_ymm_ymm[127:64])) ∘ (%ymm2_vandnpd_ymm_ymm_ymm[63:0] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[63:0] | %ymm2_vandnpd_ymm_ymm_ymm[63:0]))))[255:128]

State for specgen instruction: vandnpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm2_vandnpd_xmm_xmm_xmm[127:64] ⊕ (%ymm2_vandnpd_xmm_xmm_xmm[127:64] | %ymm3_vandnpd_xmm_xmm_xmm[127:64])) ∘ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] ⊕ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] | %ymm3_vandnpd_xmm_xmm_xmm[63:0])))

Final state
%ymm11: 0x0₁₂₈ ∘ ((%ymm2_vandnpd_ymm_ymm_ymm[255:192] ⊕ (%ymm2_vandnpd_ymm_ymm_ymm[255:192] | %ymm3_vandnpd_ymm_ymm_ymm[255:192])) ∘ (%ymm2_vandnpd_ymm_ymm_ymm[191:128] ⊕ (%ymm2_vandnpd_ymm_ymm_ymm[191:128] | %ymm3_vandnpd_ymm_ymm_ymm[191:128])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm3

Final state:
%rax/%rax: %rax_vandnpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vandnpd_ymm_ymm_ymm

%xmm0: %ymm0_vandnpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vandnpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm8_xmm9

Final state:
%rax/%rax: %rax_vorpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vorpd_ymm_ymm_ymm

%xmm0: %ymm0_vorpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vorpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm2, %xmm2

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm2: %ymm2_por_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm2: 0x0₁₂₈ ∘ %ymm2_por_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm1, %xmm2, %xmm3

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm3: %ymm3_por_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_por_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_por_xmm_xmm[255:128] ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for por %xmm2, %xmm8

.target:
vmovapd %xmm2, %xmm2
vorpd %xmm1, %xmm2, %xmm3
movdqa %xmm3, %xmm1
retq 

Initial state:
%xmm8: (%ymm8_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[127:0])[127:0]

State for specgen instruction: por %xmm2, %xmm1:
%xmm1: (%ymm1_por_xmm_xmm[255:128] ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0])))[127:0]

Final state
%xmm8: ((%ymm8_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[127:0])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[127:64] | %ymm2_vorpd_ymm_ymm_ymm[127:64]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[63:0] | %ymm2_vorpd_ymm_ymm_ymm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_256_128_ymm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vorpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vorpd_ymm_ymm_ymm

%xmm0: %ymm0_vorpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vorpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm1, %xmm2, %xmm3

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm3: %ymm3_orps_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ ((%ymm1_orps_xmm_xmm[127:64] | %ymm2_orps_xmm_xmm[127:64]) ∘ (%ymm1_orps_xmm_xmm[63:0] | %ymm2_orps_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm10_xmm11

Final state:
%rax/%rax: %rax_orps_xmm_xmm
%rdx/%rdx: %rdx_orps_xmm_xmm

%xmm0: %ymm0_orps_xmm_xmm[127:0]
%xmm1: %ymm1_orps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_orps_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_orps_xmm_xmm[255:128] ∘ ((%ymm1_orps_xmm_xmm[127:64] | %ymm2_orps_xmm_xmm[127:64]) ∘ (%ymm1_orps_xmm_xmm[63:0] | %ymm2_orps_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for orps %xmm2, %xmm1

.target:
vorpd %xmm1, %xmm2, %xmm3
callq .move_256_128_ymm3_xmm10_xmm11
movdqa %xmm10, %xmm1
retq 

Initial state:
%xmm1: %ymm1_orpd_xmm_xmm[127:0]

State for specgen instruction: orps %xmm2, %xmm1:
%xmm1: (%ymm1_orps_xmm_xmm[255:128] ∘ ((%ymm1_orps_xmm_xmm[127:64] | %ymm2_orps_xmm_xmm[127:64]) ∘ (%ymm1_orps_xmm_xmm[63:0] | %ymm2_orps_xmm_xmm[63:0])))[127:0]

Final state
%xmm1: (%ymm1_orpd_xmm_xmm[255:128] ∘ ((%ymm1_orpd_xmm_xmm[127:64] | %ymm2_orpd_xmm_xmm[127:64]) ∘ (%ymm1_orpd_xmm_xmm[63:0] | %ymm2_orpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for orpd %xmm11, %xmm9

.target:
orps %xmm2, %xmm1
retq 

Initial state:
%xmm9: (%ymm9_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[255:128])[127:0]

State for specgen instruction: orpd %xmm2, %xmm1:
%xmm1: (%ymm1_orpd_xmm_xmm[255:128] ∘ ((%ymm1_orpd_xmm_xmm[127:64] | %ymm2_orpd_xmm_xmm[127:64]) ∘ (%ymm1_orpd_xmm_xmm[63:0] | %ymm2_orpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm9: ((%ymm9_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[255:128])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[255:192] | %ymm2_vorpd_ymm_ymm_ymm[255:192]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[191:128] | %ymm2_vorpd_ymm_ymm_ymm[191:128])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vorpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vorpd_ymm_ymm_ymm

%xmm0: %ymm0_vorpd_ymm_ymm_ymm[127:0]
%xmm1: (((%ymm9_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[255:128])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[255:192] | %ymm2_vorpd_ymm_ymm_ymm[255:192]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[191:128] | %ymm2_vorpd_ymm_ymm_ymm[191:128])))[127:0][127:0] ∘ ((%ymm8_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[127:0])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[127:64] | %ymm2_vorpd_ymm_ymm_ymm[127:64]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[63:0] | %ymm2_vorpd_ymm_ymm_ymm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %ymm3, %ymm14, %ymm1

.target:
callq .move_256_128_ymm3_xmm8_xmm9
por %xmm2, %xmm8
callq .move_256_128_ymm2_xmm10_xmm11
orpd %xmm11, %xmm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm1: %ymm1_vandnpd_ymm_ymm_ymm

State for specgen instruction: vorpd %ymm3, %ymm2, %ymm1:
%ymm1: ((%ymm9_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[255:128])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[255:192] | %ymm2_vorpd_ymm_ymm_ymm[255:192]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[191:128] | %ymm2_vorpd_ymm_ymm_ymm[191:128])))[127:0][127:0] ∘ ((%ymm8_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[127:0])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[127:64] | %ymm2_vorpd_ymm_ymm_ymm[127:64]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[63:0] | %ymm2_vorpd_ymm_ymm_ymm[63:0])))[127:0][127:0]

Final state
%ymm1: (%ymm2_vandnpd_ymm_ymm_ymm[255:192] ⊕ (%ymm2_vandnpd_ymm_ymm_ymm[255:192] | %ymm3_vandnpd_ymm_ymm_ymm[255:192]) | 0x0₆₄) ∘ (%ymm2_vandnpd_ymm_ymm_ymm[191:128] ⊕ (%ymm2_vandnpd_ymm_ymm_ymm[191:128] | %ymm3_vandnpd_ymm_ymm_ymm[191:128]) | 0x0₆₄) ∘ ((%ymm2_vandnpd_ymm_ymm_ymm[127:64] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[127:64] | %ymm2_vandnpd_ymm_ymm_ymm[127:64])) ∘ (%ymm2_vandnpd_ymm_ymm_ymm[63:0] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[63:0] | %ymm2_vandnpd_ymm_ymm_ymm[63:0])))

=====================================
=====================================
Computing circuit for vandnpd %ymm13, %ymm14, %ymm13

.target:
callq .move_256_128_ymm3_xmm12_xmm13
pandn %xmm3, %xmm2
callq .move_256_128_ymm2_xmm10_xmm11
vmovdqa %xmm10, %xmm14
vandnpd %xmm13, %xmm11, %xmm11
callq .move_128_256_xmm10_xmm11_ymm3
vorpd %ymm3, %ymm14, %ymm1
retq 

Initial state:
%ymm13: 0x0₁₂₈ ∘ (%ymm2_punpcklwd_xmm_xmm[63:32] ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32]) ∘ (%ymm2_punpcklwd_xmm_xmm[31:0] ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0])))

State for specgen instruction: vandnpd %ymm3, %ymm2, %ymm1:
%ymm1: (%ymm2_vandnpd_ymm_ymm_ymm[255:192] ⊕ (%ymm2_vandnpd_ymm_ymm_ymm[255:192] | %ymm3_vandnpd_ymm_ymm_ymm[255:192]) | 0x0₆₄) ∘ (%ymm2_vandnpd_ymm_ymm_ymm[191:128] ⊕ (%ymm2_vandnpd_ymm_ymm_ymm[191:128] | %ymm3_vandnpd_ymm_ymm_ymm[191:128]) | 0x0₆₄) ∘ ((%ymm2_vandnpd_ymm_ymm_ymm[127:64] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[127:64] | %ymm2_vandnpd_ymm_ymm_ymm[127:64])) ∘ (%ymm2_vandnpd_ymm_ymm_ymm[63:0] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[63:0] | %ymm2_vandnpd_ymm_ymm_ymm[63:0])))

Final state
%ymm13: 0x0₆₄ ∘ 0x0₆₄ ∘ ((0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32]) ⊕ (%ymm2_punpcklwd_xmm_xmm[63:32] ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32]) | 0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32]))) ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) ⊕ (%ymm2_punpcklwd_xmm_xmm[31:0] ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) | 0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm2, %xmm1, %xmm6

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm6: %ymm6_xorps_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm6: 0x0₁₂₈ ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_xorps_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_xorps_xmm_xmm[255:128] ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for xorps %xmm13, %xmm1

.target:
vxorps %xmm2, %xmm1, %xmm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm1: (%ymm1_punpcklwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[15:0]))))[127:0]

State for specgen instruction: xorps %xmm2, %xmm1:
%xmm1: (%ymm1_xorps_xmm_xmm[255:128] ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0])))[127:0]

Final state
%xmm1: ((%ymm1_punpcklwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[15:0]))))[255:128] ∘ ((0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[47:32]) ⊕ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32]) ⊕ (%ymm2_punpcklwd_xmm_xmm[63:32] ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32]) | 0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32])))) ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[15:0]) ⊕ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) ⊕ (%ymm2_punpcklwd_xmm_xmm[31:0] ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) | 0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0]))))))[127:0]

=====================================
=====================================
Computing circuit for punpcklwd %xmm3, %xmm2

.target:
pmovzxwd %xmm2, %xmm5
pmovzxwd %xmm1, %xmm1
vpbroadcastw %xmm5, %xmm0
vmovsldup %xmm5, %xmm14
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7
vpbroadcastw %xmm5, %ymm3
vpunpckldq %xmm3, %xmm0, %xmm0
vpunpckldq %xmm2, %xmm0, %xmm13
vandnpd %ymm13, %ymm14, %ymm13
xorps %xmm13, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpcklwd_xmm_xmm_xmm[127:0]

State for specgen instruction: punpcklwd %xmm2, %xmm1:
%xmm1: ((%ymm1_punpcklwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[15:0]))))[255:128] ∘ ((0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[47:32]) ⊕ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32]) ⊕ (%ymm2_punpcklwd_xmm_xmm[63:32] ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32]) | 0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32])))) ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[15:0]) ⊕ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) ⊕ (%ymm2_punpcklwd_xmm_xmm[31:0] ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) | 0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0]))))))[127:0]

Final state
%xmm2: (%ymm2_vpunpcklwd_xmm_xmm_xmm[255:128] ∘ ((0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[47:32]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32]) ⊕ (%ymm3_vpunpcklwd_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32])))) ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[15:0]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]) ⊕ (%ymm3_vpunpcklwd_xmm_xmm_xmm[31:0] ∘ (%ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]))))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklwd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklwd_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklwd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklwd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vpunpcklwd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklwd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vpunpcklwd_xmm_xmm_xmm[255:128] ∘ ((0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[47:32]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32]) ⊕ (%ymm3_vpunpcklwd_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32])))) ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[15:0]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]) ⊕ (%ymm3_vpunpcklwd_xmm_xmm_xmm[31:0] ∘ (%ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]))))))[127:0][127:64][63:0] ∘ (%ymm2_vpunpcklwd_xmm_xmm_xmm[255:128] ∘ ((0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[47:32]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32]) ⊕ (%ymm3_vpunpcklwd_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32])))) ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[15:0]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]) ⊕ (%ymm3_vpunpcklwd_xmm_xmm_xmm[31:0] ∘ (%ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]))))))[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklwd %xmm8, %xmm2, %xmm10

.target:
punpcklwd %xmm3, %xmm2
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm10: %ymm10_vpunpcklwd_ymm_ymm_ymm

State for specgen instruction: vpunpcklwd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vpunpcklwd_xmm_xmm_xmm[255:128] ∘ ((0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[47:32]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32]) ⊕ (%ymm3_vpunpcklwd_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32])))) ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[15:0]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]) ⊕ (%ymm3_vpunpcklwd_xmm_xmm_xmm[31:0] ∘ (%ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]))))))[127:0][127:64][63:0] ∘ (%ymm2_vpunpcklwd_xmm_xmm_xmm[255:128] ∘ ((0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[47:32]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32]) ⊕ (%ymm3_vpunpcklwd_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32])))) ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[15:0]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]) ⊕ (%ymm3_vpunpcklwd_xmm_xmm_xmm[31:0] ∘ (%ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]))))))[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ ((0x0₁₆ ∘ %ymm2_vpunpcklwd_ymm_ymm_ymm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_ymm_ymm_ymm[47:32]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[47:32]) ⊕ (%ymm3_vpunpcklwd_ymm_ymm_ymm[63:32] ∘ (%ymm3_vpunpcklwd_ymm_ymm_ymm[47:32] ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[47:32]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[47:32])))) ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_ymm_ymm_ymm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_ymm_ymm_ymm[15:0]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[15:0]) ⊕ (%ymm3_vpunpcklwd_ymm_ymm_ymm[31:0] ∘ (%ymm3_vpunpcklwd_ymm_ymm_ymm[15:0] ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[15:0]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[15:0])))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %ymm10

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm10: %ymm10_pmovzxwd_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm10: %ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0] ∘ (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm3, %xmm8

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm8: %ymm8_vminpd_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm8: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: %ymm0_vmovups_xmm_xmm[127:0]
%xmm1: %ymm1_vmovups_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovups %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminpd_xmm_xmm_xmm

State for specgen instruction: vmovups %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm8, %ymm1, %ymm1

Final state:
%ymm1: (mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[255:192], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[255:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[255:192] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[255:192]) ∘ ((mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[191:128], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[191:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[191:128] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[191:128]) ∘ ((mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[127:64], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[127:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[127:64] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[127:64]) ∘ (mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[63:0], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[63:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[63:0] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vminpd %xmm2, %xmm1, %xmm3

.target:
vmaxps %xmm3, %xmm3, %xmm8
vmovups %xmm2, %xmm1
vminpd %ymm8, %ymm1, %ymm1
retq 

Initial state:
%ymm3: %ymm3_minpd_xmm_xmm

State for specgen instruction: vminpd %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[255:192], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[255:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[255:192] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[255:192]) ∘ ((mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[191:128], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[191:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[191:128] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[191:128]) ∘ ((mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[127:64], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[127:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[127:64] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[127:64]) ∘ (mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[63:0], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[63:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[63:0] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[63:0])))

Final state
%ymm3: 0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm3_xmm8_xmm9

Final state:
%rax/%rax: %rax_minpd_xmm_xmm
%rdx/%rdx: %rdx_minpd_xmm_xmm

%xmm0: %ymm0_minpd_xmm_xmm[127:0]
%xmm1: %ymm1_minpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_minpd_xmm_xmm
%rdx/%rdx: %rdx_minpd_xmm_xmm

%xmm0: %ymm0_minpd_xmm_xmm[127:0]
%xmm1: (%ymm1_minpd_xmm_xmm[255:128] ∘ ((%ymm9_minpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0]))))[127:0][127:64]))[127:0][63:0] ∘ (%ymm8_minpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0]))))[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for minpd %xmm10, %xmm10

.target:
vminpd %xmm2, %xmm1, %xmm3
callq .move_128_64_xmm3_xmm8_xmm9
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0] ∘ (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0]))[127:0]

State for specgen instruction: minpd %xmm2, %xmm1:
%xmm1: (%ymm1_minpd_xmm_xmm[255:128] ∘ ((%ymm9_minpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0]))))[127:0][127:64]))[127:0][63:0] ∘ (%ymm8_minpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0]))))[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0] ∘ (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vpmovzxwd_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwd_xmm_xmm

%xmm0: %ymm0_vpmovzxwd_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: %ymm0_vpmovzxwq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r12d_r13d_rdx

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_edx_r10w_r11w

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxwq %xmm5, %xmm13

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_128_064_xmm2_r10_r11
callq .move_032_064_r12d_r13d_rdx
callq .move_032_016_edx_r10w_r11w
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm13: %ymm13_vpmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0])

Final state
%ymm13: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movddup_xmm_xmm
%rdx/%rdx: %rdx_movddup_xmm_xmm

%xmm0: %ymm0_movddup_xmm_xmm[127:0]
%xmm1: %ymm1_movddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r12, %r13

Final state:
%r13/%r13: %ymm2_movddup_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movddup_xmm_xmm
%rdx/%rdx: %rdx_movddup_xmm_xmm

%xmm0: %ymm0_movddup_xmm_xmm[127:0]
%xmm1: (%ymm1_movddup_xmm_xmm[255:128] ∘ (%ymm2_movddup_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_movddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movddup %xmm4, %xmm4

.target:
callq .move_128_064_xmm2_r12_r13
movq %r12, %r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm4: (%ymm4_vpmovzxwd_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[127:0][31:0]))[127:0]

State for specgen instruction: movddup %xmm2, %xmm1:
%xmm1: (%ymm1_movddup_xmm_xmm[255:128] ∘ (%ymm2_movddup_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_movddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm4: ((%ymm4_vpmovzxwd_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[127:0][31:0]))[255:128] ∘ (0x0₃₂ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:0] ∘ (0x0₃₂ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm3

Final state:
%rax/%rax: %rax_vpmovzxwd_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwd_xmm_xmm

%xmm0: %ymm0_vpmovzxwd_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: %ymm0_vpmovzxwq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r12d_r13d_rdx

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_edx_r10w_r11w

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxwq %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_128_064_xmm2_r10_r11
callq .move_032_064_r12d_r13d_rdx
callq .move_032_016_edx_r10w_r11w
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm3, %ymm6

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm6: %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm3, %xmm6, %xmm9

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm3, %xmm2, %xmm14

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm14: %ymm14_vpor_xmm_xmm_xmm

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpor_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vpor %xmm9, %xmm9, %xmm7

.target:
vorps %xmm3, %xmm2, %xmm14
vmovapd %xmm14, %xmm1
retq 

Initial state:
%ymm7: %ymm7_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpor %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

Final state
%ymm7: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm7, %xmm2

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpckldq_xmm_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm2: (%ymm2_vpunpckldq_xmm_xmm_xmm[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm1, %xmm3

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm3: %ymm3_mulpd_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm8: %ymm8_mulpd_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmulpd %ymm8, %ymm3, %ymm6

Final state:
%ymm6: mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[255:192]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[191:128]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[127:64]) ∘ mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_mulpd_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for mulpd %xmm3, %xmm2

.target:
vmovapd %xmm1, %xmm3
vmovaps %xmm2, %xmm8
vmulpd %ymm8, %ymm3, %ymm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vmulpd_xmm_xmm_xmm[127:0]

State for specgen instruction: mulpd %xmm2, %xmm1:
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vmulpd_xmm_xmm_xmm[255:128] ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmulpd_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmulpd %xmm6, %xmm2, %xmm12

.target:
mulpd %xmm3, %xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm12: %ymm12_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vmulpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]) ∘ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm12, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vpunpckldq %xmm2, %xmm1, %xmm8

.target:
vpbroadcastq %xmm3, %ymm6
vunpcklpd %xmm3, %xmm6, %xmm9
vpor %xmm9, %xmm9, %xmm7
unpcklps %xmm7, %xmm2
vmulpd %xmm6, %xmm2, %xmm12
vxorps %xmm12, %xmm2, %xmm1
movdqu %xmm2, %xmm1
retq 

Initial state:
%ymm8: %ymm8_hsubps_xmm_xmm

State for specgen instruction: vpunpckldq %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0]))

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm2

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm2: %ymm2_vunpckhps_xmm_xmm_xmm[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm2: (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpckhps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm9, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vunpckhps_xmm_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: %ymm0_vmovq_xmm_xmm[127:0]
%xmm1: %ymm1_vmovq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movswq %bx, %r10

Final state:
%r10/%r10: sign-extend-64(%rbx_xchgl_r32_r32[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_xchgl_r32_r32[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ecx_r8w_r9w

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %rcx

Final state:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r8w_r9w_ebx

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xchgl %ebx, %ecx

.target:
movswq %bx, %r10
movslq %ebx, %rbx
callq .move_032_016_ecx_r8w_r9w
callq .move_064_032_rbx_r10d_r11d
movq %r10, %rcx
callq .move_016_032_r8w_r9w_ebx
retq 

Initial state:
%rcx/%rcx: %rcx_xorl_r32_r32
%rbx/%rbx: %rbx_xorl_r32_r32

State for specgen instruction: xchgl %ecx, %ebx:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
%rbx/%rbx: 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])

Register        -> %rcx
  translates to => %rbx
Value is               -> 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
  after renaming it is => 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

Register        -> %rbx
  translates to => %rcx
Value is               -> 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])
  after renaming it is => 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

Final state
%rcx/%rcx: 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]) = 0x0₆₄
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_ebx

Final state:
%rax/%rax: %rax_xorl_r32_r32
%rdx/%rdx: %rdx_xorl_r32_r32

%xmm0: %ymm0_xorl_r32_r32[127:0]
%xmm1: %ymm1_xorl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xorl %r13d, %r13d

.target:
xchgl %ebx, %ecx
xorq %rcx, %rbx
callq .set_szp_for_ebx
retq 

Initial state:
%r13/%r13: %ymm2_vmovq_xmm_xmm[127:0][127:64]

%cf: %cf_vmovq_xmm_xmm
%pf: %pf_vmovq_xmm_xmm
%zf: %zf_vmovq_xmm_xmm
%sf: %sf_vmovq_xmm_xmm
%of: %of_vmovq_xmm_xmm

State for specgen instruction: xorl %ecx, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0] = 0x0₃₂
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][31:31] = 0x1₁
%of: false

Register        -> %rbx
  translates to => %r13
Value is               -> 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
  after renaming it is => 0x0₆₄

Final state
%r13/%r13: 0x0₆₄

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
xorl %r13d, %r13d
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][95:64])

State for specgen instruction: vmovq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhps %xmm2, %xmm1, %xmm10

.target:
unpckhpd %xmm3, %xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovddup %xmm9, %xmm1
vmovq %xmm1, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm10: %ymm10_hsubps_xmm_xmm

State for specgen instruction: vunpckhps %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[127:96] ∘ %ymm1_hsubps_xmm_xmm[127:96] ∘ %ymm2_hsubps_xmm_xmm[95:64] ∘ %ymm1_hsubps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm3, %ymm6

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm6: %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm3, %xmm6, %xmm9

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm3, %xmm2, %xmm14

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm14: %ymm14_vpor_xmm_xmm_xmm

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpor_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vpor %xmm9, %xmm9, %xmm7

.target:
vorps %xmm3, %xmm2, %xmm14
vmovapd %xmm14, %xmm1
retq 

Initial state:
%ymm7: %ymm7_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpor %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

Final state
%ymm7: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm7, %xmm2

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpckldq_xmm_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm2: (%ymm2_vpunpckldq_xmm_xmm_xmm[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm1, %xmm3

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm3: %ymm3_mulpd_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm8: %ymm8_mulpd_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmulpd %ymm8, %ymm3, %ymm6

Final state:
%ymm6: mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[255:192]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[191:128]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[127:64]) ∘ mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_mulpd_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for mulpd %xmm3, %xmm2

.target:
vmovapd %xmm1, %xmm3
vmovaps %xmm2, %xmm8
vmulpd %ymm8, %ymm3, %ymm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vmulpd_xmm_xmm_xmm[127:0]

State for specgen instruction: mulpd %xmm2, %xmm1:
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vmulpd_xmm_xmm_xmm[255:128] ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmulpd_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmulpd %xmm6, %xmm2, %xmm12

.target:
mulpd %xmm3, %xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm12: %ymm12_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vmulpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]) ∘ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm12, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vpunpckldq %xmm10, %xmm8, %xmm15

.target:
vpbroadcastq %xmm3, %ymm6
vunpcklpd %xmm3, %xmm6, %xmm9
vpor %xmm9, %xmm9, %xmm7
unpcklps %xmm7, %xmm2
vmulpd %xmm6, %xmm2, %xmm12
vxorps %xmm12, %xmm2, %xmm1
movdqu %xmm2, %xmm1
retq 

Initial state:
%ymm15: %ymm15_hsubps_xmm_xmm

State for specgen instruction: vpunpckldq %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0]))

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[95:64] ∘ %ymm2_hsubps_xmm_xmm[31:0] ∘ (%ymm1_hsubps_xmm_xmm[95:64] ∘ %ymm1_hsubps_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm2

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm2: %ymm2_vunpckhps_xmm_xmm_xmm[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm2: (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpckhps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm9, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vunpckhps_xmm_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: %ymm0_vmovq_xmm_xmm[127:0]
%xmm1: %ymm1_vmovq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movswq %bx, %r10

Final state:
%r10/%r10: sign-extend-64(%rbx_xchgl_r32_r32[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_xchgl_r32_r32[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ecx_r8w_r9w

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %rcx

Final state:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r8w_r9w_ebx

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xchgl %ebx, %ecx

.target:
movswq %bx, %r10
movslq %ebx, %rbx
callq .move_032_016_ecx_r8w_r9w
callq .move_064_032_rbx_r10d_r11d
movq %r10, %rcx
callq .move_016_032_r8w_r9w_ebx
retq 

Initial state:
%rcx/%rcx: %rcx_xorl_r32_r32
%rbx/%rbx: %rbx_xorl_r32_r32

State for specgen instruction: xchgl %ecx, %ebx:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
%rbx/%rbx: 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])

Register        -> %rcx
  translates to => %rbx
Value is               -> 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
  after renaming it is => 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

Register        -> %rbx
  translates to => %rcx
Value is               -> 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])
  after renaming it is => 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

Final state
%rcx/%rcx: 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]) = 0x0₆₄
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_ebx

Final state:
%rax/%rax: %rax_xorl_r32_r32
%rdx/%rdx: %rdx_xorl_r32_r32

%xmm0: %ymm0_xorl_r32_r32[127:0]
%xmm1: %ymm1_xorl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xorl %r13d, %r13d

.target:
xchgl %ebx, %ecx
xorq %rcx, %rbx
callq .set_szp_for_ebx
retq 

Initial state:
%r13/%r13: %ymm2_vmovq_xmm_xmm[127:0][127:64]

%cf: %cf_vmovq_xmm_xmm
%pf: %pf_vmovq_xmm_xmm
%zf: %zf_vmovq_xmm_xmm
%sf: %sf_vmovq_xmm_xmm
%of: %of_vmovq_xmm_xmm

State for specgen instruction: xorl %ecx, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0] = 0x0₃₂
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][31:31] = 0x1₁
%of: false

Register        -> %rbx
  translates to => %r13
Value is               -> 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
  after renaming it is => 0x0₆₄

Final state
%r13/%r13: 0x0₆₄

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
xorl %r13d, %r13d
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][95:64])

State for specgen instruction: vmovq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhps %xmm2, %xmm1, %xmm8

.target:
unpckhpd %xmm3, %xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovddup %xmm9, %xmm1
vmovq %xmm1, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_punpckhdq_xmm_xmm

State for specgen instruction: vunpckhps %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ %ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm8, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_punpckhdq_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_punpckhdq_xmm_xmm[255:128] ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ (%ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])))[127:0]

=====================================
=====================================
Computing circuit for punpckhdq %xmm10, %xmm8

.target:
vunpckhps %xmm2, %xmm1, %xmm8
movdqu %xmm8, %xmm1
retq 

Initial state:
%xmm8: (0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0])))[127:0]

State for specgen instruction: punpckhdq %xmm2, %xmm1:
%xmm1: (%ymm1_punpckhdq_xmm_xmm[255:128] ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ (%ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])))[127:0]

Final state
%xmm8: ((0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0])))[255:128] ∘ (%ymm2_hsubps_xmm_xmm[127:96] ∘ %ymm2_hsubps_xmm_xmm[63:32] ∘ (%ymm1_hsubps_xmm_xmm[127:96] ∘ %ymm1_hsubps_xmm_xmm[63:32])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm14

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm14: %ymm14_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm14: 0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminps %ymm1, %ymm14, %ymm1

Final state:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vminps %xmm2, %xmm2, %xmm5

.target:
vmovdqa %xmm3, %xmm1
vmovdqu %xmm2, %xmm14
vminps %ymm1, %ymm14, %ymm1
retq 

Initial state:
%ymm5: %ymm5_vsubps_xmm_xmm_xmm

State for specgen instruction: vminps %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm5: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_subps_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm14

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm14: %ymm14_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm14: 0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminps %ymm1, %ymm14, %ymm1

Final state:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vminps %xmm1, %xmm1, %xmm4

.target:
vmovdqa %xmm3, %xmm1
vmovdqu %xmm2, %xmm14
vminps %ymm1, %ymm14, %ymm1
retq 

Initial state:
%ymm4: %ymm4_subps_xmm_xmm

State for specgen instruction: vminps %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm4: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for vsubps %ymm10, %ymm4, %ymm2

Final state:
%ymm2: sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[255:224], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[255:224]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[223:192], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[223:192]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[191:160], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[191:160]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[159:128], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[159:128]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[127:96], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[127:96]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[95:64], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[95:64]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[63:32], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[63:32]) ∘ sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[31:0], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_subps_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_subps_xmm_xmm[255:128] ∘ (sub_single(%ymm1_subps_xmm_xmm[127:96], %ymm2_subps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_subps_xmm_xmm[95:64], %ymm2_subps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_subps_xmm_xmm[63:32], %ymm2_subps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_subps_xmm_xmm[31:0], %ymm2_subps_xmm_xmm[31:0])))))[127:0]

=====================================
=====================================
Computing circuit for subps %xmm3, %xmm5

.target:
vmovaps %xmm2, %xmm10
vminps %xmm1, %xmm1, %xmm4
vsubps %ymm10, %ymm4, %ymm2
movdqu %xmm2, %xmm1
retq 

Initial state:
%xmm5: (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0]))))[127:0]

State for specgen instruction: subps %xmm2, %xmm1:
%xmm1: (%ymm1_subps_xmm_xmm[255:128] ∘ (sub_single(%ymm1_subps_xmm_xmm[127:96], %ymm2_subps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_subps_xmm_xmm[95:64], %ymm2_subps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_subps_xmm_xmm[63:32], %ymm2_subps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_subps_xmm_xmm[31:0], %ymm2_subps_xmm_xmm[31:0])))))[127:0]

Final state
%xmm5: ((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0]))))[255:128] ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0])))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm5, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vsubps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0]))))

=====================================
=====================================
Computing circuit for vsubps %xmm8, %xmm15, %xmm4

.target:
vminps %xmm2, %xmm2, %xmm5
subps %xmm3, %xmm5
vmovdqu %xmm5, %xmm1
retq 

Initial state:
%ymm4: %ymm4_hsubps_xmm_xmm

State for specgen instruction: vsubps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0]))))

Final state
%ymm4: 0x0₁₂₈ ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm4, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_hsubps_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_hsubps_xmm_xmm[255:128] ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))[127:0]

=====================================
=====================================
Computing circuit for hsubps %xmm3, %xmm2

.target:
vpunpckldq %xmm2, %xmm1, %xmm8
vunpckhps %xmm2, %xmm1, %xmm10
vpunpckldq %xmm10, %xmm8, %xmm15
punpckhdq %xmm10, %xmm8
vsubps %xmm8, %xmm15, %xmm4
movdqu %xmm4, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vhsubps_xmm_xmm_xmm[127:0]

State for specgen instruction: hsubps %xmm2, %xmm1:
%xmm1: (%ymm1_hsubps_xmm_xmm[255:128] ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))[127:0]

Final state
%xmm2: (%ymm2_vhsubps_xmm_xmm_xmm[255:128] ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vhsubps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vhsubps_xmm_xmm_xmm

%xmm0: %ymm0_vhsubps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vhsubps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vhsubps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vhsubps_xmm_xmm_xmm

%xmm0: %ymm0_vhsubps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vhsubps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vhsubps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32])))

=====================================
=====================================
Computing circuit for vhsubps %xmm13, %xmm1, %xmm1

.target:
hsubps %xmm3, %xmm2
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm1: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0]))

State for specgen instruction: vhsubps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32])))

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0])))

=====================================
=====================================
Computing circuit for vpmovzxwd %xmm10, %xmm14

.target:
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7
vpmovzxwq %xmm5, %xmm13
movddup %xmm4, %xmm4
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm3
vpmovzxwq %xmm3, %xmm1
vhsubps %xmm13, %xmm1, %xmm1
retq 

Initial state:
%ymm14: %ymm14_pmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwd %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0])))

Final state
%ymm14: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[15:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_pmovzxwd_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_pmovzxwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[15:0]))))[127:0]

=====================================
=====================================
Computing circuit for pmovzxwd %xmm2, %xmm5

.target:
vpbroadcastq %xmm2, %ymm10
minpd %xmm10, %xmm10
vpmovzxwd %xmm10, %xmm14
movapd %xmm14, %xmm1
retq 

Initial state:
%xmm5: %ymm5_punpcklwd_xmm_xmm[127:0]

State for specgen instruction: pmovzxwd %xmm2, %xmm1:
%xmm1: (%ymm1_pmovzxwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[15:0]))))[127:0]

Final state
%xmm5: (%ymm5_punpcklwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %ymm10

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm10: %ymm10_pmovzxwd_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm10: %ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0] ∘ (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm3, %xmm8

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm8: %ymm8_vminpd_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm8: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: %ymm0_vmovups_xmm_xmm[127:0]
%xmm1: %ymm1_vmovups_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovups_xmm_xmm
%rdx/%rdx: %rdx_vmovups_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovups %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminpd_xmm_xmm_xmm

State for specgen instruction: vmovups %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovups_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovups_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm8, %ymm1, %ymm1

Final state:
%ymm1: (mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[255:192], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[255:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[255:192] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[255:192]) ∘ ((mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[191:128], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[191:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[191:128] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[191:128]) ∘ ((mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[127:64], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[127:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[127:64] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[127:64]) ∘ (mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[63:0], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[63:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[63:0] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vminpd %xmm2, %xmm1, %xmm3

.target:
vmaxps %xmm3, %xmm3, %xmm8
vmovups %xmm2, %xmm1
vminpd %ymm8, %ymm1, %ymm1
retq 

Initial state:
%ymm3: %ymm3_minpd_xmm_xmm

State for specgen instruction: vminpd %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[255:192], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[255:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[255:192] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[255:192]) ∘ ((mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[191:128], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[191:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[191:128] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[191:128]) ∘ ((mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[127:64], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[127:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[127:64] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[127:64]) ∘ (mincmp_double((0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[63:0], (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[63:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminpd_xmm_xmm_xmm[127:0])[63:0] : (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm3_vminpd_xmm_xmm_xmm[127:0]))))[63:0])))

Final state
%ymm3: 0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm3_xmm8_xmm9

Final state:
%rax/%rax: %rax_minpd_xmm_xmm
%rdx/%rdx: %rdx_minpd_xmm_xmm

%xmm0: %ymm0_minpd_xmm_xmm[127:0]
%xmm1: %ymm1_minpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_minpd_xmm_xmm
%rdx/%rdx: %rdx_minpd_xmm_xmm

%xmm0: %ymm0_minpd_xmm_xmm[127:0]
%xmm1: (%ymm1_minpd_xmm_xmm[255:128] ∘ ((%ymm9_minpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0]))))[127:0][127:64]))[127:0][63:0] ∘ (%ymm8_minpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0]))))[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for minpd %xmm10, %xmm10

.target:
vminpd %xmm2, %xmm1, %xmm3
callq .move_128_64_xmm3_xmm8_xmm9
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0] ∘ (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0]))[127:0]

State for specgen instruction: minpd %xmm2, %xmm1:
%xmm1: (%ymm1_minpd_xmm_xmm[255:128] ∘ ((%ymm9_minpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0]))))[127:0][127:64]))[127:0][63:0] ∘ (%ymm8_minpd_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ ((mincmp_double(%ymm1_minpd_xmm_xmm[127:64], %ymm2_minpd_xmm_xmm[127:64]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[127:64] : %ymm2_minpd_xmm_xmm[127:64]) ∘ (mincmp_double(%ymm1_minpd_xmm_xmm[63:0], %ymm2_minpd_xmm_xmm[63:0]) = 0x1₁ ? %ymm1_minpd_xmm_xmm[63:0] : %ymm2_minpd_xmm_xmm[63:0]))))[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0] ∘ (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_pmovzxwd_xmm_xmm[63:0] ∘ %ymm2_pmovzxwd_xmm_xmm[63:0]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vpmovzxwd_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwd_xmm_xmm

%xmm0: %ymm0_vpmovzxwd_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: %ymm0_vpmovzxwq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r12d_r13d_rdx

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_edx_r10w_r11w

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxwq %xmm5, %xmm13

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_128_064_xmm2_r10_r11
callq .move_032_064_r12d_r13d_rdx
callq .move_032_016_edx_r10w_r11w
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm13: %ymm13_vpmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0])

Final state
%ymm13: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movddup_xmm_xmm
%rdx/%rdx: %rdx_movddup_xmm_xmm

%xmm0: %ymm0_movddup_xmm_xmm[127:0]
%xmm1: %ymm1_movddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r12, %r13

Final state:
%r13/%r13: %ymm2_movddup_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movddup_xmm_xmm
%rdx/%rdx: %rdx_movddup_xmm_xmm

%xmm0: %ymm0_movddup_xmm_xmm[127:0]
%xmm1: (%ymm1_movddup_xmm_xmm[255:128] ∘ (%ymm2_movddup_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_movddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movddup %xmm4, %xmm4

.target:
callq .move_128_064_xmm2_r12_r13
movq %r12, %r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm4: (%ymm4_vpmovzxwd_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[127:0][31:0]))[127:0]

State for specgen instruction: movddup %xmm2, %xmm1:
%xmm1: (%ymm1_movddup_xmm_xmm[255:128] ∘ (%ymm2_movddup_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_movddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm4: ((%ymm4_vpmovzxwd_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[127:0][31:0]))[255:128] ∘ (0x0₃₂ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:0] ∘ (0x0₃₂ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm3

Final state:
%rax/%rax: %rax_vpmovzxwd_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwd_xmm_xmm

%xmm0: %ymm0_vpmovzxwd_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: %ymm0_vpmovzxwq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxwq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxwq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r12d_r13d_rdx

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_edx_r10w_r11w

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpmovzxwq_xmm_xmm
%rdx/%rdx: %ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0]

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxwq %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_128_064_xmm2_r10_r11
callq .move_032_064_r12d_r13d_rdx
callq .move_032_016_edx_r10w_r11w
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[127:0][127:64][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][31:16])[63:0] ∘ (0x0₂₅₆[127:0][63:0][63:16] ∘ (%ymm2_vpmovzxwq_xmm_xmm[127:0][127:64][31:0][31:0] ∘ %ymm2_vpmovzxwq_xmm_xmm[127:0][63:0][31:0][31:0])[31:0][15:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm3, %ymm6

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm6: %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm3, %xmm6, %xmm9

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm3, %xmm2, %xmm14

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm14: %ymm14_vpor_xmm_xmm_xmm

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpor_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vpor %xmm9, %xmm9, %xmm7

.target:
vorps %xmm3, %xmm2, %xmm14
vmovapd %xmm14, %xmm1
retq 

Initial state:
%ymm7: %ymm7_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpor %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

Final state
%ymm7: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm7, %xmm2

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpckldq_xmm_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm2: (%ymm2_vpunpckldq_xmm_xmm_xmm[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm1, %xmm3

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm3: %ymm3_mulpd_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm8: %ymm8_mulpd_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmulpd %ymm8, %ymm3, %ymm6

Final state:
%ymm6: mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[255:192]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[191:128]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[127:64]) ∘ mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_mulpd_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for mulpd %xmm3, %xmm2

.target:
vmovapd %xmm1, %xmm3
vmovaps %xmm2, %xmm8
vmulpd %ymm8, %ymm3, %ymm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vmulpd_xmm_xmm_xmm[127:0]

State for specgen instruction: mulpd %xmm2, %xmm1:
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vmulpd_xmm_xmm_xmm[255:128] ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmulpd_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmulpd %xmm6, %xmm2, %xmm12

.target:
mulpd %xmm3, %xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm12: %ymm12_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vmulpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]) ∘ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm12, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vpunpckldq %xmm2, %xmm1, %xmm8

.target:
vpbroadcastq %xmm3, %ymm6
vunpcklpd %xmm3, %xmm6, %xmm9
vpor %xmm9, %xmm9, %xmm7
unpcklps %xmm7, %xmm2
vmulpd %xmm6, %xmm2, %xmm12
vxorps %xmm12, %xmm2, %xmm1
movdqu %xmm2, %xmm1
retq 

Initial state:
%ymm8: %ymm8_hsubps_xmm_xmm

State for specgen instruction: vpunpckldq %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0]))

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm2

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm2: %ymm2_vunpckhps_xmm_xmm_xmm[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm2: (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpckhps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm9, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vunpckhps_xmm_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: %ymm0_vmovq_xmm_xmm[127:0]
%xmm1: %ymm1_vmovq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movswq %bx, %r10

Final state:
%r10/%r10: sign-extend-64(%rbx_xchgl_r32_r32[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_xchgl_r32_r32[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ecx_r8w_r9w

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %rcx

Final state:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r8w_r9w_ebx

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xchgl %ebx, %ecx

.target:
movswq %bx, %r10
movslq %ebx, %rbx
callq .move_032_016_ecx_r8w_r9w
callq .move_064_032_rbx_r10d_r11d
movq %r10, %rcx
callq .move_016_032_r8w_r9w_ebx
retq 

Initial state:
%rcx/%rcx: %rcx_xorl_r32_r32
%rbx/%rbx: %rbx_xorl_r32_r32

State for specgen instruction: xchgl %ecx, %ebx:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
%rbx/%rbx: 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])

Register        -> %rcx
  translates to => %rbx
Value is               -> 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
  after renaming it is => 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

Register        -> %rbx
  translates to => %rcx
Value is               -> 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])
  after renaming it is => 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

Final state
%rcx/%rcx: 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]) = 0x0₆₄
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_ebx

Final state:
%rax/%rax: %rax_xorl_r32_r32
%rdx/%rdx: %rdx_xorl_r32_r32

%xmm0: %ymm0_xorl_r32_r32[127:0]
%xmm1: %ymm1_xorl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xorl %r13d, %r13d

.target:
xchgl %ebx, %ecx
xorq %rcx, %rbx
callq .set_szp_for_ebx
retq 

Initial state:
%r13/%r13: %ymm2_vmovq_xmm_xmm[127:0][127:64]

%cf: %cf_vmovq_xmm_xmm
%pf: %pf_vmovq_xmm_xmm
%zf: %zf_vmovq_xmm_xmm
%sf: %sf_vmovq_xmm_xmm
%of: %of_vmovq_xmm_xmm

State for specgen instruction: xorl %ecx, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0] = 0x0₃₂
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][31:31] = 0x1₁
%of: false

Register        -> %rbx
  translates to => %r13
Value is               -> 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
  after renaming it is => 0x0₆₄

Final state
%r13/%r13: 0x0₆₄

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
xorl %r13d, %r13d
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][95:64])

State for specgen instruction: vmovq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhps %xmm2, %xmm1, %xmm10

.target:
unpckhpd %xmm3, %xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovddup %xmm9, %xmm1
vmovq %xmm1, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm10: %ymm10_hsubps_xmm_xmm

State for specgen instruction: vunpckhps %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[127:96] ∘ %ymm1_hsubps_xmm_xmm[127:96] ∘ %ymm2_hsubps_xmm_xmm[95:64] ∘ %ymm1_hsubps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm3, %ymm6

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm6: %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm3, %xmm6, %xmm9

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm3, %xmm2, %xmm14

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm14: %ymm14_vpor_xmm_xmm_xmm

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpor_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vpor %xmm9, %xmm9, %xmm7

.target:
vorps %xmm3, %xmm2, %xmm14
vmovapd %xmm14, %xmm1
retq 

Initial state:
%ymm7: %ymm7_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpor %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

Final state
%ymm7: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm7, %xmm2

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpckldq_xmm_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm2: (%ymm2_vpunpckldq_xmm_xmm_xmm[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm1, %xmm3

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm3: %ymm3_mulpd_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm8: %ymm8_mulpd_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmulpd %ymm8, %ymm3, %ymm6

Final state:
%ymm6: mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[255:192]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[191:128]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[127:64]) ∘ mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_mulpd_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for mulpd %xmm3, %xmm2

.target:
vmovapd %xmm1, %xmm3
vmovaps %xmm2, %xmm8
vmulpd %ymm8, %ymm3, %ymm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vmulpd_xmm_xmm_xmm[127:0]

State for specgen instruction: mulpd %xmm2, %xmm1:
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vmulpd_xmm_xmm_xmm[255:128] ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmulpd_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmulpd %xmm6, %xmm2, %xmm12

.target:
mulpd %xmm3, %xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm12: %ymm12_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vmulpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]) ∘ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm12, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vpunpckldq %xmm10, %xmm8, %xmm15

.target:
vpbroadcastq %xmm3, %ymm6
vunpcklpd %xmm3, %xmm6, %xmm9
vpor %xmm9, %xmm9, %xmm7
unpcklps %xmm7, %xmm2
vmulpd %xmm6, %xmm2, %xmm12
vxorps %xmm12, %xmm2, %xmm1
movdqu %xmm2, %xmm1
retq 

Initial state:
%ymm15: %ymm15_hsubps_xmm_xmm

State for specgen instruction: vpunpckldq %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0]))

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[95:64] ∘ %ymm2_hsubps_xmm_xmm[31:0] ∘ (%ymm1_hsubps_xmm_xmm[95:64] ∘ %ymm1_hsubps_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhpd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm13, %r12

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r12/%r12: %ymm2_unpckhpd_xmm_xmm[127:0][63:0]

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r12
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm1_unpckhpd_xmm_xmm[127:64]

Final state
%r12/%r12: %ymm1_unpckhpd_xmm_xmm[127:64]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_unpckhpd_xmm_xmm
%rdx/%rdx: %rdx_unpckhpd_xmm_xmm

%xmm0: %ymm0_unpckhpd_xmm_xmm[127:0]
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhpd %xmm3, %xmm2

.target:
callq .move_128_64_xmm1_xmm12_xmm13
callq .move_128_064_xmm2_r12_r13
movq %xmm13, %r12
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm2: %ymm2_vunpckhps_xmm_xmm_xmm[127:0]

State for specgen instruction: unpckhpd %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhpd_xmm_xmm[255:128] ∘ (%ymm2_unpckhpd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm1_unpckhpd_xmm_xmm[127:64][63:0]))[127:0]

Final state
%xmm2: (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpckhps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm9, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm1: %ymm1_vunpckhps_xmm_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: %ymm0_vmovq_xmm_xmm[127:0]
%xmm1: %ymm1_vmovq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movswq %bx, %r10

Final state:
%r10/%r10: sign-extend-64(%rbx_xchgl_r32_r32[15:0])

-------------------------------------
-------------------------------------
Getting base circuit for movslq %ebx, %rbx

Final state:
%rbx/%rbx: sign-extend-64(%rbx_xchgl_r32_r32[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ecx_r8w_r9w

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %rcx

Final state:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r8w_r9w_ebx

Final state:
%rax/%rax: %rax_xchgl_r32_r32
%rdx/%rdx: %rdx_xchgl_r32_r32

%xmm0: %ymm0_xchgl_r32_r32[127:0]
%xmm1: %ymm1_xchgl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xchgl %ebx, %ecx

.target:
movswq %bx, %r10
movslq %ebx, %rbx
callq .move_032_016_ecx_r8w_r9w
callq .move_064_032_rbx_r10d_r11d
movq %r10, %rcx
callq .move_016_032_r8w_r9w_ebx
retq 

Initial state:
%rcx/%rcx: %rcx_xorl_r32_r32
%rbx/%rbx: %rbx_xorl_r32_r32

State for specgen instruction: xchgl %ecx, %ebx:
%rcx/%rcx: 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
%rbx/%rbx: 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])

Register        -> %rcx
  translates to => %rbx
Value is               -> 0x0₃₂ ∘ sign-extend-64(%rbx_xchgl_r32_r32[31:0])[31:0]
  after renaming it is => 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

Register        -> %rbx
  translates to => %rcx
Value is               -> 0x0₃₂ ∘ ((%r9_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][31:16])[15:0][15:0] ∘ (%r8_xchgl_r32_r32[63:16] ∘ %rcx_xchgl_r32_r32[31:0][15:0])[15:0][15:0])
  after renaming it is => 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

Final state
%rcx/%rcx: 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rcx, %rbx

Final state:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]) = 0x0₆₄
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_ebx

Final state:
%rax/%rax: %rax_xorl_r32_r32
%rdx/%rdx: %rdx_xorl_r32_r32

%xmm0: %ymm0_xorl_r32_r32[127:0]
%xmm1: %ymm1_xorl_r32_r32[127:0]

-------------------------------------
=====================================
Computing circuit for xorl %r13d, %r13d

.target:
xchgl %ebx, %ecx
xorq %rcx, %rbx
callq .set_szp_for_ebx
retq 

Initial state:
%r13/%r13: %ymm2_vmovq_xmm_xmm[127:0][127:64]

%cf: %cf_vmovq_xmm_xmm
%pf: %pf_vmovq_xmm_xmm
%zf: %zf_vmovq_xmm_xmm
%sf: %sf_vmovq_xmm_xmm
%of: %of_vmovq_xmm_xmm

State for specgen instruction: xorl %ecx, %ebx:
%rbx/%rbx: 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]

%cf: false
%pf: !((0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][0:0] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][1:1] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][2:2] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][3:3] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][4:4] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][5:5] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][6:6] = 0x1₁ ⊕ (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][7:0][7:7] = 0x1₁)
%zf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0] = 0x0₃₂
%sf: (0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0])[31:0][31:31] = 0x1₁
%of: false

Register        -> %rbx
  translates to => %r13
Value is               -> 0x0₃₂ ∘ %rcx_xorl_r32_r32[31:0] ⊕ 0x0₃₂ ∘ %rbx_xorl_r32_r32[31:0]
  after renaming it is => 0x0₆₄

Final state
%r13/%r13: 0x0₆₄

%cf: false
%pf: true
%zf: true
%sf: false
%of: false

=====================================
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovq_xmm_xmm
%rdx/%rdx: %rdx_vmovq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
xorl %r13d, %r13d
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][95:64])

State for specgen instruction: vmovq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (0x0₆₄[63:0] ∘ %ymm2_vmovq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm8_xmm9

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vunpckhps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpckhps_xmm_xmm_xmm

%xmm0: %ymm0_vunpckhps_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpckhps %xmm2, %xmm1, %xmm8

.target:
unpckhpd %xmm3, %xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovddup %xmm9, %xmm1
vmovq %xmm1, %xmm10
callq .move_128_64_xmm2_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_punpckhdq_xmm_xmm

State for specgen instruction: vunpckhps %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96] ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[255:128] ∘ ((%ymm11_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:96]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ (0x0₃₂ ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:96])))[127:0][31:0] ∘ ((%ymm9_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:32]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][127:64]))[127:0][31:0] ∘ ((%ymm8_vunpckhps_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][31:0]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_vunpckhps_xmm_xmm_xmm[255:128] ∘ (%ymm3_vunpckhps_xmm_xmm_xmm[127:64] ∘ %ymm2_vunpckhps_xmm_xmm_xmm[127:64]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ %ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm8, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_punpckhdq_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_punpckhdq_xmm_xmm[255:128] ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ (%ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])))[127:0]

=====================================
=====================================
Computing circuit for punpckhdq %xmm10, %xmm8

.target:
vunpckhps %xmm2, %xmm1, %xmm8
movdqu %xmm8, %xmm1
retq 

Initial state:
%xmm8: (0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0])))[127:0]

State for specgen instruction: punpckhdq %xmm2, %xmm1:
%xmm1: (%ymm1_punpckhdq_xmm_xmm[255:128] ∘ (%ymm2_punpckhdq_xmm_xmm[127:96] ∘ %ymm1_punpckhdq_xmm_xmm[127:96] ∘ (%ymm2_punpckhdq_xmm_xmm[95:64] ∘ %ymm1_punpckhdq_xmm_xmm[95:64])))[127:0]

Final state
%xmm8: ((0x0₁₂₈ ∘ (%ymm2_hsubps_xmm_xmm[63:32] ∘ %ymm1_hsubps_xmm_xmm[63:32] ∘ (%ymm2_hsubps_xmm_xmm[31:0] ∘ %ymm1_hsubps_xmm_xmm[31:0])))[255:128] ∘ (%ymm2_hsubps_xmm_xmm[127:96] ∘ %ymm2_hsubps_xmm_xmm[63:32] ∘ (%ymm1_hsubps_xmm_xmm[127:96] ∘ %ymm1_hsubps_xmm_xmm[63:32])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm14

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm14: %ymm14_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm14: 0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminps %ymm1, %ymm14, %ymm1

Final state:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vminps %xmm2, %xmm2, %xmm5

.target:
vmovdqa %xmm3, %xmm1
vmovdqu %xmm2, %xmm14
vminps %ymm1, %ymm14, %ymm1
retq 

Initial state:
%ymm5: %ymm5_vsubps_xmm_xmm_xmm

State for specgen instruction: vminps %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm5: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_subps_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm14

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm14: %ymm14_vminps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm14: 0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vminps %ymm1, %ymm14, %ymm1

Final state:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vminps %xmm1, %xmm1, %xmm4

.target:
vmovdqa %xmm3, %xmm1
vmovdqu %xmm2, %xmm14
vminps %ymm1, %ymm14, %ymm1
retq 

Initial state:
%ymm4: %ymm4_subps_xmm_xmm

State for specgen instruction: vminps %xmm3, %xmm2, %xmm1:
%ymm1: (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[63:32]) ∘ (mincmp_single((0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vminps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vminps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm4: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0])))

=====================================
-------------------------------------
Getting base circuit for vsubps %ymm10, %ymm4, %ymm2

Final state:
%ymm2: sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[255:224], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[255:224]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[223:192], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[223:192]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[191:160], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[191:160]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[159:128], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[159:128]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[127:96], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[127:96]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[95:64], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[95:64]) ∘ (sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[63:32], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[63:32]) ∘ sub_single((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm1_subps_xmm_xmm[127:0]))))[31:0], (0x0₁₂₈ ∘ %ymm2_subps_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_subps_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_subps_xmm_xmm[255:128] ∘ (sub_single(%ymm1_subps_xmm_xmm[127:96], %ymm2_subps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_subps_xmm_xmm[95:64], %ymm2_subps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_subps_xmm_xmm[63:32], %ymm2_subps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_subps_xmm_xmm[31:0], %ymm2_subps_xmm_xmm[31:0])))))[127:0]

=====================================
=====================================
Computing circuit for subps %xmm3, %xmm5

.target:
vmovaps %xmm2, %xmm10
vminps %xmm1, %xmm1, %xmm4
vsubps %ymm10, %ymm4, %ymm2
movdqu %xmm2, %xmm1
retq 

Initial state:
%xmm5: (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0]))))[127:0]

State for specgen instruction: subps %xmm2, %xmm1:
%xmm1: (%ymm1_subps_xmm_xmm[255:128] ∘ (sub_single(%ymm1_subps_xmm_xmm[127:96], %ymm2_subps_xmm_xmm[127:96]) ∘ (sub_single(%ymm1_subps_xmm_xmm[95:64], %ymm2_subps_xmm_xmm[95:64]) ∘ (sub_single(%ymm1_subps_xmm_xmm[63:32], %ymm2_subps_xmm_xmm[63:32]) ∘ sub_single(%ymm1_subps_xmm_xmm[31:0], %ymm2_subps_xmm_xmm[31:0])))))[127:0]

Final state
%xmm5: ((0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ %ymm2_vsubps_xmm_xmm_xmm[127:0]))))[255:128] ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0])))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm5, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vsubps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0]))))

=====================================
=====================================
Computing circuit for vsubps %xmm8, %xmm15, %xmm4

.target:
vminps %xmm2, %xmm2, %xmm5
subps %xmm3, %xmm5
vmovdqu %xmm5, %xmm1
retq 

Initial state:
%ymm4: %ymm4_hsubps_xmm_xmm

State for specgen instruction: vsubps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[127:96], %ymm3_vsubps_xmm_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[95:64], %ymm3_vsubps_xmm_xmm_xmm[95:64]) ∘ (sub_single(%ymm2_vsubps_xmm_xmm_xmm[63:32], %ymm3_vsubps_xmm_xmm_xmm[63:32]) ∘ sub_single(%ymm2_vsubps_xmm_xmm_xmm[31:0], %ymm3_vsubps_xmm_xmm_xmm[31:0]))))

Final state
%ymm4: 0x0₁₂₈ ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ (sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm4, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: %ymm1_hsubps_xmm_xmm[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_hsubps_xmm_xmm[255:128] ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))[127:0]

=====================================
=====================================
Computing circuit for hsubps %xmm3, %xmm2

.target:
vpunpckldq %xmm2, %xmm1, %xmm8
vunpckhps %xmm2, %xmm1, %xmm10
vpunpckldq %xmm10, %xmm8, %xmm15
punpckhdq %xmm10, %xmm8
vsubps %xmm8, %xmm15, %xmm4
movdqu %xmm4, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vhsubps_xmm_xmm_xmm[127:0]

State for specgen instruction: hsubps %xmm2, %xmm1:
%xmm1: (%ymm1_hsubps_xmm_xmm[255:128] ∘ (sub_single(%ymm2_hsubps_xmm_xmm[95:64], %ymm2_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm2_hsubps_xmm_xmm[31:0], %ymm2_hsubps_xmm_xmm[63:32]) ∘ (sub_single(%ymm1_hsubps_xmm_xmm[95:64], %ymm1_hsubps_xmm_xmm[127:96]) ∘ sub_single(%ymm1_hsubps_xmm_xmm[31:0], %ymm1_hsubps_xmm_xmm[63:32]))))[127:0]

Final state
%xmm2: (%ymm2_vhsubps_xmm_xmm_xmm[255:128] ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vhsubps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vhsubps_xmm_xmm_xmm

%xmm0: %ymm0_vhsubps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vhsubps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vhsubps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vhsubps_xmm_xmm_xmm

%xmm0: %ymm0_vhsubps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vhsubps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vhsubps_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32])))

=====================================
=====================================
Computing circuit for vhsubps %xmm13, %xmm1, %xmm1

.target:
hsubps %xmm3, %xmm2
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm1: 0x0₁₂₈ ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₄₈ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0]))

State for specgen instruction: vhsubps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (sub_single(%ymm3_vhsubps_xmm_xmm_xmm[95:64], %ymm3_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm3_vhsubps_xmm_xmm_xmm[31:0], %ymm3_vhsubps_xmm_xmm_xmm[63:32]) ∘ (sub_single(%ymm2_vhsubps_xmm_xmm_xmm[95:64], %ymm2_vhsubps_xmm_xmm_xmm[127:96]) ∘ sub_single(%ymm2_vhsubps_xmm_xmm_xmm[31:0], %ymm2_vhsubps_xmm_xmm_xmm[63:32])))

Final state
%ymm1: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0])))

=====================================
=====================================
Computing circuit for vpmovzxwd %xmm10, %xmm14

.target:
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7
vpmovzxwq %xmm5, %xmm13
movddup %xmm4, %xmm4
callq .move_032_128_xmm4_xmm5_xmm6_xmm7_xmm3
vpmovzxwq %xmm3, %xmm1
vhsubps %xmm13, %xmm1, %xmm1
retq 

Initial state:
%ymm14: %ymm14_pmovzxwd_xmm_xmm

State for specgen instruction: vpmovzxwd %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpmovzxwd_xmm_xmm[15:0])))

Final state
%ymm14: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[15:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_pmovzxwd_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_pmovzxwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[15:0]))))[127:0]

=====================================
=====================================
Computing circuit for pmovzxwd %xmm1, %xmm1

.target:
vpbroadcastq %xmm2, %ymm10
minpd %xmm10, %xmm10
vpmovzxwd %xmm10, %xmm14
movapd %xmm14, %xmm1
retq 

Initial state:
%xmm1: %ymm1_punpcklwd_xmm_xmm[127:0]

State for specgen instruction: pmovzxwd %xmm2, %xmm1:
%xmm1: (%ymm1_pmovzxwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_pmovzxwd_xmm_xmm[15:0]))))[127:0]

Final state
%xmm1: (%ymm1_punpcklwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[15:0]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vpbroadcastw_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_xmm_xmm

%xmm0: %ymm0_vpbroadcastw_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastw_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_032_r10w_r11w_ebx

Final state:
%rax/%rax: %rax_vpbroadcastw_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_xmm_xmm

%xmm0: %ymm0_vpbroadcastw_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastw_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r8b_r9b

Final state:
%rax/%rax: %rax_vpbroadcastw_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_xmm_xmm

%xmm0: %ymm0_vpbroadcastw_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastw_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r9b_to_byte_3_of_rbx

Final state:
%rax/%rax: %rax_vpbroadcastw_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_xmm_xmm

%xmm0: %ymm0_vpbroadcastw_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastw_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r8b_r9b

Final state:
%rax/%rax: %rax_vmovd_xmm_r32
%rdx/%rdx: %rdx_vmovd_xmm_r32

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r8b_to_byte_0_of_ymm1

Final state:
%rax/%rax: %rax_vmovd_xmm_r32
%rdx/%rdx: %rdx_vmovd_xmm_r32

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r9b_to_byte_1_of_ymm1

Final state:
%rax/%rax: %rax_vmovd_xmm_r32
%rdx/%rdx: %rdx_vmovd_xmm_r32

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movq $0x0, %rbx

Final state:
%rbx/%rbx: 0x0₆₄

-------------------------------------
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: %cf_movzbq_r64_r8

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for movsbq %cl, %rdi

Final state:
%rdi/%rdi: sign-extend-64(%rcx_movzbq_r64_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for adcb %dil, %bl

Final state:
%rbx/%bl: 0x0₆₄[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0][3:0] + 0x0₁ ∘ 0x0₆₄[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0][7:7] = 0x1₁
%of: (sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0][7:7] = 0x1₁ ↔ 0x0₆₄[7:0][7:7] = 0x1₁) ∧ !(sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for movzbq %bl, %r8

.target:
movq $0x0, %rbx
clc 
movsbq %cl, %rdi
adcb %dil, %bl
retq 

Initial state:
%r8/%r8: %r8_xchgb_r8_r8

State for specgen instruction: movzbq %cl, %rbx:
%rbx/%rbx: 0x0₆₄[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0]

Register        -> %rbx
  translates to => %r8
Value is               -> 0x0₆₄[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64(%rcx_movzbq_r64_r8[7:0])[7:0]) + 0x0₁ ∘ 0x0₆₄[7:0])[7:0]
  after renaming it is => 0x0₅₆ ∘ %rbx_xchgb_r8_r8[7:0]

Final state
%r8/%r8: 0x0₅₆ ∘ %rbx_xchgb_r8_r8[7:0]

=====================================
-------------------------------------
Getting base circuit for movq $0x5, %rbx

Final state:
%rbx/%rbx: 0x5₆₄

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r12d_r13d

Final state:
%rax/%rax: %rax_movzbw_r16_r8
%rdx/%rdx: %rdx_movzbw_r16_r8

%xmm0: %ymm0_movzbw_r16_r8[127:0]
%xmm1: %ymm1_movzbw_r16_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movsbq %cl, %r12

Final state:
%r12/%r12: sign-extend-64(%rcx_movzbw_r16_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r12b_r13b_bx

Final state:
%rax/%rax: %rax_movzbw_r16_r8
%rdx/%rdx: %rdx_movzbw_r16_r8

%xmm0: %ymm0_movzbw_r16_r8[127:0]
%xmm1: %ymm1_movzbw_r16_r8[127:0]

-------------------------------------
=====================================
Computing circuit for movzbw %cl, %cx

.target:
movq $0x5, %rbx
callq .move_064_032_rbx_r12d_r13d
movsbq %cl, %r12
callq .move_008_016_r12b_r13b_bx
retq 

Initial state:
%rcx/%cx: %rcx_xchgb_r8_r8

State for specgen instruction: movzbw %cl, %bx:
%rbx/%bx: 0x5₆₄[63:16] ∘ ((0x0₃₂ ∘ 0x5₆₄[63:32])[7:0][7:0] ∘ sign-extend-64(%rcx_movzbw_r16_r8[7:0])[7:0][7:0])

Register        -> %bx
  translates to => %cx
Value is               -> (0x5₆₄[63:16] ∘ ((0x0₃₂ ∘ 0x5₆₄[63:32])[7:0][7:0] ∘ sign-extend-64(%rcx_movzbw_r16_r8[7:0])[7:0][7:0]))[15:0]
  after renaming it is => 0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]

Final state
%rcx/%cx: %rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0])

=====================================
-------------------------------------
Getting base circuit for movq $0x40, %rbx

Final state:
%rbx/%rbx: 0x40₆₄

-------------------------------------
-------------------------------------
Getting base circuit for movb %ah, %bl

Final state:
%rbx/%bl: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

-------------------------------------
=====================================
Computing circuit for movzbl %bh, %edx

.target:
movq $0x40, %rbx
movb %ah, %bl
retq 

Initial state:
%rdx/%rdx: %rdx_movb_rh_rh

State for specgen instruction: movzbl %ah, %ebx:
%rbx/%rbx: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

Register        -> %rbx
  translates to => %rdx
Value is               -> 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]
  after renaming it is => 0x0₅₆ ∘ %rbx_movb_rh_rh[15:8]

Final state
%rdx/%rdx: 0x0₅₆ ∘ %rbx_movb_rh_rh[15:8]

=====================================
-------------------------------------
Getting base circuit for callq .move_064_032_rdx_r8d_r9d

Final state:
%rax/%rax: %rax_movb_rh_rh
%rdx/%rdx: 0x0₅₆ ∘ %rbx_movb_rh_rh[15:8]

%xmm0: %ymm0_movb_rh_rh[127:0]
%xmm1: %ymm1_movb_rh_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r8d_r9d_rcx

Final state:
%rax/%rax: %rax_movb_rh_rh
%rdx/%rdx: 0x0₅₆ ∘ %rbx_movb_rh_rh[15:8]

%xmm0: %ymm0_movb_rh_rh[127:0]
%xmm1: %ymm1_movb_rh_rh[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movb %cl, %ah

Final state:
%rax/%ah: %rax_movb_rh_rh[63:16] ∘ ((0x0₃₂ ∘ (0x0₅₆ ∘ %rbx_movb_rh_rh[15:8])[63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ (0x0₅₆ ∘ %rbx_movb_rh_rh[15:8])[31:0])[31:0][31:0])[7:0] ∘ %rax_movb_rh_rh[7:0]

-------------------------------------
=====================================
Computing circuit for movb %ch, %bh

.target:
movzbl %bh, %edx
callq .move_064_032_rdx_r8d_r9d
callq .move_032_064_r8d_r9d_rcx
movb %cl, %ah
retq 

Initial state:
%rbx/%bh: %rbx_xchgb_r8_r8

State for specgen instruction: movb %bh, %ah:
%rax/%ah: %rax_movb_rh_rh[63:16] ∘ ((0x0₃₂ ∘ (0x0₅₆ ∘ %rbx_movb_rh_rh[15:8])[63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ (0x0₅₆ ∘ %rbx_movb_rh_rh[15:8])[31:0])[31:0][31:0])[7:0] ∘ %rax_movb_rh_rh[7:0]

Register        -> %ah
  translates to => %bh
Value is               -> (%rax_movb_rh_rh[63:16] ∘ ((0x0₃₂ ∘ (0x0₅₆ ∘ %rbx_movb_rh_rh[15:8])[63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ (0x0₅₆ ∘ %rbx_movb_rh_rh[15:8])[31:0])[31:0][31:0])[7:0] ∘ %rax_movb_rh_rh[7:0])[15:8]
  after renaming it is => 0x0₈

Final state
%rbx/%bh: %rbx_xchgb_r8_r8[63:16] ∘ 0x0₈ ∘ %rbx_xchgb_r8_r8[7:0]

=====================================
-------------------------------------
Getting base circuit for movq $0x40, %rbx

Final state:
%rbx/%rbx: 0x40₆₄

-------------------------------------
-------------------------------------
Getting base circuit for movb %ah, %bl

Final state:
%rbx/%bl: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

-------------------------------------
=====================================
Computing circuit for movzbl %ah, %edx

.target:
movq $0x40, %rbx
movb %ah, %bl
retq 

Initial state:
%rdx/%rdx: %rdx_xaddb_rh_r8

State for specgen instruction: movzbl %ah, %ebx:
%rbx/%rbx: 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]

Register        -> %rbx
  translates to => %rdx
Value is               -> 0x40₆₄[63:8] ∘ %rax_movzbl_r32_rh[15:8]
  after renaming it is => 0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8]

Final state
%rdx/%rdx: 0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8]

=====================================
-------------------------------------
Getting base circuit for callq .clear_cf

Final state:
%rax/%rax: %rax_xaddb_r8_r8
%rdx/%rdx: %rdx_xaddb_r8_r8

%xmm0: %ymm0_xaddb_r8_r8[127:0]
%xmm1: %ymm1_xaddb_r8_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_of

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_of_into_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movsbq %cl, %r10

Final state:
%r10/%r10: sign-extend-64(%rcx_movsbl_r32_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
=====================================
Computing circuit for movsbl %cl, %r13d

.target:
callq .set_of
callq .read_of_into_rbx
callq .move_064_032_rbx_r10d_r11d
movsbq %cl, %r10
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r13/%r13: %r13_xaddb_r8_r8

State for specgen instruction: movsbl %cl, %ebx:
%rbx/%rbx: (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r13
Value is               -> (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0]

Final state
%r13/%r13: 0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0]

=====================================
-------------------------------------
Getting base circuit for callq .set_of

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .read_of_into_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_032_rbx_r10d_r11d

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for movsbq %cl, %r10

Final state:
%r10/%r10: sign-extend-64(%rcx_movsbl_r32_r8[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movsbl_r32_r8
%rdx/%rdx: %rdx_movsbl_r32_r8

%xmm0: %ymm0_movsbl_r32_r8[127:0]
%xmm1: %ymm1_movsbl_r32_r8[127:0]

-------------------------------------
=====================================
Computing circuit for movsbl %bl, %r15d

.target:
callq .set_of
callq .read_of_into_rbx
callq .move_064_032_rbx_r10d_r11d
movsbq %cl, %r10
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r15/%r15: %r15_xaddb_r8_r8

State for specgen instruction: movsbl %cl, %ebx:
%rbx/%rbx: (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r15
Value is               -> (0x0₃₂ ∘ (0x0₆₃ ∘ (true ? 0x1₁ : 0x0₁))[63:32])[31:0][31:0] ∘ sign-extend-64(%rcx_movsbl_r32_r8[7:0])[31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0]

Final state
%r15/%r15: 0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0]

=====================================
-------------------------------------
Getting base circuit for movsbq %r15b, %rcx

Final state:
%rcx/%rcx: sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])

-------------------------------------
-------------------------------------
Getting base circuit for adcb %cl, %r13b

Final state:
%r13/%r13b: (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][3:0] + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁
%of: (sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][7:7] = 0x1₁) ∧ !(sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:7] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r13d, %rbx

Final state:
%rbx/%rbx: sign-extend-64(((0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0])[31:0])

-------------------------------------
=====================================
Computing circuit for xaddb %bl, %dl

.target:
callq .clear_cf
movsbl %cl, %r13d
movsbl %bl, %r15d
movsbq %r15b, %rcx
adcb %cl, %r13b
movslq %r13d, %rbx
retq 

Initial state:
%rdx/%dl: 0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8]
%rbx/%bl: %rbx_xaddb_rh_r8

%cf: %cf_xaddb_rh_r8
%pf: %pf_xaddb_rh_r8
%af: %af_xaddb_rh_r8
%zf: %zf_xaddb_rh_r8
%sf: %sf_xaddb_rh_r8
%of: %of_xaddb_rh_r8

State for specgen instruction: xaddb %cl, %bl:
%rcx/%cl: sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])
%rbx/%bl: sign-extend-64(((0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[63:8] ∘ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0])[31:0])

%cf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][3:0] + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁
%of: (sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0][7:7] = 0x1₁) ∧ !(sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0] + 0x1₉ : 0x0₁ ∘ sign-extend-64((0x0₃₂ ∘ sign-extend-64(%rbx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:0]) + 0x0₁ ∘ (0x0₃₂ ∘ sign-extend-64(%rcx_xaddb_r8_r8[7:0])[31:0])[7:0])[7:7] = 0x1₁)

Final state
%rdx/%dl: (0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8])[63:8] ∘ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0]
%rbx/%bl: %rbx_xaddb_rh_r8[63:8] ∘ %rax_xaddb_rh_r8[15:8]

%cf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[8:8] = 0x1₁
%pf: !((0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rax_xaddb_rh_r8[11:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0] = 0x0₈
%sf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁
%of: (%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ %rbx_xaddb_rh_r8[7:7] = 0x1₁) ∧ !(%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for movb %dl, %ah

Final state:
%rax/%ah: %rax_xaddb_rh_r8[63:16] ∘ ((0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8])[63:8] ∘ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0])[7:0] ∘ %rax_xaddb_rh_r8[7:0]

-------------------------------------
=====================================
Computing circuit for xaddb %bl, %ch

.target:
movzbl %ah, %edx
xaddb %bl, %dl
movb %dl, %ah
retq 

Initial state:
%rcx/%ch: %rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0])
%rbx/%bl: %rbx_xchgb_r8_r8[63:16] ∘ 0x0₈ ∘ %rbx_xchgb_r8_r8[7:0]

%cf: %cf_xchgb_r8_r8
%pf: %pf_xchgb_r8_r8
%af: %af_xchgb_r8_r8
%zf: %zf_xchgb_r8_r8
%sf: %sf_xchgb_r8_r8
%of: %of_xchgb_r8_r8

State for specgen instruction: xaddb %bl, %ah:
%rax/%ah: %rax_xaddb_rh_r8[63:16] ∘ ((0x0₅₆ ∘ %rax_xaddb_rh_r8[15:8])[63:8] ∘ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0])[7:0] ∘ %rax_xaddb_rh_r8[7:0]
%rbx/%bl: %rbx_xaddb_rh_r8[63:8] ∘ %rax_xaddb_rh_r8[15:8]

%cf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[8:8] = 0x1₁
%pf: !((0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rax_xaddb_rh_r8[11:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:0] = 0x0₈
%sf: (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁
%of: (%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ %rbx_xaddb_rh_r8[7:7] = 0x1₁) ∧ !(%rax_xaddb_rh_r8[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rax_xaddb_rh_r8[15:8] + 0x0₁ ∘ %rbx_xaddb_rh_r8[7:0])[7:7] = 0x1₁)

Final state
%rcx/%ch: (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ %rbx_xchgb_r8_r8[7:0] ∘ (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[7:0]
%rbx/%bl: (%rbx_xchgb_r8_r8[63:16] ∘ 0x0₈ ∘ %rbx_xchgb_r8_r8[7:0])[63:8] ∘ 0x0₈

%cf: false
%pf: !(%rbx_xchgb_r8_r8[0:0] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[1:1] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[2:2] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[3:3] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[4:4] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[5:5] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[6:6] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[7:7] = 0x1₁)
%af: false
%zf: %rbx_xchgb_r8_r8[7:0] = 0x0₈
%sf: %rbx_xchgb_r8_r8[7:7] = 0x1₁
%of: (false ↔ %rbx_xchgb_r8_r8[7:7] = 0x1₁) ∧ !(false ↔ %rbx_xchgb_r8_r8[7:7] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r10b_r11b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_cx_r8b_r9b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r10b_r11b_cx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r8b_r9b_bx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for xchgw %cx, %bx

.target:
callq .move_016_008_bx_r10b_r11b
callq .move_016_008_cx_r8b_r9b
callq .move_008_016_r10b_r11b_cx
callq .move_008_016_r8b_r9b_bx
retq 

Initial state:
%rcx/%cx: %rcx_xaddw_r16_r16
%rbx/%bx: %rbx_xaddw_r16_r16

State for specgen instruction: xchgw %cx, %bx:
%rcx/%cx: %rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])
%rbx/%bx: %rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])

Register        -> %cx
  translates to => %cx
Value is               -> (%rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => %rbx_xaddw_r16_r16[15:0]

Register        -> %bx
  translates to => %bx
Value is               -> (%rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => %rcx_xaddw_r16_r16[15:0]

Final state
%rcx/%cx: %rcx_xaddw_r16_r16[63:16] ∘ %rbx_xaddw_r16_r16[15:0]
%rbx/%bx: %rbx_xaddw_r16_r16[63:16] ∘ %rcx_xaddw_r16_r16[15:0]

=====================================
-------------------------------------
Getting base circuit for xorq %rax, %rax

Final state:
%rax/%rax: %rax_clc ⊕ %rax_clc

%cf: false
%pf: !((%rax_clc ⊕ %rax_clc)[7:0][0:0] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][1:1] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][2:2] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][3:3] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][4:4] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][5:5] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][6:6] = 0x1₁ ⊕ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁)
%zf: (%rax_clc ⊕ %rax_clc) = 0x0₆₄
%sf: (%rax_clc ⊕ %rax_clc)[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for adcb %al, %al

Final state:
%rax/%al: (%rax_clc ⊕ %rax_clc)[63:8] ∘ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0]

%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0] + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0] = 0x0₈
%sf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:0][7:7] = 0x1₁
%of: ((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ (%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁) ∧ !((%rax_clc ⊕ %rax_clc)[7:0][7:7] = 0x1₁ ↔ ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[7:7] = 0x1₁)

-------------------------------------
=====================================
Computing circuit for clc 

.target:
xorq %rax, %rax
adcb %al, %al
retq 

Initial state:
%cf: %cf_addw_r16_r16

State for specgen instruction: clc :
%cf: ((false ? 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0] + 0x1₉ : 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0]) + 0x0₁ ∘ (%rax_clc ⊕ %rax_clc)[7:0])[8:8] = 0x1₁

Final state
%cf: false

=====================================
-------------------------------------
Getting base circuit for adcw %cx, %bx

Final state:
%rbx/%bx: %rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[16:16] = 0x1₁
%pf: !(((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addw_r16_r16[15:0][3:0] + 0x0₁ ∘ %rbx_addw_r16_r16[15:0][3:0])[4:4] = 0x1₁
%zf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0] = 0x0₁₆
%sf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0][15:15] = 0x1₁
%of: (%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ %rbx_addw_r16_r16[15:0][15:15] = 0x1₁) ∧ !(%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:15] = 0x1₁)

-------------------------------------
-------------------------------------
Getting base circuit for callq .set_szp_for_bx

Final state:
%rax/%rax: %rax_addw_r16_r16
%rdx/%rdx: %rdx_addw_r16_r16

%xmm0: %ymm0_addw_r16_r16[127:0]
%xmm1: %ymm1_addw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for addw %cx, %bx

.target:
clc 
adcw %cx, %bx
callq .set_szp_for_bx
retq 

Initial state:
%rbx/%bx: %rbx_xaddw_r16_r16[63:16] ∘ %rcx_xaddw_r16_r16[15:0]

%cf: %cf_xaddw_r16_r16
%pf: %pf_xaddw_r16_r16
%af: %af_xaddw_r16_r16
%zf: %zf_xaddw_r16_r16
%sf: %sf_xaddw_r16_r16
%of: %of_xaddw_r16_r16

State for specgen instruction: addw %cx, %bx:
%rbx/%bx: %rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0]

%cf: ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[16:16] = 0x1₁
%pf: !((%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][0:0] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][1:1] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][2:2] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][3:3] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][4:4] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][5:5] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][6:6] = 0x1₁ ⊕ (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][7:0][7:7] = 0x1₁)
%af: (0x0₁ ∘ %rcx_addw_r16_r16[15:0][3:0] + 0x0₁ ∘ %rbx_addw_r16_r16[15:0][3:0])[4:4] = 0x1₁
%zf: (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0] = 0x0₁₆
%sf: (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0][15:15] = 0x1₁
%of: (%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ %rbx_addw_r16_r16[15:0][15:15] = 0x1₁) ∧ !(%rcx_addw_r16_r16[15:0][15:15] = 0x1₁ ↔ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:15] = 0x1₁)

Register        -> %bx
  translates to => %bx
Value is               -> (%rbx_addw_r16_r16[63:16] ∘ ((false ? 0x0₁ ∘ %rcx_addw_r16_r16[15:0] + 0x1₁₇ : 0x0₁ ∘ %rcx_addw_r16_r16[15:0]) + 0x0₁ ∘ %rbx_addw_r16_r16[15:0])[15:0])[15:0]
  after renaming it is => (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:0]

Final state
%rbx/%bx: (%rbx_xaddw_r16_r16[63:16] ∘ %rcx_xaddw_r16_r16[15:0])[63:16] ∘ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:0]

%cf: (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[16:16] = 0x1₁
%pf: !((0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rbx_xaddw_r16_r16[3:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:0] = 0x0₁₆
%sf: (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:15] = 0x1₁
%of: (%rbx_xaddw_r16_r16[15:15] = 0x1₁ ↔ %rcx_xaddw_r16_r16[15:15] = 0x1₁) ∧ !(%rbx_xaddw_r16_r16[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:15] = 0x1₁)

=====================================
=====================================
Computing circuit for xaddw %bx, %cx

.target:
xchgw %cx, %bx
addw %cx, %bx
retq 

Initial state:
%rcx/%cx: (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ %rbx_xchgb_r8_r8[7:0] ∘ (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[7:0]
%rbx/%bx: (%rbx_xchgb_r8_r8[63:16] ∘ 0x0₈ ∘ %rbx_xchgb_r8_r8[7:0])[63:8] ∘ 0x0₈

%cf: false
%pf: !(%rbx_xchgb_r8_r8[0:0] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[1:1] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[2:2] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[3:3] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[4:4] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[5:5] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[6:6] = 0x1₁ ⊕ %rbx_xchgb_r8_r8[7:7] = 0x1₁)
%af: false
%zf: %rbx_xchgb_r8_r8[7:0] = 0x0₈
%sf: %rbx_xchgb_r8_r8[7:7] = 0x1₁
%of: (false ↔ %rbx_xchgb_r8_r8[7:7] = 0x1₁) ∧ !(false ↔ %rbx_xchgb_r8_r8[7:7] = 0x1₁)

State for specgen instruction: xaddw %cx, %bx:
%rcx/%cx: %rcx_xaddw_r16_r16[63:16] ∘ %rbx_xaddw_r16_r16[15:0]
%rbx/%bx: (%rbx_xaddw_r16_r16[63:16] ∘ %rcx_xaddw_r16_r16[15:0])[63:16] ∘ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:0]

%cf: (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[16:16] = 0x1₁
%pf: !((0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[0:0] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[1:1] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[2:2] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[3:3] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[4:4] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[5:5] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[6:6] = 0x1₁ ⊕ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[7:7] = 0x1₁)
%af: (0x0₁ ∘ %rbx_xaddw_r16_r16[3:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[3:0])[4:4] = 0x1₁
%zf: (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:0] = 0x0₁₆
%sf: (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:15] = 0x1₁
%of: (%rbx_xaddw_r16_r16[15:15] = 0x1₁ ↔ %rcx_xaddw_r16_r16[15:15] = 0x1₁) ∧ !(%rbx_xaddw_r16_r16[15:15] = 0x1₁ ↔ (0x0₁ ∘ %rbx_xaddw_r16_r16[15:0] + 0x0₁ ∘ %rcx_xaddw_r16_r16[15:0])[15:15] = 0x1₁)

Final state
%rcx/%cx: ((%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ %rbx_xchgb_r8_r8[7:0] ∘ (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[7:0])[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0])
%rbx/%bx: ((%rbx_xchgb_r8_r8[63:16] ∘ 0x0₈ ∘ %rbx_xchgb_r8_r8[7:0])[63:8] ∘ 0x0₈)[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0])

%cf: false
%pf: !(%rcx_xchgb_r8_r8[0:0] = 0x1₁ ⊕ %rcx_xchgb_r8_r8[1:1] = 0x1₁ ⊕ %rcx_xchgb_r8_r8[2:2] = 0x1₁ ⊕ %rcx_xchgb_r8_r8[3:3] = 0x1₁ ⊕ %rcx_xchgb_r8_r8[4:4] = 0x1₁ ⊕ %rcx_xchgb_r8_r8[5:5] = 0x1₁ ⊕ %rcx_xchgb_r8_r8[6:6] = 0x1₁ ⊕ %rcx_xchgb_r8_r8[7:7] = 0x1₁)
%af: false
%zf: %rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0] = 0x0₁₆
%sf: %rbx_xchgb_r8_r8[7:7] = 0x1₁
%of: (%rbx_xchgb_r8_r8[7:7] = 0x1₁ ↔ false) ∧ !(%rbx_xchgb_r8_r8[7:7] = 0x1₁ ↔ %rbx_xchgb_r8_r8[7:7] = 0x1₁)

=====================================
-------------------------------------
Getting base circuit for callq .move_016_008_bx_r10b_r11b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_016_008_cx_r8b_r9b

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r10b_r11b_cx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_008_016_r8b_r9b_bx

Final state:
%rax/%rax: %rax_xchgw_r16_r16
%rdx/%rdx: %rdx_xchgw_r16_r16

%xmm0: %ymm0_xchgw_r16_r16[127:0]
%xmm1: %ymm1_xchgw_r16_r16[127:0]

-------------------------------------
=====================================
Computing circuit for xchgw %cx, %r8w

.target:
callq .move_016_008_bx_r10b_r11b
callq .move_016_008_cx_r8b_r9b
callq .move_008_016_r10b_r11b_cx
callq .move_008_016_r8b_r9b_bx
retq 

Initial state:
%rcx/%cx: ((%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ %rbx_xchgb_r8_r8[7:0] ∘ (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[7:0])[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0])
%r8/%r8w: 0x0₅₆ ∘ %rbx_xchgb_r8_r8[7:0]

State for specgen instruction: xchgw %cx, %bx:
%rcx/%cx: %rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])
%rbx/%bx: %rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0])

Register        -> %cx
  translates to => %cx
Value is               -> (%rcx_xchgw_r16_r16[63:16] ∘ ((%r11_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r10_xchgw_r16_r16[63:8] ∘ %rbx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => 0x0₈ ∘ %rbx_xchgb_r8_r8[7:0]

Register        -> %bx
  translates to => %r8w
Value is               -> (%rbx_xchgw_r16_r16[63:16] ∘ ((%r9_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][15:8])[7:0][7:0] ∘ (%r8_xchgw_r16_r16[63:8] ∘ %rcx_xchgw_r16_r16[15:0][7:0])[7:0][7:0]))[15:0]
  after renaming it is => %rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0]

Final state
%rcx/%cx: (((%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ %rbx_xchgb_r8_r8[7:0] ∘ (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[7:0])[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ (0x0₈ ∘ %rbx_xchgb_r8_r8[7:0])
%r8/%r8w: (0x0₅₆ ∘ %rbx_xchgb_r8_r8[7:0])[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0])

=====================================
=====================================
Computing circuit for xchgb %r8b, %bl

.target:
movzbq %bl, %r8
movzbw %cl, %cx
movb %ch, %bh
xaddb %bl, %ch
xaddw %bx, %cx
xchgw %cx, %r8w
retq 

Initial state:
%rbx/%bl: %rbx_vmovd_xmm_r32
%r8/%r8b: %r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0]

State for specgen instruction: xchgb %cl, %bl:
%rcx/%cl: (((%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ %rbx_xchgb_r8_r8[7:0] ∘ (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[7:0])[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ (0x0₈ ∘ %rbx_xchgb_r8_r8[7:0])
%rbx/%bl: ((%rbx_xchgb_r8_r8[63:16] ∘ 0x0₈ ∘ %rbx_xchgb_r8_r8[7:0])[63:8] ∘ 0x0₈)[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0])

Register        -> %cl
  translates to => %r8b
Value is               -> ((((%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ %rbx_xchgb_r8_r8[7:0] ∘ (%rcx_xchgb_r8_r8[63:16] ∘ (0x0₈ ∘ %rcx_xchgb_r8_r8[7:0]))[7:0])[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0]))[63:16] ∘ (0x0₈ ∘ %rbx_xchgb_r8_r8[7:0]))[7:0]
  after renaming it is => %rbx_vmovd_xmm_r32[7:0]

Register        -> %bl
  translates to => %bl
Value is               -> (((%rbx_xchgb_r8_r8[63:16] ∘ 0x0₈ ∘ %rbx_xchgb_r8_r8[7:0])[63:8] ∘ 0x0₈)[63:16] ∘ (%rbx_xchgb_r8_r8[7:0] ∘ %rcx_xchgb_r8_r8[7:0]))[7:0]
  after renaming it is => %rbx_vmovd_xmm_r32[7:0]

Final state
%rbx/%bl: %rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0]
%r8/%r8b: (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[63:8] ∘ %rbx_vmovd_xmm_r32[7:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_r9b_to_byte_3_of_ymm1

Final state:
%rax/%rax: %rax_vmovd_xmm_r32
%rdx/%rdx: %rdx_vmovd_xmm_r32

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_016_ebx_r8w_r9w

Final state:
%rax/%rax: %rax_vmovd_xmm_r32
%rdx/%rdx: %rdx_vmovd_xmm_r32

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_3_of_rbx_to_r8b

Final state:
%rax/%rax: %rax_vmovd_xmm_r32
%rdx/%rdx: %rdx_vmovd_xmm_r32

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r9b_to_byte_2_of_ymm1

Final state:
%rax/%rax: %rax_vmovd_xmm_r32
%rdx/%rdx: %rdx_vmovd_xmm_r32

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[255:24] ∘ ((%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[63:16] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:0][31:16])[7:0] ∘ (((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[15:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r8b_to_byte_3_of_ymm1

Final state:
%rax/%rax: %rax_vmovd_xmm_r32
%rdx/%rdx: %rdx_vmovd_xmm_r32

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (((((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[255:24] ∘ ((%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[63:16] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:0][31:16])[7:0] ∘ (((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[15:0])[255:32] ∘ ((((%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[63:16] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:0][15:0])[63:8] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:24])[7:0] ∘ ((((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[255:24] ∘ ((%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[63:16] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:0][31:16])[7:0] ∘ (((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[15:0])[23:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovd %ebx, %xmm1

.target:
vzeroall 
callq .move_016_008_bx_r8b_r9b
callq .move_r8b_to_byte_0_of_ymm1
callq .move_r9b_to_byte_1_of_ymm1
xchgb %r8b, %bl
callq .move_r9b_to_byte_3_of_ymm1
callq .move_032_016_ebx_r8w_r9w
callq .move_byte_3_of_rbx_to_r8b
callq .move_r9b_to_byte_2_of_ymm1
callq .move_r8b_to_byte_3_of_ymm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastw_xmm_xmm

State for specgen instruction: vmovd %ebx, %xmm1:
%ymm1: ((((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[255:24] ∘ ((%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[63:16] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:0][31:16])[7:0] ∘ (((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[15:0])[255:32] ∘ ((((%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[63:16] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:0][15:0])[63:8] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:24])[7:0] ∘ ((((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[255:24] ∘ ((%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[63:16] ∘ (%rbx_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[7:0])[31:0][31:16])[7:0] ∘ (((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[255:32] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ ((0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[255:16] ∘ (%r9_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][15:8])[7:0] ∘ (0x0₂₅₆[255:8] ∘ (%r8_vmovd_xmm_r32[63:8] ∘ %rbx_vmovd_xmm_r32[15:0][7:0])[7:0])[7:0])[23:0])[15:0])[23:0]

Final state
%ymm1: 0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_r9b_to_byte_19_of_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastw_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_xmm_xmm

%xmm0: %ymm0_vpbroadcastw_xmm_xmm[127:0]
%xmm1: ((0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[255:160] ∘ (%r9_vpbroadcastw_xmm_xmm[63:8] ∘ (0x0₃₂ ∘ ((0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][63:32])[15:0][15:0] ∘ (0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][31:0])[15:0][15:0]))[15:0][15:8])[7:0] ∘ (0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[151:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r8b_to_byte_2_of_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastw_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_xmm_xmm

%xmm0: %ymm0_vpbroadcastw_xmm_xmm[127:0]
%xmm1: (((0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[255:160] ∘ (%r9_vpbroadcastw_xmm_xmm[63:8] ∘ (0x0₃₂ ∘ ((0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][63:32])[15:0][15:0] ∘ (0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][31:0])[15:0][15:0]))[15:0][15:8])[7:0] ∘ (0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[151:0])[255:24] ∘ (%r8_vpbroadcastw_xmm_xmm[63:8] ∘ (0x0₃₂ ∘ ((0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][63:32])[15:0][15:0] ∘ (0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][31:0])[15:0][15:0]))[15:0][7:0])[7:0] ∘ ((0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[255:160] ∘ (%r9_vpbroadcastw_xmm_xmm[63:8] ∘ (0x0₃₂ ∘ ((0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][63:32])[15:0][15:0] ∘ (0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][31:0])[15:0][15:0]))[15:0][15:8])[7:0] ∘ (0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[151:0])[15:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm1, %xmm1

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm1: ((0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[255:160] ∘ (%r9_vpbroadcastw_xmm_xmm[63:8] ∘ (0x0₃₂ ∘ ((0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][63:32])[15:0][15:0] ∘ (0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][31:0])[15:0][15:0]))[15:0][15:8])[7:0] ∘ (0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[151:0])[255:24] ∘ (%r8_vpbroadcastw_xmm_xmm[63:8] ∘ (0x0₃₂ ∘ ((0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][63:32])[15:0][15:0] ∘ (0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][31:0])[15:0][15:0]))[15:0][7:0])[7:0] ∘ ((0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[255:160] ∘ (%r9_vpbroadcastw_xmm_xmm[63:8] ∘ (0x0₃₂ ∘ ((0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][63:32])[15:0][15:0] ∘ (0x0₃₂ ∘ %ymm2_vpbroadcastw_xmm_xmm[127:0][31:0])[15:0][15:0]))[15:0][15:8])[7:0] ∘ (0x0₂₂₄ ∘ %ymm2_vpbroadcastw_xmm_xmm[15:8] ∘ (%ymm2_vpbroadcastw_xmm_xmm[39:32] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))[151:0])[15:0]

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ (%ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]) ∘ (%ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]) ∘ (%ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))

=====================================
=====================================
Computing circuit for vpbroadcastw %xmm5, %xmm0

.target:
callq .move_128_032_xmm2_r10d_r11d_r12d_r13d
callq .move_016_032_r10w_r11w_ebx
callq .move_016_008_bx_r8b_r9b
callq .move_r9b_to_byte_3_of_rbx
vmovd %ebx, %xmm1
callq .move_r9b_to_byte_19_of_ymm1
callq .move_r8b_to_byte_2_of_ymm1
vbroadcastss %xmm1, %xmm1
retq 

Initial state:
%ymm0: %ymm0_punpcklwd_xmm_xmm

State for specgen instruction: vpbroadcastw %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ (%ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]) ∘ (%ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]) ∘ (%ymm2_vpbroadcastw_xmm_xmm[15:0] ∘ %ymm2_vpbroadcastw_xmm_xmm[15:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0] ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm5, %xmm14

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm14: %ymm14_punpcklwd_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_punpcklwd_xmm_xmm
%rdx/%rdx: %rdx_punpcklwd_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0] ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0])))[127:0]
%xmm1: (%ymm1_punpcklwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[15:0]))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vbroadcastss_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastss_ymm_xmm

%xmm0: %ymm0_vbroadcastss_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastss_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm3

Final state:
%rax/%rax: %rax_vbroadcastss_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastss_ymm_xmm

%xmm0: %ymm0_vbroadcastss_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastss_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm3, %xmm1

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vbroadcastss_ymm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_r8b_to_byte_23_of_ymm1

Final state:
%rax/%rax: %rax_vbroadcastss_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastss_ymm_xmm

%xmm0: %ymm0_vbroadcastss_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]))[255:192] ∘ %ymm2_vbroadcastss_ymm_xmm[127:0][63:0][7:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]))[183:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]))[255:192] ∘ %ymm2_vbroadcastss_ymm_xmm[127:0][63:0][7:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]))[183:0]

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm1: %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]) ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vbroadcastss %xmm2, %ymm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm3
vbroadcastss %xmm3, %xmm1
callq .move_r8b_to_byte_23_of_ymm1
vbroadcastsd %xmm1, %ymm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastw_ymm_xmm

State for specgen instruction: vbroadcastss %xmm2, %ymm1:
%ymm1: %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]) ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]))

Final state
%ymm1: %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_byte_1_of_ymm1_to_r8b

Final state:
%rax/%rax: %rax_vpbroadcastw_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_ymm_xmm

%xmm0: %ymm0_vpbroadcastw_ymm_xmm[127:0]
%xmm1: (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_0_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpbroadcastw_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_ymm_xmm

%xmm0: %ymm0_vpbroadcastw_ymm_xmm[127:0]
%xmm1: (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r8b_to_byte_3_of_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastw_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_ymm_xmm

%xmm0: %ymm0_vpbroadcastw_ymm_xmm[127:0]
%xmm1: ((%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[255:32] ∘ (%r8_vpbroadcastw_ymm_xmm[63:8] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[15:8])[7:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[23:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_r9b_to_byte_2_of_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastw_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastw_ymm_xmm

%xmm0: %ymm0_vpbroadcastw_ymm_xmm[127:0]
%xmm1: (((%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[255:32] ∘ (%r8_vpbroadcastw_ymm_xmm[63:8] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[15:8])[7:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[23:0])[255:24] ∘ (%r9_vpbroadcastw_ymm_xmm[63:8] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[7:0])[7:0] ∘ ((%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[255:32] ∘ (%r8_vpbroadcastw_ymm_xmm[63:8] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[15:8])[7:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[23:0])[15:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vbroadcastss_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastss_ymm_xmm

%xmm0: %ymm0_vbroadcastss_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastss_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm3

Final state:
%rax/%rax: %rax_vbroadcastss_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastss_ymm_xmm

%xmm0: %ymm0_vbroadcastss_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastss_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm3, %xmm1

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vbroadcastss_ymm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_r8b_to_byte_23_of_ymm1

Final state:
%rax/%rax: %rax_vbroadcastss_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastss_ymm_xmm

%xmm0: %ymm0_vbroadcastss_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]))[255:192] ∘ %ymm2_vbroadcastss_ymm_xmm[127:0][63:0][7:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]))[183:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]))[255:192] ∘ %ymm2_vbroadcastss_ymm_xmm[127:0][63:0][7:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]))[183:0]

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm1: %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]) ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vbroadcastss %xmm1, %ymm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm3
vbroadcastss %xmm3, %xmm1
callq .move_r8b_to_byte_23_of_ymm1
vbroadcastsd %xmm1, %ymm1
retq 

Initial state:
%ymm1: ((%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[255:32] ∘ (%r8_vpbroadcastw_ymm_xmm[63:8] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[15:8])[7:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[23:0])[255:24] ∘ (%r9_vpbroadcastw_ymm_xmm[63:8] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[7:0])[7:0] ∘ ((%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[255:32] ∘ (%r8_vpbroadcastw_ymm_xmm[63:8] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[15:8])[7:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[31:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[31:0])))[23:0])[15:0]

State for specgen instruction: vbroadcastss %xmm2, %ymm1:
%ymm1: %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]) ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0] ∘ (%ymm2_vbroadcastss_ymm_xmm[31:0] ∘ %ymm2_vbroadcastss_ymm_xmm[31:0]))

Final state
%ymm1: %ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0])) ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0])))

=====================================
=====================================
Computing circuit for vpbroadcastw %xmm5, %ymm3

.target:
vbroadcastss %xmm2, %ymm1
callq .move_byte_1_of_ymm1_to_r8b
callq .move_byte_0_of_ymm1_to_r9b
callq .move_r8b_to_byte_3_of_ymm1
callq .move_r9b_to_byte_2_of_ymm1
vbroadcastss %xmm1, %ymm1
retq 

Initial state:
%ymm3: %ymm3_punpcklwd_xmm_xmm

State for specgen instruction: vpbroadcastw %xmm2, %ymm1:
%ymm1: %ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0])) ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0]) ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ (%ymm2_vpbroadcastw_ymm_xmm[15:0] ∘ %ymm2_vpbroadcastw_ymm_xmm[15:0])))

Final state
%ymm3: %ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32]) ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32])) ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32]) ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm3, %ymm6

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm6: %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm3, %xmm6, %xmm9

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm3, %xmm2, %xmm14

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm14: %ymm14_vpor_xmm_xmm_xmm

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpor_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vpor %xmm9, %xmm9, %xmm7

.target:
vorps %xmm3, %xmm2, %xmm14
vmovapd %xmm14, %xmm1
retq 

Initial state:
%ymm7: %ymm7_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpor %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

Final state
%ymm7: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm7, %xmm2

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpckldq_xmm_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm2: (%ymm2_vpunpckldq_xmm_xmm_xmm[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm1, %xmm3

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm3: %ymm3_mulpd_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm8: %ymm8_mulpd_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmulpd %ymm8, %ymm3, %ymm6

Final state:
%ymm6: mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[255:192]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[191:128]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[127:64]) ∘ mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_mulpd_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for mulpd %xmm3, %xmm2

.target:
vmovapd %xmm1, %xmm3
vmovaps %xmm2, %xmm8
vmulpd %ymm8, %ymm3, %ymm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vmulpd_xmm_xmm_xmm[127:0]

State for specgen instruction: mulpd %xmm2, %xmm1:
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vmulpd_xmm_xmm_xmm[255:128] ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmulpd_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmulpd %xmm6, %xmm2, %xmm12

.target:
mulpd %xmm3, %xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm12: %ymm12_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vmulpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]) ∘ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm12, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vpunpckldq %xmm3, %xmm0, %xmm0

.target:
vpbroadcastq %xmm3, %ymm6
vunpcklpd %xmm3, %xmm6, %xmm9
vpor %xmm9, %xmm9, %xmm7
unpcklps %xmm7, %xmm2
vmulpd %xmm6, %xmm2, %xmm12
vxorps %xmm12, %xmm2, %xmm1
movdqu %xmm2, %xmm1
retq 

Initial state:
%ymm0: 0x0₁₂₈ ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0] ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0]))

State for specgen instruction: vpunpckldq %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpbroadcastq_ymm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm1, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm8: %ymm8_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqa %ymm1, %ymm9

.target:
vminpd %ymm2, %ymm2, %ymm1
retq 

Initial state:
%ymm9: %ymm9_vpbroadcastq_ymm_xmm

State for specgen instruction: vmovdqa %ymm2, %ymm1:
%ymm1: (mincmp_double(%ymm2_vmovdqa_ymm_ymm[255:192], %ymm2_vmovdqa_ymm_ymm[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[255:192] : %ymm2_vmovdqa_ymm_ymm[255:192]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[191:128], %ymm2_vmovdqa_ymm_ymm[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[191:128] : %ymm2_vmovdqa_ymm_ymm[191:128]) ∘ ((mincmp_double(%ymm2_vmovdqa_ymm_ymm[127:64], %ymm2_vmovdqa_ymm_ymm[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[127:64] : %ymm2_vmovdqa_ymm_ymm[127:64]) ∘ (mincmp_double(%ymm2_vmovdqa_ymm_ymm[63:0], %ymm2_vmovdqa_ymm_ymm[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqa_ymm_ymm[63:0] : %ymm2_vmovdqa_ymm_ymm[63:0])))

Final state
%ymm9: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vpbroadcastq_ymm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_ymm_xmm

%xmm0: %ymm0_vpbroadcastq_ymm_xmm[127:0]
%xmm1: ((0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm3, %ymm6

.target:
vpbroadcastq %xmm2, %xmm1
vmovupd %xmm1, %xmm8
vmovdqa %ymm1, %ymm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm6: %ymm6_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpbroadcastq %xmm2, %ymm1:
%ymm1: (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0])))[127:0][127:0] ∘ (0x0₁₂₈ ∘ (%ymm2_vpbroadcastq_ymm_xmm[63:0] ∘ %ymm2_vpbroadcastq_ymm_xmm[63:0]))[127:0][127:0]

Final state
%ymm6: %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_r10d_r11d_r12d_r13d

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_vmovq_r64_xmm
%rdx/%rdx: %rdx_vmovq_r64_xmm

%xmm0: %ymm0_vmovq_r64_xmm[127:0]
%xmm1: %ymm1_vmovq_r64_xmm[127:0]

-------------------------------------
=====================================
Computing circuit for vmovq %xmm1, %r10

.target:
callq .move_128_032_xmm1_r10d_r11d_r12d_r13d
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r10/%r10: %r10_movq_r64_xmm

State for specgen instruction: vmovq %xmm1, %rbx:
%rbx/%rbx: (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]

Register        -> %rbx
  translates to => %r10
Value is               -> (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][63:32])[31:0][31:0] ∘ (0x0₃₂ ∘ %ymm1_vmovq_r64_xmm[127:0][31:0])[31:0][31:0]
  after renaming it is => %ymm1_movq_r64_xmm[63:0]

Final state
%r10/%r10: %ymm1_movq_r64_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for movq %r10, %rbx

Final state:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

-------------------------------------
=====================================
Computing circuit for movq %xmm3, %r8

.target:
vmovq %xmm1, %r10
movq %r10, %rbx
retq 

Initial state:
%r8/%r8: %r8_vunpcklpd_xmm_xmm_xmm

State for specgen instruction: movq %xmm1, %rbx:
%rbx/%rbx: %ymm1_movq_r64_xmm[63:0]

Register        -> %rbx
  translates to => %r8
Value is               -> %ymm1_movq_r64_xmm[63:0]
  after renaming it is => %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

Final state
%r8/%r8: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: %ymm0_vunpcklpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vunpcklpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vunpcklpd_xmm_xmm_xmm[63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vunpcklpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vunpcklpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vunpcklpd %xmm3, %xmm6, %xmm9

.target:
movq %xmm3, %r8
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vunpcklpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vunpcklpd_xmm_xmm_xmm[63:0][63:0] ∘ %ymm2_vunpcklpd_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm3, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vorps_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vorps %xmm3, %xmm2, %xmm14

.target:
vorpd %xmm3, %xmm2, %xmm1
retq 

Initial state:
%ymm14: %ymm14_vpor_xmm_xmm_xmm

State for specgen instruction: vorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vorps_xmm_xmm_xmm[127:64] | %ymm2_vorps_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vorps_xmm_xmm_xmm[63:0] | %ymm2_vorps_xmm_xmm_xmm[63:0]))

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm14, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpor_xmm_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vpor %xmm9, %xmm9, %xmm7

.target:
vorps %xmm3, %xmm2, %xmm14
vmovapd %xmm14, %xmm1
retq 

Initial state:
%ymm7: %ymm7_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vpor %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpor_xmm_xmm_xmm[127:64] | %ymm2_vpor_xmm_xmm_xmm[127:64]) ∘ (%ymm3_vpor_xmm_xmm_xmm[63:0] | %ymm2_vpor_xmm_xmm_xmm[63:0]))

Final state
%ymm7: 0x0₁₂₈ ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:0] ∘ %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: %ymm1_vbroadcastsd_ymm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm10, %xmm10, %xmm11

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm11: %ymm11_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][127:64])

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm2, %ymm2, %ymm10

Final state:
%ymm10: (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for vmaxpd %ymm10, %ymm2, %ymm1

Final state:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

-------------------------------------
=====================================
Computing circuit for vmovdqu %ymm11, %ymm10

.target:
vmaxps %ymm2, %ymm2, %ymm10
vmaxpd %ymm10, %ymm2, %ymm1
retq 

Initial state:
%ymm10: %ymm10_vbroadcastsd_ymm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_vbroadcastsd_ymm_xmm[127:0][63:0])

State for specgen instruction: vmovdqu %ymm2, %ymm1:
%ymm1: (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[255:192], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:192] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[255:192]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[191:128], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:128] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[191:128]) ∘ ((maxcmp_double(%ymm2_vmovdqu_ymm_ymm[127:64], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:64] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[127:64]) ∘ (maxcmp_double(%ymm2_vmovdqu_ymm_ymm[63:0], ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:0] : ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[255:224], %ymm2_vmovdqu_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[255:224] : %ymm2_vmovdqu_ymm_ymm[255:224]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[223:192], %ymm2_vmovdqu_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[223:192] : %ymm2_vmovdqu_ymm_ymm[223:192]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[191:160], %ymm2_vmovdqu_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[191:160] : %ymm2_vmovdqu_ymm_ymm[191:160]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[159:128], %ymm2_vmovdqu_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[159:128] : %ymm2_vmovdqu_ymm_ymm[159:128]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[127:96], %ymm2_vmovdqu_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[127:96] : %ymm2_vmovdqu_ymm_ymm[127:96]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[95:64], %ymm2_vmovdqu_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[95:64] : %ymm2_vmovdqu_ymm_ymm[95:64]) ∘ ((maxcmp_single(%ymm2_vmovdqu_ymm_ymm[63:32], %ymm2_vmovdqu_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[63:32] : %ymm2_vmovdqu_ymm_ymm[63:32]) ∘ (maxcmp_single(%ymm2_vmovdqu_ymm_ymm[31:0], %ymm2_vmovdqu_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovdqu_ymm_ymm[31:0] : %ymm2_vmovdqu_ymm_ymm[31:0]))))))))[63:0])))

Final state
%ymm10: 0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vbroadcastsd_ymm_xmm
%rdx/%rdx: %rdx_vbroadcastsd_ymm_xmm

%xmm0: %ymm0_vbroadcastsd_ymm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastsd %xmm1, %ymm9

.target:
callq .move_128_64_xmm2_xmm10_xmm11
vpunpcklqdq %xmm10, %xmm10, %xmm11
vmovdqu %ymm11, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm9: %ymm9_unpcklps_xmm_xmm

State for specgen instruction: vbroadcastsd %xmm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0]))[127:0][127:0] ∘ (0x0₆₄ ∘ (0x0₆₄ ∘ (%ymm2_vbroadcastsd_ymm_xmm[63:0] ∘ %ymm2_vbroadcastsd_ymm_xmm[63:0])))[127:0][127:0]

Final state
%ymm9: %ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0] ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm9, %xmm10

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm10: %ymm10_unpcklps_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm10: 0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovddup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovddup_xmm_xmm
%rdx/%rdx: %rdx_vmovddup_xmm_xmm

%xmm0: %ymm0_vmovddup_xmm_xmm[127:0]
%xmm1: (%ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: %ymm0_vpbroadcastq_xmm_xmm[127:0]
%xmm1: %ymm1_vpbroadcastq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r10, %r11

Final state:
%r11/%r11: %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpbroadcastq_xmm_xmm
%rdx/%rdx: %rdx_vpbroadcastq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpbroadcastq %xmm1, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r10, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovddup_xmm_xmm[255:128] ∘ (%ymm2_vmovddup_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovddup_xmm_xmm[127:0][63:0][63:0])

State for specgen instruction: vpbroadcastq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpbroadcastq_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

=====================================
=====================================
Computing circuit for vmovddup %xmm2, %xmm15

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
vpbroadcastq %xmm1, %xmm1
retq 

Initial state:
%ymm15: %ymm15_unpcklps_xmm_xmm

State for specgen instruction: vmovddup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovddup_xmm_xmm[63:0] ∘ %ymm2_vmovddup_xmm_xmm[63:0])

Final state
%ymm15: 0x0₁₂₈ ∘ (%ymm2_unpcklps_xmm_xmm[63:0] ∘ %ymm2_unpcklps_xmm_xmm[63:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: %ymm0_unpckhps_xmm_xmm[127:0]
%xmm1: %ymm1_unpckhps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: %ymm0_vmovupd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovupd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovupd_xmm_xmm
%rdx/%rdx: %rdx_vmovupd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmovupd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovupd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7

Final state:
%rax/%rax: %rax_vmaxss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmaxss_xmm_xmm_xmm

%xmm0: %ymm0_vmaxss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm3

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm3: %ymm3_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm11

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm11: %ymm11_vmaxps_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmaxps %ymm3, %ymm11, %ymm1

Final state:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

-------------------------------------
=====================================
Computing circuit for vmaxps %xmm3, %xmm4, %xmm13

.target:
vmovdqa %xmm3, %xmm3
vmovdqa %xmm2, %xmm11
vmaxps %ymm3, %ymm11, %ymm1
retq 

Initial state:
%ymm13: %ymm13_vmaxss_xmm_xmm_xmm

State for specgen instruction: vmaxps %xmm3, %xmm2, %xmm1:
%ymm1: (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[255:224] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[255:224]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[223:192] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[223:192]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[191:160] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[191:160]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[159:128] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[159:128]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[127:96] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[127:96]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[95:64] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[95:64]) ∘ ((maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[63:32] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[63:32]) ∘ (maxcmp_single((0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0], (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])[0:0] = 0x1₁ ? (0x0₁₂₈ ∘ %ymm2_vmaxps_xmm_xmm_xmm[127:0])[31:0] : (0x0₁₂₈ ∘ %ymm3_vmaxps_xmm_xmm_xmm[127:0])[31:0])))))))

Final state
%ymm13: 0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ (0x0₃₂ ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[127:96]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[127:96]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[95:64]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[95:64]) ∘ ((maxcmp_single(0x0₃₂, %ymm3_vmaxss_xmm_xmm_xmm[63:32]) = 0x1₁ ? 0x0₃₂ : %ymm3_vmaxss_xmm_xmm_xmm[63:32]) ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: %ymm1_movss_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: %ymm0_vpmovzxdq_xmm_xmm[127:0]
%xmm1: %ymm1_vpmovzxdq_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_byte_5_of_ymm1_to_r9b

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm2

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_vpmovzxdq_xmm_xmm
%rdx/%rdx: %rdx_vpmovzxdq_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpmovzxdq %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_byte_5_of_ymm1_to_r9b
callq .move_064_128_r8_r9_xmm2
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%ymm8: %ymm8_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][31:0])

State for specgen instruction: vpmovzxdq %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][63:32]))[127:0][63:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₉₆ ∘ (0x0₂₅₆[255:128] ∘ ((%ymm2_vpmovzxdq_xmm_xmm[127:0][127:64][63:8] ∘ 0x0₂₅₆[47:40])[63:0] ∘ %ymm2_vpmovzxdq_xmm_xmm[127:0][63:0][63:0]))[127:0][31:0]))[127:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movss_xmm_xmm
%rdx/%rdx: %rdx_movss_xmm_xmm

%xmm0: %ymm0_movss_xmm_xmm[127:0]
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movss %xmm13, %xmm1

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vpmovzxdq %xmm2, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[127:0]

State for specgen instruction: movss %xmm2, %xmm1:
%xmm1: (%ymm1_movss_xmm_xmm[255:128] ∘ ((%ymm11_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_movss_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movss_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[63:32] ∘ (0x0₃₂ ∘ %ymm2_movss_xmm_xmm[31:0])))[127:0][31:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vmaxss %xmm13, %xmm13, %xmm0

.target:
vmovupd %xmm2, %xmm1
callq .move_128_032_xmm1_xmm4_xmm5_xmm6_xmm7
vmaxps %xmm3, %xmm4, %xmm13
movss %xmm13, %xmm1
retq 

Initial state:
%ymm0: %ymm0_unpckhps_xmm_xmm

State for specgen instruction: vmaxss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm2_vmaxss_xmm_xmm_xmm[127:0])[255:128] ∘ (%ymm2_vmaxss_xmm_xmm_xmm[127:32] ∘ (maxcmp_single(%ymm2_vmaxss_xmm_xmm_xmm[31:0], %ymm3_vmaxss_xmm_xmm_xmm[31:0]) = 0x1₁ ? %ymm2_vmaxss_xmm_xmm_xmm[31:0] : %ymm3_vmaxss_xmm_xmm_xmm[31:0]))

Final state
%ymm0: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm11, %xmm13, %xmm9

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][63:32])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovsldup_xmm_xmm
%rdx/%rdx: %rdx_vmovsldup_xmm_xmm

%xmm0: %ymm0_vmovsldup_xmm_xmm[127:0]
%xmm1: %ymm1_vmovsldup_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm2, %xmm9

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm9: %ymm9_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm9: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: %ymm1_movd_r32_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r10_r11

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_064_r10d_r11d_rbx

Final state:
%rax/%rax: %rax_movd_r32_xmm
%rdx/%rdx: %rdx_movd_r32_xmm

%xmm0: %ymm0_movd_r32_xmm[127:0]
%xmm1: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for movd %xmm2, %r8d

.target:
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
callq .move_128_256_xmm8_xmm9_ymm1
callq .move_128_064_xmm1_r10_r11
callq .move_032_064_r10d_r11d_rbx
retq 

Initial state:
%r8/%r8: %r8_vbroadcastss_xmm_xmm

State for specgen instruction: movd %xmm1, %ebx:
%rbx/%rbx: ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]

Register        -> %rbx
  translates to => %r8
Value is               -> ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][127:64][31:0][31:0] ∘ ((%ymm9_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][63:32]))[127:0][127:0] ∘ (%ymm8_movd_r32_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_movd_r32_xmm[127:0][31:0]))[127:0][127:0])[127:0][63:0][31:0][31:0]
  after renaming it is => 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

Final state
%r8/%r8: 0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0]

=====================================
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movslq %r8d, %r9

Final state:
%r9/%r9: sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm10_xmm11

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_64_xmm1_xmm8_xmm9

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vbroadcastss_xmm_xmm
%rdx/%rdx: %rdx_vbroadcastss_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vbroadcastss %xmm13, %xmm5

.target:
movd %xmm2, %r8d
vzeroall 
movslq %r8d, %r9
callq .move_064_128_r8_r9_xmm1
callq .move_128_64_xmm1_xmm10_xmm11
callq .move_128_64_xmm1_xmm8_xmm9
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm5: %ymm5_vmovsldup_xmm_xmm

State for specgen instruction: vbroadcastss %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[255:128] ∘ ((0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][127:64]))[127:0][31:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₆₄ ∘ (0x0₂₅₆[255:128] ∘ (sign-extend-64((0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[31:0])[63:0] ∘ (0x0₃₂ ∘ %ymm2_vbroadcastss_xmm_xmm[31:0])[63:0]))[127:0][63:0]))[127:0][31:0])

Final state
%ymm5: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklqdq_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklqdq_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for movq %r8, %r11

Final state:
%r11/%r11: %ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vpunpcklqdq_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklqdq_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklqdq %xmm5, %xmm9, %xmm1

.target:
callq .move_128_064_xmm3_r8_r9
callq .move_128_064_xmm2_r10_r11
vzeroall 
movq %r8, %r11
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm1: %ymm1_vmovsldup_xmm_xmm

State for specgen instruction: vpunpcklqdq %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm3_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0] ∘ %ymm2_vpunpcklqdq_xmm_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

=====================================
=====================================
Computing circuit for vmovsldup %xmm2, %xmm12

.target:
callq .move_128_64_xmm2_xmm12_xmm13
vbroadcastss %xmm2, %xmm9
vbroadcastss %xmm13, %xmm5
vpunpcklqdq %xmm5, %xmm9, %xmm1
retq 

Initial state:
%ymm12: %ymm12_movsldup_xmm_xmm

State for specgen instruction: vmovsldup %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (%ymm2_vmovsldup_xmm_xmm[95:64] ∘ %ymm2_vmovsldup_xmm_xmm[95:64] ∘ (%ymm2_vmovsldup_xmm_xmm[31:0] ∘ %ymm2_vmovsldup_xmm_xmm[31:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm12, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_movsldup_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for movsldup %xmm0, %xmm13

.target:
vmovsldup %xmm2, %xmm12
movdqa %xmm12, %xmm1
retq 

Initial state:
%xmm13: (%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[127:0]

State for specgen instruction: movsldup %xmm2, %xmm1:
%xmm1: (%ymm1_movsldup_xmm_xmm[255:128] ∘ (%ymm2_movsldup_xmm_xmm[95:64] ∘ %ymm2_movsldup_xmm_xmm[95:64] ∘ (%ymm2_movsldup_xmm_xmm[31:0] ∘ %ymm2_movsldup_xmm_xmm[31:0])))[127:0]

Final state
%xmm13: ((%ymm13_unpckhps_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:0][127:64]))[255:128] ∘ (0x0₆₄ ∘ (%ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm2_unpckhps_xmm_xmm[95:64])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: %ymm0_vrcpps_xmm_xmm[127:0]
%xmm1: %ymm1_vrcpps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vrcpps %ymm1, %ymm10

Final state:
%ymm10: approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vrcpps_xmm_xmm
%rdx/%rdx: %rdx_vrcpps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vrcpps %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
vrcpps %ymm1, %ymm10
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmovss_xmm_xmm_xmm

State for specgen instruction: vrcpps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[127:0][127:0] ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[255:224]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[223:192]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[191:160]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[159:128]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[127:96]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[95:64]) ∘ (approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[63:32]) ∘ approx_reciprocal_single((0x0₂₅₆[255:128] ∘ (%ymm2_vrcpps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vrcpps_xmm_xmm[127:0][63:0][63:0]))[31:0]))))))))[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm3, %xmm8

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm8: %ymm8_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_vmovss_xmm_xmm_xmm
%rdx/%rdx: %rdx_vmovss_xmm_xmm_xmm

%xmm0: %ymm0_vmovss_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovss %xmm10, %xmm13, %xmm8

.target:
vrcpps %xmm3, %xmm1
callq .move_128_032_xmm2_xmm8_xmm9_xmm10_xmm11
vmovdqu %xmm3, %xmm8
callq .move_032_128_xmm8_xmm9_xmm10_xmm11_xmm1
retq 

Initial state:
%ymm8: %ymm8_unpckhps_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm1_unpckhps_xmm_xmm[127:0][31:0])

State for specgen instruction: vmovss %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[127:96]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[95:64]) ∘ (approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[63:32]) ∘ approx_reciprocal_single(%ymm3_vmovss_xmm_xmm_xmm[31:0])))))[255:128] ∘ ((%ymm11_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][127:96]))[127:0][31:0] ∘ (%ymm10_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][95:64]))[127:0][31:0] ∘ (%ymm9_vmovss_xmm_xmm_xmm[255:128] ∘ (0x0₉₆ ∘ %ymm2_vmovss_xmm_xmm_xmm[127:0][63:32]))[127:0][31:0] ∘ (0x0₁₂₈ ∘ %ymm3_vmovss_xmm_xmm_xmm[127:0])[127:0][31:0])

Final state
%ymm8: 0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64])

=====================================
-------------------------------------
Getting base circuit for callq .move_64_128_xmm8_xmm9_xmm1

Final state:
%rax/%rax: %rax_unpckhps_xmm_xmm
%rdx/%rdx: %rdx_unpckhps_xmm_xmm

%xmm0: (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm2_unpckhps_xmm_xmm[95:64]))[127:0]
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for unpckhps %xmm15, %xmm10

.target:
callq .move_128_64_xmm2_xmm12_xmm13
callq .move_128_032_xmm1_xmm8_xmm9_xmm10_xmm11
vmaxss %xmm13, %xmm13, %xmm0
vmovss %xmm11, %xmm13, %xmm9
movsldup %xmm0, %xmm13
vmovss %xmm10, %xmm13, %xmm8
callq .move_64_128_xmm8_xmm9_xmm1
retq 

Initial state:
%xmm10: (0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[127:0]

State for specgen instruction: unpckhps %xmm2, %xmm1:
%xmm1: (%ymm1_unpckhps_xmm_xmm[255:128] ∘ ((0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[127:96] ∘ %ymm1_unpckhps_xmm_xmm[127:96]))[127:0][63:0] ∘ (0x0₁₂₈ ∘ (0x0₆₄ ∘ %ymm2_unpckhps_xmm_xmm[95:64] ∘ %ymm1_unpckhps_xmm_xmm[95:64]))[127:0][63:0]))[127:0]

Final state
%xmm10: ((0x0₁₂₈ ∘ (%ymm1_unpcklps_xmm_xmm[63:0] ∘ %ymm1_unpcklps_xmm_xmm[63:0]))[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: %ymm1_movapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_movapd_xmm_xmm
%rdx/%rdx: %rdx_movapd_xmm_xmm

%xmm0: %ymm0_movapd_xmm_xmm[127:0]
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movapd %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%xmm1: %ymm1_unpcklps_xmm_xmm[127:0]

State for specgen instruction: movapd %xmm2, %xmm1:
%xmm1: (%ymm1_movapd_xmm_xmm[255:128] ∘ (%ymm2_movapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for unpcklps %xmm7, %xmm2

.target:
vbroadcastsd %xmm1, %ymm9
vmovdqa %xmm9, %xmm10
vmovddup %xmm2, %xmm15
unpckhps %xmm15, %xmm10
movapd %xmm10, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpckldq_xmm_xmm_xmm[127:0]

State for specgen instruction: unpcklps %xmm2, %xmm1:
%xmm1: (%ymm1_unpcklps_xmm_xmm[255:128] ∘ (%ymm2_unpcklps_xmm_xmm[63:32] ∘ %ymm1_unpcklps_xmm_xmm[63:32] ∘ (%ymm2_unpcklps_xmm_xmm[31:0] ∘ %ymm1_unpcklps_xmm_xmm[31:0])))[127:0]

Final state
%xmm2: (%ymm2_vpunpckldq_xmm_xmm_xmm[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm1, %xmm3

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm3: %ymm3_mulpd_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: %ymm0_vmovaps_xmm_xmm[127:0]
%xmm1: %ymm1_vmovaps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovaps_xmm_xmm
%rdx/%rdx: %rdx_vmovaps_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovaps %xmm2, %xmm8

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm8: %ymm8_mulpd_xmm_xmm

State for specgen instruction: vmovaps %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovaps_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovaps_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm8: 0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for vmulpd %ymm8, %ymm3, %ymm6

Final state:
%ymm6: mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[255:192], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[255:192]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[191:128], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[191:128]) ∘ (mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[127:64], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[127:64]) ∘ mul_double((0x0₁₂₈ ∘ %ymm1_mulpd_xmm_xmm[127:0])[63:0], (0x0₁₂₈ ∘ %ymm2_mulpd_xmm_xmm[127:0])[63:0])))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_mulpd_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for mulpd %xmm3, %xmm2

.target:
vmovapd %xmm1, %xmm3
vmovaps %xmm2, %xmm8
vmulpd %ymm8, %ymm3, %ymm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vmulpd_xmm_xmm_xmm[127:0]

State for specgen instruction: mulpd %xmm2, %xmm1:
%xmm1: (%ymm1_mulpd_xmm_xmm[255:128] ∘ (mul_double(%ymm1_mulpd_xmm_xmm[127:64], %ymm2_mulpd_xmm_xmm[127:64]) ∘ mul_double(%ymm1_mulpd_xmm_xmm[63:0], %ymm2_mulpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vmulpd_xmm_xmm_xmm[255:128] ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm1: %ymm1_vmulpd_xmm_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

=====================================
=====================================
Computing circuit for vmulpd %xmm6, %xmm2, %xmm12

.target:
mulpd %xmm3, %xmm2
vmovdqu %xmm2, %xmm1
retq 

Initial state:
%ymm12: %ymm12_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vmulpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ (mul_double(%ymm2_vmulpd_xmm_xmm_xmm[127:64], %ymm3_vmulpd_xmm_xmm_xmm[127:64]) ∘ mul_double(%ymm2_vmulpd_xmm_xmm_xmm[63:0], %ymm3_vmulpd_xmm_xmm_xmm[63:0]))

Final state
%ymm12: 0x0₁₂₈ ∘ (mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]) ∘ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm12, %xmm2, %xmm1

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckldq_xmm_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_64_xmm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: %ymm1_movdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_64_128_xmm10_xmm11_xmm1

Final state:
%rax/%rax: %rax_movdqu_xmm_xmm
%rdx/%rdx: %rdx_movdqu_xmm_xmm

%xmm0: %ymm0_movdqu_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqu %xmm2, %xmm1

.target:
callq .move_128_64_xmm2_xmm10_xmm11
callq .move_64_128_xmm10_xmm11_xmm1
retq 

Initial state:
%xmm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[127:0]

State for specgen instruction: movdqu %xmm2, %xmm1:
%xmm1: (%ymm1_movdqu_xmm_xmm[255:128] ∘ ((%ymm11_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][127:64]))[127:0][63:0] ∘ (%ymm10_movdqu_xmm_xmm[255:128] ∘ (0x0₆₄ ∘ %ymm2_movdqu_xmm_xmm[127:0][63:0]))[127:0][63:0]))[127:0]

Final state
%xmm1: ((0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0])))[127:0]

=====================================
=====================================
Computing circuit for vpunpckldq %xmm2, %xmm0, %xmm13

.target:
vpbroadcastq %xmm3, %ymm6
vunpcklpd %xmm3, %xmm6, %xmm9
vpor %xmm9, %xmm9, %xmm7
unpcklps %xmm7, %xmm2
vmulpd %xmm6, %xmm2, %xmm12
vxorps %xmm12, %xmm2, %xmm1
movdqu %xmm2, %xmm1
retq 

Initial state:
%ymm13: %ymm13_punpcklwd_xmm_xmm

State for specgen instruction: vpunpckldq %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ ((%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0])) ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0] ⊕ mul_double(%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0], %ymm3_vpunpckldq_xmm_xmm_xmm[63:0]))))[255:128] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[63:32] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpckldq_xmm_xmm_xmm[31:0] ∘ %ymm2_vpunpckldq_xmm_xmm_xmm[31:0]))

Final state
%ymm13: 0x0₁₂₈ ∘ (%ymm2_punpcklwd_xmm_xmm[63:32] ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32]) ∘ (%ymm2_punpcklwd_xmm_xmm[31:0] ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vandnpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vandnpd_ymm_ymm_ymm

%xmm0: %ymm0_vandnpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vandnpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm2, %xmm2

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm2: %ymm2_por_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm2: 0x0₁₂₈ ∘ %ymm2_por_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm1, %xmm2, %xmm3

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm3: %ymm3_por_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_por_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_por_xmm_xmm[255:128] ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for por %xmm1, %xmm2

.target:
vmovapd %xmm2, %xmm2
vorpd %xmm1, %xmm2, %xmm3
movdqa %xmm3, %xmm1
retq 

Initial state:
%xmm2: %ymm2_pandn_xmm_xmm[127:0]

State for specgen instruction: por %xmm2, %xmm1:
%xmm1: (%ymm1_por_xmm_xmm[255:128] ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_pandn_xmm_xmm[255:128] ∘ ((%ymm2_pandn_xmm_xmm[127:64] | %ymm1_pandn_xmm_xmm[127:64]) ∘ (%ymm2_pandn_xmm_xmm[63:0] | %ymm1_pandn_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm2, %xmm1, %xmm6

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm6: %ymm6_xorps_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm6: 0x0₁₂₈ ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_xorps_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_xorps_xmm_xmm[255:128] ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for xorps %xmm2, %xmm1

.target:
vxorps %xmm2, %xmm1, %xmm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm1: %ymm1_pxor_xmm_xmm[127:0]

State for specgen instruction: xorps %xmm2, %xmm1:
%xmm1: (%ymm1_xorps_xmm_xmm[255:128] ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0])))[127:0]

Final state
%xmm1: (%ymm1_pxor_xmm_xmm[255:128] ∘ ((%ymm1_pxor_xmm_xmm[127:64] ⊕ %ymm2_pxor_xmm_xmm[127:64]) ∘ (%ymm1_pxor_xmm_xmm[63:0] ⊕ %ymm2_pxor_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for pxor %xmm2, %xmm1

.target:
xorps %xmm2, %xmm1
retq 

Initial state:
%xmm1: %ymm1_pandn_xmm_xmm[127:0]

State for specgen instruction: pxor %xmm2, %xmm1:
%xmm1: (%ymm1_pxor_xmm_xmm[255:128] ∘ ((%ymm1_pxor_xmm_xmm[127:64] ⊕ %ymm2_pxor_xmm_xmm[127:64]) ∘ (%ymm1_pxor_xmm_xmm[63:0] ⊕ %ymm2_pxor_xmm_xmm[63:0])))[127:0]

Final state
%xmm1: (%ymm1_pandn_xmm_xmm[255:128] ∘ ((%ymm1_pandn_xmm_xmm[127:64] ⊕ (%ymm2_pandn_xmm_xmm[127:64] | %ymm1_pandn_xmm_xmm[127:64])) ∘ (%ymm1_pandn_xmm_xmm[63:0] ⊕ (%ymm2_pandn_xmm_xmm[63:0] | %ymm1_pandn_xmm_xmm[63:0]))))[127:0]

=====================================
=====================================
Computing circuit for pandn %xmm3, %xmm2

.target:
por %xmm1, %xmm2
pxor %xmm2, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vandnpd_ymm_ymm_ymm[127:0]

State for specgen instruction: pandn %xmm2, %xmm1:
%xmm1: (%ymm1_pandn_xmm_xmm[255:128] ∘ ((%ymm1_pandn_xmm_xmm[127:64] ⊕ (%ymm2_pandn_xmm_xmm[127:64] | %ymm1_pandn_xmm_xmm[127:64])) ∘ (%ymm1_pandn_xmm_xmm[63:0] ⊕ (%ymm2_pandn_xmm_xmm[63:0] | %ymm1_pandn_xmm_xmm[63:0]))))[127:0]

Final state
%xmm2: (%ymm2_vandnpd_ymm_ymm_ymm[255:128] ∘ ((%ymm2_vandnpd_ymm_ymm_ymm[127:64] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[127:64] | %ymm2_vandnpd_ymm_ymm_ymm[127:64])) ∘ (%ymm2_vandnpd_ymm_ymm_ymm[63:0] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[63:0] | %ymm2_vandnpd_ymm_ymm_ymm[63:0]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_256_128_ymm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vandnpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vandnpd_ymm_ymm_ymm

%xmm0: %ymm0_vandnpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vandnpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm10, %xmm14

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm14: %ymm14_vandnpd_ymm_ymm_ymm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm2_vandnpd_ymm_ymm_ymm[127:64] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[127:64] | %ymm2_vandnpd_ymm_ymm_ymm[127:64])) ∘ (%ymm2_vandnpd_ymm_ymm_ymm[63:0] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[63:0] | %ymm2_vandnpd_ymm_ymm_ymm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm2, %xmm3, %xmm12

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm12: %ymm12_vandnpd_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm12: 0x0₁₂₈ ∘ ((%ymm2_vandnpd_xmm_xmm_xmm[127:64] | %ymm3_vandnpd_xmm_xmm_xmm[127:64]) ∘ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] | %ymm3_vandnpd_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovupd_ymm_ymm
%rdx/%rdx: %rdx_vmovupd_ymm_ymm

%xmm0: %ymm0_vmovupd_ymm_ymm[127:0]
%xmm1: %ymm1_vmovupd_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vminps %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_single(%ymm2_vmovupd_ymm_ymm[255:224], %ymm2_vmovupd_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[255:224] : %ymm2_vmovupd_ymm_ymm[255:224]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[223:192], %ymm2_vmovupd_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[223:192] : %ymm2_vmovupd_ymm_ymm[223:192]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[191:160], %ymm2_vmovupd_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[191:160] : %ymm2_vmovupd_ymm_ymm[191:160]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[159:128], %ymm2_vmovupd_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[159:128] : %ymm2_vmovupd_ymm_ymm[159:128]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[127:96], %ymm2_vmovupd_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[127:96] : %ymm2_vmovupd_ymm_ymm[127:96]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[95:64], %ymm2_vmovupd_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[95:64] : %ymm2_vmovupd_ymm_ymm[95:64]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[63:32], %ymm2_vmovupd_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[63:32] : %ymm2_vmovupd_ymm_ymm[63:32]) ∘ (mincmp_single(%ymm2_vmovupd_ymm_ymm[31:0], %ymm2_vmovupd_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[31:0] : %ymm2_vmovupd_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovupd_ymm_ymm
%rdx/%rdx: %rdx_vmovupd_ymm_ymm

%xmm0: %ymm0_vmovupd_ymm_ymm[127:0]
%xmm1: (((mincmp_single(%ymm2_vmovupd_ymm_ymm[255:224], %ymm2_vmovupd_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[255:224] : %ymm2_vmovupd_ymm_ymm[255:224]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[223:192], %ymm2_vmovupd_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[223:192] : %ymm2_vmovupd_ymm_ymm[223:192]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[191:160], %ymm2_vmovupd_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[191:160] : %ymm2_vmovupd_ymm_ymm[191:160]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[159:128], %ymm2_vmovupd_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[159:128] : %ymm2_vmovupd_ymm_ymm[159:128]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[127:96], %ymm2_vmovupd_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[127:96] : %ymm2_vmovupd_ymm_ymm[127:96]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[95:64], %ymm2_vmovupd_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[95:64] : %ymm2_vmovupd_ymm_ymm[95:64]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[63:32], %ymm2_vmovupd_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[63:32] : %ymm2_vmovupd_ymm_ymm[63:32]) ∘ (mincmp_single(%ymm2_vmovupd_ymm_ymm[31:0], %ymm2_vmovupd_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[31:0] : %ymm2_vmovupd_ymm_ymm[31:0]))))))))[255:128] ∘ (%ymm2_vmovupd_ymm_ymm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_ymm_ymm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %ymm12, %ymm1

.target:
callq .move_128_064_xmm2_r12_r13
vminps %ymm2, %ymm2, %ymm1
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vandnpd_xmm_xmm_xmm

State for specgen instruction: vmovupd %ymm2, %ymm1:
%ymm1: ((mincmp_single(%ymm2_vmovupd_ymm_ymm[255:224], %ymm2_vmovupd_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[255:224] : %ymm2_vmovupd_ymm_ymm[255:224]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[223:192], %ymm2_vmovupd_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[223:192] : %ymm2_vmovupd_ymm_ymm[223:192]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[191:160], %ymm2_vmovupd_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[191:160] : %ymm2_vmovupd_ymm_ymm[191:160]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[159:128], %ymm2_vmovupd_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[159:128] : %ymm2_vmovupd_ymm_ymm[159:128]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[127:96], %ymm2_vmovupd_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[127:96] : %ymm2_vmovupd_ymm_ymm[127:96]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[95:64], %ymm2_vmovupd_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[95:64] : %ymm2_vmovupd_ymm_ymm[95:64]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[63:32], %ymm2_vmovupd_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[63:32] : %ymm2_vmovupd_ymm_ymm[63:32]) ∘ (mincmp_single(%ymm2_vmovupd_ymm_ymm[31:0], %ymm2_vmovupd_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[31:0] : %ymm2_vmovupd_ymm_ymm[31:0]))))))))[255:128] ∘ (%ymm2_vmovupd_ymm_ymm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_ymm_ymm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₃₂ ∘ (0x0₃₂ ∘ 0x0₆₄) ∘ ((%ymm2_vandnpd_xmm_xmm_xmm[127:64] | %ymm3_vandnpd_xmm_xmm_xmm[127:64]) ∘ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] | %ymm3_vandnpd_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm2, %xmm1, %xmm6

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm6: %ymm6_xorps_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm6: 0x0₁₂₈ ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_xorps_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_xorps_xmm_xmm[255:128] ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for xorps %xmm2, %xmm1

.target:
vxorps %xmm2, %xmm1, %xmm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm1: %ymm1_pxor_xmm_xmm[127:0]

State for specgen instruction: xorps %xmm2, %xmm1:
%xmm1: (%ymm1_xorps_xmm_xmm[255:128] ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0])))[127:0]

Final state
%xmm1: (%ymm1_pxor_xmm_xmm[255:128] ∘ ((%ymm1_pxor_xmm_xmm[127:64] ⊕ %ymm2_pxor_xmm_xmm[127:64]) ∘ (%ymm1_pxor_xmm_xmm[63:0] ⊕ %ymm2_pxor_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for pxor %xmm1, %xmm2

.target:
xorps %xmm2, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vandnpd_xmm_xmm_xmm[127:0]

State for specgen instruction: pxor %xmm2, %xmm1:
%xmm1: (%ymm1_pxor_xmm_xmm[255:128] ∘ ((%ymm1_pxor_xmm_xmm[127:64] ⊕ %ymm2_pxor_xmm_xmm[127:64]) ∘ (%ymm1_pxor_xmm_xmm[63:0] ⊕ %ymm2_pxor_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vandnpd_xmm_xmm_xmm[255:128] ∘ ((%ymm2_vandnpd_xmm_xmm_xmm[127:64] ⊕ (%ymm2_vandnpd_xmm_xmm_xmm[127:64] | %ymm3_vandnpd_xmm_xmm_xmm[127:64])) ∘ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] ⊕ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] | %ymm3_vandnpd_xmm_xmm_xmm[63:0]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: 0x0₃₂ ∘ (0x0₃₂ ∘ 0x0₆₄) ∘ ((%ymm2_vandnpd_xmm_xmm_xmm[127:64] | %ymm3_vandnpd_xmm_xmm_xmm[127:64]) ∘ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] | %ymm3_vandnpd_xmm_xmm_xmm[63:0]))

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm2_vandnpd_xmm_xmm_xmm[127:64] ⊕ (%ymm2_vandnpd_xmm_xmm_xmm[127:64] | %ymm3_vandnpd_xmm_xmm_xmm[127:64])) ∘ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] ⊕ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] | %ymm3_vandnpd_xmm_xmm_xmm[63:0])))

=====================================
=====================================
Computing circuit for vandnpd %xmm13, %xmm11, %xmm11

.target:
vorpd %xmm2, %xmm3, %xmm12
vmovupd %ymm12, %ymm1
pxor %xmm1, %xmm2
vmovdqa %xmm2, %xmm1
retq 

Initial state:
%ymm11: %ymm11_vandnpd_ymm_ymm_ymm[255:128] ∘ (%ymm2_vandnpd_ymm_ymm_ymm[255:128] ∘ ((%ymm2_vandnpd_ymm_ymm_ymm[127:64] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[127:64] | %ymm2_vandnpd_ymm_ymm_ymm[127:64])) ∘ (%ymm2_vandnpd_ymm_ymm_ymm[63:0] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[63:0] | %ymm2_vandnpd_ymm_ymm_ymm[63:0]))))[255:128]

State for specgen instruction: vandnpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm2_vandnpd_xmm_xmm_xmm[127:64] ⊕ (%ymm2_vandnpd_xmm_xmm_xmm[127:64] | %ymm3_vandnpd_xmm_xmm_xmm[127:64])) ∘ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] ⊕ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] | %ymm3_vandnpd_xmm_xmm_xmm[63:0])))

Final state
%ymm11: 0x0₁₂₈ ∘ ((%ymm2_vandnpd_ymm_ymm_ymm[255:192] ⊕ (%ymm2_vandnpd_ymm_ymm_ymm[255:192] | %ymm3_vandnpd_ymm_ymm_ymm[255:192])) ∘ (%ymm2_vandnpd_ymm_ymm_ymm[191:128] ⊕ (%ymm2_vandnpd_ymm_ymm_ymm[191:128] | %ymm3_vandnpd_ymm_ymm_ymm[191:128])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm3

Final state:
%rax/%rax: %rax_vandnpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vandnpd_ymm_ymm_ymm

%xmm0: %ymm0_vandnpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vandnpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm8_xmm9

Final state:
%rax/%rax: %rax_vorpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vorpd_ymm_ymm_ymm

%xmm0: %ymm0_vorpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vorpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm2, %xmm2

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm2: %ymm2_por_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm2: 0x0₁₂₈ ∘ %ymm2_por_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm1, %xmm2, %xmm3

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm3: %ymm3_por_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_por_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_por_xmm_xmm[255:128] ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for por %xmm2, %xmm8

.target:
vmovapd %xmm2, %xmm2
vorpd %xmm1, %xmm2, %xmm3
movdqa %xmm3, %xmm1
retq 

Initial state:
%xmm8: (%ymm8_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[127:0])[127:0]

State for specgen instruction: por %xmm2, %xmm1:
%xmm1: (%ymm1_por_xmm_xmm[255:128] ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0])))[127:0]

Final state
%xmm8: ((%ymm8_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[127:0])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[127:64] | %ymm2_vorpd_ymm_ymm_ymm[127:64]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[63:0] | %ymm2_vorpd_ymm_ymm_ymm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_256_128_ymm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vorpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vorpd_ymm_ymm_ymm

%xmm0: %ymm0_vorpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vorpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm1, %xmm2, %xmm3

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm3: %ymm3_orps_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ ((%ymm1_orps_xmm_xmm[127:64] | %ymm2_orps_xmm_xmm[127:64]) ∘ (%ymm1_orps_xmm_xmm[63:0] | %ymm2_orps_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm10_xmm11

Final state:
%rax/%rax: %rax_orps_xmm_xmm
%rdx/%rdx: %rdx_orps_xmm_xmm

%xmm0: %ymm0_orps_xmm_xmm[127:0]
%xmm1: %ymm1_orps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_orps_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_orps_xmm_xmm[255:128] ∘ ((%ymm1_orps_xmm_xmm[127:64] | %ymm2_orps_xmm_xmm[127:64]) ∘ (%ymm1_orps_xmm_xmm[63:0] | %ymm2_orps_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for orps %xmm2, %xmm1

.target:
vorpd %xmm1, %xmm2, %xmm3
callq .move_256_128_ymm3_xmm10_xmm11
movdqa %xmm10, %xmm1
retq 

Initial state:
%xmm1: %ymm1_orpd_xmm_xmm[127:0]

State for specgen instruction: orps %xmm2, %xmm1:
%xmm1: (%ymm1_orps_xmm_xmm[255:128] ∘ ((%ymm1_orps_xmm_xmm[127:64] | %ymm2_orps_xmm_xmm[127:64]) ∘ (%ymm1_orps_xmm_xmm[63:0] | %ymm2_orps_xmm_xmm[63:0])))[127:0]

Final state
%xmm1: (%ymm1_orpd_xmm_xmm[255:128] ∘ ((%ymm1_orpd_xmm_xmm[127:64] | %ymm2_orpd_xmm_xmm[127:64]) ∘ (%ymm1_orpd_xmm_xmm[63:0] | %ymm2_orpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for orpd %xmm11, %xmm9

.target:
orps %xmm2, %xmm1
retq 

Initial state:
%xmm9: (%ymm9_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[255:128])[127:0]

State for specgen instruction: orpd %xmm2, %xmm1:
%xmm1: (%ymm1_orpd_xmm_xmm[255:128] ∘ ((%ymm1_orpd_xmm_xmm[127:64] | %ymm2_orpd_xmm_xmm[127:64]) ∘ (%ymm1_orpd_xmm_xmm[63:0] | %ymm2_orpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm9: ((%ymm9_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[255:128])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[255:192] | %ymm2_vorpd_ymm_ymm_ymm[255:192]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[191:128] | %ymm2_vorpd_ymm_ymm_ymm[191:128])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vorpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vorpd_ymm_ymm_ymm

%xmm0: %ymm0_vorpd_ymm_ymm_ymm[127:0]
%xmm1: (((%ymm9_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[255:128])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[255:192] | %ymm2_vorpd_ymm_ymm_ymm[255:192]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[191:128] | %ymm2_vorpd_ymm_ymm_ymm[191:128])))[127:0][127:0] ∘ ((%ymm8_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[127:0])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[127:64] | %ymm2_vorpd_ymm_ymm_ymm[127:64]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[63:0] | %ymm2_vorpd_ymm_ymm_ymm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %ymm3, %ymm14, %ymm1

.target:
callq .move_256_128_ymm3_xmm8_xmm9
por %xmm2, %xmm8
callq .move_256_128_ymm2_xmm10_xmm11
orpd %xmm11, %xmm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm1: %ymm1_vandnpd_ymm_ymm_ymm

State for specgen instruction: vorpd %ymm3, %ymm2, %ymm1:
%ymm1: ((%ymm9_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[255:128])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[255:192] | %ymm2_vorpd_ymm_ymm_ymm[255:192]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[191:128] | %ymm2_vorpd_ymm_ymm_ymm[191:128])))[127:0][127:0] ∘ ((%ymm8_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[127:0])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[127:64] | %ymm2_vorpd_ymm_ymm_ymm[127:64]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[63:0] | %ymm2_vorpd_ymm_ymm_ymm[63:0])))[127:0][127:0]

Final state
%ymm1: (%ymm2_vandnpd_ymm_ymm_ymm[255:192] ⊕ (%ymm2_vandnpd_ymm_ymm_ymm[255:192] | %ymm3_vandnpd_ymm_ymm_ymm[255:192]) | 0x0₆₄) ∘ (%ymm2_vandnpd_ymm_ymm_ymm[191:128] ⊕ (%ymm2_vandnpd_ymm_ymm_ymm[191:128] | %ymm3_vandnpd_ymm_ymm_ymm[191:128]) | 0x0₆₄) ∘ ((%ymm2_vandnpd_ymm_ymm_ymm[127:64] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[127:64] | %ymm2_vandnpd_ymm_ymm_ymm[127:64])) ∘ (%ymm2_vandnpd_ymm_ymm_ymm[63:0] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[63:0] | %ymm2_vandnpd_ymm_ymm_ymm[63:0])))

=====================================
=====================================
Computing circuit for vandnpd %ymm13, %ymm14, %ymm13

.target:
callq .move_256_128_ymm3_xmm12_xmm13
pandn %xmm3, %xmm2
callq .move_256_128_ymm2_xmm10_xmm11
vmovdqa %xmm10, %xmm14
vandnpd %xmm13, %xmm11, %xmm11
callq .move_128_256_xmm10_xmm11_ymm3
vorpd %ymm3, %ymm14, %ymm1
retq 

Initial state:
%ymm13: 0x0₁₂₈ ∘ (%ymm2_punpcklwd_xmm_xmm[63:32] ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32]) ∘ (%ymm2_punpcklwd_xmm_xmm[31:0] ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0])))

State for specgen instruction: vandnpd %ymm3, %ymm2, %ymm1:
%ymm1: (%ymm2_vandnpd_ymm_ymm_ymm[255:192] ⊕ (%ymm2_vandnpd_ymm_ymm_ymm[255:192] | %ymm3_vandnpd_ymm_ymm_ymm[255:192]) | 0x0₆₄) ∘ (%ymm2_vandnpd_ymm_ymm_ymm[191:128] ⊕ (%ymm2_vandnpd_ymm_ymm_ymm[191:128] | %ymm3_vandnpd_ymm_ymm_ymm[191:128]) | 0x0₆₄) ∘ ((%ymm2_vandnpd_ymm_ymm_ymm[127:64] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[127:64] | %ymm2_vandnpd_ymm_ymm_ymm[127:64])) ∘ (%ymm2_vandnpd_ymm_ymm_ymm[63:0] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[63:0] | %ymm2_vandnpd_ymm_ymm_ymm[63:0])))

Final state
%ymm13: 0x0₆₄ ∘ 0x0₆₄ ∘ ((0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32]) ⊕ (%ymm2_punpcklwd_xmm_xmm[63:32] ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32]) | 0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32]))) ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) ⊕ (%ymm2_punpcklwd_xmm_xmm[31:0] ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) | 0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0]))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm2, %xmm1, %xmm6

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm6: %ymm6_xorps_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm6: 0x0₁₂₈ ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_xorps_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_xorps_xmm_xmm[255:128] ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for xorps %xmm13, %xmm1

.target:
vxorps %xmm2, %xmm1, %xmm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm1: (%ymm1_punpcklwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[15:0]))))[127:0]

State for specgen instruction: xorps %xmm2, %xmm1:
%xmm1: (%ymm1_xorps_xmm_xmm[255:128] ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0])))[127:0]

Final state
%xmm1: ((%ymm1_punpcklwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[15:0]))))[255:128] ∘ ((0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[47:32]) ⊕ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32]) ⊕ (%ymm2_punpcklwd_xmm_xmm[63:32] ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32]) | 0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32])))) ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[15:0]) ⊕ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) ⊕ (%ymm2_punpcklwd_xmm_xmm[31:0] ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) | 0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0]))))))[127:0]

=====================================
=====================================
Computing circuit for punpcklwd %xmm3, %xmm2

.target:
pmovzxwd %xmm2, %xmm5
pmovzxwd %xmm1, %xmm1
vpbroadcastw %xmm5, %xmm0
vmovsldup %xmm5, %xmm14
callq .move_128_032_xmm2_xmm4_xmm5_xmm6_xmm7
vpbroadcastw %xmm5, %ymm3
vpunpckldq %xmm3, %xmm0, %xmm0
vpunpckldq %xmm2, %xmm0, %xmm13
vandnpd %ymm13, %ymm14, %ymm13
xorps %xmm13, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vpunpcklwd_xmm_xmm_xmm[127:0]

State for specgen instruction: punpcklwd %xmm2, %xmm1:
%xmm1: ((%ymm1_punpcklwd_xmm_xmm[255:128] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[47:32]) ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[15:0]))))[255:128] ∘ ((0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[47:32]) ⊕ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32]) ⊕ (%ymm2_punpcklwd_xmm_xmm[63:32] ∘ (%ymm2_punpcklwd_xmm_xmm[47:32] ∘ %ymm2_punpcklwd_xmm_xmm[47:32]) | 0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[47:32])))) ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm1_punpcklwd_xmm_xmm[15:0]) ⊕ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) ⊕ (%ymm2_punpcklwd_xmm_xmm[31:0] ∘ (%ymm2_punpcklwd_xmm_xmm[15:0] ∘ %ymm2_punpcklwd_xmm_xmm[15:0]) | 0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm2_punpcklwd_xmm_xmm[15:0]))))))[127:0]

Final state
%xmm2: (%ymm2_vpunpcklwd_xmm_xmm_xmm[255:128] ∘ ((0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[47:32]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32]) ⊕ (%ymm3_vpunpcklwd_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32])))) ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[15:0]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]) ⊕ (%ymm3_vpunpcklwd_xmm_xmm_xmm[31:0] ∘ (%ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]))))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vpunpcklwd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklwd_xmm_xmm_xmm

%xmm0: %ymm0_vpunpcklwd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpunpcklwd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vpunpcklwd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpunpcklwd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vpunpcklwd_xmm_xmm_xmm[255:128] ∘ ((0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[47:32]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32]) ⊕ (%ymm3_vpunpcklwd_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32])))) ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[15:0]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]) ⊕ (%ymm3_vpunpcklwd_xmm_xmm_xmm[31:0] ∘ (%ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]))))))[127:0][127:64][63:0] ∘ (%ymm2_vpunpcklwd_xmm_xmm_xmm[255:128] ∘ ((0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[47:32]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32]) ⊕ (%ymm3_vpunpcklwd_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32])))) ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[15:0]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]) ⊕ (%ymm3_vpunpcklwd_xmm_xmm_xmm[31:0] ∘ (%ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]))))))[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklwd %xmm9, %xmm13, %xmm11

.target:
punpcklwd %xmm3, %xmm2
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm11: %ymm11_vpunpcklwd_ymm_ymm_ymm

State for specgen instruction: vpunpcklwd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vpunpcklwd_xmm_xmm_xmm[255:128] ∘ ((0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[47:32]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32]) ⊕ (%ymm3_vpunpcklwd_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32])))) ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[15:0]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]) ⊕ (%ymm3_vpunpcklwd_xmm_xmm_xmm[31:0] ∘ (%ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]))))))[127:0][127:64][63:0] ∘ (%ymm2_vpunpcklwd_xmm_xmm_xmm[255:128] ∘ ((0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[47:32]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32]) ⊕ (%ymm3_vpunpcklwd_xmm_xmm_xmm[63:32] ∘ (%ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[47:32])))) ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_xmm_xmm_xmm[15:0]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]) ⊕ (%ymm3_vpunpcklwd_xmm_xmm_xmm[31:0] ∘ (%ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_xmm_xmm_xmm[15:0]))))))[127:0][63:0][63:0])

Final state
%ymm11: 0x0₁₂₈ ∘ ((0x0₁₆ ∘ %ymm2_vpunpcklwd_ymm_ymm_ymm[191:176] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_ymm_ymm_ymm[175:160]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[175:160] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[175:160]) ⊕ (%ymm3_vpunpcklwd_ymm_ymm_ymm[191:160] ∘ (%ymm3_vpunpcklwd_ymm_ymm_ymm[175:160] ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[175:160]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[175:160] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[175:160])))) ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_ymm_ymm_ymm[159:144] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_ymm_ymm_ymm[143:128]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[143:128] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[143:128]) ⊕ (%ymm3_vpunpcklwd_ymm_ymm_ymm[159:128] ∘ (%ymm3_vpunpcklwd_ymm_ymm_ymm[143:128] ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[143:128]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[143:128] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[143:128])))))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm1

Final state:
%rax/%rax: %rax_vpunpcklwd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vpunpcklwd_ymm_ymm_ymm

%xmm0: %ymm0_vpunpcklwd_ymm_ymm_ymm[127:0]
%xmm1: ((0x0₁₂₈ ∘ ((0x0₁₆ ∘ %ymm2_vpunpcklwd_ymm_ymm_ymm[191:176] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_ymm_ymm_ymm[175:160]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[175:160] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[175:160]) ⊕ (%ymm3_vpunpcklwd_ymm_ymm_ymm[191:160] ∘ (%ymm3_vpunpcklwd_ymm_ymm_ymm[175:160] ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[175:160]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[175:160] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[175:160])))) ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_ymm_ymm_ymm[159:144] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_ymm_ymm_ymm[143:128]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[143:128] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[143:128]) ⊕ (%ymm3_vpunpcklwd_ymm_ymm_ymm[159:128] ∘ (%ymm3_vpunpcklwd_ymm_ymm_ymm[143:128] ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[143:128]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[143:128] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[143:128]))))))[127:0][127:0] ∘ (0x0₁₂₈ ∘ ((0x0₁₆ ∘ %ymm2_vpunpcklwd_ymm_ymm_ymm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_ymm_ymm_ymm[47:32]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[47:32]) ⊕ (%ymm3_vpunpcklwd_ymm_ymm_ymm[63:32] ∘ (%ymm3_vpunpcklwd_ymm_ymm_ymm[47:32] ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[47:32]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[47:32])))) ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_ymm_ymm_ymm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_ymm_ymm_ymm[15:0]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[15:0]) ⊕ (%ymm3_vpunpcklwd_ymm_ymm_ymm[31:0] ∘ (%ymm3_vpunpcklwd_ymm_ymm_ymm[15:0] ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[15:0]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[15:0]))))))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vpunpcklwd %ymm5, %ymm4, %ymm1

.target:
callq .move_256_128_ymm2_xmm12_xmm13
callq .move_256_128_ymm3_xmm8_xmm9
vpunpcklwd %xmm8, %xmm2, %xmm10
vpunpcklwd %xmm9, %xmm13, %xmm11
callq .move_128_256_xmm10_xmm11_ymm1
retq 

Initial state:
%ymm1: %ymm1_vpunpckhwd_ymm_ymm_ymm

State for specgen instruction: vpunpcklwd %ymm3, %ymm2, %ymm1:
%ymm1: (0x0₁₂₈ ∘ ((0x0₁₆ ∘ %ymm2_vpunpcklwd_ymm_ymm_ymm[191:176] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_ymm_ymm_ymm[175:160]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[175:160] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[175:160]) ⊕ (%ymm3_vpunpcklwd_ymm_ymm_ymm[191:160] ∘ (%ymm3_vpunpcklwd_ymm_ymm_ymm[175:160] ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[175:160]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[175:160] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[175:160])))) ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_ymm_ymm_ymm[159:144] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_ymm_ymm_ymm[143:128]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[143:128] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[143:128]) ⊕ (%ymm3_vpunpcklwd_ymm_ymm_ymm[159:128] ∘ (%ymm3_vpunpcklwd_ymm_ymm_ymm[143:128] ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[143:128]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[143:128] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[143:128]))))))[127:0][127:0] ∘ (0x0₁₂₈ ∘ ((0x0₁₆ ∘ %ymm2_vpunpcklwd_ymm_ymm_ymm[63:48] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_ymm_ymm_ymm[47:32]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[47:32]) ⊕ (%ymm3_vpunpcklwd_ymm_ymm_ymm[63:32] ∘ (%ymm3_vpunpcklwd_ymm_ymm_ymm[47:32] ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[47:32]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[47:32] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[47:32])))) ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_ymm_ymm_ymm[31:16] ∘ (0x0₁₆ ∘ %ymm2_vpunpcklwd_ymm_ymm_ymm[15:0]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[15:0]) ⊕ (%ymm3_vpunpcklwd_ymm_ymm_ymm[31:0] ∘ (%ymm3_vpunpcklwd_ymm_ymm_ymm[15:0] ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[15:0]) | 0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[15:0] ∘ (0x0₁₆ ∘ %ymm3_vpunpcklwd_ymm_ymm_ymm[15:0]))))))[127:0][127:0]

Final state
%ymm1: (0x0₁₆ ∘ %ymm2_vpunpckhwd_ymm_ymm_ymm[255:240] ∘ (0x0₁₆ ∘ %ymm2_vpunpckhwd_ymm_ymm_ymm[239:224]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[239:224] ∘ (0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[239:224]) ⊕ (%ymm3_vpunpckhwd_ymm_ymm_ymm[255:224] ∘ (%ymm3_vpunpckhwd_ymm_ymm_ymm[239:224] ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[239:224]) | 0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[239:224] ∘ (0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[239:224])))) ∘ (0x0₁₆ ∘ %ymm2_vpunpckhwd_ymm_ymm_ymm[223:208] ∘ (0x0₁₆ ∘ %ymm2_vpunpckhwd_ymm_ymm_ymm[207:192]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[207:192] ∘ (0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[207:192]) ⊕ (%ymm3_vpunpckhwd_ymm_ymm_ymm[223:192] ∘ (%ymm3_vpunpckhwd_ymm_ymm_ymm[207:192] ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[207:192]) | 0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[207:192] ∘ (0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[207:192])))) ∘ ((0x0₁₆ ∘ %ymm2_vpunpckhwd_ymm_ymm_ymm[127:112] ∘ (0x0₁₆ ∘ %ymm2_vpunpckhwd_ymm_ymm_ymm[111:96]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[111:96] ∘ (0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[111:96]) ⊕ (%ymm3_vpunpckhwd_ymm_ymm_ymm[127:96] ∘ (%ymm3_vpunpckhwd_ymm_ymm_ymm[111:96] ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[111:96]) | 0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[111:96] ∘ (0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[111:96])))) ∘ (0x0₁₆ ∘ %ymm2_vpunpckhwd_ymm_ymm_ymm[95:80] ∘ (0x0₁₆ ∘ %ymm2_vpunpckhwd_ymm_ymm_ymm[79:64]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[79:64] ∘ (0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[79:64]) ⊕ (%ymm3_vpunpckhwd_ymm_ymm_ymm[95:64] ∘ (%ymm3_vpunpckhwd_ymm_ymm_ymm[79:64] ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[79:64]) | 0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[79:64] ∘ (0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[79:64])))))

=====================================
=====================================
Computing circuit for vpunpckhwd %ymm3, %ymm2, %ymm1

.target:
vpunpckhqdq %ymm3, %ymm2, %ymm4
vunpckhpd %ymm4, %ymm4, %ymm5
vpunpcklwd %ymm5, %ymm4, %ymm1
retq 

Initial state:
%ymm1: %ymm1

State for specgen instruction: vpunpckhwd %ymm3, %ymm2, %ymm1:
%ymm1: (0x0₁₆ ∘ %ymm2_vpunpckhwd_ymm_ymm_ymm[255:240] ∘ (0x0₁₆ ∘ %ymm2_vpunpckhwd_ymm_ymm_ymm[239:224]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[239:224] ∘ (0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[239:224]) ⊕ (%ymm3_vpunpckhwd_ymm_ymm_ymm[255:224] ∘ (%ymm3_vpunpckhwd_ymm_ymm_ymm[239:224] ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[239:224]) | 0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[239:224] ∘ (0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[239:224])))) ∘ (0x0₁₆ ∘ %ymm2_vpunpckhwd_ymm_ymm_ymm[223:208] ∘ (0x0₁₆ ∘ %ymm2_vpunpckhwd_ymm_ymm_ymm[207:192]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[207:192] ∘ (0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[207:192]) ⊕ (%ymm3_vpunpckhwd_ymm_ymm_ymm[223:192] ∘ (%ymm3_vpunpckhwd_ymm_ymm_ymm[207:192] ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[207:192]) | 0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[207:192] ∘ (0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[207:192])))) ∘ ((0x0₁₆ ∘ %ymm2_vpunpckhwd_ymm_ymm_ymm[127:112] ∘ (0x0₁₆ ∘ %ymm2_vpunpckhwd_ymm_ymm_ymm[111:96]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[111:96] ∘ (0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[111:96]) ⊕ (%ymm3_vpunpckhwd_ymm_ymm_ymm[127:96] ∘ (%ymm3_vpunpckhwd_ymm_ymm_ymm[111:96] ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[111:96]) | 0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[111:96] ∘ (0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[111:96])))) ∘ (0x0₁₆ ∘ %ymm2_vpunpckhwd_ymm_ymm_ymm[95:80] ∘ (0x0₁₆ ∘ %ymm2_vpunpckhwd_ymm_ymm_ymm[79:64]) ⊕ (0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[79:64] ∘ (0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[79:64]) ⊕ (%ymm3_vpunpckhwd_ymm_ymm_ymm[95:64] ∘ (%ymm3_vpunpckhwd_ymm_ymm_ymm[79:64] ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[79:64]) | 0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[79:64] ∘ (0x0₁₆ ∘ %ymm3_vpunpckhwd_ymm_ymm_ymm[79:64])))))

Final state
%ymm1: (0x0₁₆ ∘ %ymm2[255:240] ∘ (0x0₁₆ ∘ %ymm2[239:224]) ⊕ (0x0₁₆ ∘ %ymm3[239:224] ∘ (0x0₁₆ ∘ %ymm3[239:224]) ⊕ (%ymm3[255:224] ∘ (%ymm3[239:224] ∘ %ymm3[239:224]) | 0x0₁₆ ∘ %ymm3[239:224] ∘ (0x0₁₆ ∘ %ymm3[239:224])))) ∘ (0x0₁₆ ∘ %ymm2[223:208] ∘ (0x0₁₆ ∘ %ymm2[207:192]) ⊕ (0x0₁₆ ∘ %ymm3[207:192] ∘ (0x0₁₆ ∘ %ymm3[207:192]) ⊕ (%ymm3[223:192] ∘ (%ymm3[207:192] ∘ %ymm3[207:192]) | 0x0₁₆ ∘ %ymm3[207:192] ∘ (0x0₁₆ ∘ %ymm3[207:192])))) ∘ ((0x0₁₆ ∘ %ymm2[127:112] ∘ (0x0₁₆ ∘ %ymm2[111:96]) ⊕ (0x0₁₆ ∘ %ymm3[111:96] ∘ (0x0₁₆ ∘ %ymm3[111:96]) ⊕ (%ymm3[127:96] ∘ (%ymm3[111:96] ∘ %ymm3[111:96]) | 0x0₁₆ ∘ %ymm3[111:96] ∘ (0x0₁₆ ∘ %ymm3[111:96])))) ∘ (0x0₁₆ ∘ %ymm2[95:80] ∘ (0x0₁₆ ∘ %ymm2[79:64]) ⊕ (0x0₁₆ ∘ %ymm3[79:64] ∘ (0x0₁₆ ∘ %ymm3[79:64]) ⊕ (%ymm3[95:64] ∘ (%ymm3[79:64] ∘ %ymm3[79:64]) | 0x0₁₆ ∘ %ymm3[79:64] ∘ (0x0₁₆ ∘ %ymm3[79:64])))))

=====================================
Circuits:

%ymm1  : (0x0₁₆ ∘ %ymm2[255:240] ∘ (0x0₁₆ ∘ %ymm2[239:224]) ⊕ (0x0₁₆ ∘ %ymm3[239:224] ∘ (0x0₁₆ ∘ %ymm3[239:224]) ⊕ (%ymm3[255:224] ∘ (%ymm3[239:224] ∘ %ymm3[239:224]) | 0x0₁₆ ∘ %ymm3[239:224] ∘ (0x0₁₆ ∘ %ymm3[239:224])))) ∘ (0x0₁₆ ∘ %ymm2[223:208] ∘ (0x0₁₆ ∘ %ymm2[207:192]) ⊕ (0x0₁₆ ∘ %ymm3[207:192] ∘ (0x0₁₆ ∘ %ymm3[207:192]) ⊕ (%ymm3[223:192] ∘ (%ymm3[207:192] ∘ %ymm3[207:192]) | 0x0₁₆ ∘ %ymm3[207:192] ∘ (0x0₁₆ ∘ %ymm3[207:192])))) ∘ ((0x0₁₆ ∘ %ymm2[127:112] ∘ (0x0₁₆ ∘ %ymm2[111:96]) ⊕ (0x0₁₆ ∘ %ymm3[111:96] ∘ (0x0₁₆ ∘ %ymm3[111:96]) ⊕ (%ymm3[127:96] ∘ (%ymm3[111:96] ∘ %ymm3[111:96]) | 0x0₁₆ ∘ %ymm3[111:96] ∘ (0x0₁₆ ∘ %ymm3[111:96])))) ∘ (0x0₁₆ ∘ %ymm2[95:80] ∘ (0x0₁₆ ∘ %ymm2[79:64]) ⊕ (0x0₁₆ ∘ %ymm3[79:64] ∘ (0x0₁₆ ∘ %ymm3[79:64]) ⊕ (%ymm3[95:64] ∘ (%ymm3[79:64] ∘ %ymm3[79:64]) | 0x0₁₆ ∘ %ymm3[79:64] ∘ (0x0₁₆ ∘ %ymm3[79:64])))))

sigfpe  : sigfpe
sigbus  : sigbus
sigsegv : sigsegv

*/