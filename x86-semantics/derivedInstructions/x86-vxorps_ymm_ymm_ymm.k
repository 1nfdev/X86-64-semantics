// Autogenerated using stratification.
requires "x86-configuration.k"

module VXORPS-YMM-YMM-YMM
  imports X86-CONFIGURATION

  rule <k>
    execinstr (vxorps R1:Ymm, R2:Ymm, R3:Ymm,  .Typedoperands) => .
  ...</k>
    <regstate>
RSMap:Map => updateMap(RSMap,
convToRegKeys(R3) |-> (concatenateMInt(concatenateMInt(xorMInt(orMInt(orMInt(extractMInt(getParentValue(R2, RSMap), 0, 64), extractMInt(getParentValue(R1, RSMap), 0, 64)), xorMInt(orMInt(xorMInt(extractMInt(getParentValue(R1, RSMap), 0, 64), extractMInt(getParentValue(R2, RSMap), 0, 64)), extractMInt(getParentValue(R2, RSMap), 0, 64)), xorMInt(extractMInt(getParentValue(R1, RSMap), 0, 64), extractMInt(getParentValue(R2, RSMap), 0, 64)))), xorMInt(orMInt(xorMInt(extractMInt(getParentValue(R1, RSMap), 0, 64), extractMInt(getParentValue(R2, RSMap), 0, 64)), extractMInt(getParentValue(R2, RSMap), 0, 64)), xorMInt(extractMInt(getParentValue(R1, RSMap), 0, 64), extractMInt(getParentValue(R2, RSMap), 0, 64)))), xorMInt(orMInt(orMInt(extractMInt(getParentValue(R2, RSMap), 64, 128), extractMInt(getParentValue(R1, RSMap), 64, 128)), xorMInt(orMInt(xorMInt(extractMInt(getParentValue(R1, RSMap), 64, 128), extractMInt(getParentValue(R2, RSMap), 64, 128)), extractMInt(getParentValue(R2, RSMap), 64, 128)), xorMInt(extractMInt(getParentValue(R1, RSMap), 64, 128), extractMInt(getParentValue(R2, RSMap), 64, 128)))), xorMInt(orMInt(xorMInt(extractMInt(getParentValue(R1, RSMap), 64, 128), extractMInt(getParentValue(R2, RSMap), 64, 128)), extractMInt(getParentValue(R2, RSMap), 64, 128)), xorMInt(extractMInt(getParentValue(R1, RSMap), 64, 128), extractMInt(getParentValue(R2, RSMap), 64, 128))))), concatenateMInt(xorMInt(orMInt(xorMInt(orMInt(xorMInt(extractMInt(getParentValue(R1, RSMap), 128, 192), extractMInt(getParentValue(R2, RSMap), 128, 192)), extractMInt(getParentValue(R2, RSMap), 128, 192)), xorMInt(extractMInt(getParentValue(R1, RSMap), 128, 192), extractMInt(getParentValue(R2, RSMap), 128, 192))), orMInt(extractMInt(getParentValue(R2, RSMap), 128, 192), extractMInt(getParentValue(R1, RSMap), 128, 192))), xorMInt(orMInt(xorMInt(extractMInt(getParentValue(R1, RSMap), 128, 192), extractMInt(getParentValue(R2, RSMap), 128, 192)), extractMInt(getParentValue(R2, RSMap), 128, 192)), xorMInt(extractMInt(getParentValue(R1, RSMap), 128, 192), extractMInt(getParentValue(R2, RSMap), 128, 192)))), xorMInt(orMInt(xorMInt(orMInt(xorMInt(extractMInt(getParentValue(R1, RSMap), 192, 256), extractMInt(getParentValue(R2, RSMap), 192, 256)), extractMInt(getParentValue(R2, RSMap), 192, 256)), xorMInt(extractMInt(getParentValue(R1, RSMap), 192, 256), extractMInt(getParentValue(R2, RSMap), 192, 256))), orMInt(extractMInt(getParentValue(R2, RSMap), 192, 256), extractMInt(getParentValue(R1, RSMap), 192, 256))), xorMInt(orMInt(xorMInt(extractMInt(getParentValue(R1, RSMap), 192, 256), extractMInt(getParentValue(R2, RSMap), 192, 256)), extractMInt(getParentValue(R2, RSMap), 192, 256)), xorMInt(extractMInt(getParentValue(R1, RSMap), 192, 256), extractMInt(getParentValue(R2, RSMap), 192, 256)))))) )


)

    </regstate>
endmodule

module VXORPS-YMM-YMM-YMM-SEMANTICS
  imports VXORPS-YMM-YMM-YMM
endmodule
/*
TargetInstr:
vxorps %ymm3, %ymm2, %ymm1
RWSet:
maybe read:{ %ymm2 %ymm3 }
must read:{ %ymm2 %ymm3 }
maybe write:{ %ymm1 }
must write:{ %ymm1 }
maybe undef:{ }
must undef:{ }
required flags:{ avx }

Circuit:
circuit:vpor %ymm2, %ymm3, %ymm14     #  1     0    4      OPC=vpor_ymm_ymm_ymm
circuit:vandps %ymm3, %ymm2, %ymm4    #  2     0x4  4      OPC=vandps_ymm_ymm_ymm
circuit:vandnpd %ymm14, %ymm4, %ymm1  #  3     0x8  5      OPC=vandnpd_ymm_ymm_ymm
BVF:
WARNING: No live out values provided, assuming { }
WARNING: No def in values provided; assuming { %mxcsr::rc[0] }
Target

vxorps %ymm3, %ymm2, %ymm1

  maybe read:      { %ymm2 %ymm3 }
  must read:       { %ymm2 %ymm3 }
  maybe write:     { %ymm1 }
  must write:      { %ymm1 }
  maybe undef:     { }
  must undef:      { }
  required flags:  { avx }

-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm8_xmm9

Final state:
%rax/%rax: %rax_vorpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vorpd_ymm_ymm_ymm

%xmm0: %ymm0_vorpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vorpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm2, %xmm2

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm2: %ymm2_por_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm2: 0x0₁₂₈ ∘ %ymm2_por_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm1, %xmm2, %xmm3

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm3: %ymm3_por_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_por_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_por_xmm_xmm[255:128] ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for por %xmm2, %xmm8

.target:
vmovapd %xmm2, %xmm2
vorpd %xmm1, %xmm2, %xmm3
movdqa %xmm3, %xmm1
retq 

Initial state:
%xmm8: (%ymm8_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[127:0])[127:0]

State for specgen instruction: por %xmm2, %xmm1:
%xmm1: (%ymm1_por_xmm_xmm[255:128] ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0])))[127:0]

Final state
%xmm8: ((%ymm8_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[127:0])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[127:64] | %ymm2_vorpd_ymm_ymm_ymm[127:64]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[63:0] | %ymm2_vorpd_ymm_ymm_ymm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_256_128_ymm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vorpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vorpd_ymm_ymm_ymm

%xmm0: %ymm0_vorpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vorpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm1, %xmm2, %xmm3

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm3: %ymm3_orps_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ ((%ymm1_orps_xmm_xmm[127:64] | %ymm2_orps_xmm_xmm[127:64]) ∘ (%ymm1_orps_xmm_xmm[63:0] | %ymm2_orps_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm10_xmm11

Final state:
%rax/%rax: %rax_orps_xmm_xmm
%rdx/%rdx: %rdx_orps_xmm_xmm

%xmm0: %ymm0_orps_xmm_xmm[127:0]
%xmm1: %ymm1_orps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_orps_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_orps_xmm_xmm[255:128] ∘ ((%ymm1_orps_xmm_xmm[127:64] | %ymm2_orps_xmm_xmm[127:64]) ∘ (%ymm1_orps_xmm_xmm[63:0] | %ymm2_orps_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for orps %xmm2, %xmm1

.target:
vorpd %xmm1, %xmm2, %xmm3
callq .move_256_128_ymm3_xmm10_xmm11
movdqa %xmm10, %xmm1
retq 

Initial state:
%xmm1: %ymm1_orpd_xmm_xmm[127:0]

State for specgen instruction: orps %xmm2, %xmm1:
%xmm1: (%ymm1_orps_xmm_xmm[255:128] ∘ ((%ymm1_orps_xmm_xmm[127:64] | %ymm2_orps_xmm_xmm[127:64]) ∘ (%ymm1_orps_xmm_xmm[63:0] | %ymm2_orps_xmm_xmm[63:0])))[127:0]

Final state
%xmm1: (%ymm1_orpd_xmm_xmm[255:128] ∘ ((%ymm1_orpd_xmm_xmm[127:64] | %ymm2_orpd_xmm_xmm[127:64]) ∘ (%ymm1_orpd_xmm_xmm[63:0] | %ymm2_orpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for orpd %xmm11, %xmm9

.target:
orps %xmm2, %xmm1
retq 

Initial state:
%xmm9: (%ymm9_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[255:128])[127:0]

State for specgen instruction: orpd %xmm2, %xmm1:
%xmm1: (%ymm1_orpd_xmm_xmm[255:128] ∘ ((%ymm1_orpd_xmm_xmm[127:64] | %ymm2_orpd_xmm_xmm[127:64]) ∘ (%ymm1_orpd_xmm_xmm[63:0] | %ymm2_orpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm9: ((%ymm9_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[255:128])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[255:192] | %ymm2_vorpd_ymm_ymm_ymm[255:192]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[191:128] | %ymm2_vorpd_ymm_ymm_ymm[191:128])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vorpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vorpd_ymm_ymm_ymm

%xmm0: %ymm0_vorpd_ymm_ymm_ymm[127:0]
%xmm1: (((%ymm9_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[255:128])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[255:192] | %ymm2_vorpd_ymm_ymm_ymm[255:192]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[191:128] | %ymm2_vorpd_ymm_ymm_ymm[191:128])))[127:0][127:0] ∘ ((%ymm8_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[127:0])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[127:64] | %ymm2_vorpd_ymm_ymm_ymm[127:64]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[63:0] | %ymm2_vorpd_ymm_ymm_ymm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %ymm2, %ymm3, %ymm5

.target:
callq .move_256_128_ymm3_xmm8_xmm9
por %xmm2, %xmm8
callq .move_256_128_ymm2_xmm10_xmm11
orpd %xmm11, %xmm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm5: %ymm5_vpor_ymm_ymm_ymm

State for specgen instruction: vorpd %ymm3, %ymm2, %ymm1:
%ymm1: ((%ymm9_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[255:128])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[255:192] | %ymm2_vorpd_ymm_ymm_ymm[255:192]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[191:128] | %ymm2_vorpd_ymm_ymm_ymm[191:128])))[127:0][127:0] ∘ ((%ymm8_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[127:0])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[127:64] | %ymm2_vorpd_ymm_ymm_ymm[127:64]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[63:0] | %ymm2_vorpd_ymm_ymm_ymm[63:0])))[127:0][127:0]

Final state
%ymm5: (%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0]))

=====================================
-------------------------------------
Getting base circuit for vminpd %ymm5, %ymm5, %ymm1

Final state:
%ymm1: (mincmp_double(((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[255:192], ((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[255:192])[0:0] = 0x1₁ ? ((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[255:192] : ((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[255:192]) ∘ ((mincmp_double(((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[191:128], ((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[191:128])[0:0] = 0x1₁ ? ((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[191:128] : ((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[191:128]) ∘ ((mincmp_double(((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[127:64], ((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[127:64])[0:0] = 0x1₁ ? ((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[127:64] : ((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[127:64]) ∘ (mincmp_double(((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[63:0], ((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[63:0])[0:0] = 0x1₁ ? ((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[63:0] : ((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[63:0])))

-------------------------------------
=====================================
Computing circuit for vpor %ymm2, %ymm3, %ymm14

.target:
vorpd %ymm2, %ymm3, %ymm5
vminpd %ymm5, %ymm5, %ymm1
retq 

Initial state:
%ymm14: %ymm14_vxorps_ymm_ymm_ymm

State for specgen instruction: vpor %ymm3, %ymm2, %ymm1:
%ymm1: (mincmp_double(((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[255:192], ((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[255:192])[0:0] = 0x1₁ ? ((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[255:192] : ((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[255:192]) ∘ ((mincmp_double(((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[191:128], ((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[191:128])[0:0] = 0x1₁ ? ((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[191:128] : ((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[191:128]) ∘ ((mincmp_double(((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[127:64], ((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[127:64])[0:0] = 0x1₁ ? ((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[127:64] : ((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[127:64]) ∘ (mincmp_double(((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[63:0], ((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[63:0])[0:0] = 0x1₁ ? ((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[63:0] : ((%ymm2_vpor_ymm_ymm_ymm[255:192] | %ymm3_vpor_ymm_ymm_ymm[255:192]) ∘ (%ymm2_vpor_ymm_ymm_ymm[191:128] | %ymm3_vpor_ymm_ymm_ymm[191:128]) ∘ ((%ymm2_vpor_ymm_ymm_ymm[127:64] | %ymm3_vpor_ymm_ymm_ymm[127:64]) ∘ (%ymm2_vpor_ymm_ymm_ymm[63:0] | %ymm3_vpor_ymm_ymm_ymm[63:0])))[63:0])))

Final state
%ymm14: (%ymm3_vxorps_ymm_ymm_ymm[255:192] | %ymm2_vxorps_ymm_ymm_ymm[255:192]) ∘ ((%ymm3_vxorps_ymm_ymm_ymm[191:128] | %ymm2_vxorps_ymm_ymm_ymm[191:128]) ∘ ((%ymm3_vxorps_ymm_ymm_ymm[127:64] | %ymm2_vxorps_ymm_ymm_ymm[127:64]) ∘ (%ymm3_vxorps_ymm_ymm_ymm[63:0] | %ymm2_vxorps_ymm_ymm_ymm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r10_r11

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: %ymm0_vmovdqu_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqu_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm3

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: 0x0₂₅₆[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_256_xmm12_xmm13_ymm1

Final state:
%rax/%rax: %rax_vmovdqu_xmm_xmm
%rdx/%rdx: %rdx_vmovdqu_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: ((0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqu %xmm2, %xmm10

.target:
callq .move_128_064_xmm2_r10_r11
vzeroall 
callq .move_064_128_r10_r11_xmm3
callq .move_256_128_ymm3_xmm12_xmm13
callq .move_128_256_xmm12_xmm13_ymm1
retq 

Initial state:
%ymm10: %ymm10_andps_xmm_xmm

State for specgen instruction: vmovdqu %xmm2, %xmm1:
%ymm1: (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[255:128])[127:0][127:0] ∘ (0x0₂₅₆[255:128] ∘ (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqu_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqu_xmm_xmm[127:0][63:0][63:0]))[127:0])[127:0][127:0]

Final state
%ymm10: 0x0₁₂₈ ∘ %ymm2_andps_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm2, %xmm10, %xmm4

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm4: %ymm4_andps_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm4: 0x0₁₂₈ ∘ %ymm2_andps_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpxor_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpxor_xmm_xmm_xmm

%xmm0: %ymm0_vpxor_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpxor_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpxor_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r8_r9

Final state:
%rax/%rax: %rax_vpxor_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpxor_xmm_xmm_xmm

%xmm0: %ymm0_vpxor_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r8, %r12

Final state:
%r12/%r12: %ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0]

%cf: false
%pf: !((%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r9, %r13

Final state:
%r13/%r13: %ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64]

%cf: false
%pf: !((%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vpxor_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpxor_xmm_xmm_xmm

%xmm0: %ymm0_vpxor_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[255:128] ∘ ((%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[63:0] ∘ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpxor %xmm1, %xmm2, %xmm0

.target:
callq .move_128_064_xmm2_r12_r13
vmovdqa %xmm3, %xmm1
callq .move_128_064_xmm1_r8_r9
xorq %r8, %r12
xorq %r9, %r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm0: %ymm0_pand_xmm_xmm

State for specgen instruction: vpxor %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[255:128] ∘ ((%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[63:0] ∘ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[63:0])

Final state
%ymm0: 0x0₁₂₈ ∘ ((%ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64]) ∘ (%ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm2, %xmm2

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm2: %ymm2_por_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm2: 0x0₁₂₈ ∘ %ymm2_por_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm1, %xmm2, %xmm3

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm3: %ymm3_por_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_por_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_por_xmm_xmm[255:128] ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for por %xmm1, %xmm2

.target:
vmovapd %xmm2, %xmm2
vorpd %xmm1, %xmm2, %xmm3
movdqa %xmm3, %xmm1
retq 

Initial state:
%xmm2: %ymm2_pandn_xmm_xmm[127:0]

State for specgen instruction: por %xmm2, %xmm1:
%xmm1: (%ymm1_por_xmm_xmm[255:128] ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_pandn_xmm_xmm[255:128] ∘ ((%ymm2_pandn_xmm_xmm[127:64] | %ymm1_pandn_xmm_xmm[127:64]) ∘ (%ymm2_pandn_xmm_xmm[63:0] | %ymm1_pandn_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm2, %xmm1, %xmm6

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm6: %ymm6_xorps_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm6: 0x0₁₂₈ ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_xorps_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_xorps_xmm_xmm[255:128] ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for xorps %xmm2, %xmm1

.target:
vxorps %xmm2, %xmm1, %xmm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm1: %ymm1_pxor_xmm_xmm[127:0]

State for specgen instruction: xorps %xmm2, %xmm1:
%xmm1: (%ymm1_xorps_xmm_xmm[255:128] ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0])))[127:0]

Final state
%xmm1: (%ymm1_pxor_xmm_xmm[255:128] ∘ ((%ymm1_pxor_xmm_xmm[127:64] ⊕ %ymm2_pxor_xmm_xmm[127:64]) ∘ (%ymm1_pxor_xmm_xmm[63:0] ⊕ %ymm2_pxor_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for pxor %xmm2, %xmm1

.target:
xorps %xmm2, %xmm1
retq 

Initial state:
%xmm1: %ymm1_pandn_xmm_xmm[127:0]

State for specgen instruction: pxor %xmm2, %xmm1:
%xmm1: (%ymm1_pxor_xmm_xmm[255:128] ∘ ((%ymm1_pxor_xmm_xmm[127:64] ⊕ %ymm2_pxor_xmm_xmm[127:64]) ∘ (%ymm1_pxor_xmm_xmm[63:0] ⊕ %ymm2_pxor_xmm_xmm[63:0])))[127:0]

Final state
%xmm1: (%ymm1_pandn_xmm_xmm[255:128] ∘ ((%ymm1_pandn_xmm_xmm[127:64] ⊕ (%ymm2_pandn_xmm_xmm[127:64] | %ymm1_pandn_xmm_xmm[127:64])) ∘ (%ymm1_pandn_xmm_xmm[63:0] ⊕ (%ymm2_pandn_xmm_xmm[63:0] | %ymm1_pandn_xmm_xmm[63:0]))))[127:0]

=====================================
=====================================
Computing circuit for pandn %xmm2, %xmm0

.target:
por %xmm1, %xmm2
pxor %xmm2, %xmm1
retq 

Initial state:
%xmm0: (0x0₁₂₈ ∘ ((%ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64]) ∘ (%ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0])))[127:0]

State for specgen instruction: pandn %xmm2, %xmm1:
%xmm1: (%ymm1_pandn_xmm_xmm[255:128] ∘ ((%ymm1_pandn_xmm_xmm[127:64] ⊕ (%ymm2_pandn_xmm_xmm[127:64] | %ymm1_pandn_xmm_xmm[127:64])) ∘ (%ymm1_pandn_xmm_xmm[63:0] ⊕ (%ymm2_pandn_xmm_xmm[63:0] | %ymm1_pandn_xmm_xmm[63:0]))))[127:0]

Final state
%xmm0: ((0x0₁₂₈ ∘ ((%ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64]) ∘ (%ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0])))[255:128] ∘ ((%ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64] ⊕ (%ymm2_pand_xmm_xmm[127:64] | %ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64])) ∘ (%ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0] ⊕ (%ymm2_pand_xmm_xmm[63:0] | %ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm0, %xmm2

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm2: %ymm2_pand_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm2: 0x0₁₂₈ ∘ ((%ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64] ⊕ (%ymm2_pand_xmm_xmm[127:64] | %ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64])) ∘ (%ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0] ⊕ (%ymm2_pand_xmm_xmm[63:0] | %ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_pand_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_pand_xmm_xmm[255:128] ∘ ((%ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64] ⊕ (%ymm2_pand_xmm_xmm[127:64] | %ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64])) ∘ (%ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0] ⊕ (%ymm2_pand_xmm_xmm[63:0] | %ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0]))))[127:0]

=====================================
=====================================
Computing circuit for pand %xmm4, %xmm1

.target:
vpxor %xmm1, %xmm2, %xmm0
pandn %xmm2, %xmm0
vmovapd %xmm0, %xmm2
movdqa %xmm2, %xmm1
retq 

Initial state:
%xmm1: %ymm1_andps_xmm_xmm[127:0]

State for specgen instruction: pand %xmm2, %xmm1:
%xmm1: (%ymm1_pand_xmm_xmm[255:128] ∘ ((%ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64] ⊕ (%ymm2_pand_xmm_xmm[127:64] | %ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64])) ∘ (%ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0] ⊕ (%ymm2_pand_xmm_xmm[63:0] | %ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0]))))[127:0]

Final state
%xmm1: (%ymm1_andps_xmm_xmm[255:128] ∘ ((%ymm2_andps_xmm_xmm[127:64] ⊕ %ymm1_andps_xmm_xmm[127:64] ⊕ (%ymm2_andps_xmm_xmm[127:64] | %ymm2_andps_xmm_xmm[127:64] ⊕ %ymm1_andps_xmm_xmm[127:64])) ∘ (%ymm2_andps_xmm_xmm[63:0] ⊕ %ymm1_andps_xmm_xmm[63:0] ⊕ (%ymm2_andps_xmm_xmm[63:0] | %ymm2_andps_xmm_xmm[63:0] ⊕ %ymm1_andps_xmm_xmm[63:0]))))[127:0]

=====================================
=====================================
Computing circuit for andps %xmm2, %xmm3

.target:
vmovdqu %xmm2, %xmm10
vorpd %xmm2, %xmm10, %xmm4
pand %xmm4, %xmm1
retq 

Initial state:
%xmm3: %ymm3_vandps_ymm_ymm_ymm[127:0]

State for specgen instruction: andps %xmm2, %xmm1:
%xmm1: (%ymm1_andps_xmm_xmm[255:128] ∘ ((%ymm2_andps_xmm_xmm[127:64] ⊕ %ymm1_andps_xmm_xmm[127:64] ⊕ (%ymm2_andps_xmm_xmm[127:64] | %ymm2_andps_xmm_xmm[127:64] ⊕ %ymm1_andps_xmm_xmm[127:64])) ∘ (%ymm2_andps_xmm_xmm[63:0] ⊕ %ymm1_andps_xmm_xmm[63:0] ⊕ (%ymm2_andps_xmm_xmm[63:0] | %ymm2_andps_xmm_xmm[63:0] ⊕ %ymm1_andps_xmm_xmm[63:0]))))[127:0]

Final state
%xmm3: (%ymm3_vandps_ymm_ymm_ymm[255:128] ∘ ((%ymm2_vandps_ymm_ymm_ymm[127:64] ⊕ %ymm3_vandps_ymm_ymm_ymm[127:64] ⊕ (%ymm2_vandps_ymm_ymm_ymm[127:64] | %ymm2_vandps_ymm_ymm_ymm[127:64] ⊕ %ymm3_vandps_ymm_ymm_ymm[127:64])) ∘ (%ymm2_vandps_ymm_ymm_ymm[63:0] ⊕ %ymm3_vandps_ymm_ymm_ymm[63:0] ⊕ (%ymm2_vandps_ymm_ymm_ymm[63:0] | %ymm2_vandps_ymm_ymm_ymm[63:0] ⊕ %ymm3_vandps_ymm_ymm_ymm[63:0]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_256_128_ymm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vandps_ymm_ymm_ymm
%rdx/%rdx: %rdx_vandps_ymm_ymm_ymm

%xmm0: %ymm0_vandps_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vandps_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm8_xmm9

Final state:
%rax/%rax: %rax_vandps_ymm_ymm_ymm
%rdx/%rdx: %rdx_vandps_ymm_ymm_ymm

%xmm0: %ymm0_vandps_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vandps_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vpxor_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpxor_xmm_xmm_xmm

%xmm0: %ymm0_vpxor_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vpxor_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vpxor_xmm_xmm_xmm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm1_r8_r9

Final state:
%rax/%rax: %rax_vpxor_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpxor_xmm_xmm_xmm

%xmm0: %ymm0_vpxor_xmm_xmm_xmm[127:0]
%xmm1: (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r8, %r12

Final state:
%r12/%r12: %ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0]

%cf: false
%pf: !((%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r9, %r13

Final state:
%r13/%r13: %ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64]

%cf: false
%pf: !((%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vpxor_xmm_xmm_xmm
%rdx/%rdx: %rdx_vpxor_xmm_xmm_xmm

%xmm0: %ymm0_vpxor_xmm_xmm_xmm[127:0]
%xmm1: ((0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[255:128] ∘ ((%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[63:0] ∘ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vpxor %xmm1, %xmm2, %xmm0

.target:
callq .move_128_064_xmm2_r12_r13
vmovdqa %xmm3, %xmm1
callq .move_128_064_xmm1_r8_r9
xorq %r8, %r12
xorq %r9, %r13
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm0: %ymm0_pand_xmm_xmm

State for specgen instruction: vpxor %xmm3, %xmm2, %xmm1:
%ymm1: (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[255:128] ∘ ((%ymm2_vpxor_xmm_xmm_xmm[127:0][127:64] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][127:64])[63:0] ∘ (%ymm2_vpxor_xmm_xmm_xmm[127:0][63:0] ⊕ (0x0₁₂₈ ∘ %ymm3_vpxor_xmm_xmm_xmm[127:0])[127:0][63:0])[63:0])

Final state
%ymm0: 0x0₁₂₈ ∘ ((%ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64]) ∘ (%ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm2, %xmm2

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm2: %ymm2_por_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm2: 0x0₁₂₈ ∘ %ymm2_por_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm1, %xmm2, %xmm3

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm3: %ymm3_por_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_por_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_por_xmm_xmm[255:128] ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for por %xmm1, %xmm2

.target:
vmovapd %xmm2, %xmm2
vorpd %xmm1, %xmm2, %xmm3
movdqa %xmm3, %xmm1
retq 

Initial state:
%xmm2: %ymm2_pandn_xmm_xmm[127:0]

State for specgen instruction: por %xmm2, %xmm1:
%xmm1: (%ymm1_por_xmm_xmm[255:128] ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_pandn_xmm_xmm[255:128] ∘ ((%ymm2_pandn_xmm_xmm[127:64] | %ymm1_pandn_xmm_xmm[127:64]) ∘ (%ymm2_pandn_xmm_xmm[63:0] | %ymm1_pandn_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm2, %xmm1, %xmm6

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm6: %ymm6_xorps_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm6: 0x0₁₂₈ ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_xorps_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_xorps_xmm_xmm[255:128] ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for xorps %xmm2, %xmm1

.target:
vxorps %xmm2, %xmm1, %xmm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm1: %ymm1_pxor_xmm_xmm[127:0]

State for specgen instruction: xorps %xmm2, %xmm1:
%xmm1: (%ymm1_xorps_xmm_xmm[255:128] ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0])))[127:0]

Final state
%xmm1: (%ymm1_pxor_xmm_xmm[255:128] ∘ ((%ymm1_pxor_xmm_xmm[127:64] ⊕ %ymm2_pxor_xmm_xmm[127:64]) ∘ (%ymm1_pxor_xmm_xmm[63:0] ⊕ %ymm2_pxor_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for pxor %xmm2, %xmm1

.target:
xorps %xmm2, %xmm1
retq 

Initial state:
%xmm1: %ymm1_pandn_xmm_xmm[127:0]

State for specgen instruction: pxor %xmm2, %xmm1:
%xmm1: (%ymm1_pxor_xmm_xmm[255:128] ∘ ((%ymm1_pxor_xmm_xmm[127:64] ⊕ %ymm2_pxor_xmm_xmm[127:64]) ∘ (%ymm1_pxor_xmm_xmm[63:0] ⊕ %ymm2_pxor_xmm_xmm[63:0])))[127:0]

Final state
%xmm1: (%ymm1_pandn_xmm_xmm[255:128] ∘ ((%ymm1_pandn_xmm_xmm[127:64] ⊕ (%ymm2_pandn_xmm_xmm[127:64] | %ymm1_pandn_xmm_xmm[127:64])) ∘ (%ymm1_pandn_xmm_xmm[63:0] ⊕ (%ymm2_pandn_xmm_xmm[63:0] | %ymm1_pandn_xmm_xmm[63:0]))))[127:0]

=====================================
=====================================
Computing circuit for pandn %xmm2, %xmm0

.target:
por %xmm1, %xmm2
pxor %xmm2, %xmm1
retq 

Initial state:
%xmm0: (0x0₁₂₈ ∘ ((%ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64]) ∘ (%ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0])))[127:0]

State for specgen instruction: pandn %xmm2, %xmm1:
%xmm1: (%ymm1_pandn_xmm_xmm[255:128] ∘ ((%ymm1_pandn_xmm_xmm[127:64] ⊕ (%ymm2_pandn_xmm_xmm[127:64] | %ymm1_pandn_xmm_xmm[127:64])) ∘ (%ymm1_pandn_xmm_xmm[63:0] ⊕ (%ymm2_pandn_xmm_xmm[63:0] | %ymm1_pandn_xmm_xmm[63:0]))))[127:0]

Final state
%xmm0: ((0x0₁₂₈ ∘ ((%ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64]) ∘ (%ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0])))[255:128] ∘ ((%ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64] ⊕ (%ymm2_pand_xmm_xmm[127:64] | %ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64])) ∘ (%ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0] ⊕ (%ymm2_pand_xmm_xmm[63:0] | %ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm0, %xmm2

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm2: %ymm2_pand_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm2: 0x0₁₂₈ ∘ ((%ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64] ⊕ (%ymm2_pand_xmm_xmm[127:64] | %ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64])) ∘ (%ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0] ⊕ (%ymm2_pand_xmm_xmm[63:0] | %ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_pand_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_pand_xmm_xmm[255:128] ∘ ((%ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64] ⊕ (%ymm2_pand_xmm_xmm[127:64] | %ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64])) ∘ (%ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0] ⊕ (%ymm2_pand_xmm_xmm[63:0] | %ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0]))))[127:0]

=====================================
=====================================
Computing circuit for pand %xmm11, %xmm9

.target:
vpxor %xmm1, %xmm2, %xmm0
pandn %xmm2, %xmm0
vmovapd %xmm0, %xmm2
movdqa %xmm2, %xmm1
retq 

Initial state:
%xmm9: (%ymm9_vandps_ymm_ymm_ymm[255:128] ∘ (%ymm3_vandps_ymm_ymm_ymm[255:128] ∘ ((%ymm2_vandps_ymm_ymm_ymm[127:64] ⊕ %ymm3_vandps_ymm_ymm_ymm[127:64] ⊕ (%ymm2_vandps_ymm_ymm_ymm[127:64] | %ymm2_vandps_ymm_ymm_ymm[127:64] ⊕ %ymm3_vandps_ymm_ymm_ymm[127:64])) ∘ (%ymm2_vandps_ymm_ymm_ymm[63:0] ⊕ %ymm3_vandps_ymm_ymm_ymm[63:0] ⊕ (%ymm2_vandps_ymm_ymm_ymm[63:0] | %ymm2_vandps_ymm_ymm_ymm[63:0] ⊕ %ymm3_vandps_ymm_ymm_ymm[63:0]))))[255:128])[127:0]

State for specgen instruction: pand %xmm2, %xmm1:
%xmm1: (%ymm1_pand_xmm_xmm[255:128] ∘ ((%ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64] ⊕ (%ymm2_pand_xmm_xmm[127:64] | %ymm2_pand_xmm_xmm[127:64] ⊕ %ymm1_pand_xmm_xmm[127:64])) ∘ (%ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0] ⊕ (%ymm2_pand_xmm_xmm[63:0] | %ymm2_pand_xmm_xmm[63:0] ⊕ %ymm1_pand_xmm_xmm[63:0]))))[127:0]

Final state
%xmm9: ((%ymm9_vandps_ymm_ymm_ymm[255:128] ∘ (%ymm3_vandps_ymm_ymm_ymm[255:128] ∘ ((%ymm2_vandps_ymm_ymm_ymm[127:64] ⊕ %ymm3_vandps_ymm_ymm_ymm[127:64] ⊕ (%ymm2_vandps_ymm_ymm_ymm[127:64] | %ymm2_vandps_ymm_ymm_ymm[127:64] ⊕ %ymm3_vandps_ymm_ymm_ymm[127:64])) ∘ (%ymm2_vandps_ymm_ymm_ymm[63:0] ⊕ %ymm3_vandps_ymm_ymm_ymm[63:0] ⊕ (%ymm2_vandps_ymm_ymm_ymm[63:0] | %ymm2_vandps_ymm_ymm_ymm[63:0] ⊕ %ymm3_vandps_ymm_ymm_ymm[63:0]))))[255:128])[255:128] ∘ ((%ymm2_vandps_ymm_ymm_ymm[255:192] ⊕ %ymm3_vandps_ymm_ymm_ymm[255:192] ⊕ (%ymm2_vandps_ymm_ymm_ymm[255:192] | %ymm2_vandps_ymm_ymm_ymm[255:192] ⊕ %ymm3_vandps_ymm_ymm_ymm[255:192])) ∘ (%ymm2_vandps_ymm_ymm_ymm[191:128] ⊕ %ymm3_vandps_ymm_ymm_ymm[191:128] ⊕ (%ymm2_vandps_ymm_ymm_ymm[191:128] | %ymm2_vandps_ymm_ymm_ymm[191:128] ⊕ %ymm3_vandps_ymm_ymm_ymm[191:128]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vandps_ymm_ymm_ymm
%rdx/%rdx: %rdx_vandps_ymm_ymm_ymm

%xmm0: %ymm0_vandps_ymm_ymm_ymm[127:0]
%xmm1: (((%ymm9_vandps_ymm_ymm_ymm[255:128] ∘ (%ymm3_vandps_ymm_ymm_ymm[255:128] ∘ ((%ymm2_vandps_ymm_ymm_ymm[127:64] ⊕ %ymm3_vandps_ymm_ymm_ymm[127:64] ⊕ (%ymm2_vandps_ymm_ymm_ymm[127:64] | %ymm2_vandps_ymm_ymm_ymm[127:64] ⊕ %ymm3_vandps_ymm_ymm_ymm[127:64])) ∘ (%ymm2_vandps_ymm_ymm_ymm[63:0] ⊕ %ymm3_vandps_ymm_ymm_ymm[63:0] ⊕ (%ymm2_vandps_ymm_ymm_ymm[63:0] | %ymm2_vandps_ymm_ymm_ymm[63:0] ⊕ %ymm3_vandps_ymm_ymm_ymm[63:0]))))[255:128])[255:128] ∘ ((%ymm2_vandps_ymm_ymm_ymm[255:192] ⊕ %ymm3_vandps_ymm_ymm_ymm[255:192] ⊕ (%ymm2_vandps_ymm_ymm_ymm[255:192] | %ymm2_vandps_ymm_ymm_ymm[255:192] ⊕ %ymm3_vandps_ymm_ymm_ymm[255:192])) ∘ (%ymm2_vandps_ymm_ymm_ymm[191:128] ⊕ %ymm3_vandps_ymm_ymm_ymm[191:128] ⊕ (%ymm2_vandps_ymm_ymm_ymm[191:128] | %ymm2_vandps_ymm_ymm_ymm[191:128] ⊕ %ymm3_vandps_ymm_ymm_ymm[191:128]))))[127:0][127:0] ∘ (%ymm8_vandps_ymm_ymm_ymm[255:128] ∘ (%ymm3_vandps_ymm_ymm_ymm[255:128] ∘ ((%ymm2_vandps_ymm_ymm_ymm[127:64] ⊕ %ymm3_vandps_ymm_ymm_ymm[127:64] ⊕ (%ymm2_vandps_ymm_ymm_ymm[127:64] | %ymm2_vandps_ymm_ymm_ymm[127:64] ⊕ %ymm3_vandps_ymm_ymm_ymm[127:64])) ∘ (%ymm2_vandps_ymm_ymm_ymm[63:0] ⊕ %ymm3_vandps_ymm_ymm_ymm[63:0] ⊕ (%ymm2_vandps_ymm_ymm_ymm[63:0] | %ymm2_vandps_ymm_ymm_ymm[63:0] ⊕ %ymm3_vandps_ymm_ymm_ymm[63:0]))))[127:0])[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vandps %ymm3, %ymm2, %ymm4

.target:
andps %xmm2, %xmm3
callq .move_256_128_ymm2_xmm10_xmm11
callq .move_256_128_ymm3_xmm8_xmm9
pand %xmm11, %xmm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm4: %ymm4_vxorps_ymm_ymm_ymm

State for specgen instruction: vandps %ymm3, %ymm2, %ymm1:
%ymm1: ((%ymm9_vandps_ymm_ymm_ymm[255:128] ∘ (%ymm3_vandps_ymm_ymm_ymm[255:128] ∘ ((%ymm2_vandps_ymm_ymm_ymm[127:64] ⊕ %ymm3_vandps_ymm_ymm_ymm[127:64] ⊕ (%ymm2_vandps_ymm_ymm_ymm[127:64] | %ymm2_vandps_ymm_ymm_ymm[127:64] ⊕ %ymm3_vandps_ymm_ymm_ymm[127:64])) ∘ (%ymm2_vandps_ymm_ymm_ymm[63:0] ⊕ %ymm3_vandps_ymm_ymm_ymm[63:0] ⊕ (%ymm2_vandps_ymm_ymm_ymm[63:0] | %ymm2_vandps_ymm_ymm_ymm[63:0] ⊕ %ymm3_vandps_ymm_ymm_ymm[63:0]))))[255:128])[255:128] ∘ ((%ymm2_vandps_ymm_ymm_ymm[255:192] ⊕ %ymm3_vandps_ymm_ymm_ymm[255:192] ⊕ (%ymm2_vandps_ymm_ymm_ymm[255:192] | %ymm2_vandps_ymm_ymm_ymm[255:192] ⊕ %ymm3_vandps_ymm_ymm_ymm[255:192])) ∘ (%ymm2_vandps_ymm_ymm_ymm[191:128] ⊕ %ymm3_vandps_ymm_ymm_ymm[191:128] ⊕ (%ymm2_vandps_ymm_ymm_ymm[191:128] | %ymm2_vandps_ymm_ymm_ymm[191:128] ⊕ %ymm3_vandps_ymm_ymm_ymm[191:128]))))[127:0][127:0] ∘ (%ymm8_vandps_ymm_ymm_ymm[255:128] ∘ (%ymm3_vandps_ymm_ymm_ymm[255:128] ∘ ((%ymm2_vandps_ymm_ymm_ymm[127:64] ⊕ %ymm3_vandps_ymm_ymm_ymm[127:64] ⊕ (%ymm2_vandps_ymm_ymm_ymm[127:64] | %ymm2_vandps_ymm_ymm_ymm[127:64] ⊕ %ymm3_vandps_ymm_ymm_ymm[127:64])) ∘ (%ymm2_vandps_ymm_ymm_ymm[63:0] ⊕ %ymm3_vandps_ymm_ymm_ymm[63:0] ⊕ (%ymm2_vandps_ymm_ymm_ymm[63:0] | %ymm2_vandps_ymm_ymm_ymm[63:0] ⊕ %ymm3_vandps_ymm_ymm_ymm[63:0]))))[127:0])[127:0][127:0]

Final state
%ymm4: (%ymm2_vxorps_ymm_ymm_ymm[255:192] ⊕ %ymm3_vxorps_ymm_ymm_ymm[255:192] ⊕ (%ymm2_vxorps_ymm_ymm_ymm[255:192] | %ymm2_vxorps_ymm_ymm_ymm[255:192] ⊕ %ymm3_vxorps_ymm_ymm_ymm[255:192])) ∘ (%ymm2_vxorps_ymm_ymm_ymm[191:128] ⊕ %ymm3_vxorps_ymm_ymm_ymm[191:128] ⊕ (%ymm2_vxorps_ymm_ymm_ymm[191:128] | %ymm2_vxorps_ymm_ymm_ymm[191:128] ⊕ %ymm3_vxorps_ymm_ymm_ymm[191:128])) ∘ ((%ymm2_vxorps_ymm_ymm_ymm[127:64] ⊕ %ymm3_vxorps_ymm_ymm_ymm[127:64] ⊕ (%ymm2_vxorps_ymm_ymm_ymm[127:64] | %ymm2_vxorps_ymm_ymm_ymm[127:64] ⊕ %ymm3_vxorps_ymm_ymm_ymm[127:64])) ∘ (%ymm2_vxorps_ymm_ymm_ymm[63:0] ⊕ %ymm3_vxorps_ymm_ymm_ymm[63:0] ⊕ (%ymm2_vxorps_ymm_ymm_ymm[63:0] | %ymm2_vxorps_ymm_ymm_ymm[63:0] ⊕ %ymm3_vxorps_ymm_ymm_ymm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm12_xmm13

Final state:
%rax/%rax: %rax_vandnpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vandnpd_ymm_ymm_ymm

%xmm0: %ymm0_vandnpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vandnpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm2, %xmm2

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm2: %ymm2_por_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm2: 0x0₁₂₈ ∘ %ymm2_por_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm1, %xmm2, %xmm3

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm3: %ymm3_por_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_por_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_por_xmm_xmm[255:128] ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for por %xmm1, %xmm2

.target:
vmovapd %xmm2, %xmm2
vorpd %xmm1, %xmm2, %xmm3
movdqa %xmm3, %xmm1
retq 

Initial state:
%xmm2: %ymm2_pandn_xmm_xmm[127:0]

State for specgen instruction: por %xmm2, %xmm1:
%xmm1: (%ymm1_por_xmm_xmm[255:128] ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_pandn_xmm_xmm[255:128] ∘ ((%ymm2_pandn_xmm_xmm[127:64] | %ymm1_pandn_xmm_xmm[127:64]) ∘ (%ymm2_pandn_xmm_xmm[63:0] | %ymm1_pandn_xmm_xmm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm2, %xmm1, %xmm6

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm6: %ymm6_xorps_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm6: 0x0₁₂₈ ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_xorps_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_xorps_xmm_xmm[255:128] ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for xorps %xmm2, %xmm1

.target:
vxorps %xmm2, %xmm1, %xmm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm1: %ymm1_pxor_xmm_xmm[127:0]

State for specgen instruction: xorps %xmm2, %xmm1:
%xmm1: (%ymm1_xorps_xmm_xmm[255:128] ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0])))[127:0]

Final state
%xmm1: (%ymm1_pxor_xmm_xmm[255:128] ∘ ((%ymm1_pxor_xmm_xmm[127:64] ⊕ %ymm2_pxor_xmm_xmm[127:64]) ∘ (%ymm1_pxor_xmm_xmm[63:0] ⊕ %ymm2_pxor_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for pxor %xmm2, %xmm1

.target:
xorps %xmm2, %xmm1
retq 

Initial state:
%xmm1: %ymm1_pandn_xmm_xmm[127:0]

State for specgen instruction: pxor %xmm2, %xmm1:
%xmm1: (%ymm1_pxor_xmm_xmm[255:128] ∘ ((%ymm1_pxor_xmm_xmm[127:64] ⊕ %ymm2_pxor_xmm_xmm[127:64]) ∘ (%ymm1_pxor_xmm_xmm[63:0] ⊕ %ymm2_pxor_xmm_xmm[63:0])))[127:0]

Final state
%xmm1: (%ymm1_pandn_xmm_xmm[255:128] ∘ ((%ymm1_pandn_xmm_xmm[127:64] ⊕ (%ymm2_pandn_xmm_xmm[127:64] | %ymm1_pandn_xmm_xmm[127:64])) ∘ (%ymm1_pandn_xmm_xmm[63:0] ⊕ (%ymm2_pandn_xmm_xmm[63:0] | %ymm1_pandn_xmm_xmm[63:0]))))[127:0]

=====================================
=====================================
Computing circuit for pandn %xmm3, %xmm2

.target:
por %xmm1, %xmm2
pxor %xmm2, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vandnpd_ymm_ymm_ymm[127:0]

State for specgen instruction: pandn %xmm2, %xmm1:
%xmm1: (%ymm1_pandn_xmm_xmm[255:128] ∘ ((%ymm1_pandn_xmm_xmm[127:64] ⊕ (%ymm2_pandn_xmm_xmm[127:64] | %ymm1_pandn_xmm_xmm[127:64])) ∘ (%ymm1_pandn_xmm_xmm[63:0] ⊕ (%ymm2_pandn_xmm_xmm[63:0] | %ymm1_pandn_xmm_xmm[63:0]))))[127:0]

Final state
%xmm2: (%ymm2_vandnpd_ymm_ymm_ymm[255:128] ∘ ((%ymm2_vandnpd_ymm_ymm_ymm[127:64] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[127:64] | %ymm2_vandnpd_ymm_ymm_ymm[127:64])) ∘ (%ymm2_vandnpd_ymm_ymm_ymm[63:0] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[63:0] | %ymm2_vandnpd_ymm_ymm_ymm[63:0]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_256_128_ymm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vandnpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vandnpd_ymm_ymm_ymm

%xmm0: %ymm0_vandnpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vandnpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm10, %xmm14

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm14: %ymm14_vandnpd_ymm_ymm_ymm

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm14: 0x0₁₂₈ ∘ ((%ymm2_vandnpd_ymm_ymm_ymm[127:64] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[127:64] | %ymm2_vandnpd_ymm_ymm_ymm[127:64])) ∘ (%ymm2_vandnpd_ymm_ymm_ymm[63:0] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[63:0] | %ymm2_vandnpd_ymm_ymm_ymm[63:0])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm2, %xmm3, %xmm12

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm12: %ymm12_vandnpd_xmm_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm12: 0x0₁₂₈ ∘ ((%ymm2_vandnpd_xmm_xmm_xmm[127:64] | %ymm3_vandnpd_xmm_xmm_xmm[127:64]) ∘ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] | %ymm3_vandnpd_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovupd_ymm_ymm
%rdx/%rdx: %rdx_vmovupd_ymm_ymm

%xmm0: %ymm0_vmovupd_ymm_ymm[127:0]
%xmm1: %ymm1_vmovupd_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vminps %ymm2, %ymm2, %ymm1

Final state:
%ymm1: (mincmp_single(%ymm2_vmovupd_ymm_ymm[255:224], %ymm2_vmovupd_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[255:224] : %ymm2_vmovupd_ymm_ymm[255:224]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[223:192], %ymm2_vmovupd_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[223:192] : %ymm2_vmovupd_ymm_ymm[223:192]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[191:160], %ymm2_vmovupd_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[191:160] : %ymm2_vmovupd_ymm_ymm[191:160]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[159:128], %ymm2_vmovupd_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[159:128] : %ymm2_vmovupd_ymm_ymm[159:128]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[127:96], %ymm2_vmovupd_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[127:96] : %ymm2_vmovupd_ymm_ymm[127:96]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[95:64], %ymm2_vmovupd_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[95:64] : %ymm2_vmovupd_ymm_ymm[95:64]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[63:32], %ymm2_vmovupd_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[63:32] : %ymm2_vmovupd_ymm_ymm[63:32]) ∘ (mincmp_single(%ymm2_vmovupd_ymm_ymm[31:0], %ymm2_vmovupd_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[31:0] : %ymm2_vmovupd_ymm_ymm[31:0])))))))

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovupd_ymm_ymm
%rdx/%rdx: %rdx_vmovupd_ymm_ymm

%xmm0: %ymm0_vmovupd_ymm_ymm[127:0]
%xmm1: (((mincmp_single(%ymm2_vmovupd_ymm_ymm[255:224], %ymm2_vmovupd_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[255:224] : %ymm2_vmovupd_ymm_ymm[255:224]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[223:192], %ymm2_vmovupd_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[223:192] : %ymm2_vmovupd_ymm_ymm[223:192]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[191:160], %ymm2_vmovupd_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[191:160] : %ymm2_vmovupd_ymm_ymm[191:160]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[159:128], %ymm2_vmovupd_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[159:128] : %ymm2_vmovupd_ymm_ymm[159:128]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[127:96], %ymm2_vmovupd_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[127:96] : %ymm2_vmovupd_ymm_ymm[127:96]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[95:64], %ymm2_vmovupd_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[95:64] : %ymm2_vmovupd_ymm_ymm[95:64]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[63:32], %ymm2_vmovupd_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[63:32] : %ymm2_vmovupd_ymm_ymm[63:32]) ∘ (mincmp_single(%ymm2_vmovupd_ymm_ymm[31:0], %ymm2_vmovupd_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[31:0] : %ymm2_vmovupd_ymm_ymm[31:0]))))))))[255:128] ∘ (%ymm2_vmovupd_ymm_ymm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_ymm_ymm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovupd %ymm12, %ymm1

.target:
callq .move_128_064_xmm2_r12_r13
vminps %ymm2, %ymm2, %ymm1
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: %ymm1_vandnpd_xmm_xmm_xmm

State for specgen instruction: vmovupd %ymm2, %ymm1:
%ymm1: ((mincmp_single(%ymm2_vmovupd_ymm_ymm[255:224], %ymm2_vmovupd_ymm_ymm[255:224])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[255:224] : %ymm2_vmovupd_ymm_ymm[255:224]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[223:192], %ymm2_vmovupd_ymm_ymm[223:192])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[223:192] : %ymm2_vmovupd_ymm_ymm[223:192]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[191:160], %ymm2_vmovupd_ymm_ymm[191:160])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[191:160] : %ymm2_vmovupd_ymm_ymm[191:160]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[159:128], %ymm2_vmovupd_ymm_ymm[159:128])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[159:128] : %ymm2_vmovupd_ymm_ymm[159:128]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[127:96], %ymm2_vmovupd_ymm_ymm[127:96])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[127:96] : %ymm2_vmovupd_ymm_ymm[127:96]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[95:64], %ymm2_vmovupd_ymm_ymm[95:64])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[95:64] : %ymm2_vmovupd_ymm_ymm[95:64]) ∘ ((mincmp_single(%ymm2_vmovupd_ymm_ymm[63:32], %ymm2_vmovupd_ymm_ymm[63:32])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[63:32] : %ymm2_vmovupd_ymm_ymm[63:32]) ∘ (mincmp_single(%ymm2_vmovupd_ymm_ymm[31:0], %ymm2_vmovupd_ymm_ymm[31:0])[0:0] = 0x1₁ ? %ymm2_vmovupd_ymm_ymm[31:0] : %ymm2_vmovupd_ymm_ymm[31:0]))))))))[255:128] ∘ (%ymm2_vmovupd_ymm_ymm[127:0][127:64][63:0] ∘ %ymm2_vmovupd_ymm_ymm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₃₂ ∘ (0x0₃₂ ∘ 0x0₆₄) ∘ ((%ymm2_vandnpd_xmm_xmm_xmm[127:64] | %ymm3_vandnpd_xmm_xmm_xmm[127:64]) ∘ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] | %ymm3_vandnpd_xmm_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r12_r13

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: %ymm0_vxorps_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vxorps_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r13, %r9

Final state:
%r9/%r9: %ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for xorq %r12, %r8

Final state:
%r8/%r8: %ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vxorps_xmm_xmm_xmm
%rdx/%rdx: %rdx_vxorps_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vxorps %xmm2, %xmm1, %xmm6

.target:
callq .move_128_064_xmm3_r12_r13
callq .move_128_064_xmm2_r8_r9
vzeroall 
xorq %r13, %r9
xorq %r12, %r8
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm6: %ymm6_xorps_xmm_xmm

State for specgen instruction: vxorps %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm2_vxorps_xmm_xmm_xmm[127:0][127:64] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm2_vxorps_xmm_xmm_xmm[127:0][63:0] ⊕ %ymm3_vxorps_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm6: 0x0₁₂₈ ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm6, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_xorps_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_xorps_xmm_xmm[255:128] ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for xorps %xmm2, %xmm1

.target:
vxorps %xmm2, %xmm1, %xmm6
movdqa %xmm6, %xmm1
retq 

Initial state:
%xmm1: %ymm1_pxor_xmm_xmm[127:0]

State for specgen instruction: xorps %xmm2, %xmm1:
%xmm1: (%ymm1_xorps_xmm_xmm[255:128] ∘ ((%ymm1_xorps_xmm_xmm[127:64] ⊕ %ymm2_xorps_xmm_xmm[127:64]) ∘ (%ymm1_xorps_xmm_xmm[63:0] ⊕ %ymm2_xorps_xmm_xmm[63:0])))[127:0]

Final state
%xmm1: (%ymm1_pxor_xmm_xmm[255:128] ∘ ((%ymm1_pxor_xmm_xmm[127:64] ⊕ %ymm2_pxor_xmm_xmm[127:64]) ∘ (%ymm1_pxor_xmm_xmm[63:0] ⊕ %ymm2_pxor_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for pxor %xmm1, %xmm2

.target:
xorps %xmm2, %xmm1
retq 

Initial state:
%xmm2: %ymm2_vandnpd_xmm_xmm_xmm[127:0]

State for specgen instruction: pxor %xmm2, %xmm1:
%xmm1: (%ymm1_pxor_xmm_xmm[255:128] ∘ ((%ymm1_pxor_xmm_xmm[127:64] ⊕ %ymm2_pxor_xmm_xmm[127:64]) ∘ (%ymm1_pxor_xmm_xmm[63:0] ⊕ %ymm2_pxor_xmm_xmm[63:0])))[127:0]

Final state
%xmm2: (%ymm2_vandnpd_xmm_xmm_xmm[255:128] ∘ ((%ymm2_vandnpd_xmm_xmm_xmm[127:64] ⊕ (%ymm2_vandnpd_xmm_xmm_xmm[127:64] | %ymm3_vandnpd_xmm_xmm_xmm[127:64])) ∘ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] ⊕ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] | %ymm3_vandnpd_xmm_xmm_xmm[63:0]))))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r12_r13

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: %ymm0_vmovdqa_xmm_xmm[127:0]
%xmm1: %ymm1_vmovdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r12_r13_xmm1

Final state:
%rax/%rax: %rax_vmovdqa_xmm_xmm
%rdx/%rdx: %rdx_vmovdqa_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovdqa %xmm2, %xmm1

.target:
callq .move_128_064_xmm2_r12_r13
vzeroall 
callq .move_064_128_r12_r13_xmm1
retq 

Initial state:
%ymm1: 0x0₃₂ ∘ (0x0₃₂ ∘ 0x0₆₄) ∘ ((%ymm2_vandnpd_xmm_xmm_xmm[127:64] | %ymm3_vandnpd_xmm_xmm_xmm[127:64]) ∘ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] | %ymm3_vandnpd_xmm_xmm_xmm[63:0]))

State for specgen instruction: vmovdqa %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovdqa_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm1: 0x0₁₂₈ ∘ ((%ymm2_vandnpd_xmm_xmm_xmm[127:64] ⊕ (%ymm2_vandnpd_xmm_xmm_xmm[127:64] | %ymm3_vandnpd_xmm_xmm_xmm[127:64])) ∘ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] ⊕ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] | %ymm3_vandnpd_xmm_xmm_xmm[63:0])))

=====================================
=====================================
Computing circuit for vandnpd %xmm13, %xmm11, %xmm11

.target:
vorpd %xmm2, %xmm3, %xmm12
vmovupd %ymm12, %ymm1
pxor %xmm1, %xmm2
vmovdqa %xmm2, %xmm1
retq 

Initial state:
%ymm11: %ymm11_vandnpd_ymm_ymm_ymm[255:128] ∘ (%ymm2_vandnpd_ymm_ymm_ymm[255:128] ∘ ((%ymm2_vandnpd_ymm_ymm_ymm[127:64] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[127:64] | %ymm2_vandnpd_ymm_ymm_ymm[127:64])) ∘ (%ymm2_vandnpd_ymm_ymm_ymm[63:0] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[63:0] | %ymm2_vandnpd_ymm_ymm_ymm[63:0]))))[255:128]

State for specgen instruction: vandnpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₁₂₈ ∘ ((%ymm2_vandnpd_xmm_xmm_xmm[127:64] ⊕ (%ymm2_vandnpd_xmm_xmm_xmm[127:64] | %ymm3_vandnpd_xmm_xmm_xmm[127:64])) ∘ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] ⊕ (%ymm2_vandnpd_xmm_xmm_xmm[63:0] | %ymm3_vandnpd_xmm_xmm_xmm[63:0])))

Final state
%ymm11: 0x0₁₂₈ ∘ ((%ymm2_vandnpd_ymm_ymm_ymm[255:192] ⊕ (%ymm2_vandnpd_ymm_ymm_ymm[255:192] | %ymm3_vandnpd_ymm_ymm_ymm[255:192])) ∘ (%ymm2_vandnpd_ymm_ymm_ymm[191:128] ⊕ (%ymm2_vandnpd_ymm_ymm_ymm[191:128] | %ymm3_vandnpd_ymm_ymm_ymm[191:128])))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm10_xmm11_ymm3

Final state:
%rax/%rax: %rax_vandnpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vandnpd_ymm_ymm_ymm

%xmm0: %ymm0_vandnpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vandnpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm8_xmm9

Final state:
%rax/%rax: %rax_vorpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vorpd_ymm_ymm_ymm

%xmm0: %ymm0_vorpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vorpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: %ymm0_vmovapd_xmm_xmm[127:0]
%xmm1: %ymm1_vmovapd_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_vmovapd_xmm_xmm
%rdx/%rdx: %rdx_vmovapd_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vmovapd %xmm2, %xmm2

.target:
callq .move_128_064_xmm2_r8_r9
vzeroall 
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%ymm2: %ymm2_por_xmm_xmm

State for specgen instruction: vmovapd %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ (%ymm2_vmovapd_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_vmovapd_xmm_xmm[127:0][63:0][63:0])

Final state
%ymm2: 0x0₁₂₈ ∘ %ymm2_por_xmm_xmm[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm1, %xmm2, %xmm3

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm3: %ymm3_por_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm3, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_por_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_por_xmm_xmm[255:128] ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for por %xmm2, %xmm8

.target:
vmovapd %xmm2, %xmm2
vorpd %xmm1, %xmm2, %xmm3
movdqa %xmm3, %xmm1
retq 

Initial state:
%xmm8: (%ymm8_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[127:0])[127:0]

State for specgen instruction: por %xmm2, %xmm1:
%xmm1: (%ymm1_por_xmm_xmm[255:128] ∘ ((%ymm1_por_xmm_xmm[127:64] | %ymm2_por_xmm_xmm[127:64]) ∘ (%ymm1_por_xmm_xmm[63:0] | %ymm2_por_xmm_xmm[63:0])))[127:0]

Final state
%xmm8: ((%ymm8_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[127:0])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[127:64] | %ymm2_vorpd_ymm_ymm_ymm[127:64]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[63:0] | %ymm2_vorpd_ymm_ymm_ymm[63:0])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_256_128_ymm2_xmm10_xmm11

Final state:
%rax/%rax: %rax_vorpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vorpd_ymm_ymm_ymm

%xmm0: %ymm0_vorpd_ymm_ymm_ymm[127:0]
%xmm1: %ymm1_vorpd_ymm_ymm_ymm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm3_r10_r11

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: %ymm0_vorpd_xmm_xmm_xmm[127:0]
%xmm1: %ymm1_vorpd_xmm_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for vzeroall 

Final state:
%ymm0: 0x0₂₅₆
%ymm1: 0x0₂₅₆
%ymm2: 0x0₂₅₆
%ymm3: 0x0₂₅₆
%ymm4: 0x0₂₅₆
%ymm5: 0x0₂₅₆
%ymm6: 0x0₂₅₆
%ymm7: 0x0₂₅₆
%ymm8: 0x0₂₅₆
%ymm9: 0x0₂₅₆
%ymm10: 0x0₂₅₆
%ymm11: 0x0₂₅₆
%ymm12: 0x0₂₅₆
%ymm13: 0x0₂₅₆
%ymm14: 0x0₂₅₆
%ymm15: 0x0₂₅₆

-------------------------------------
-------------------------------------
Getting base circuit for orq %r9, %r11

Final state:
%r11/%r11: %ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for orq %r8, %r10

Final state:
%r10/%r10: %ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]

%cf: false
%pf: !((%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][0:0] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][1:1] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][2:2] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][3:3] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][4:4] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][5:5] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][6:6] = 0x1₁ ⊕ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[7:0][7:7] = 0x1₁)
%zf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0]) = 0x0₆₄
%sf: (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:63] = 0x1₁
%of: false

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r10_r11_xmm1

Final state:
%rax/%rax: %rax_vorpd_xmm_xmm_xmm
%rdx/%rdx: %rdx_vorpd_xmm_xmm_xmm

%xmm0: 0x0₂₅₆[127:0]
%xmm1: (0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %xmm1, %xmm2, %xmm3

.target:
callq .move_128_064_xmm3_r10_r11
callq .move_128_064_xmm2_r8_r9
vzeroall 
orq %r9, %r11
orq %r8, %r10
callq .move_064_128_r10_r11_xmm1
retq 

Initial state:
%ymm3: %ymm3_orps_xmm_xmm

State for specgen instruction: vorpd %xmm3, %xmm2, %xmm1:
%ymm1: 0x0₂₅₆[255:128] ∘ ((%ymm3_vorpd_xmm_xmm_xmm[127:0][127:64] | %ymm2_vorpd_xmm_xmm_xmm[127:0][127:64])[63:0] ∘ (%ymm3_vorpd_xmm_xmm_xmm[127:0][63:0] | %ymm2_vorpd_xmm_xmm_xmm[127:0][63:0])[63:0])

Final state
%ymm3: 0x0₁₂₈ ∘ ((%ymm1_orps_xmm_xmm[127:64] | %ymm2_orps_xmm_xmm[127:64]) ∘ (%ymm1_orps_xmm_xmm[63:0] | %ymm2_orps_xmm_xmm[63:0]))

=====================================
-------------------------------------
Getting base circuit for callq .move_256_128_ymm3_xmm10_xmm11

Final state:
%rax/%rax: %rax_orps_xmm_xmm
%rdx/%rdx: %rdx_orps_xmm_xmm

%xmm0: %ymm0_orps_xmm_xmm[127:0]
%xmm1: %ymm1_orps_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_128_064_xmm2_r8_r9

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: %ymm1_movdqa_xmm_xmm[127:0]

-------------------------------------
-------------------------------------
Getting base circuit for callq .move_064_128_r8_r9_xmm1

Final state:
%rax/%rax: %rax_movdqa_xmm_xmm
%rdx/%rdx: %rdx_movdqa_xmm_xmm

%xmm0: %ymm0_movdqa_xmm_xmm[127:0]
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

-------------------------------------
=====================================
Computing circuit for movdqa %xmm10, %xmm1

.target:
callq .move_128_064_xmm2_r8_r9
callq .move_064_128_r8_r9_xmm1
retq 

Initial state:
%xmm1: %ymm1_orps_xmm_xmm[127:0]

State for specgen instruction: movdqa %xmm2, %xmm1:
%xmm1: (%ymm1_movdqa_xmm_xmm[255:128] ∘ (%ymm2_movdqa_xmm_xmm[127:0][127:64][63:0] ∘ %ymm2_movdqa_xmm_xmm[127:0][63:0][63:0]))[127:0]

Final state
%xmm1: (%ymm1_orps_xmm_xmm[255:128] ∘ ((%ymm1_orps_xmm_xmm[127:64] | %ymm2_orps_xmm_xmm[127:64]) ∘ (%ymm1_orps_xmm_xmm[63:0] | %ymm2_orps_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for orps %xmm2, %xmm1

.target:
vorpd %xmm1, %xmm2, %xmm3
callq .move_256_128_ymm3_xmm10_xmm11
movdqa %xmm10, %xmm1
retq 

Initial state:
%xmm1: %ymm1_orpd_xmm_xmm[127:0]

State for specgen instruction: orps %xmm2, %xmm1:
%xmm1: (%ymm1_orps_xmm_xmm[255:128] ∘ ((%ymm1_orps_xmm_xmm[127:64] | %ymm2_orps_xmm_xmm[127:64]) ∘ (%ymm1_orps_xmm_xmm[63:0] | %ymm2_orps_xmm_xmm[63:0])))[127:0]

Final state
%xmm1: (%ymm1_orpd_xmm_xmm[255:128] ∘ ((%ymm1_orpd_xmm_xmm[127:64] | %ymm2_orpd_xmm_xmm[127:64]) ∘ (%ymm1_orpd_xmm_xmm[63:0] | %ymm2_orpd_xmm_xmm[63:0])))[127:0]

=====================================
=====================================
Computing circuit for orpd %xmm11, %xmm9

.target:
orps %xmm2, %xmm1
retq 

Initial state:
%xmm9: (%ymm9_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[255:128])[127:0]

State for specgen instruction: orpd %xmm2, %xmm1:
%xmm1: (%ymm1_orpd_xmm_xmm[255:128] ∘ ((%ymm1_orpd_xmm_xmm[127:64] | %ymm2_orpd_xmm_xmm[127:64]) ∘ (%ymm1_orpd_xmm_xmm[63:0] | %ymm2_orpd_xmm_xmm[63:0])))[127:0]

Final state
%xmm9: ((%ymm9_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[255:128])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[255:192] | %ymm2_vorpd_ymm_ymm_ymm[255:192]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[191:128] | %ymm2_vorpd_ymm_ymm_ymm[191:128])))[127:0]

=====================================
-------------------------------------
Getting base circuit for callq .move_128_256_xmm8_xmm9_ymm1

Final state:
%rax/%rax: %rax_vorpd_ymm_ymm_ymm
%rdx/%rdx: %rdx_vorpd_ymm_ymm_ymm

%xmm0: %ymm0_vorpd_ymm_ymm_ymm[127:0]
%xmm1: (((%ymm9_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[255:128])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[255:192] | %ymm2_vorpd_ymm_ymm_ymm[255:192]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[191:128] | %ymm2_vorpd_ymm_ymm_ymm[191:128])))[127:0][127:0] ∘ ((%ymm8_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[127:0])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[127:64] | %ymm2_vorpd_ymm_ymm_ymm[127:64]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[63:0] | %ymm2_vorpd_ymm_ymm_ymm[63:0])))[127:0][127:0])[127:0]

-------------------------------------
=====================================
Computing circuit for vorpd %ymm3, %ymm14, %ymm1

.target:
callq .move_256_128_ymm3_xmm8_xmm9
por %xmm2, %xmm8
callq .move_256_128_ymm2_xmm10_xmm11
orpd %xmm11, %xmm9
callq .move_128_256_xmm8_xmm9_ymm1
retq 

Initial state:
%ymm1: %ymm1_vandnpd_ymm_ymm_ymm

State for specgen instruction: vorpd %ymm3, %ymm2, %ymm1:
%ymm1: ((%ymm9_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[255:128])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[255:192] | %ymm2_vorpd_ymm_ymm_ymm[255:192]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[191:128] | %ymm2_vorpd_ymm_ymm_ymm[191:128])))[127:0][127:0] ∘ ((%ymm8_vorpd_ymm_ymm_ymm[255:128] ∘ %ymm3_vorpd_ymm_ymm_ymm[127:0])[255:128] ∘ ((%ymm3_vorpd_ymm_ymm_ymm[127:64] | %ymm2_vorpd_ymm_ymm_ymm[127:64]) ∘ (%ymm3_vorpd_ymm_ymm_ymm[63:0] | %ymm2_vorpd_ymm_ymm_ymm[63:0])))[127:0][127:0]

Final state
%ymm1: (%ymm2_vandnpd_ymm_ymm_ymm[255:192] ⊕ (%ymm2_vandnpd_ymm_ymm_ymm[255:192] | %ymm3_vandnpd_ymm_ymm_ymm[255:192]) | 0x0₆₄) ∘ (%ymm2_vandnpd_ymm_ymm_ymm[191:128] ⊕ (%ymm2_vandnpd_ymm_ymm_ymm[191:128] | %ymm3_vandnpd_ymm_ymm_ymm[191:128]) | 0x0₆₄) ∘ ((%ymm2_vandnpd_ymm_ymm_ymm[127:64] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[127:64] | %ymm2_vandnpd_ymm_ymm_ymm[127:64])) ∘ (%ymm2_vandnpd_ymm_ymm_ymm[63:0] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[63:0] | %ymm2_vandnpd_ymm_ymm_ymm[63:0])))

=====================================
=====================================
Computing circuit for vandnpd %ymm14, %ymm4, %ymm1

.target:
callq .move_256_128_ymm3_xmm12_xmm13
pandn %xmm3, %xmm2
callq .move_256_128_ymm2_xmm10_xmm11
vmovdqa %xmm10, %xmm14
vandnpd %xmm13, %xmm11, %xmm11
callq .move_128_256_xmm10_xmm11_ymm3
vorpd %ymm3, %ymm14, %ymm1
retq 

Initial state:
%ymm1: %ymm1_vxorps_ymm_ymm_ymm

State for specgen instruction: vandnpd %ymm3, %ymm2, %ymm1:
%ymm1: (%ymm2_vandnpd_ymm_ymm_ymm[255:192] ⊕ (%ymm2_vandnpd_ymm_ymm_ymm[255:192] | %ymm3_vandnpd_ymm_ymm_ymm[255:192]) | 0x0₆₄) ∘ (%ymm2_vandnpd_ymm_ymm_ymm[191:128] ⊕ (%ymm2_vandnpd_ymm_ymm_ymm[191:128] | %ymm3_vandnpd_ymm_ymm_ymm[191:128]) | 0x0₆₄) ∘ ((%ymm2_vandnpd_ymm_ymm_ymm[127:64] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[127:64] | %ymm2_vandnpd_ymm_ymm_ymm[127:64])) ∘ (%ymm2_vandnpd_ymm_ymm_ymm[63:0] ⊕ (%ymm3_vandnpd_ymm_ymm_ymm[63:0] | %ymm2_vandnpd_ymm_ymm_ymm[63:0])))

Final state
%ymm1: (%ymm2_vxorps_ymm_ymm_ymm[255:192] ⊕ %ymm3_vxorps_ymm_ymm_ymm[255:192] ⊕ (%ymm2_vxorps_ymm_ymm_ymm[255:192] | %ymm2_vxorps_ymm_ymm_ymm[255:192] ⊕ %ymm3_vxorps_ymm_ymm_ymm[255:192]) ⊕ (%ymm2_vxorps_ymm_ymm_ymm[255:192] ⊕ %ymm3_vxorps_ymm_ymm_ymm[255:192] ⊕ (%ymm2_vxorps_ymm_ymm_ymm[255:192] | %ymm2_vxorps_ymm_ymm_ymm[255:192] ⊕ %ymm3_vxorps_ymm_ymm_ymm[255:192]) | (%ymm3_vxorps_ymm_ymm_ymm[255:192] | %ymm2_vxorps_ymm_ymm_ymm[255:192])) | 0x0₆₄) ∘ (%ymm2_vxorps_ymm_ymm_ymm[191:128] ⊕ %ymm3_vxorps_ymm_ymm_ymm[191:128] ⊕ (%ymm2_vxorps_ymm_ymm_ymm[191:128] | %ymm2_vxorps_ymm_ymm_ymm[191:128] ⊕ %ymm3_vxorps_ymm_ymm_ymm[191:128]) ⊕ (%ymm2_vxorps_ymm_ymm_ymm[191:128] ⊕ %ymm3_vxorps_ymm_ymm_ymm[191:128] ⊕ (%ymm2_vxorps_ymm_ymm_ymm[191:128] | %ymm2_vxorps_ymm_ymm_ymm[191:128] ⊕ %ymm3_vxorps_ymm_ymm_ymm[191:128]) | (%ymm3_vxorps_ymm_ymm_ymm[191:128] | %ymm2_vxorps_ymm_ymm_ymm[191:128])) | 0x0₆₄) ∘ ((%ymm2_vxorps_ymm_ymm_ymm[127:64] ⊕ %ymm3_vxorps_ymm_ymm_ymm[127:64] ⊕ (%ymm2_vxorps_ymm_ymm_ymm[127:64] | %ymm2_vxorps_ymm_ymm_ymm[127:64] ⊕ %ymm3_vxorps_ymm_ymm_ymm[127:64]) ⊕ (%ymm3_vxorps_ymm_ymm_ymm[127:64] | %ymm2_vxorps_ymm_ymm_ymm[127:64] | %ymm2_vxorps_ymm_ymm_ymm[127:64] ⊕ %ymm3_vxorps_ymm_ymm_ymm[127:64] ⊕ (%ymm2_vxorps_ymm_ymm_ymm[127:64] | %ymm2_vxorps_ymm_ymm_ymm[127:64] ⊕ %ymm3_vxorps_ymm_ymm_ymm[127:64]))) ∘ (%ymm2_vxorps_ymm_ymm_ymm[63:0] ⊕ %ymm3_vxorps_ymm_ymm_ymm[63:0] ⊕ (%ymm2_vxorps_ymm_ymm_ymm[63:0] | %ymm2_vxorps_ymm_ymm_ymm[63:0] ⊕ %ymm3_vxorps_ymm_ymm_ymm[63:0]) ⊕ (%ymm3_vxorps_ymm_ymm_ymm[63:0] | %ymm2_vxorps_ymm_ymm_ymm[63:0] | %ymm2_vxorps_ymm_ymm_ymm[63:0] ⊕ %ymm3_vxorps_ymm_ymm_ymm[63:0] ⊕ (%ymm2_vxorps_ymm_ymm_ymm[63:0] | %ymm2_vxorps_ymm_ymm_ymm[63:0] ⊕ %ymm3_vxorps_ymm_ymm_ymm[63:0]))))

=====================================
=====================================
Computing circuit for vxorps %ymm3, %ymm2, %ymm1

.target:
vpor %ymm2, %ymm3, %ymm14
vandps %ymm3, %ymm2, %ymm4
vandnpd %ymm14, %ymm4, %ymm1
retq 

Initial state:
%ymm1: %ymm1

State for specgen instruction: vxorps %ymm3, %ymm2, %ymm1:
%ymm1: (%ymm2_vxorps_ymm_ymm_ymm[255:192] ⊕ %ymm3_vxorps_ymm_ymm_ymm[255:192] ⊕ (%ymm2_vxorps_ymm_ymm_ymm[255:192] | %ymm2_vxorps_ymm_ymm_ymm[255:192] ⊕ %ymm3_vxorps_ymm_ymm_ymm[255:192]) ⊕ (%ymm2_vxorps_ymm_ymm_ymm[255:192] ⊕ %ymm3_vxorps_ymm_ymm_ymm[255:192] ⊕ (%ymm2_vxorps_ymm_ymm_ymm[255:192] | %ymm2_vxorps_ymm_ymm_ymm[255:192] ⊕ %ymm3_vxorps_ymm_ymm_ymm[255:192]) | (%ymm3_vxorps_ymm_ymm_ymm[255:192] | %ymm2_vxorps_ymm_ymm_ymm[255:192])) | 0x0₆₄) ∘ (%ymm2_vxorps_ymm_ymm_ymm[191:128] ⊕ %ymm3_vxorps_ymm_ymm_ymm[191:128] ⊕ (%ymm2_vxorps_ymm_ymm_ymm[191:128] | %ymm2_vxorps_ymm_ymm_ymm[191:128] ⊕ %ymm3_vxorps_ymm_ymm_ymm[191:128]) ⊕ (%ymm2_vxorps_ymm_ymm_ymm[191:128] ⊕ %ymm3_vxorps_ymm_ymm_ymm[191:128] ⊕ (%ymm2_vxorps_ymm_ymm_ymm[191:128] | %ymm2_vxorps_ymm_ymm_ymm[191:128] ⊕ %ymm3_vxorps_ymm_ymm_ymm[191:128]) | (%ymm3_vxorps_ymm_ymm_ymm[191:128] | %ymm2_vxorps_ymm_ymm_ymm[191:128])) | 0x0₆₄) ∘ ((%ymm2_vxorps_ymm_ymm_ymm[127:64] ⊕ %ymm3_vxorps_ymm_ymm_ymm[127:64] ⊕ (%ymm2_vxorps_ymm_ymm_ymm[127:64] | %ymm2_vxorps_ymm_ymm_ymm[127:64] ⊕ %ymm3_vxorps_ymm_ymm_ymm[127:64]) ⊕ (%ymm3_vxorps_ymm_ymm_ymm[127:64] | %ymm2_vxorps_ymm_ymm_ymm[127:64] | %ymm2_vxorps_ymm_ymm_ymm[127:64] ⊕ %ymm3_vxorps_ymm_ymm_ymm[127:64] ⊕ (%ymm2_vxorps_ymm_ymm_ymm[127:64] | %ymm2_vxorps_ymm_ymm_ymm[127:64] ⊕ %ymm3_vxorps_ymm_ymm_ymm[127:64]))) ∘ (%ymm2_vxorps_ymm_ymm_ymm[63:0] ⊕ %ymm3_vxorps_ymm_ymm_ymm[63:0] ⊕ (%ymm2_vxorps_ymm_ymm_ymm[63:0] | %ymm2_vxorps_ymm_ymm_ymm[63:0] ⊕ %ymm3_vxorps_ymm_ymm_ymm[63:0]) ⊕ (%ymm3_vxorps_ymm_ymm_ymm[63:0] | %ymm2_vxorps_ymm_ymm_ymm[63:0] | %ymm2_vxorps_ymm_ymm_ymm[63:0] ⊕ %ymm3_vxorps_ymm_ymm_ymm[63:0] ⊕ (%ymm2_vxorps_ymm_ymm_ymm[63:0] | %ymm2_vxorps_ymm_ymm_ymm[63:0] ⊕ %ymm3_vxorps_ymm_ymm_ymm[63:0]))))

Final state
%ymm1: (%ymm2[255:192] ⊕ %ymm3[255:192] ⊕ (%ymm2[255:192] | %ymm2[255:192] ⊕ %ymm3[255:192]) ⊕ (%ymm2[255:192] ⊕ %ymm3[255:192] ⊕ (%ymm2[255:192] | %ymm2[255:192] ⊕ %ymm3[255:192]) | (%ymm3[255:192] | %ymm2[255:192])) | 0x0₆₄) ∘ (%ymm2[191:128] ⊕ %ymm3[191:128] ⊕ (%ymm2[191:128] | %ymm2[191:128] ⊕ %ymm3[191:128]) ⊕ (%ymm2[191:128] ⊕ %ymm3[191:128] ⊕ (%ymm2[191:128] | %ymm2[191:128] ⊕ %ymm3[191:128]) | (%ymm3[191:128] | %ymm2[191:128])) | 0x0₆₄) ∘ ((%ymm2[127:64] ⊕ %ymm3[127:64] ⊕ (%ymm2[127:64] | %ymm2[127:64] ⊕ %ymm3[127:64]) ⊕ (%ymm3[127:64] | %ymm2[127:64] | %ymm2[127:64] ⊕ %ymm3[127:64] ⊕ (%ymm2[127:64] | %ymm2[127:64] ⊕ %ymm3[127:64]))) ∘ (%ymm2[63:0] ⊕ %ymm3[63:0] ⊕ (%ymm2[63:0] | %ymm2[63:0] ⊕ %ymm3[63:0]) ⊕ (%ymm3[63:0] | %ymm2[63:0] | %ymm2[63:0] ⊕ %ymm3[63:0] ⊕ (%ymm2[63:0] | %ymm2[63:0] ⊕ %ymm3[63:0]))))

=====================================
Circuits:

%ymm1  : (%ymm2[255:192] ⊕ %ymm3[255:192] ⊕ (%ymm2[255:192] | %ymm2[255:192] ⊕ %ymm3[255:192]) ⊕ (%ymm2[255:192] ⊕ %ymm3[255:192] ⊕ (%ymm2[255:192] | %ymm2[255:192] ⊕ %ymm3[255:192]) | (%ymm3[255:192] | %ymm2[255:192])) | 0x0₆₄) ∘ (%ymm2[191:128] ⊕ %ymm3[191:128] ⊕ (%ymm2[191:128] | %ymm2[191:128] ⊕ %ymm3[191:128]) ⊕ (%ymm2[191:128] ⊕ %ymm3[191:128] ⊕ (%ymm2[191:128] | %ymm2[191:128] ⊕ %ymm3[191:128]) | (%ymm3[191:128] | %ymm2[191:128])) | 0x0₆₄) ∘ ((%ymm2[127:64] ⊕ %ymm3[127:64] ⊕ (%ymm2[127:64] | %ymm2[127:64] ⊕ %ymm3[127:64]) ⊕ (%ymm3[127:64] | %ymm2[127:64] | %ymm2[127:64] ⊕ %ymm3[127:64] ⊕ (%ymm2[127:64] | %ymm2[127:64] ⊕ %ymm3[127:64]))) ∘ (%ymm2[63:0] ⊕ %ymm3[63:0] ⊕ (%ymm2[63:0] | %ymm2[63:0] ⊕ %ymm3[63:0]) ⊕ (%ymm3[63:0] | %ymm2[63:0] | %ymm2[63:0] ⊕ %ymm3[63:0] ⊕ (%ymm2[63:0] | %ymm2[63:0] ⊕ %ymm3[63:0]))))

sigfpe  : sigfpe
sigbus  : sigbus
sigsegv : sigsegv

*/